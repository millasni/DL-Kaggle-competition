{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predicting_with_LSTM_CNN_GRU.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DsTH-Q4o76_S"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uyz7ZdY2gpzy",
        "colab_type": "text"
      },
      "source": [
        "# 1. Summary\n",
        "\n",
        "Please note that no external data was used to improve predictions, i.e. only data available in 5 files on Kaggle was used in training models.\n",
        "\n",
        "This code file contains predictions with **CNN, LSTM, GRU** by using:\n",
        "\n",
        "*   Just article titles (valid.accuracy capped at 75% in colab and at 72.6% in Kaggle) \n",
        "*   Article own titles + titles of incoming/outgoing references concatenated - accuracy about 80.8-81.1% in colab, 81.7-82.1% in kaggle\n",
        "*   Embeddings learnt on the training set vs GloVe and Word2Vec embeddings.\n",
        "\n",
        "Other models were implemented in separate files:\n",
        "\n",
        "*   **Using BERT with ktrain in keras** - accuracy 75.3% in colab, 74% in kaggle using own titles only; own titles+reference titles - 81.5% acc in colab, not used for kaggle uploads due to lower accuracy than for other implementation of BERT.\n",
        "*   **Using BERT in PyTorch** - accuracy using titles only: 76% in colab, 74.5% in kaggle; accuracy using own titles + titles of incoming/outgoing references: 83-85% in colab and 81.7-82.9% in kaggle (trained on whole training data for 3 epochs). **The best model produces 82.86% accuracy on kaggle**.\n",
        "*   **Using text mining techniques** - accuracy using own titles only with logistic regression on TF-IDF matrix - 72% in colab and 69.6% in kaggle. Using own titles + reference titles concatenated + TF-IDF: logistic regression: 82% in colab and kaggle; multi-layer perceptron with (128,256) layers: 82.6% in kaggle (**the second-best!**).\n",
        "\n",
        "It's interesting that using TF-IDF matrix of own titles + reference titles and a logistic regression or multilayer perceptron allows reaching higher accuracy than with most specialized NLP models except BERT and one instance of CNN. It might be due to the fact that our training data is small (12k)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBP76s36DZhs",
        "colab_type": "text"
      },
      "source": [
        "# 2. Data prep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvIRP07PgeiF",
        "colab_type": "text"
      },
      "source": [
        "## Reading in data and installing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75D3A19MjlY2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "3b4198b5-e0d0-436b-bb68-24b8ed15307a"
      },
      "source": [
        "# download the repo to get access to data\n",
        "!rm -rf DL-Kaggle-competition/\n",
        "!git clone https://github.com/millasni/DL-Kaggle-competition/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DL-Kaggle-competition'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 25 (delta 4), reused 23 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (25/25), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmaaxB6XmnrN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c6ffecc-7605-4252-a80b-e8218f5483f3"
      },
      "source": [
        "!pip install -q torch skorch torchvision torchtext\n",
        "tf\n",
        "!pip install keras\n",
        "!pip install h5py\n",
        "!pip3 install ktrain\n",
        "!pip install NLTK\n",
        "# !pip install bert-tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |██▉                             | 10kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 20kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 30kB 3.6MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 40kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 51kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 61kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 71kB 3.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 81kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 92kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0rc2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0rc0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.28.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (46.1.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.18.2)\n",
            "Collecting ktrain\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/26/b66d9a4e27ca2854ee7f2c66084f90b7bf7e27e46b7611be52f2fe9ae5dc/ktrain-0.13.2.tar.gz (25.2MB)\n",
            "\u001b[K     |████████████████████████████████| 25.2MB 183kB/s \n",
            "\u001b[?25hCollecting tensorflow==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 37kB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.22.2.post1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from ktrain) (3.2.1)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.0.3)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.2.3)\n",
            "Collecting keras_bert>=0.81.0\n",
            "  Downloading https://files.pythonhosted.org/packages/2c/0f/cdc886c1018943ea62d3209bc964413d5aa9d0eb7e493abd8545be679294/keras-bert-0.81.0.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.21.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.14.1)\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 42.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (from ktrain) (0.42.1)\n",
            "Collecting cchardet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/c5/7e1a0d7b4afd83d6f8de794fce82820ec4c5136c6d52e14000822681a842/cchardet-2.1.6-cp36-cp36m-manylinux2010_x86_64.whl (241kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 48.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.4)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.6/dist-packages (from ktrain) (1.4.0)\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from ktrain) (20.3)\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.6/dist-packages (from ktrain) (2.1.0)\n",
            "Collecting transformers>=2.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 41.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from ktrain) (5.5.0)\n",
            "Collecting syntok\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/36/5b423791cd877a21c2771a2b070194270f163f2969066923f89aa3099e2d/syntok-1.2.2.tar.gz\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.18.2)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 44.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.12.1)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.28.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (3.2.0)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 38.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (0.34.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (0.8.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0->ktrain) (0.2.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_bert>=0.81.0->ktrain) (2.3.1)\n",
            "Collecting keras-transformer>=0.30.0\n",
            "  Downloading https://files.pythonhosted.org/packages/54/0c/fede535ac576c03863c44bf2e0bf051fe21f5e10103631b6b6236ae446f3/keras-transformer-0.32.0.tar.gz\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ktrain) (2020.4.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.3->ktrain) (4.4.2)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (3.13)\n",
            "Requirement already satisfied: pillow>=4.0 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (7.0.0)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (2.11.1)\n",
            "Requirement already satisfied: tornado>=4.3 in /usr/local/lib/python3.6/dist-packages (from bokeh->ktrain) (4.5.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (0.21.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (0.16.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (19.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (4.38.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (0.3.1.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->ktrain) (2.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->ktrain) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 46.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 44.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->ktrain) (0.7)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 44.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->ktrain) (3.0.12)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.7.0->ktrain) (1.12.38)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (4.3.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (2.1.3)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (46.1.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->ktrain) (1.0.18)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.7.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0->ktrain) (2.10.0)\n",
            "Collecting keras-pos-embd>=0.10.0\n",
            "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n",
            "Collecting keras-multi-head>=0.22.0\n",
            "  Downloading https://files.pythonhosted.org/packages/40/3e/d0a64bb2ac5217928effe4507c26bbd19b86145d16a1948bc2d4f4c6338a/keras-multi-head-0.22.0.tar.gz\n",
            "Collecting keras-layer-normalization>=0.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n",
            "Collecting keras-position-wise-feed-forward>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n",
            "Collecting keras-embed-sim>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/20/735fd53f6896e2af63af47e212601c1b8a7a80d00b6126c388c9d1233892/keras-embed-sim-0.7.0.tar.gz\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.7->bokeh->ktrain) (1.1.1)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow_datasets->ktrain) (1.51.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.7.0->ktrain) (7.1.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.7.0->ktrain) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.7.0->ktrain) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.38 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.7.0->ktrain) (1.15.38)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->ktrain) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ktrain) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ktrain) (0.1.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.3.0)\n",
            "Collecting keras-self-attention==0.41.0\n",
            "  Downloading https://files.pythonhosted.org/packages/1b/1c/01599219bef7266fa43b3316e4f55bcb487734d3bafdc60ffd564f3cfe29/keras-self-attention-0.41.0.tar.gz\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.38->boto3->transformers>=2.7.0->ktrain) (0.15.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.1.0)\n",
            "Building wheels for collected packages: ktrain, keras-bert, langdetect, seqeval, syntok, gast, keras-transformer, sacremoses, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
            "  Building wheel for ktrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ktrain: filename=ktrain-0.13.2-cp36-none-any.whl size=25239774 sha256=8cd21c95c633677462b83ceea67cf9d62a6616a561b4cf239b70fbb38a88ccc2\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/fb/62/cf5424c7a9c267b78db4efacfe8b4c3a0a3f1a755f2d63e428\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.81.0-cp36-none-any.whl size=37913 sha256=173c1063ebf1de9df4898bd2db8df8f8bf99810f01ccd46ddf9dcb04a6b2b703\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/27/da/ffc2d573aa48b87440ec4f98bc7c992e3a2d899edb2d22ef9e\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993193 sha256=a9ac987a158ff54bfeb72333846be8a386344fd7219af059f4a1abd6a1a6bc9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=c033f232db7a7c2d47124130d97e888226503160753e0517dc85c833d0c30c5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "  Building wheel for syntok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for syntok: filename=syntok-1.2.2-cp36-none-any.whl size=20724 sha256=50a2724be9d469cb874770ab9b5cddca697706d578bf2249e63749e554363ef6\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/b0/d2/ffdbbc1a16cb37e580fb7b3a6fbaaf09c7f7c163981db385b3\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=6401c355f40f0860094e4d665c4065e75c9ad777888580d00d464e51ba4d47d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.32.0-cp36-none-any.whl size=13266 sha256=6163b96baa8b6b9ee8a407383d8e1d474c4b1befaef5322a8ad4db0371bf4f6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f0/ce/82fa5d024d5ef8e263f26a50dcee23820efe245680ce9c922a\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=d8b013d0ae69daf6cc54b72906e24d020119908a51b3d6c9cdfc20a16b986736\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7554 sha256=8bc8dfd7a43e6beb6652f662f48c846707acfe8f7a7ad3b6a6f09ec5a9befda0\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.22.0-cp36-none-any.whl size=15371 sha256=78b46f8d98919680c0a004939e511dc2e167f503f4e79b4ff6e1a1eac5861edd\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/df/3f/81b36f41b66e6a9cd69224c70a737de2bb6b2f7feb3272c25e\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=412ddab6e28ab89ae6cf4c820853f4818d7555892f71af4628973167f8ecd315\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5623 sha256=40364f227a01df2b7d1ecac07a87d654371cd6caf506b39653309031584679ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.7.0-cp36-none-any.whl size=4676 sha256=ec1e43057df46f866b736fcccb543562fcebd19911ba898c66d8d53ca5a28ddb\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/bc/b1/b0c45cee4ca2e6c86586b0218ffafe7f0703c6d07fdf049866\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.41.0-cp36-none-any.whl size=17288 sha256=7cf641a88f949daa7048b9f878339a4cb4563ca51c119d3c1fb475373d3e36e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/dc/17/84258b27a04cd38ac91998abe148203720ca696186635db694\n",
            "Successfully built ktrain keras-bert langdetect seqeval syntok gast keras-transformer sacremoses keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
            "Installing collected packages: gast, tensorboard, tensorflow-estimator, tensorflow, keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert, langdetect, cchardet, seqeval, sentencepiece, sacremoses, tokenizers, transformers, syntok, ktrain\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.2.0\n",
            "    Uninstalling tensorboard-2.2.0:\n",
            "      Successfully uninstalled tensorboard-2.2.0\n",
            "  Found existing installation: tensorflow-estimator 2.2.0rc0\n",
            "    Uninstalling tensorflow-estimator-2.2.0rc0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0rc0\n",
            "  Found existing installation: tensorflow 2.2.0rc2\n",
            "    Uninstalling tensorflow-2.2.0rc2:\n",
            "      Successfully uninstalled tensorflow-2.2.0rc2\n",
            "Successfully installed cchardet-2.1.6 gast-0.2.2 keras-bert-0.81.0 keras-embed-sim-0.7.0 keras-layer-normalization-0.14.0 keras-multi-head-0.22.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.41.0 keras-transformer-0.32.0 ktrain-0.13.2 langdetect-1.0.8 sacremoses-0.0.41 sentencepiece-0.1.85 seqeval-0.0.12 syntok-1.2.2 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0 tokenizers-0.5.2 transformers-2.8.0\n",
            "Requirement already satisfied: NLTK in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from NLTK) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXYdZ9IagpF7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "093629e1-33bd-4a12-924c-4f6589e35894"
      },
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import skorch\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K # or from keras...?\n",
        "from tensorflow.keras.backend import concatenate\n",
        "\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Embedding, Dense, GRU, LSTM, Bidirectional,SpatialDropout1D,Concatenate\n",
        "from tensorflow.keras.layers import Conv1D,GlobalMaxPooling1D,MaxPooling1D,Dropout,Flatten,Activation\n",
        "\n",
        "# from tensorflow.python.keras.layers import Dense\n",
        "# from tensorflow.python.keras import Sequential\n",
        "\n",
        "from keras.utils.np_utils import to_categorical \n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences \n",
        "from tensorflow.keras import optimizers\n",
        "from keras.initializers import Constant\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "\n",
        "import ktrain\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXiv3Bcumuc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('DL-Kaggle-competition/train.csv') \n",
        "test = pd.read_csv('DL-Kaggle-competition/test.csv') \n",
        "text = pd.read_csv('DL-Kaggle-competition/text.csv') \n",
        "reference = pd.read_csv('DL-Kaggle-competition/reference.csv') \n",
        "reference_classes = pd.read_csv('DL-Kaggle-competition/ref_class_shares.csv') \n",
        "cross_ref = pd.read_csv('DL-Kaggle-competition/ref_in_out.csv') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TQ6A_0mbPfX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "d1d655d2-b32c-486a-a971-da0076130d80"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label\n",
              "0   0      1\n",
              "1   3      1\n",
              "2   6      1\n",
              "3   8      0\n",
              "4   9      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR-laMsksDcb",
        "colab_type": "text"
      },
      "source": [
        "## Data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPZWNyVJhuvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "b7077856-4a3b-4018-cb58-9f841a153158"
      },
      "source": [
        "# One-hot encode the classes in the train\n",
        "Y = to_categorical(train[['label']])\n",
        "print(Y.shape)\n",
        "print(Y[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12779, 5)\n",
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gjzj-tC9cjIk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "bb1bfbc8-bc4c-4a72-a0a8-d9e7a4ed7696"
      },
      "source": [
        "print(text.head())\n",
        "text.shape # we have twice as many lines in text than in train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   id                                              title\n",
            "0   0  interactive visual exploration of neighbor bas...\n",
            "1   1  autodomainmine a graphical data mining system ...\n",
            "2   2  anipqo almost non intrusive parametric query o...\n",
            "3   3  relational division four algorithms and their ...\n",
            "4   4  selection and ranking of text from highly impe...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25561, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5ZVLLiouozU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "1c9542bd-be1a-455c-8dcd-887abab8375f"
      },
      "source": [
        "train = train.join(text, how='left', on='id',  lsuffix='', rsuffix='text')\n",
        "train.head()\n",
        "train.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>idtext</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12774</th>\n",
              "      <td>25547</td>\n",
              "      <td>4</td>\n",
              "      <td>25547</td>\n",
              "      <td>scaling up from dialogue to multilogue some pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12775</th>\n",
              "      <td>25548</td>\n",
              "      <td>3</td>\n",
              "      <td>25548</td>\n",
              "      <td>a laboratory for the development and evaluatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12776</th>\n",
              "      <td>25554</td>\n",
              "      <td>2</td>\n",
              "      <td>25554</td>\n",
              "      <td>an analysis of transformational analogy genera...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12777</th>\n",
              "      <td>25555</td>\n",
              "      <td>2</td>\n",
              "      <td>25555</td>\n",
              "      <td>exploiting known taxonomies in learning overla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12778</th>\n",
              "      <td>25557</td>\n",
              "      <td>1</td>\n",
              "      <td>25557</td>\n",
              "      <td>maintaining materialized views in distributed ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  label  idtext                                              title\n",
              "12774  25547      4   25547  scaling up from dialogue to multilogue some pr...\n",
              "12775  25548      3   25548  a laboratory for the development and evaluatio...\n",
              "12776  25554      2   25554  an analysis of transformational analogy genera...\n",
              "12777  25555      2   25555  exploiting known taxonomies in learning overla...\n",
              "12778  25557      1   25557  maintaining materialized views in distributed ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6xJXgRQy2fj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "126a3544-8c7b-4ac8-d220-a0b92df1cef4"
      },
      "source": [
        "train = train[['id','label','title']]\n",
        "train.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>interactive visual exploration of neighbor bas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>relational division four algorithms and their ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>simplifying xml schema effortless handling of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>funbase a function based information managemen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>inverted matrix efficient discovery of frequen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label                                              title\n",
              "0   0      1  interactive visual exploration of neighbor bas...\n",
              "1   3      1  relational division four algorithms and their ...\n",
              "2   6      1  simplifying xml schema effortless handling of ...\n",
              "3   8      0  funbase a function based information managemen...\n",
              "4   9      0  inverted matrix efficient discovery of frequen..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ps8pKPnI9_F7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "outputId": "ed0aab3f-9a0b-4a19-d10d-6f4e05883b27"
      },
      "source": [
        "train2 = train.join(reference_classes.set_index('id'), how='left', on='id',  lsuffix='', rsuffix='ref')\n",
        "train2.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>title</th>\n",
              "      <th>sh_to.0</th>\n",
              "      <th>sh_to.1</th>\n",
              "      <th>sh_to.2</th>\n",
              "      <th>sh_to.3</th>\n",
              "      <th>sh_to.4</th>\n",
              "      <th>sh_from.0</th>\n",
              "      <th>sh_from.1</th>\n",
              "      <th>sh_from.2</th>\n",
              "      <th>sh_from.3</th>\n",
              "      <th>sh_from.4</th>\n",
              "      <th>deg_in_norm</th>\n",
              "      <th>deg_out_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>interactive visual exploration of neighbor bas...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.033333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>relational division four algorithms and their ...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>simplifying xml schema effortless handling of ...</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.233333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>funbase a function based information managemen...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>inverted matrix efficient discovery of frequen...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.133333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label  ... deg_in_norm  deg_out_norm\n",
              "0   0      1  ...         0.0      0.033333\n",
              "1   3      1  ...         0.0      0.066667\n",
              "2   6      1  ...         0.0      0.233333\n",
              "3   8      0  ...         0.0      0.000000\n",
              "4   9      0  ...         0.0      0.133333\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yplnzqjF-Wja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "3561073c-380c-4698-c9ce-1882fa0ca437"
      },
      "source": [
        "train2.columns\n",
        "train2 = train2.iloc[:,3:]\n",
        "train2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sh_to.0</th>\n",
              "      <th>sh_to.1</th>\n",
              "      <th>sh_to.2</th>\n",
              "      <th>sh_to.3</th>\n",
              "      <th>sh_to.4</th>\n",
              "      <th>sh_from.0</th>\n",
              "      <th>sh_from.1</th>\n",
              "      <th>sh_from.2</th>\n",
              "      <th>sh_from.3</th>\n",
              "      <th>sh_from.4</th>\n",
              "      <th>deg_in_norm</th>\n",
              "      <th>deg_out_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.033333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.233333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.133333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sh_to.0   sh_to.1  sh_to.2  ...  sh_from.4  deg_in_norm  deg_out_norm\n",
              "0  1.000000  0.000000      0.0  ...        0.0          0.0      0.033333\n",
              "1  0.000000  1.000000      0.0  ...        0.0          0.0      0.066667\n",
              "2  0.142857  0.857143      0.0  ...        0.0          0.0      0.233333\n",
              "3  0.000000  0.000000      0.0  ...        0.0          0.0      0.000000\n",
              "4  0.000000  1.000000      0.0  ...        0.0          0.0      0.133333\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLRaDZ3ExQv-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "33d40bbf-170f-4df5-b2e8-508dd6a7b720"
      },
      "source": [
        "test = test.join(text, how='left', on='id',  lsuffix='', rsuffix='text')\n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>idtext</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>autodomainmine a graphical data mining system ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>anipqo almost non intrusive parametric query o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>selection and ranking of text from highly impe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>conditional random fields for multi agent rein...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>multi dimensional description logics</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  idtext                                              title\n",
              "0   1       1  autodomainmine a graphical data mining system ...\n",
              "1   2       2  anipqo almost non intrusive parametric query o...\n",
              "2   4       4  selection and ranking of text from highly impe...\n",
              "3   5       5  conditional random fields for multi agent rein...\n",
              "4   7       7               multi dimensional description logics"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fE-MQ_oozDq1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "92790f48-55ad-4c9d-9596-f43d3487dcab"
      },
      "source": [
        "test = test[['id','title']]\n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>autodomainmine a graphical data mining system ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>anipqo almost non intrusive parametric query o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>selection and ranking of text from highly impe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>conditional random fields for multi agent rein...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>multi dimensional description logics</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                              title\n",
              "0   1  autodomainmine a graphical data mining system ...\n",
              "1   2  anipqo almost non intrusive parametric query o...\n",
              "2   4  selection and ranking of text from highly impe...\n",
              "3   5  conditional random fields for multi agent rein...\n",
              "4   7               multi dimensional description logics"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK6_K8xVAmXd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "7bd9fa16-9733-4399-d336-7edf2c37c341"
      },
      "source": [
        "test2 = test.join(reference_classes.set_index('id'), how='left', on='id',  lsuffix='', rsuffix='ref')\n",
        "test2.head()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>sh_to.0</th>\n",
              "      <th>sh_to.1</th>\n",
              "      <th>sh_to.2</th>\n",
              "      <th>sh_to.3</th>\n",
              "      <th>sh_to.4</th>\n",
              "      <th>sh_from.0</th>\n",
              "      <th>sh_from.1</th>\n",
              "      <th>sh_from.2</th>\n",
              "      <th>sh_from.3</th>\n",
              "      <th>sh_from.4</th>\n",
              "      <th>deg_in_norm</th>\n",
              "      <th>deg_out_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>autodomainmine a graphical data mining system ...</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>anipqo almost non intrusive parametric query o...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005682</td>\n",
              "      <td>0.033333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>selection and ranking of text from highly impe...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>conditional random fields for multi agent rein...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>multi dimensional description logics</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ... deg_out_norm\n",
              "0   1  ...     0.066667\n",
              "1   2  ...     0.033333\n",
              "2   4  ...     0.000000\n",
              "3   5  ...     0.000000\n",
              "4   7  ...     0.000000\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTW7PAmgA4_H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "57c387e1-6b9c-426f-cb49-4090ef20769b"
      },
      "source": [
        "test2.columns\n",
        "test2 = test2.iloc[:,2:]\n",
        "test2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sh_to.0</th>\n",
              "      <th>sh_to.1</th>\n",
              "      <th>sh_to.2</th>\n",
              "      <th>sh_to.3</th>\n",
              "      <th>sh_to.4</th>\n",
              "      <th>sh_from.0</th>\n",
              "      <th>sh_from.1</th>\n",
              "      <th>sh_from.2</th>\n",
              "      <th>sh_from.3</th>\n",
              "      <th>sh_from.4</th>\n",
              "      <th>deg_in_norm</th>\n",
              "      <th>deg_out_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005682</td>\n",
              "      <td>0.033333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sh_to.0  sh_to.1  sh_to.2  ...  sh_from.4  deg_in_norm  deg_out_norm\n",
              "0      0.5      0.5      0.0  ...        0.0     0.000000      0.066667\n",
              "1      0.0      1.0      0.0  ...        0.0     0.005682      0.033333\n",
              "2      0.0      0.0      0.0  ...        0.0     0.000000      0.000000\n",
              "3      0.0      0.0      0.0  ...        0.0     0.000000      0.000000\n",
              "4      0.0      0.0      0.0  ...        0.0     0.000000      0.000000\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srmaulRH8VOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenize train data on the whole TEXT (train+test) to see the max sent_len - - for exploration only\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text.title)\n",
        "t = tokenizer.texts_to_sequences(text.title)\n",
        "print(t[:10])\n",
        "print(len(max(t, key=len)))\n",
        "sent_len = []\n",
        "for i in t:\n",
        "  sent_len.append(len(i))\n",
        "\n",
        "plt.hist(sent_len,bins=28)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDcaxRln0Wni",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "f8074f5e-ce0d-4420-e62c-84b74a52660b"
      },
      "source": [
        "# tokenize train data (on the whole set of labeled data)\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train.title)\n",
        "X = tokenizer.texts_to_sequences(train.title)\n",
        "print(X[:10])\n",
        "X = pad_sequences(X, maxlen=20)\n",
        "X[:10]\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "print(word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[132, 247, 402, 2, 834, 9, 126, 5, 8, 161], [44, 2099, 1325, 61, 4, 415, 58], [1865, 63, 213, 4596, 478, 2, 1866, 1444, 622], [4597, 3, 262, 9, 18, 51, 15], [1038, 531, 30, 214, 2, 429, 1228, 5, 45, 545, 5, 6, 122, 2, 132, 32], [248, 673, 2, 1686, 5, 1687, 180], [4598, 3, 127, 65, 389, 14, 7, 1229, 379, 27], [765, 6, 4599, 1688, 515, 6, 238, 2, 22, 2366, 5, 16, 928], [4600, 1230, 3, 4601, 1231, 304, 1, 6, 16, 10, 2367, 50], [130, 1039, 99, 1, 6, 72, 2, 75, 1689]]\n",
            "Found 9321 unique tokens.\n",
            "{'for': 1, 'of': 2, 'a': 3, 'and': 4, 'in': 5, 'the': 6, 'to': 7, 'data': 8, 'based': 9, 'on': 10, 'an': 11, 'with': 12, 'using': 13, 'learning': 14, 'system': 15, 'web': 16, 'database': 17, 'information': 18, 'systems': 19, 'query': 20, 'from': 21, 'search': 22, 'model': 23, 'retrieval': 24, 'analysis': 25, 'approach': 26, 'language': 27, 'software': 28, 'databases': 29, 'efficient': 30, 'semantic': 31, 'mining': 32, 'by': 33, 'models': 34, 'text': 35, 'programming': 36, 'knowledge': 37, 'distributed': 38, 'time': 39, 'processing': 40, 'design': 41, 'queries': 42, 'object': 43, 'relational': 44, 'large': 45, 'evaluation': 46, 'multi': 47, 'oriented': 48, 'automatic': 49, 'computer': 50, 'management': 51, 'clustering': 52, 'algorithm': 53, 'dynamic': 54, 'machine': 55, 'logic': 56, 'classification': 57, 'performance': 58, 'translation': 59, 'networks': 60, 'algorithms': 61, 'document': 62, 'xml': 63, 'framework': 64, 'structure': 65, 'optimization': 66, 'detection': 67, 'engineering': 68, 'modeling': 69, 'study': 70, 'parallel': 71, 'method': 72, 'programs': 73, 'parsing': 74, 'temporal': 75, 'reasoning': 76, 'generation': 77, 'applications': 78, 'as': 79, 'multiple': 80, 'user': 81, 'high': 82, 'probabilistic': 83, 'control': 84, 'program': 85, 'towards': 86, 'extraction': 87, 'case': 88, 'new': 89, 'support': 90, 'statistical': 91, 'science': 92, 'tree': 93, 'application': 94, 'selection': 95, 'word': 96, 'planning': 97, 'network': 98, 'semantics': 99, 'development': 100, 'through': 101, 'environment': 102, 'via': 103, 'course': 104, 'natural': 105, 'adaptive': 106, 'fast': 107, 'teaching': 108, 'methods': 109, 'rules': 110, 'problem': 111, 'memory': 112, 'indexing': 113, 'graph': 114, 'techniques': 115, 'real': 116, 'process': 117, 'theory': 118, 'online': 119, 'ranking': 120, 'similarity': 121, 'context': 122, 'tool': 123, 'structured': 124, 'access': 125, 'patterns': 126, 'feature': 127, 'architecture': 128, 'hierarchical': 129, 'non': 130, 'constraints': 131, 'interactive': 132, 'computing': 133, 'implementation': 134, 'languages': 135, 'integration': 136, 'domain': 137, 'inference': 138, 'into': 139, 'improving': 140, 'order': 141, 'representation': 142, 'level': 143, 'relevance': 144, 'incremental': 145, 'structures': 146, 'type': 147, 'linear': 148, 'documents': 149, 'first': 150, 'over': 151, 'scale': 152, 'active': 153, 'integrating': 154, 'rule': 155, 'estimation': 156, 'code': 157, 'recognition': 158, 'constraint': 159, 'complex': 160, 'streams': 161, 'optimal': 162, 'base': 163, 'feedback': 164, 'trees': 165, 'content': 166, 'join': 167, 'social': 168, 'its': 169, 'effective': 170, 'objects': 171, 'supervised': 172, 'problems': 173, 'decision': 174, 'semi': 175, 'between': 176, 'matching': 177, 'at': 178, 'space': 179, 'graphs': 180, 'driven': 181, 'local': 182, 'collaborative': 183, 'resolution': 184, 'answering': 185, 'topic': 186, 'is': 187, 'automated': 188, 'relations': 189, 'state': 190, 'computation': 191, 'image': 192, 'spatial': 193, 'generalized': 194, 'speech': 195, 'combining': 196, 'filtering': 197, 'grammar': 198, 'use': 199, 'exploiting': 200, 'two': 201, 'dimensional': 202, 'syntactic': 203, 'supporting': 204, 'bayesian': 205, 'complexity': 206, 'services': 207, 'dependency': 208, 'comparison': 209, 'grammars': 210, 'quality': 211, 'acquisition': 212, 'schema': 213, 'discovery': 214, 'test': 215, 'flow': 216, 'mobile': 217, 'understanding': 218, 'java': 219, 'robust': 220, 'peer': 221, 'pattern': 222, 'prediction': 223, 'strategies': 224, 'integrated': 225, 'class': 226, 'solving': 227, 'testing': 228, 'random': 229, 'querying': 230, 'transaction': 231, 'project': 232, 'chinese': 233, 'abstract': 234, 'views': 235, 'report': 236, 'results': 237, 'value': 238, 'engine': 239, 'finding': 240, 'functional': 241, 'scalable': 242, 'cross': 243, 'research': 244, 'disambiguation': 245, 'unsupervised': 246, 'visual': 247, 'computational': 248, 'experience': 249, 'term': 250, 'view': 251, 'self': 252, 'markov': 253, 'heterogeneous': 254, 'concept': 255, 'summarization': 256, 'japanese': 257, 'formal': 258, 'building': 259, 'types': 260, 'kernel': 261, 'function': 262, 'generating': 263, 'question': 264, 'verification': 265, 'general': 266, 'execution': 267, 'concurrent': 268, 'simple': 269, 'specification': 270, 'event': 271, 'approximate': 272, 'features': 273, 'bases': 274, 'practical': 275, 'processes': 276, 'extracting': 277, 'agent': 278, 'extended': 279, 'concurrency': 280, 'requirements': 281, 'lexical': 282, 'evaluating': 283, 'index': 284, 'construction': 285, 'partial': 286, 'regression': 287, 'corpora': 288, 'linguistic': 289, 'checking': 290, 'students': 291, 'interpretation': 292, 'conceptual': 293, 'environments': 294, 'cost': 295, 'hybrid': 296, 'association': 297, 'domains': 298, 'about': 299, 'sets': 300, 'sql': 301, 'description': 302, 'games': 303, 'interface': 304, 'global': 305, 'service': 306, 'functions': 307, 'machines': 308, 'scheduling': 309, 'corpus': 310, 'behavior': 311, 'open': 312, 'sense': 313, 'concepts': 314, 'file': 315, 'how': 316, 'path': 317, 'empirical': 318, 'introductory': 319, 'line': 320, 'role': 321, 'training': 322, 'allocation': 323, 'free': 324, 'english': 325, 'detecting': 326, 'multimedia': 327, 'storage': 328, 'experiments': 329, 'stream': 330, 'set': 331, 'interaction': 332, 'human': 333, 'server': 334, 'segmentation': 335, 'evolution': 336, 'searching': 337, 'abstraction': 338, 'stochastic': 339, 'independent': 340, 'ontology': 341, 'vector': 342, 'technique': 343, 'scheme': 344, 'consistency': 345, 'without': 346, 'entity': 347, 'world': 348, 'intelligent': 349, 'continuous': 350, 'projects': 351, 'identification': 352, 'k': 353, 'tools': 354, 'maintenance': 355, 'optimizing': 356, 'visualization': 357, 'structural': 358, 'mapping': 359, 'experimental': 360, 'sources': 361, 'curriculum': 362, 'source': 363, 'collection': 364, 'making': 365, 'security': 366, 'sampling': 367, 'monitoring': 368, 'task': 369, 'predicting': 370, 'agents': 371, 'categorization': 372, 'improve': 373, 'dbms': 374, 'undergraduate': 375, 'discovering': 376, 'logical': 377, 'conditional': 378, 'spoken': 379, 'strategy': 380, 'latent': 381, 'privacy': 382, 'sensitive': 383, 'aware': 384, 'flexible': 385, 'discourse': 386, 'dependencies': 387, 'calculus': 388, 'parser': 389, 'that': 390, 'caching': 391, 'form': 392, 'expert': 393, 'sequence': 394, 'tracking': 395, 'dialogue': 396, 'workshop': 397, 'heuristic': 398, 'reinforcement': 399, 'improved': 400, 'alignment': 401, 'exploration': 402, 'are': 403, 'unified': 404, 'robot': 405, 'sensor': 406, 'compiler': 407, 'decomposition': 408, 'expansion': 409, 'recursive': 410, 'aggregation': 411, 'representations': 412, 'preserving': 413, 'unification': 414, 'their': 415, 'specifications': 416, 'distance': 417, 'constrained': 418, 'what': 419, 'top': 420, 'resource': 421, 'one': 422, 'relationship': 423, 'some': 424, 'texts': 425, 'cs': 426, 'browsing': 427, 'education': 428, 'frequent': 429, 'classifiers': 430, 'transformation': 431, 'sequential': 432, 'link': 433, 'error': 434, 'transfer': 435, 'induction': 436, 'static': 437, 'effects': 438, 'measures': 439, 'more': 440, 'transactions': 441, 'directed': 442, 'weighted': 443, 'component': 444, 'recovery': 445, 'bilingual': 446, 'community': 447, 'annotation': 448, 'estimating': 449, 'joins': 450, 'experiences': 451, 'interfaces': 452, 'series': 453, 'toward': 454, 'action': 455, 'or': 456, 'deductive': 457, 'users': 458, 'tagging': 459, 'spaces': 460, 'pages': 461, 'communication': 462, 'video': 463, 'co': 464, 'game': 465, 'descriptions': 466, 'specific': 467, 'extending': 468, 'plans': 469, 'up': 470, 'courses': 471, 'propagation': 472, 'approximation': 473, 'intelligence': 474, 'mechanism': 475, 'product': 476, 'under': 477, 'handling': 478, 'methodology': 479, 'approaches': 480, 'it': 481, 'graphical': 482, 'sharing': 483, 'maximum': 484, 'belief': 485, 'analyzing': 486, 'page': 487, 'virtual': 488, 'incorporating': 489, 'architectures': 490, 'collections': 491, 'c': 492, 'hashing': 493, 'exploring': 494, 'labeling': 495, 'organization': 496, 'lexicon': 497, 'rank': 498, 'modelling': 499, 'perspective': 500, 'update': 501, 'internet': 502, 'very': 503, 'relation': 504, 'dictionary': 505, 'cluster': 506, 'issues': 507, 'technology': 508, 'neural': 509, 'cache': 510, 'digital': 511, 'operations': 512, 'metric': 513, 'identifying': 514, 'measuring': 515, 'reduction': 516, 'finite': 517, 'shared': 518, 'logics': 519, 'boolean': 520, 'pruning': 521, 'hidden': 522, 'phrase': 523, 'algebra': 524, 'not': 525, 'power': 526, 'plan': 527, 'ad': 528, 'iterative': 529, 'managing': 530, 'matrix': 531, 'discriminative': 532, 'cooperative': 533, 'news': 534, 'ir': 535, 'words': 536, 'debugging': 537, 'impact': 538, 'qualitative': 539, 'efficiency': 540, 'laboratory': 541, 'kernels': 542, 'incomplete': 543, 'group': 544, 'datasets': 545, 'do': 546, 'comparative': 547, 'n': 548, 'effectiveness': 549, 'updates': 550, 'automatically': 551, 'modular': 552, 'prolog': 553, 'dependence': 554, 'properties': 555, 'cs1': 556, 'production': 557, 'string': 558, 'b': 559, 'diagnosis': 560, 'extensible': 561, 'vs': 562, 'range': 563, 'uncertainty': 564, 'student': 565, 'advanced': 566, 'sentence': 567, 'generic': 568, 'novel': 569, 'business': 570, 'assessment': 571, 'mixture': 572, 'theoretic': 573, 'classes': 574, 'boosting': 575, 'compression': 576, 'auctions': 577, 'syntax': 578, 'fault': 579, 'olap': 580, 'named': 581, 'representing': 582, 'distribution': 583, 'probability': 584, 'components': 585, 'tasks': 586, 'example': 587, 'good': 588, 'schemes': 589, 'low': 590, 'implementing': 591, 'operating': 592, 'partitioning': 593, 'higher': 594, 'integrity': 595, 'artificial': 596, 'scientific': 597, 'beyond': 598, 'personalized': 599, 'protocols': 600, 'utility': 601, 'processor': 602, 'engines': 603, 'history': 604, 'refinement': 605, 'goal': 606, 'actions': 607, 'common': 608, 'examples': 609, 'indexes': 610, 'reuse': 611, 'compilation': 612, 'ordering': 613, 'hierarchies': 614, 'principles': 615, 'better': 616, 'preferences': 617, 'multidimensional': 618, 'locking': 619, 'satisfaction': 620, 'comparing': 621, 'expressions': 622, 'binary': 623, 'applying': 624, 'sentences': 625, 'implicit': 626, 'practice': 627, 'hash': 628, 'introducing': 629, 'different': 630, 'simulation': 631, 'policies': 632, 'uncertain': 633, 'wide': 634, 'attribute': 635, 'composition': 636, 'meta': 637, 'assignment': 638, 'coordination': 639, 'relationships': 640, 'e': 641, 'keyword': 642, 'resources': 643, 'when': 644, 'transformations': 645, 'terms': 646, 'robots': 647, 'buffer': 648, 'why': 649, 'protocol': 650, 'tag': 651, 'typed': 652, 'entropy': 653, 'extension': 654, 'schemas': 655, 'designing': 656, 'aggregate': 657, 'causal': 658, 'reference': 659, 'events': 660, 'physical': 661, 'best': 662, 'log': 663, 'sat': 664, 'you': 665, 'proving': 666, 'change': 667, 'answers': 668, 'autonomous': 669, 'multilingual': 670, 'solution': 671, 'complete': 672, 'aspects': 673, 'merging': 674, 'site': 675, 'fuzzy': 676, 'disk': 677, 'instance': 678, 'sparse': 679, 'record': 680, 'relevant': 681, 'morphological': 682, 'explanation': 683, 'nested': 684, 'main': 685, 'diagrams': 686, 'files': 687, 'field': 688, 'images': 689, 'margin': 690, 'bounded': 691, 'propositional': 692, 'highly': 693, 'classifier': 694, 'nearest': 695, 'theorem': 696, 'guided': 697, 'single': 698, 'small': 699, 'sequences': 700, 'presence': 701, 'variable': 702, 'interactions': 703, 'versus': 704, 'moving': 705, 'evidence': 706, 'challenges': 707, 'expression': 708, 'sites': 709, 'prototype': 710, 'noun': 711, 'generalization': 712, 'can': 713, 'correlation': 714, 'future': 715, 'declarative': 716, 'efficiently': 717, 'proof': 718, 'predicate': 719, 'direct': 720, 'preference': 721, 'usage': 722, 'secure': 723, 'graphics': 724, 'full': 725, 'map': 726, 'distributions': 727, 'parallelism': 728, 'embedded': 729, 'media': 730, 'gaussian': 731, 'xquery': 732, 'three': 733, 'mt': 734, 'criteria': 735, 'measure': 736, 'modules': 737, 'vision': 738, 'clusters': 739, 'changes': 740, 'modal': 741, 'key': 742, 'basis': 743, 'dependent': 744, 'client': 745, 'size': 746, 'precision': 747, 'adaptation': 748, 'aspect': 749, 'multimodal': 750, 'tutorial': 751, 'weighting': 752, 'accurate': 753, 'paradigm': 754, 'activity': 755, 'part': 756, 'generative': 757, 'parametric': 758, 'subspace': 759, 'metrics': 760, 'medical': 761, 'recommendation': 762, 'universal': 763, 'accuracy': 764, 'assessing': 765, 'inferring': 766, 'garbage': 767, 'music': 768, 'manipulation': 769, 'limited': 770, 'uml': 771, 'writing': 772, 'experiment': 773, 'personal': 774, 'load': 775, 'materialized': 776, 'motion': 777, 'compressed': 778, 'algebraic': 779, 'quantitative': 780, 'expressive': 781, 'architectural': 782, 'preliminary': 783, 'grid': 784, 'predictive': 785, 'replicated': 786, 'point': 787, 'specifying': 788, 'bridging': 789, 'heuristics': 790, 'developing': 791, 'attributes': 792, 'fields': 793, 'hoc': 794, 'tables': 795, 'lessons': 796, 'entities': 797, 'constructing': 798, 'errors': 799, 'electronic': 800, 'proximity': 801, 'wireless': 802, 'answer': 803, 'replication': 804, 'classifying': 805, 'inheritance': 806, 'workflow': 807, 'region': 808, 'safe': 809, 'automata': 810, 'investigation': 811, 'overview': 812, 'ai': 813, 'reliable': 814, 'redundancy': 815, 'correctness': 816, 'instruction': 817, 'streaming': 818, 'revision': 819, 'scaling': 820, 'systematic': 821, 're': 822, 'polynomial': 823, 'implications': 824, 'visualizing': 825, 'discriminant': 826, 'international': 827, 'rdf': 828, 'default': 829, 'precise': 830, 'synthesis': 831, 'version': 832, 'ontologies': 833, 'neighbor': 834, 'recommendations': 835, 'summaries': 836, 'dimensionality': 837, 'optimizations': 838, 'genetic': 839, 'introduction': 840, 'help': 841, 'tolerant': 842, 'cognitive': 843, 'down': 844, 'spectral': 845, 'opinion': 846, 'enterprise': 847, 'policy': 848, 'effect': 849, 'bound': 850, 'interprocedural': 851, 'dynamically': 852, 'bounds': 853, 'symbolic': 854, 'inductive': 855, 'combinatorial': 856, 'hardware': 857, 'validation': 858, 'solutions': 859, 'classroom': 860, 'step': 861, 'fine': 862, 'location': 863, 'equivalence': 864, 'long': 865, 'sentiment': 866, 'variables': 867, 'intensive': 868, 'deterministic': 869, 'duplicate': 870, 'spatio': 871, 'output': 872, 'definition': 873, 'procedures': 874, 'factorization': 875, 'phase': 876, 'joint': 877, 'uniform': 878, 'result': 879, 'values': 880, 'external': 881, 'theoretical': 882, 'university': 883, 'max': 884, 'means': 885, 'alternative': 886, 'profiling': 887, 'platform': 888, 'maintaining': 889, 'partially': 890, 'tractable': 891, 'historical': 892, 'enhanced': 893, 'coverage': 894, 'early': 895, 'taxonomy': 896, 'selectivity': 897, 'transactional': 898, 'library': 899, 'pseudo': 900, 'trust': 901, 'categories': 902, 'evolving': 903, 'progressive': 904, 'extensions': 905, 'message': 906, 'core': 907, 'reverse': 908, 'simultaneous': 909, 'enhancing': 910, 'p2p': 911, 'anaphora': 912, 'near': 913, 'gap': 914, 'lazy': 915, 'density': 916, 'loop': 917, 'like': 918, 'commerce': 919, 'progress': 920, 'optimized': 921, 'across': 922, 'demonstration': 923, 'mechanisms': 924, 'optimizer': 925, 'revisited': 926, 'commitment': 927, 'logs': 928, 'geometric': 929, 'indices': 930, 'arabic': 931, 'topics': 932, 'array': 933, 'demand': 934, 'satisfiability': 935, 'school': 936, 'reordering': 937, 'table': 938, 'pre': 939, 'composite': 940, 'textual': 941, 'hypertext': 942, 'configuration': 943, 'parts': 944, 'reliability': 945, 'r': 946, 'within': 947, 'automating': 948, 'projection': 949, 'polymorphic': 950, 'interoperability': 951, 'routing': 952, 'way': 953, 'compact': 954, 'technologies': 955, 'minimal': 956, 'chart': 957, 'score': 958, 'explicit': 959, 'contextual': 960, 'critical': 961, 'synchronous': 962, 'xpath': 963, 'gene': 964, 'associative': 965, 'definitions': 966, 'goals': 967, 'dual': 968, 'db2': 969, 'communities': 970, 'statistics': 971, 'capturing': 972, 'perception': 973, 'valued': 974, 'influence': 975, 'related': 976, 'infrastructure': 977, 'dirichlet': 978, 'wikipedia': 979, 'localization': 980, 'end': 981, 'among': 982, 'number': 983, 'theories': 984, 'consistent': 985, 'warehouse': 986, 'register': 987, 'navigation': 988, 'label': 989, 'tuning': 990, 'multiprocessor': 991, 'we': 992, 'interval': 993, 'review': 994, 'diverse': 995, 'call': 996, 'korean': 997, 'right': 998, 'oracle': 999, 'devices': 1000, 'mixed': 1001, 'redundant': 1002, 'learned': 1003, 'rewriting': 1004, 'counting': 1005, 'importance': 1006, 'adjoining': 1007, 'than': 1008, 'survey': 1009, 'elimination': 1010, 'personalization': 1011, 'all': 1012, 'reviews': 1013, 'phrases': 1014, 'transitive': 1015, 'look': 1016, 'team': 1017, 'nlp': 1018, 'center': 1019, 'deep': 1020, 'points': 1021, 'normal': 1022, 'soft': 1023, 'negotiation': 1024, 'characterization': 1025, 'studies': 1026, 'nonmonotonic': 1027, 'skills': 1028, 'ii': 1029, 'cubes': 1030, 'minimization': 1031, 'principle': 1032, 'partitioned': 1033, 'summary': 1034, 'side': 1035, 'centric': 1036, 'ambiguity': 1037, 'inverted': 1038, 'standard': 1039, 'hard': 1040, 'observations': 1041, 'length': 1042, 'spam': 1043, 'reducing': 1044, 'market': 1045, 'evolutionary': 1046, 'informative': 1047, 'during': 1048, 'derivation': 1049, 'industrial': 1050, 'unstructured': 1051, 'translating': 1052, 'csp': 1053, 'signature': 1054, 'noise': 1055, 'thinking': 1056, 'pomdps': 1057, 'mdps': 1058, 'relative': 1059, 'abstractions': 1060, 'algorithmic': 1061, 'operators': 1062, 'disjunctive': 1063, 'formation': 1064, 'pointer': 1065, 'argumentation': 1066, 'teach': 1067, 'creating': 1068, 'embedding': 1069, 'experts': 1070, 'customer': 1071, '1': 1072, 'discrete': 1073, 'closed': 1074, 'hierarchy': 1075, 'conversion': 1076, 'shape': 1077, 'behaviors': 1078, 'target': 1079, 'robustness': 1080, 'procedure': 1081, 'operation': 1082, 'interesting': 1083, 'pragmatic': 1084, 'other': 1085, 'combination': 1086, 'fusion': 1087, 'reactive': 1088, 'compiling': 1089, 'difference': 1090, 'sound': 1091, 'deadlock': 1092, 'click': 1093, 'grained': 1094, 'parameter': 1095, 'independence': 1096, 'questions': 1097, 'federated': 1098, 'noisy': 1099, 'programmers': 1100, 'stable': 1101, 'speed': 1102, 'attacks': 1103, 'levels': 1104, 'focus': 1105, 'similar': 1106, 'morphology': 1107, 'bootstrapping': 1108, 'animation': 1109, 'forward': 1110, 'negative': 1111, 'measurement': 1112, 'simulator': 1113, 'blog': 1114, 'zero': 1115, 'prototyping': 1116, 'multidatabase': 1117, 'short': 1118, 'depth': 1119, 'organizing': 1120, 'dialogues': 1121, 'warehouses': 1122, 'focused': 1123, 'safety': 1124, 'biased': 1125, 'parameterized': 1126, 'profiles': 1127, 'off': 1128, 'orientation': 1129, 'office': 1130, 'style': 1131, 'occurrence': 1132, 'go': 1133, 'transition': 1134, 'termination': 1135, 'predicates': 1136, 'crawling': 1137, 'benchmark': 1138, 'inconsistency': 1139, 'creation': 1140, 'frequency': 1141, '3': 1142, 'forms': 1143, 'pagerank': 1144, 'reranking': 1145, 'gradient': 1146, '3d': 1147, 'match': 1148, 'multiagent': 1149, 'situation': 1150, 'biomedical': 1151, 'annotations': 1152, 'generalizing': 1153, 'aided': 1154, 'dynamics': 1155, 'name': 1156, 'verb': 1157, 'enhance': 1158, 'logistic': 1159, 'aligning': 1160, 'libraries': 1161, 'weak': 1162, 'bottom': 1163, 'skyline': 1164, 'recursion': 1165, 'input': 1166, 'quantified': 1167, 'blind': 1168, 'lr': 1169, 'back': 1170, 'ordered': 1171, 'correction': 1172, 'servers': 1173, 'learn': 1174, 'clause': 1175, 'cs2': 1176, 'unlabeled': 1177, 'life': 1178, 'trajectories': 1179, 'less': 1180, 'recall': 1181, 'account': 1182, 'quasi': 1183, 'middle': 1184, 'middleware': 1185, 'ensemble': 1186, 'dimension': 1187, 'no': 1188, 'predict': 1189, 'energy': 1190, 'ml': 1191, 'warehousing': 1192, 'providing': 1193, 'labeled': 1194, 'generator': 1195, 'formulas': 1196, 'lexicalized': 1197, 'formalism': 1198, 'family': 1199, 'rate': 1200, 'german': 1201, 'mathematical': 1202, 'operational': 1203, 'unifying': 1204, 'outliers': 1205, 'analogy': 1206, 'confidence': 1207, 'selective': 1208, 'generate': 1209, 'passing': 1210, 'work': 1211, 'centered': 1212, 'only': 1213, 'articles': 1214, 'bias': 1215, 'versions': 1216, 'anytime': 1217, 'planner': 1218, 'instances': 1219, 'second': 1220, 'gram': 1221, 'practices': 1222, 'i': 1223, 'separation': 1224, 'filter': 1225, 'coreference': 1226, 'differences': 1227, 'items': 1228, 'parse': 1229, 'enabling': 1230, 'reading': 1231, 'voting': 1232, 'intent': 1233, 'educational': 1234, 'characterizing': 1235, 'deriving': 1236, 'reorganization': 1237, 'transliteration': 1238, 'proactive': 1239, 'frame': 1240, 'topological': 1241, 'topical': 1242, 'head': 1243, 'mental': 1244, 'paper': 1245, 'paradigms': 1246, 'assistant': 1247, 'thesaurus': 1248, 'iteration': 1249, 'strings': 1250, 'adapting': 1251, 'determination': 1252, 'inclusion': 1253, 'find': 1254, 'decisions': 1255, 'infinite': 1256, 'be': 1257, 'run': 1258, 'broadcast': 1259, 'logging': 1260, 'foundations': 1261, 'balancing': 1262, 'toolkit': 1263, 'paths': 1264, 'convex': 1265, 'expected': 1266, 'projections': 1267, 'leveraging': 1268, 'curricula': 1269, 'browser': 1270, 'assignments': 1271, 'manager': 1272, 'computers': 1273, 'list': 1274, 'solver': 1275, 'parsers': 1276, 'broad': 1277, 'biological': 1278, 'cube': 1279, 'judgments': 1280, 'analyzer': 1281, 'mathematics': 1282, 'runtime': 1283, 'metadata': 1284, 'monotonic': 1285, 'ranked': 1286, 'itemsets': 1287, 'csps': 1288, 'email': 1289, 'dictionaries': 1290, 'just': 1291, 'massive': 1292, 'ethics': 1293, 'applied': 1294, 'traffic': 1295, 'placement': 1296, 'does': 1297, 'd': 1298, 'geometry': 1299, 'conscious': 1300, 'your': 1301, 'compositional': 1302, 'linking': 1303, 'contexts': 1304, 'mappings': 1305, 'normalization': 1306, 'exact': 1307, 'processors': 1308, 'lightweight': 1309, 'networked': 1310, 'synchronization': 1311, 'interpreter': 1312, 'aggregates': 1313, 'tags': 1314, 'locality': 1315, 'conflict': 1316, 'links': 1317, 'dataflow': 1318, 'ensembles': 1319, 'closure': 1320, 'neighborhood': 1321, 'explanations': 1322, 'batch': 1323, 'structuring': 1324, 'four': 1325, 'manipulating': 1326, 'bidirectional': 1327, 'majors': 1328, 'randomized': 1329, 'lists': 1330, 'serializability': 1331, 'grammatical': 1332, 'eliminating': 1333, 'layout': 1334, 'provenance': 1335, 'undergraduates': 1336, 'sort': 1337, 'contract': 1338, 'sorting': 1339, 'facility': 1340, 'persistent': 1341, 'out': 1342, 'availability': 1343, 'positive': 1344, 'fully': 1345, 'clickthrough': 1346, 'advertising': 1347, 'comprehension': 1348, 'restructuring': 1349, 'repositories': 1350, 'cad': 1351, 'easy': 1352, 'costs': 1353, 'probabilities': 1354, 'ambiguous': 1355, 'suggestion': 1356, 'categorial': 1357, 'completeness': 1358, 'minimum': 1359, 'transparent': 1360, 'histograms': 1361, 'quantifying': 1362, 'lisp': 1363, 'diagnostic': 1364, 'against': 1365, 'template': 1366, 'beliefs': 1367, 'least': 1368, 'window': 1369, 'svm': 1370, 'isolation': 1371, 'emerging': 1372, 'regularization': 1373, 'road': 1374, 'associations': 1375, 'poster': 1376, 'svms': 1377, 'lingual': 1378, 'lock': 1379, 'spontaneous': 1380, 'french': 1381, 'presentation': 1382, 'states': 1383, 'roles': 1384, 'anomaly': 1385, 'difficult': 1386, 'need': 1387, 'dissemination': 1388, 'investigating': 1389, 'determining': 1390, 'module': 1391, 'expertise': 1392, 'prior': 1393, 'profile': 1394, 'pairs': 1395, 'arbitrary': 1396, 'smoothing': 1397, 'tutoring': 1398, 'area': 1399, 'ada': 1400, 'workflows': 1401, 'names': 1402, 'genre': 1403, 'coupling': 1404, 'owl': 1405, 'meets': 1406, 'nonlinear': 1407, 'numeric': 1408, 'geographic': 1409, 'frameworks': 1410, 'inducing': 1411, 'sensing': 1412, 'possibilistic': 1413, 'directions': 1414, 'usability': 1415, 'classical': 1416, 'procedural': 1417, 'designs': 1418, 'bayes': 1419, 'binding': 1420, 'authority': 1421, 'legacy': 1422, 'session': 1423, 'circumscription': 1424, 'constructive': 1425, 'well': 1426, 'sample': 1427, 'signatures': 1428, 'native': 1429, 'purpose': 1430, 'year': 1431, 'channel': 1432, 'behaviour': 1433, 'invariants': 1434, 'treatment': 1435, 'branch': 1436, 'walk': 1437, 'adding': 1438, 'improvement': 1439, 'formalization': 1440, 'contents': 1441, 'dialog': 1442, 'net': 1443, 'regular': 1444, 'vertical': 1445, 'useful': 1446, 'effort': 1447, 'speculative': 1448, 'combined': 1449, 'formulation': 1450, 'cardinality': 1451, 'arc': 1452, 'light': 1453, 'activities': 1454, 'directional': 1455, 'guide': 1456, 'inter': 1457, 'records': 1458, 'html': 1459, 'current': 1460, 'suite': 1461, 'generated': 1462, 'typing': 1463, 'category': 1464, 'teachers': 1465, 'relaxed': 1466, 'terminology': 1467, 'vocabulary': 1468, 'agile': 1469, 'filters': 1470, 'implementations': 1471, 'diversity': 1472, 'archives': 1473, 'compound': 1474, 'loops': 1475, 'proofs': 1476, 'categorical': 1477, 'factors': 1478, 'missing': 1479, 'asynchronous': 1480, 'inspection': 1481, 'networking': 1482, 'calls': 1483, 'optimistic': 1484, 'outlier': 1485, 'who': 1486, 'behavioral': 1487, 'describing': 1488, 'windows': 1489, 'anonymous': 1490, 'utilizing': 1491, 'multiclass': 1492, 'tradeoffs': 1493, 'strong': 1494, 'read': 1495, 'poisson': 1496, 'portable': 1497, 'directory': 1498, 'challenge': 1499, 'nets': 1500, 'playing': 1501, 'interest': 1502, 'argument': 1503, 'coalitional': 1504, 'correct': 1505, 'defect': 1506, 'public': 1507, 'smart': 1508, 'annotated': 1509, 'women': 1510, 'unit': 1511, 'io': 1512, 'reduce': 1513, 'prover': 1514, 'conversational': 1515, 'dealing': 1516, 'mode': 1517, 'needs': 1518, 'collective': 1519, 'block': 1520, 'trends': 1521, 'maps': 1522, 'workload': 1523, 'groups': 1524, 'microarray': 1525, 'terminological': 1526, 'defined': 1527, 'edge': 1528, 'analytical': 1529, 'modified': 1530, 'instructions': 1531, 'choice': 1532, 'modularity': 1533, 'reusable': 1534, 'pairwise': 1535, 'commit': 1536, 'competitive': 1537, 'make': 1538, 'observation': 1539, 'controlled': 1540, 'templates': 1541, 'granularity': 1542, 'affective': 1543, 'secondary': 1544, 'failures': 1545, 'meaning': 1546, 'bringing': 1547, 'optimality': 1548, 'perspectives': 1549, 'breaking': 1550, 'bi': 1551, 'pos': 1552, 'approximating': 1553, 'analyses': 1554, 'failure': 1555, 'expectation': 1556, 'backtracking': 1557, 'concerns': 1558, 'blogs': 1559, 'operator': 1560, 'boundary': 1561, 'decentralized': 1562, 'discrimination': 1563, 'accessing': 1564, 'semantically': 1565, 'histogram': 1566, 'response': 1567, 'abductive': 1568, 'symmetric': 1569, 'generators': 1570, 'refining': 1571, 'arrays': 1572, 'bug': 1573, 'attention': 1574, 'transducers': 1575, 'symmetry': 1576, 'existing': 1577, 'collocations': 1578, 'derived': 1579, 'enough': 1580, 'unknown': 1581, 'adaptable': 1582, 'approximations': 1583, 'www': 1584, 'boundaries': 1585, 'assurance': 1586, 'slicing': 1587, 'write': 1588, 'rdbms': 1589, 'controlling': 1590, 'almost': 1591, 'maximal': 1592, 'parallelization': 1593, 'gathering': 1594, 'integer': 1595, 'viewing': 1596, 'benefits': 1597, 'character': 1598, 'scoring': 1599, 'metaphor': 1600, 'dont': 1601, 'subtyping': 1602, 'greedy': 1603, 'updating': 1604, 'considerations': 1605, 'automation': 1606, 'know': 1607, 'nonparametric': 1608, 'predictions': 1609, 'modern': 1610, 'desktop': 1611, 'likelihood': 1612, 'risk': 1613, 'experimentation': 1614, 'collaboration': 1615, 'lattice': 1616, 'constituent': 1617, 'globally': 1618, 'metasearch': 1619, 'horn': 1620, 'reconstruction': 1621, 'scene': 1622, 'face': 1623, 'de': 1624, 'remote': 1625, 'stage': 1626, 'delayed': 1627, 'lines': 1628, 'cs1cs2': 1629, 'subsequence': 1630, 'wordnet': 1631, 'criterion': 1632, 'semistructured': 1633, 'coding': 1634, 'foundation': 1635, 'decoding': 1636, 'scenarios': 1637, 'frames': 1638, 'ubiquitous': 1639, 'display': 1640, 'specified': 1641, 'law': 1642, 'axiomatic': 1643, 'p': 1644, 'em': 1645, 'individual': 1646, 'pair': 1647, 'learners': 1648, 'ability': 1649, 'walks': 1650, 'surface': 1651, 'opportunities': 1652, 'private': 1653, 'synchronized': 1654, 'cases': 1655, 'validating': 1656, 'assembly': 1657, 'optimizers': 1658, '2': 1659, 'notes': 1660, 'hot': 1661, 'sketch': 1662, 'paraphrasing': 1663, 'oodb': 1664, 'significance': 1665, 'nonnegative': 1666, 'panel': 1667, 'verbs': 1668, 'resolving': 1669, 'note': 1670, 'success': 1671, 'refactoring': 1672, 'people': 1673, 'prioritized': 1674, 'breadth': 1675, 'store': 1676, 'ahead': 1677, 'passage': 1678, 'atomic': 1679, 'codes': 1680, 'retention': 1681, 'comparisons': 1682, 'convergence': 1683, 'interpreting': 1684, 'differential': 1685, 'covering': 1686, 'dominance': 1687, 'route': 1688, 'arguments': 1689, 'threshold': 1690, 'charts': 1691, 'compressing': 1692, 'live': 1693, 'coarse': 1694, 'containment': 1695, 'sum': 1696, 'auction': 1697, 'sensors': 1698, 'stemming': 1699, 'false': 1700, 'whole': 1701, 'applicative': 1702, 'imprecise': 1703, 'lfg': 1704, 'thematic': 1705, 'taxonomies': 1706, 'organizational': 1707, 'alternatives': 1708, 'javascript': 1709, 'communications': 1710, 'replacement': 1711, 'position': 1712, 'left': 1713, 'circuits': 1714, 'bag': 1715, 'analytic': 1716, 'there': 1717, 'interoperable': 1718, 'conjunctive': 1719, 'activation': 1720, 'rates': 1721, 'selecting': 1722, 'both': 1723, 'copy': 1724, 'computations': 1725, 'coupled': 1726, 'cooperating': 1727, 'deduction': 1728, 'polymorphism': 1729, 'cut': 1730, 'lecture': 1731, 'tier': 1732, 'standards': 1733, 'defaults': 1734, 'faults': 1735, 'accessibility': 1736, 'prosodic': 1737, 'arts': 1738, 'accesses': 1739, 'wise': 1740, 'rfid': 1741, 'factor': 1742, 'characters': 1743, 'parameters': 1744, 'interests': 1745, 'monte': 1746, 'carlo': 1747, 'augmented': 1748, 'informed': 1749, 'autonomic': 1750, 'balanced': 1751, 'where': 1752, 'loosely': 1753, 'sponsored': 1754, 'adoption': 1755, 'twig': 1756, 'smalltalk': 1757, 'scope': 1758, 'extracted': 1759, 'subgraphs': 1760, 'urls': 1761, 'advice': 1762, 'bidding': 1763, 'visually': 1764, 'subjectivity': 1765, 'realistic': 1766, 'contention': 1767, 'rich': 1768, 'player': 1769, 'executing': 1770, 'hypothesis': 1771, 'alias': 1772, 'micro': 1773, 'ground': 1774, 'serial': 1775, 'few': 1776, 'pass': 1777, 'pipelined': 1778, 'pc': 1779, 'college': 1780, 'stories': 1781, 'laboratories': 1782, 'microsoft': 1783, 'partition': 1784, 'reformulation': 1785, 'strategic': 1786, 'something': 1787, 'fundamental': 1788, 'most': 1789, 'restrictions': 1790, 'changing': 1791, 'mutual': 1792, 'package': 1793, 'searches': 1794, 'synopses': 1795, 'technical': 1796, 'meanings': 1797, 'robotic': 1798, 'citation': 1799, 'primitives': 1800, 'discussion': 1801, 'company': 1802, 'wavelets': 1803, 'wrapper': 1804, 'recognizing': 1805, 'specialization': 1806, 'performing': 1807, 'verifying': 1808, 'recommender': 1809, 'cyclic': 1810, 'mechanical': 1811, 'fragments': 1812, 'taking': 1813, 'industry': 1814, 'linkage': 1815, 'augmenting': 1816, 'numerical': 1817, 'indexed': 1818, 'robotics': 1819, 'shift': 1820, 'entailment': 1821, 'denotational': 1822, 'focusing': 1823, 'written': 1824, 'theorems': 1825, 'chain': 1826, 'additive': 1827, 'living': 1828, 'comparable': 1829, 'invariant': 1830, '20': 1831, 'friendly': 1832, 'inputs': 1833, 'regularized': 1834, 'holistic': 1835, 'splitting': 1836, 'intrusion': 1837, 'recent': 1838, 'price': 1839, 'phrasal': 1840, 'physics': 1841, 'build': 1842, 'buffering': 1843, 'minimizing': 1844, 'cooperation': 1845, 'auxiliary': 1846, 'exception': 1847, 'pronoun': 1848, 'petri': 1849, 'next': 1850, 'divide': 1851, 'decompositions': 1852, 'weight': 1853, 'publishing': 1854, 'manifold': 1855, 'anchor': 1856, 'qa': 1857, 'merge': 1858, 'revealing': 1859, 'suffix': 1860, 'clauses': 1861, 'combinatory': 1862, 'whats': 1863, 'capture': 1864, 'simplifying': 1865, 'nondeterministic': 1866, 'node': 1867, 'induced': 1868, 'grams': 1869, 'quantifier': 1870, 'choices': 1871, 'distributing': 1872, 'really': 1873, 'total': 1874, 'interdisciplinary': 1875, 'explaining': 1876, 'eye': 1877, 'priors': 1878, 'versioning': 1879, 'double': 1880, 'chains': 1881, 'expensive': 1882, 'reporting': 1883, 'functionality': 1884, 'statements': 1885, 'financial': 1886, 'fair': 1887, 'but': 1888, '2003': 1889, 'messages': 1890, 'weights': 1891, 'monolingual': 1892, 'argumentative': 1893, 'massively': 1894, 'basic': 1895, 'rapid': 1896, 'forecasting': 1897, 'made': 1898, 'integrate': 1899, 'chemical': 1900, 'multilevel': 1901, 'intention': 1902, 'api': 1903, 'disks': 1904, 'worlds': 1905, 'flickr': 1906, 'gaps': 1907, 'abduction': 1908, 'strictness': 1909, 'recurrent': 1910, 'liberal': 1911, 'rewrite': 1912, 'solve': 1913, 'materialization': 1914, 'completion': 1915, 'website': 1916, 'mapreduce': 1917, 'dominant': 1918, 'expressing': 1919, 'bioinformatics': 1920, 'compilers': 1921, 'prefetching': 1922, 'transductive': 1923, 'achieving': 1924, 'anaphoric': 1925, 'notion': 1926, 'lambek': 1927, 'samples': 1928, 'connectionist': 1929, 'x': 1930, 'art': 1931, 'anomalies': 1932, 'producing': 1933, 'meaningful': 1934, 'assisted': 1935, 'formalisms': 1936, 'too': 1937, 'manufacturing': 1938, 'elements': 1939, 'comments': 1940, 'lda': 1941, 'treewidth': 1942, 'column': 1943, 'maximizing': 1944, 'm': 1945, 'much': 1946, 'localized': 1947, 'transport': 1948, 'helping': 1949, 'stationary': 1950, 'automotive': 1951, 'stored': 1952, 'strongly': 1953, 'reports': 1954, 'subject': 1955, 'predictors': 1956, 'traversal': 1957, 'post': 1958, 'interpretations': 1959, 'vague': 1960, 'flows': 1961, 'threads': 1962, 'negation': 1963, 'seed': 1964, 'methodologies': 1965, 'shapes': 1966, 'skew': 1967, 'lab': 1968, 'correspondences': 1969, 'timed': 1970, 'race': 1971, 'candidate': 1972, 'permutation': 1973, 'trace': 1974, '2000': 1975, 'observable': 1976, 'nominal': 1977, 'synthesizing': 1978, 'coherent': 1979, 'bit': 1980, 'senses': 1981, 'archiving': 1982, 'hypermedia': 1983, 'act': 1984, 'regions': 1985, 'color': 1986, 'improvements': 1987, 'pascal': 1988, 'ill': 1989, 'transformational': 1990, 'ellipsis': 1991, 'pipeline': 1992, 'quantification': 1993, 'instructional': 1994, 'keyphrase': 1995, 'indirect': 1996, 'author': 1997, 'blocking': 1998, 'retrieving': 1999, 'exchange': 2000, 'settings': 2001, 'possible': 2002, 'containing': 2003, 'transduction': 2004, 'imperfect': 2005, 'delivery': 2006, 'characteristics': 2007, 'sketching': 2008, 'horizontal': 2009, 'instant': 2010, 'continuations': 2011, 'videos': 2012, 'facts': 2013, 'hand': 2014, 'facilitate': 2015, 'multivariate': 2016, 'inverse': 2017, 'lasso': 2018, 'multithreaded': 2019, 'guarantees': 2020, 'restricted': 2021, 'status': 2022, 'studying': 2023, 'transform': 2024, 'contracts': 2025, 'trade': 2026, 'checker': 2027, 'bad': 2028, 'everyone': 2029, 'labs': 2030, 'correlated': 2031, 'correspondence': 2032, 'literature': 2033, 'pipelining': 2034, 'grouping': 2035, 'connected': 2036, 'teams': 2037, 'regret': 2038, 'snippets': 2039, 'acm': 2040, 'many': 2041, 'initiative': 2042, 'diagnosing': 2043, 'cleaning': 2044, 'skill': 2045, 'intensional': 2046, 'built': 2047, 'command': 2048, 'conditions': 2049, 'piecewise': 2050, 'codasyl': 2051, 'encodings': 2052, 'layered': 2053, 'dimensions': 2054, 'difficulty': 2055, 'correcting': 2056, 'q': 2057, 'communicating': 2058, 'modes': 2059, 'protein': 2060, 'perceptron': 2061, 'seeking': 2062, 'fractal': 2063, 'poker': 2064, 'snapshot': 2065, 'comprehensive': 2066, 'particle': 2067, 'novice': 2068, 'hmm': 2069, 'analogical': 2070, 'unix': 2071, 'audio': 2072, 'heap': 2073, 'consensus': 2074, 'yahoo': 2075, 'extensibility': 2076, 'intermediate': 2077, 'scenes': 2078, 'place': 2079, 'mediator': 2080, 'commercial': 2081, 'past': 2082, 'treebank': 2083, 'smt': 2084, 'google': 2085, 'overlapping': 2086, 'heterogeneity': 2087, 'aid': 2088, 'internal': 2089, 'coalition': 2090, 'equality': 2091, 'tensor': 2092, 'force': 2093, 'accurately': 2094, 'repository': 2095, 'reputation': 2096, 'keys': 2097, 'elicitation': 2098, 'division': 2099, 'coloring': 2100, 'healthcare': 2101, 'collector': 2102, 'utilization': 2103, 'gpsg': 2104, 'bitmap': 2105, 'pointers': 2106, 'corner': 2107, 'inferencing': 2108, 'intended': 2109, 'should': 2110, 'tagged': 2111, 'courseware': 2112, 'pedagogy': 2113, 'examination': 2114, 'varying': 2115, 'temporally': 2116, 'alpha': 2117, 'rankings': 2118, 'publishsubscribe': 2119, 'referring': 2120, 'pictures': 2121, 'factored': 2122, 'spreading': 2123, 'inferences': 2124, 'documentation': 2125, 'detect': 2126, 'overlay': 2127, 'story': 2128, 'winner': 2129, 'locating': 2130, 'reusing': 2131, 'paraphrases': 2132, 'optimize': 2133, 'loss': 2134, 'cues': 2135, 'stack': 2136, 'pca': 2137, 'similarities': 2138, 'equilibria': 2139, 'flash': 2140, 'pure': 2141, 'mean': 2142, 'preservation': 2143, 'referential': 2144, 'repairs': 2145, 'special': 2146, 'issue': 2147, 'walking': 2148, 'exploratory': 2149, 'major': 2150, 'traditional': 2151, 'starburst': 2152, 'if': 2153, 'equations': 2154, 'facilitating': 2155, 'hiding': 2156, 'satisfying': 2157, 'biology': 2158, 'minimax': 2159, 'drift': 2160, 'multiversion': 2161, 'device': 2162, 'ocr': 2163, 'extendible': 2164, 'editors': 2165, 's': 2166, 'summer': 2167, 'centering': 2168, 'works': 2169, 'orthogonal': 2170, 'conformant': 2171, 'bibliography': 2172, 'spatiotemporal': 2173, 'testbed': 2174, 'numbers': 2175, 'party': 2176, 'definite': 2177, 'relating': 2178, 'linguistically': 2179, 'connecting': 2180, 'enforcement': 2181, 'clues': 2182, 'lexicons': 2183, 'ontological': 2184, 'stability': 2185, 'replica': 2186, 'choosing': 2187, 'defining': 2188, 'count': 2189, 'intranet': 2190, 'exponential': 2191, 'while': 2192, 'geo': 2193, 'diffusion': 2194, 'conversation': 2195, 'manual': 2196, 'indefinite': 2197, 'triggers': 2198, 'variation': 2199, 'navigational': 2200, 'la': 2201, 'hpsg': 2202, 'requirement': 2203, 'anatomy': 2204, 'mutation': 2205, 'rational': 2206, 'simulations': 2207, 'so': 2208, 'including': 2209, 'switching': 2210, 'measurements': 2211, 'seminar': 2212, 'constructed': 2213, 'inversion': 2214, 'spelling': 2215, 'idea': 2216, '12': 2217, 'shallow': 2218, 'rare': 2219, 'job': 2220, 'vehicle': 2221, 'another': 2222, 'loading': 2223, 'organized': 2224, 'significant': 2225, 'addressing': 2226, 'visualisation': 2227, 'proxy': 2228, 'encryption': 2229, 'freshness': 2230, 'presentations': 2231, 'fact': 2232, 'filling': 2233, 'axioms': 2234, 'play': 2235, 'formed': 2236, 'migration': 2237, 'equivalent': 2238, 'distributional': 2239, 'decidable': 2240, 'government': 2241, 'adjectives': 2242, 'searchers': 2243, 'capstone': 2244, 'crawler': 2245, 'evaluate': 2246, 'shell': 2247, 'concrete': 2248, 'blogosphere': 2249, 'styles': 2250, 'protecting': 2251, 'db': 2252, 'turkish': 2253, 'attack': 2254, 'roc': 2255, 'iterated': 2256, 'directories': 2257, 'situations': 2258, 'distances': 2259, 'exodus': 2260, 'curve': 2261, 'grounded': 2262, 'traceability': 2263, 'humans': 2264, 'memories': 2265, 'null': 2266, 'labels': 2267, 'ads': 2268, 'summarizing': 2269, 'clusterings': 2270, 'descent': 2271, 'verbal': 2272, '2001': 2273, 'entry': 2274, 'concise': 2275, 'pilot': 2276, 'edit': 2277, 'wrapping': 2278, 'oltp': 2279, 'individuals': 2280, 'bounding': 2281, 'posterior': 2282, 'trec': 2283, 'environmental': 2284, 'consumer': 2285, 'me': 2286, 'signal': 2287, 'neighbors': 2288, 'viewpoint': 2289, 'multidatabases': 2290, 'promoting': 2291, 'hyper': 2292, 'which': 2293, 'tertiary': 2294, 'background': 2295, 'corporate': 2296, 'attitudes': 2297, 'skewed': 2298, 'reversible': 2299, 'relaxation': 2300, 'simplified': 2301, 'years': 2302, 'underlying': 2303, 'authorship': 2304, 'advances': 2305, 'acts': 2306, 'estimates': 2307, 'proper': 2308, 'tests': 2309, 'hits': 2310, 'portals': 2311, 'edges': 2312, 'utterances': 2313, 'acquiring': 2314, 'flat': 2315, 'prevention': 2316, 'capability': 2317, 'extreme': 2318, 'aliasing': 2319, 'papers': 2320, 'attachment': 2321, 'periodic': 2322, 'subcategorization': 2323, 'achieve': 2324, 'readability': 2325, 'available': 2326, 'ccg': 2327, 'constant': 2328, 'distillation': 2329, 'forests': 2330, 'hypotheses': 2331, 'pervasive': 2332, 'invited': 2333, 'mind': 2334, 'conquer': 2335, 'lower': 2336, 'encoding': 2337, 'assistance': 2338, 'travel': 2339, 'diagram': 2340, 'correlations': 2341, 'estimate': 2342, 'represent': 2343, 'maximization': 2344, 'segment': 2345, 'increasing': 2346, 'dl': 2347, 'phonological': 2348, 'advantages': 2349, 'composing': 2350, 'o': 2351, 'revisiting': 2352, 'stratified': 2353, 'randomization': 2354, 'variance': 2355, 'miner': 2356, 'inconsistent': 2357, 'obligations': 2358, 'novelty': 2359, 'weakly': 2360, 'trend': 2361, 'vote': 2362, 'objective': 2363, 'final': 2364, 'categorizing': 2365, 'trails': 2366, 'any': 2367, 'they': 2368, 'opinions': 2369, 'sms': 2370, 'movements': 2371, 'scoping': 2372, 'baseline': 2373, 'anonymizing': 2374, 'declustering': 2375, 'macro': 2376, 'shortest': 2377, 'knn': 2378, 'proposed': 2379, 'tape': 2380, 'ssa': 2381, 'phi': 2382, 'harmful': 2383, 'parsed': 2384, 'hypergraph': 2385, 'principal': 2386, 'segments': 2387, 'accessible': 2388, 'strength': 2389, 'informational': 2390, 'clinical': 2391, 'polarity': 2392, 'aqualogic': 2393, 'graded': 2394, 'neutral': 2395, 'degree': 2396, 'sciences': 2397, 'expressiveness': 2398, 'divergence': 2399, 'controls': 2400, 'taxonomic': 2401, 'beta': 2402, 'faceted': 2403, 'elections': 2404, 'readers': 2405, 'mixtures': 2406, 'spammers': 2407, 'transforms': 2408, 'ibm': 2409, 'setting': 2410, 'weaving': 2411, 'reconstructing': 2412, 'ciphers': 2413, 'release': 2414, 'last': 2415, 'blackboard': 2416, 'nash': 2417, 'enhancement': 2418, 'deviation': 2419, 'mediation': 2420, 'skylines': 2421, 'patent': 2422, 'thread': 2423, 'show': 2424, 'constituency': 2425, 'ode': 2426, 'elaboration': 2427, 'postgres': 2428, 'us': 2429, 'ecommerce': 2430, 'pi': 2431, 'clouds': 2432, 'sales': 2433, 'popular': 2434, 'important': 2435, 'snippet': 2436, 'extract': 2437, 'editing': 2438, 'fifteen': 2439, 'productivity': 2440, 'rating': 2441, 'associated': 2442, 'fragment': 2443, 'before': 2444, 'bulk': 2445, 'population': 2446, 'resident': 2447, 'curse': 2448, 'gui': 2449, 'topology': 2450, 'trading': 2451, 'cs0': 2452, 'exclusive': 2453, 'disjunctions': 2454, 'neighbour': 2455, 'viewpoints': 2456, 'andor': 2457, 'messaging': 2458, 'lite': 2459, 'factory': 2460, 'pronominal': 2461, 'duality': 2462, 'mandarin': 2463, 'chunks': 2464, 'geographical': 2465, 'subexpressions': 2466, 'interpreters': 2467, 'fraud': 2468, 'potential': 2469, 'reusability': 2470, 'attribution': 2471, 'onto': 2472, 'syntactically': 2473, 'root': 2474, 'getting': 2475, 'reduced': 2476, 'cp': 2477, 'see': 2478, 'lexicalization': 2479, 'prepositional': 2480, 'injection': 2481, 'multiparty': 2482, 'matrices': 2483, 'nonmyopic': 2484, 'limits': 2485, 'provide': 2486, 'atms': 2487, 'pronunciation': 2488, 'brief': 2489, 'elementary': 2490, 'exercise': 2491, 'barrier': 2492, 'grain': 2493, 'contrast': 2494, 'hypergraphs': 2495, 'sub': 2496, 'counts': 2497, 'webpage': 2498, 'customization': 2499, 'discovered': 2500, 'mu': 2501, 'conservative': 2502, 'commodity': 2503, 'gis': 2504, 'morpheme': 2505, 'board': 2506, 'molecular': 2507, 'must': 2508, 'mobility': 2509, 'tracing': 2510, 'going': 2511, 'supported': 2512, 'identify': 2513, 'causes': 2514, 'earth': 2515, 'orders': 2516, 'algebras': 2517, 'hierarchically': 2518, 'avoidance': 2519, 'intractable': 2520, 'encyclopedic': 2521, 'optical': 2522, 'prototypes': 2523, 'star': 2524, 'sensitivity': 2525, 'cycles': 2526, 'fixpoint': 2527, 'exploitation': 2528, 'spreadsheets': 2529, 'products': 2530, 'packing': 2531, 'tabular': 2532, 'gain': 2533, 'wavelet': 2534, 'exceptions': 2535, 'reengineering': 2536, 'layer': 2537, 'stopping': 2538, 'icse': 2539, 'gender': 2540, 'acyclic': 2541, 'nl': 2542, 'marketing': 2543, 'bandit': 2544, 'designed': 2545, 'analyze': 2546, 'coordinating': 2547, 'staged': 2548, 'essential': 2549, 'guarantee': 2550, 'purchase': 2551, 'f': 2552, 'screening': 2553, 'adjusting': 2554, 'iceberg': 2555, 'evaluations': 2556, 'monitor': 2557, 'naive': 2558, 'restarts': 2559, 'defeasible': 2560, 'subspaces': 2561, 'proposal': 2562, 'ansi': 2563, 'vectors': 2564, 'persistence': 2565, 'preprocessing': 2566, 'tokenization': 2567, 'continuation': 2568, 'compromise': 2569, 'epsilon': 2570, 'mediated': 2571, 'notation': 2572, 'defense': 2573, 'trajectory': 2574, 'tailoring': 2575, 'sliding': 2576, 'bootstrap': 2577, 'normalized': 2578, 'crash': 2579, 'clones': 2580, 'promises': 2581, 'admissible': 2582, 'engineers': 2583, 'examining': 2584, 'agenda': 2585, 'dependability': 2586, 'portal': 2587, 'scheduler': 2588, 'optimum': 2589, 'factoring': 2590, 'salience': 2591, 'estimators': 2592, 'compatibility': 2593, 'used': 2594, 'decoupling': 2595, 'big': 2596, 'closing': 2597, 'keywords': 2598, 'picture': 2599, 'ie': 2600, 'awareness': 2601, 'analytics': 2602, '10': 2603, '3rd': 2604, 'powerful': 2605, 'quorum': 2606, 'perform': 2607, 'collocation': 2608, 'classify': 2609, 'sequencing': 2610, 'interlingual': 2611, 'growth': 2612, 'morpho': 2613, 'analyser': 2614, 'learner': 2615, 'risc': 2616, 'mail': 2617, 'required': 2618, 'dependable': 2619, 'optimally': 2620, 'avoiding': 2621, 'identifiers': 2622, 'clustered': 2623, 'aids': 2624, 'haplotype': 2625, 'quantile': 2626, 'annotating': 2627, 'million': 2628, 'bank': 2629, 'stores': 2630, 'distinguishing': 2631, 'fundamentals': 2632, 'running': 2633, 'assertion': 2634, 'critique': 2635, 'emotions': 2636, 'script': 2637, 'camera': 2638, 'pushing': 2639, 'magic': 2640, 'subsumption': 2641, 'surfaces': 2642, 'telecommunication': 2643, 'linguistics': 2644, 'date': 2645, 'bid': 2646, 'atomicity': 2647, 'reachability': 2648, 'clone': 2649, 'arithmetic': 2650, 'specify': 2651, 'ambiguities': 2652, '2008': 2653, 'great': 2654, 'recovering': 2655, 'spacecraft': 2656, 'syllable': 2657, 'closures': 2658, 'transitions': 2659, 'generalised': 2660, 'parallelizing': 2661, 'constructions': 2662, 'statically': 2663, 'steps': 2664, 'plus': 2665, 'resistant': 2666, 'economic': 2667, 'translations': 2668, 'enforcing': 2669, 'asking': 2670, 'several': 2671, 'spectrum': 2672, 'enumeration': 2673, 'locks': 2674, 'tv': 2675, 'hands': 2676, 'have': 2677, 'mdl': 2678, 'aggressive': 2679, 'reason': 2680, 'irrelevance': 2681, 'departments': 2682, 'popularity': 2683, 'lambda': 2684, 'catalogs': 2685, 'auto': 2686, 'academic': 2687, 'grounding': 2688, 'nmf': 2689, 'ease': 2690, 'russian': 2691, 'assumptions': 2692, 'phenomena': 2693, 'bottleneck': 2694, 'tractability': 2695, 'workloads': 2696, 'lectures': 2697, 'options': 2698, 'speeding': 2699, 'graduate': 2700, 'assistants': 2701, 'motivated': 2702, 'grids': 2703, 'bin': 2704, 'membership': 2705, 'cipher': 2706, 'get': 2707, 'retrospective': 2708, 'linked': 2709, 'sizes': 2710, 'article': 2711, 'trip': 2712, 'handle': 2713, 'handwriting': 2714, 'decade': 2715, 'connection': 2716, 'datalog': 2717, 'pictorial': 2718, 'pdas': 2719, 'cultural': 2720, 'formulae': 2721, 'turing': 2722, 'priority': 2723, 'multiattribute': 2724, 'likely': 2725, 'authoring': 2726, 'clicks': 2727, 'lifetime': 2728, 'infer': 2729, 'puzzles': 2730, 'ingres': 2731, 'constructs': 2732, 'descriptive': 2733, 'preconditions': 2734, 'developments': 2735, 'h': 2736, 'mashups': 2737, 'successful': 2738, 'meeting': 2739, 'situated': 2740, 'item': 2741, 'transforming': 2742, 'girls': 2743, 'initial': 2744, 'perfect': 2745, 'lifted': 2746, 'assigning': 2747, 'engaging': 2748, 'offline': 2749, 'probe': 2750, 'locations': 2751, 'fixed': 2752, 'cryptography': 2753, 'floating': 2754, 'interrelated': 2755, 'expectations': 2756, 'shelf': 2757, 'literacy': 2758, 'outputs': 2759, 'spanish': 2760, 'progression': 2761, 'passive': 2762, 'threaded': 2763, 'discussions': 2764, 'computable': 2765, 'statistic': 2766, 'establishing': 2767, 'commonsense': 2768, 'motivation': 2769, 'clients': 2770, 'push': 2771, 'scalar': 2772, 'outerjoins': 2773, 'aqua': 2774, 'projected': 2775, 'troubleshooting': 2776, 'mass': 2777, 'salsa': 2778, 'sky': 2779, 'hindsight': 2780, 'consequence': 2781, 'drt': 2782, 'simd': 2783, 'patient': 2784, 'lego': 2785, 'fluents': 2786, 'day': 2787, 'currency': 2788, 'again': 2789, 'variant': 2790, 'dataspaces': 2791, 'bio': 2792, 'abandonment': 2793, 'jump': 2794, 'abnormal': 2795, 'emotion': 2796, 'novices': 2797, 'track': 2798, 'taught': 2799, 'coherency': 2800, 'duplication': 2801, 'pragmatics': 2802, 'concert': 2803, 'incrementality': 2804, 'dataspace': 2805, 'ideal': 2806, 'present': 2807, 'organizations': 2808, 'same': 2809, 'fractals': 2810, 'tsimmis': 2811, 'provision': 2812, 'mid': 2813, 'continual': 2814, 'unrestricted': 2815, 'boltzmann': 2816, 'ebl': 2817, 'forgetting': 2818, 'adversarial': 2819, 'squares': 2820, 'editor': 2821, 'foreign': 2822, 'discontinuous': 2823, 'bytecode': 2824, 'notions': 2825, 'tcp': 2826, 'feed': 2827, 'providers': 2828, 'cmm': 2829, 'identity': 2830, 'epistemic': 2831, 'infrastructures': 2832, 'detailed': 2833, 'delta': 2834, 'duration': 2835, 'imperative': 2836, 'nodes': 2837, 'encyclopedia': 2838, 'catalog': 2839, 'contest': 2840, 'substitution': 2841, 'focal': 2842, 'principled': 2843, 'connections': 2844, 'hyperlinked': 2845, 'empty': 2846, 'subqueries': 2847, 'anonymity': 2848, 'publication': 2849, 'element': 2850, 'nn': 2851, 'inspections': 2852, 'snapshots': 2853, 'scaled': 2854, 'visibility': 2855, 'cumulative': 2856, 'transducer': 2857, 'infosleuth': 2858, 'manage': 2859, 'fly': 2860, 'intrusions': 2861, 'phonology': 2862, 'refined': 2863, 'uniqueness': 2864, 'soccer': 2865, 'edits': 2866, 'prism': 2867, 'far': 2868, 'stemmer': 2869, 'provably': 2870, 'cover': 2871, 'violation': 2872, 'tough': 2873, 'tuples': 2874, 'tagger': 2875, '10g': 2876, 'customizable': 2877, 'subgraph': 2878, 'substring': 2879, 'sentential': 2880, 'mediators': 2881, 'characterizations': 2882, 'schools': 2883, 'overcoming': 2884, 'deployment': 2885, 'suspicious': 2886, 'observed': 2887, 'relief': 2888, 'requests': 2889, 'vod': 2890, 'movie': 2891, 'subsystem': 2892, 'scripting': 2893, 'hp': 2894, 'opportunity': 2895, 'idiom': 2896, 'sorted': 2897, 'semijoin': 2898, 'tracks': 2899, 'pay': 2900, 'demo': 2901, 'htn': 2902, 'heterogenous': 2903, 'simpler': 2904, 'insurance': 2905, 'connectivity': 2906, 'pitch': 2907, 'des': 2908, 'envy': 2909, 'goods': 2910, 'emergent': 2911, 'executable': 2912, 'sgml': 2913, 'tunable': 2914, 'exemplar': 2915, 'tighter': 2916, 'recency': 2917, 'recurrence': 2918, 'humor': 2919, 'agnostic': 2920, 'wave': 2921, 'mls': 2922, 'certifying': 2923, 'necessity': 2924, 'home': 2925, 'century': 2926, 'asymptotic': 2927, 'this': 2928, 'variety': 2929, 'verbose': 2930, 'intersection': 2931, 'yet': 2932, 'segmenting': 2933, 'goes': 2934, 'locally': 2935, 'nothing': 2936, 'quickly': 2937, 'durations': 2938, 'dilemma': 2939, 'add': 2940, 'competence': 2941, 'compliance': 2942, 'together': 2943, 'interacting': 2944, 'cloning': 2945, 'envelope': 2946, 'skewing': 2947, 'frontier': 2948, 'compile': 2949, 'hosting': 2950, 'developers': 2951, 'robocup': 2952, 'masses': 2953, 'imitation': 2954, 'coping': 2955, 'those': 2956, 'cant': 2957, 'scores': 2958, 'medicine': 2959, 'augmentation': 2960, 'lookahead': 2961, 'biologically': 2962, 'suites': 2963, 'markets': 2964, 'exactly': 2965, 'exhaustive': 2966, 'vp': 2967, 'signals': 2968, 'personality': 2969, 'cognition': 2970, 'cue': 2971, 'ordinal': 2972, 'deletion': 2973, 'feasibility': 2974, 'units': 2975, 'wisdom': 2976, 'polyhedral': 2977, 'yes': 2978, 'makes': 2979, 'capabilities': 2980, 'request': 2981, 'bisimulation': 2982, 'ambients': 2983, 'legal': 2984, 'enhancements': 2985, 'traces': 2986, 'proportional': 2987, 'chance': 2988, '2005': 2989, 'shopping': 2990, 'bugs': 2991, 'portfolio': 2992, 'property': 2993, 'vlsi': 2994, 'reducible': 2995, 'average': 2996, 'will': 2997, 'versatile': 2998, 'select': 2999, 'transmission': 3000, 'propagating': 3001, 'combinations': 3002, 'projective': 3003, 'derive': 3004, 'bibliographic': 3005, 'fragmentation': 3006, 'permission': 3007, 'combine': 3008, 'generality': 3009, 'chip': 3010, 'inflectional': 3011, 'super': 3012, 'learnable': 3013, 'compressor': 3014, 'organize': 3015, 'distinct': 3016, 'multiset': 3017, 'exploits': 3018, 'checkpointing': 3019, 'essence': 3020, 'alignments': 3021, 'known': 3022, 'backbone': 3023, 'accelerating': 3024, 'terminologies': 3025, 'priorities': 3026, 'o2': 3027, 'putting': 3028, 'blogging': 3029, 'conversations': 3030, 'coordinate': 3031, 'aerial': 3032, 'tune': 3033, 'deictic': 3034, 'gestures': 3035, 'jflap': 3036, 'incrementally': 3037, 'authors': 3038, 'accreditation': 3039, 'scenario': 3040, 'stop': 3041, 'fourier': 3042, 'aligned': 3043, 'webdav': 3044, 'compare': 3045, 'branching': 3046, 'conflicts': 3047, 'quadratic': 3048, 'cheap': 3049, 'creative': 3050, 'pool': 3051, 'subscription': 3052, 'standardization': 3053, 'equivalents': 3054, 'haystack': 3055, 'brain': 3056, 'rotation': 3057, 'sharable': 3058, 'benchmarking': 3059, 'ugly': 3060, 'interactivity': 3061, 'nsf': 3062, 'funding': 3063, 'thresholding': 3064, 'multiprocessors': 3065, 'nasa': 3066, 'banks': 3067, 'debugger': 3068, 'math': 3069, 'rigorous': 3070, 'typical': 3071, 'accelerated': 3072, 'backup': 3073, 'philosophy': 3074, 'subsets': 3075, 'participation': 3076, 'square': 3077, 'succinct': 3078, 'velocity': 3079, 'hit': 3080, 'recognize': 3081, 'plagiarism': 3082, 'given': 3083, 'ajax': 3084, 'cryptographically': 3085, 'era': 3086, 'implicatures': 3087, 'bipartite': 3088, 'thumb': 3089, 'thought': 3090, 'has': 3091, 'discontinuities': 3092, 'narratives': 3093, 'developer': 3094, 'mashup': 3095, 'sampled': 3096, 'hypertree': 3097, 'third': 3098, 'valid': 3099, 'delivering': 3100, 'metatheory': 3101, 'overload': 3102, 'garden': 3103, 'female': 3104, 'broadening': 3105, 'categorisation': 3106, 'descriptors': 3107, 'title': 3108, 'effectively': 3109, 'chunking': 3110, 'mixing': 3111, 'dense': 3112, 'rime': 3113, 'extensional': 3114, 'imbalanced': 3115, 'insight': 3116, 'configuring': 3117, 'versioned': 3118, 'competition': 3119, 'multiway': 3120, 'tournament': 3121, 'equilibrium': 3122, 'abstracts': 3123, 'cots': 3124, 'soar': 3125, 'conjunctions': 3126, 'eliciting': 3127, 'conference': 3128, 'translate': 3129, 'laplacian': 3130, 'nf2': 3131, 'perceptual': 3132, 'evolvable': 3133, 'talk': 3134, 'normalizing': 3135, 'compiled': 3136, 'invention': 3137, 'vehicles': 3138, 'oodbms': 3139, 'puzzle': 3140, 'benefit': 3141, 'episodes': 3142, 'give': 3143, 'whose': 3144, 'portability': 3145, 'universities': 3146, 'throughout': 3147, 'reminiscences': 3148, 'influential': 3149, 'folding': 3150, 'child': 3151, 'leak': 3152, 'formulating': 3153, 'enabled': 3154, 'systolic': 3155, 'rue': 3156, 'cells': 3157, 'culture': 3158, 'encapsulation': 3159, 'comprehensibility': 3160, 'substructure': 3161, 'hyperlinks': 3162, 'nomadic': 3163, 'schedules': 3164, 'hypothetical': 3165, 'spin': 3166, 'disambiguating': 3167, 'aspectual': 3168, 'layers': 3169, 'philosophers': 3170, 'cancer': 3171, 'securing': 3172, 'unbounded': 3173, 'specialized': 3174, 'scattergather': 3175, 'adequacy': 3176, 'thin': 3177, 'turning': 3178, 'bed': 3179, 'verified': 3180, 'interpolation': 3181, 'recommending': 3182, 'packages': 3183, 'various': 3184, 'certification': 3185, 'causality': 3186, 'sections': 3187, 'hide': 3188, 'choose': 3189, 'bdds': 3190, 'learnability': 3191, 'slam': 3192, 'odmg': 3193, 'naming': 3194, 'every': 3195, 'visualizations': 3196, 'capacity': 3197, 'internationalization': 3198, 'subclass': 3199, 'multilabel': 3200, 'manifesto': 3201, 'covers': 3202, 'nulls': 3203, 'discriminating': 3204, 'multiplication': 3205, 'anomalous': 3206, 'guessing': 3207, 'reversing': 3208, 'bloom': 3209, 'covariance': 3210, 'ownership': 3211, 'cc': 3212, 'translators': 3213, 'whom': 3214, 'markers': 3215, 'preparation': 3216, 'hci': 3217, 'angle': 3218, 'populated': 3219, 'ratings': 3220, 'lifecycle': 3221, 'basket': 3222, 'removing': 3223, 'iconic': 3224, 'times': 3225, 'treating': 3226, 'propositions': 3227, 'opportunistic': 3228, 'brokering': 3229, 'faculty': 3230, 'discipline': 3231, 'groupware': 3232, 'iterator': 3233, 'wild': 3234, 'remarks': 3235, 'construct': 3236, 'phoneme': 3237, 'educators': 3238, 'marketplace': 3239, 'contour': 3240, 'closest': 3241, 'contribution': 3242, 'preferential': 3243, 'acquired': 3244, 'adaboost': 3245, 'start': 3246, 'simulating': 3247, 'hindi': 3248, 'illinois': 3249, 'sessions': 3250, 'volume': 3251, '99': 3252, 'improves': 3253, 'haskell': 3254, 'diversification': 3255, 'keyframe': 3256, 'iii': 3257, 'folksonomy': 3258, 'car': 3259, 'holdem': 3260, 'removal': 3261, 'anti': 3262, 'converting': 3263, 'bagging': 3264, 'kdd': 3265, 'reclamation': 3266, 'displays': 3267, 'raid': 3268, 'genome': 3269, 'banner': 3270, 'national': 3271, 'monotonicity': 3272, 'innovative': 3273, 'retrieve': 3274, 'autoepistemic': 3275, 'microprocessor': 3276, 'overlap': 3277, 'folksonomies': 3278, 'informal': 3279, 'multifaceted': 3280, 'create': 3281, 'minority': 3282, 'material': 3283, 'sap': 3284, 'coefficient': 3285, 'connectives': 3286, 'v': 3287, 'hunt': 3288, 'person': 3289, 'manifolds': 3290, 'medium': 3291, 'grading': 3292, 'isometric': 3293, 'thesauri': 3294, 'talking': 3295, 'intervals': 3296, 'forest': 3297, 'coral': 3298, 'revolution': 3299, 'detectors': 3300, 'equational': 3301, 'gps': 3302, 'cell': 3303, 'behind': 3304, 'qualifiers': 3305, 'gold': 3306, 'actor': 3307, 'union': 3308, 't': 3309, 'fitting': 3310, 'du': 3311, 'oral': 3312, 'uses': 3313, 'primary': 3314, 'round': 3315, 'repair': 3316, 'coalescing': 3317, 'supports': 3318, 'them': 3319, 'representative': 3320, 'intonational': 3321, 'spreadsheet': 3322, 'convolution': 3323, 'truth': 3324, 'penalty': 3325, 'spilling': 3326, 'dec': 3327, 'theme': 3328, 'bucket': 3329, 'evidential': 3330, 'restart': 3331, 'tpc': 3332, 'bodies': 3333, 'chaining': 3334, 'schemata': 3335, 'still': 3336, 'decidability': 3337, 'according': 3338, 'integrator': 3339, 'nouns': 3340, 'simulated': 3341, 'referencing': 3342, 'coherence': 3343, 'exist': 3344, 'dag': 3345, 'erp': 3346, 'datr': 3347, 'adapted': 3348, 'island': 3349, 'jungle': 3350, 'customizing': 3351, 'overhead': 3352, 'positions': 3353, 'freshman': 3354, 'singular': 3355, 'follow': 3356, 'rationale': 3357, 'taint': 3358, 'aging': 3359, 'promotion': 3360, 'freely': 3361, 'redescription': 3362, 'replay': 3363, 'reconfigurable': 3364, 'economics': 3365, 'parsimonious': 3366, 'positives': 3367, 'scanning': 3368, 'scientists': 3369, 'superoptimizer': 3370, 'lsh': 3371, 'grace': 3372, 'classic': 3373, 'freshmen': 3374, 'mindstorms': 3375, 'disaster': 3376, 'african': 3377, 'american': 3378, 'him': 3379, 'broadcasts': 3380, 'backjumping': 3381, 'ria': 3382, 'ap': 3383, 'ndcg': 3384, 'calendar': 3385, 'pushdown': 3386, 'clique': 3387, 'letting': 3388, 'cat': 3389, 'say': 3390, 'defects': 3391, 'eufid': 3392, 'after': 3393, 'kernelized': 3394, 'viewed': 3395, 'w3qs': 3396, 'survivability': 3397, 'ethical': 3398, 'accounting': 3399, 'inspired': 3400, 'tutors': 3401, 'health': 3402, 'von': 3403, 'interestingness': 3404, 'emotional': 3405, 'certified': 3406, 'pronouns': 3407, 'maintain': 3408, 'echo': 3409, 'anticipating': 3410, 'harmonic': 3411, 'variational': 3412, 'junction': 3413, 'asymmetric': 3414, 'decomposing': 3415, 'outsourcing': 3416, 'fixpoints': 3417, 'firing': 3418, 'coalitions': 3419, 'macros': 3420, 'exponentially': 3421, 'animations': 3422, 'sift': 3423, 'privatization': 3424, 'oo': 3425, 'hilbert': 3426, 'mosaic': 3427, 'mark': 3428, 'queueing': 3429, 'subtypes': 3430, 'optimisation': 3431, 'respond': 3432, 'performances': 3433, 'telegraph': 3434, 'indicators': 3435, 'newton': 3436, 'smooth': 3437, 'payment': 3438, 'repairing': 3439, 'dls': 3440, 'analysing': 3441, 'cohesion': 3442, 'summarisation': 3443, 'schemasql': 3444, 'guest': 3445, 'skip': 3446, 'prune': 3447, 'cosine': 3448, 'reconsideration': 3449, 'judgements': 3450, 'worst': 3451, 'subtype': 3452, 'care': 3453, 'cpu': 3454, 'orchestra': 3455, 'unusual': 3456, 'terabyte': 3457, 'sized': 3458, 'shaping': 3459, 'formally': 3460, 'interpreted': 3461, 'agree': 3462, 'identifiability': 3463, 'geographically': 3464, 'supervision': 3465, 'statistically': 3466, 'lookup': 3467, 'simplification': 3468, 'apply': 3469, 'catching': 3470, 'myths': 3471, 'days': 3472, 'stride': 3473, 'department': 3474, 'thai': 3475, 'ccgbank': 3476, 'little': 3477, 'responses': 3478, 'ultra': 3479, 'dyadic': 3480, 'captions': 3481, 'existential': 3482, 'intentional': 3483, 'metu': 3484, 'satisfiable': 3485, 'workbench': 3486, 'handwritten': 3487, 'circumscribing': 3488, 'isomorphism': 3489, 'zoo': 3490, 'centrality': 3491, 'sketched': 3492, 'acceleration': 3493, 'revised': 3494, 'cyc': 3495, 'prioritization': 3496, 'implement': 3497, 'scalability': 3498, 'increase': 3499, 'realising': 3500, 'syntactified': 3501, 'backwards': 3502, 'controllers': 3503, 'fairness': 3504, 'perceived': 3505, 'stock': 3506, 'misuse': 3507, 'bigrams': 3508, 'combinator': 3509, 'variability': 3510, 'budget': 3511, 'plots': 3512, 'speculation': 3513, 'formulations': 3514, 'crawlers': 3515, 'diam': 3516, 'texture': 3517, 'assign': 3518, 'gist': 3519, 'knowledgeable': 3520, 'per': 3521, 'affinity': 3522, 'regeneration': 3523, 'acronym': 3524, 'credit': 3525, 'clp': 3526, '95': 3527, 'nuggets': 3528, 'definitional': 3529, 'trained': 3530, 'pearl': 3531, 'prefix': 3532, 'atoms': 3533, 'reconciling': 3534, 'clarification': 3535, 'guiding': 3536, 'impaired': 3537, 'thumbs': 3538, 'compacting': 3539, 'cf': 3540, 'diagnosability': 3541, '6': 3542, 'leakage': 3543, 'quantiles': 3544, 'subjective': 3545, 'affect': 3546, 'xprs': 3547, 'selections': 3548, 'gossiping': 3549, 'unnesting': 3550, 'member': 3551, 'devise': 3552, 'dialect': 3553, 'maybe': 3554, 'section': 3555, 'actively': 3556, 'steroids': 3557, 'mention': 3558, 'maxent': 3559, 'reciprocal': 3560, 'accents': 3561, 'suppressed': 3562, 'rooted': 3563, 'par': 3564, 'le': 3565, 'taken': 3566, 'dom': 3567, 'freeness': 3568, 'indivisible': 3569, 'mailing': 3570, 'regulatory': 3571, 'mine': 3572, 'alc': 3573, 'ratio': 3574, 'qos': 3575, 'incompleteness': 3576, 'degrees': 3577, 'freedom': 3578, 'immune': 3579, 'rasdaman': 3580, 'exercises': 3581, 'disambiguate': 3582, 'chatting': 3583, 'collectors': 3584, 'disequilibrium': 3585, 'sloan': 3586, 'oop': 3587, 'topically': 3588, 'discount': 3589, 'critiquing': 3590, 'occlusion': 3591, 'shapelets': 3592, 'interrupts': 3593, 'ddb': 3594, 'nature': 3595, 'logically': 3596, 'wallet': 3597, 'seemed': 3598, 'spill': 3599, 'tumor': 3600, 'reaching': 3601, 'motivational': 3602, 'unsatisfiability': 3603, 'drawings': 3604, 'magnitude': 3605, 'fix': 3606, 'delimited': 3607, 'heads': 3608, 'graduates': 3609, 'compatible': 3610, 'tight': 3611, 'auc': 3612, 'pareto': 3613, 'maturity': 3614, 'gradual': 3615, 'addition': 3616, 'studio': 3617, 'tying': 3618, 'subquery': 3619, 'disc': 3620, 'subtopic': 3621, 'fresh': 3622, 'marginal': 3623, 'coordinates': 3624, 'channels': 3625, 'drug': 3626, 'sequoia': 3627, 'prefer': 3628, 'observer': 3629, 'costly': 3630, 'explainable': 3631, 'tactical': 3632, 'storing': 3633, 'administration': 3634, 'compete': 3635, 'superscalar': 3636, 'superimposed': 3637, 'subsumers': 3638, 'eportal': 3639, 'empirically': 3640, 'janus': 3641, 'centers': 3642, 'offering': 3643, 'verbmobil': 3644, 'coach': 3645, 'antlima': 3646, 'autonomy': 3647, 'even': 3648, 'managers': 3649, 'paragraph': 3650, 'rectangle': 3651, 'kronecker': 3652, 'burst': 3653, 'behavioural': 3654, 'justification': 3655, 'dominators': 3656, 'banking': 3657, 'genes': 3658, 'wildcards': 3659, 'surf': 3660, 'height': 3661, 'cougar': 3662, 'lrtak': 3663, 'metonymy': 3664, 'developed': 3665, 'cascaded': 3666, 'tutor': 3667, 'adjustment': 3668, 'pac': 3669, 'planners': 3670, 'dbs': 3671, 'my': 3672, 'swing': 3673, 'xtra': 3674, 'semidefinite': 3675, 'corba': 3676, 'connect': 3677, 'yield': 3678, 'differing': 3679, 'address': 3680, 'animate': 3681, 'lexicalised': 3682, 'advance': 3683, 'organizer': 3684, 'ltag': 3685, 'ephemeral': 3686, 'martingale': 3687, 'calling': 3688, 'predicted': 3689, 'cape': 3690, 'advisor': 3691, 'wrap': 3692, 'fluid': 3693, 'externalities': 3694, 'psychology': 3695, 'translator': 3696, 'gait': 3697, 'intellectual': 3698, 'basics': 3699, 'instructors': 3700, 'striping': 3701, 'thresholds': 3702, 'delay': 3703, 'scripts': 3704, 'bridge': 3705, 'philosophical': 3706, 'modest': 3707, 'influencing': 3708, 'constraining': 3709, 'oss': 3710, 'encouraging': 3711, 'achievement': 3712, 'gmap': 3713, 'huge': 3714, 'uncovering': 3715, 'blogscope': 3716, 'outer': 3717, 'california': 3718, 'railroad': 3719, 'scopes': 3720, 'lilog': 3721, 'vdm': 3722, 'strudel': 3723, 'eos': 3724, 'targeted': 3725, 'paradigmatic': 3726, 'timing': 3727, 'counterfactuals': 3728, 'lingo': 3729, 'checkpoints': 3730, 'longevity': 3731, 'dbmss': 3732, 'limiting': 3733, 'preferred': 3734, 'dialectical': 3735, 'unexpected': 3736, 'platforms': 3737, 'multinomial': 3738, 'repeated': 3739, 'associating': 3740, 'perceptions': 3741, 'entropic': 3742, 'paging': 3743, 'fetches': 3744, 'authentication': 3745, 'investment': 3746, 'extensive': 3747, 'populations': 3748, 'inapplicable': 3749, 'storm': 3750, 'introspection': 3751, 'disjunction': 3752, 'convergent': 3753, 'plsa': 3754, 'deepening': 3755, 'workplace': 3756, 'inexpensive': 3757, 'factoid': 3758, 'observational': 3759, 'reasoners': 3760, 'magnetic': 3761, 'strictly': 3762, 'inlining': 3763, 'mcdb': 3764, 'modifying': 3765, 'intermittently': 3766, 'scans': 3767, 'bandwidth': 3768, 'hints': 3769, 'informatics': 3770, 'backbones': 3771, 'backdoors': 3772, 'tac': 3773, 'passages': 3774, 'direction': 3775, 'atlas': 3776, 'maze': 3777, 'targets': 3778, 'unfamiliar': 3779, 'clip': 3780, 'participants': 3781, 'lattices': 3782, 'determine': 3783, 'subgoal': 3784, 'systemt': 3785, 'accent': 3786, 'architecting': 3787, 'gesture': 3788, 'truncated': 3789, 'circular': 3790, 'sublanguage': 3791, 'incentive': 3792, 'synchronisation': 3793, 'damping': 3794, 'exclusion': 3795, 'modularization': 3796, 'phonemes': 3797, 'z': 3798, 'idlp': 3799, 'dnnf': 3800, 'relatively': 3801, 'redundancies': 3802, 'propbank': 3803, 'mentions': 3804, 'notification': 3805, 'parametricity': 3806, 'revelation': 3807, 'return': 3808, 'densification': 3809, 'crowds': 3810, 'decomposability': 3811, 'disseminating': 3812, 'linearizing': 3813, 'amazons': 3814, 'itemset': 3815, 'debate': 3816, 'malware': 3817, 'gray': 3818, 'offs': 3819, 'money': 3820, 'crimes': 3821, 'forum': 3822, 'gradients': 3823, 'gibbs': 3824, 'fun': 3825, 'convenient': 3826, 'motor': 3827, 'typechecking': 3828, 'ended': 3829, 'linker': 3830, 'astral': 3831, 'connectors': 3832, 'guidelines': 3833, 'motifs': 3834, 'resiliency': 3835, 'oil': 3836, 'equipment': 3837, 'accelerator': 3838, 'previews': 3839, 'spider': 3840, 'prioritizing': 3841, 'quadratically': 3842, 'figures': 3843, 'commitments': 3844, 'jawaa': 3845, 'formations': 3846, 'adaptivity': 3847, 'oid': 3848, 'european': 3849, 'abstracting': 3850, 'may': 3851, 'want': 3852, 'experiencing': 3853, 'idioms': 3854, 'drawing': 3855, 'literal': 3856, 'cryptographic': 3857, 'percentile': 3858, 'runs': 3859, 'revenue': 3860, 'branches': 3861, 'led': 3862, 'deduplication': 3863, 'intents': 3864, 'overlapped': 3865, 'quantifiers': 3866, 'translational': 3867, 'derivatives': 3868, 'miss': 3869, 'assertions': 3870, 'eth': 3871, 'zurich': 3872, 'synopsis': 3873, 'perplexity': 3874, 'subset': 3875, 'mars': 3876, 'customers': 3877, 'boat': 3878, 'el': 3879, 'bcnf': 3880, 'institutions': 3881, 'quizzes': 3882, 'reaction': 3883, 'circuit': 3884, 'burstiness': 3885, 'enriching': 3886, 'publish': 3887, 'subscribe': 3888, 'negotiating': 3889, 'five': 3890, 'ten': 3891, 'decide': 3892, 'whether': 3893, 'schedule': 3894, 'continuously': 3895, 'carrier': 3896, 'hiv': 3897, 'therapy': 3898, 'valency': 3899, 'pedagogical': 3900, 'competing': 3901, 'reserve': 3902, 'prices': 3903, 'bids': 3904, 'cellular': 3905, 'positional': 3906, 'bubble': 3907, 'enactment': 3908, 'acoustic': 3909, 'spotting': 3910, 'constituents': 3911, 'indian': 3912, 'explorer': 3913, 'rationality': 3914, 'formatting': 3915, 'teamwork': 3916, 'intra': 3917, 'curves': 3918, 'rendering': 3919, 'espresso': 3920, 'harvesting': 3921, 'conjunction': 3922, 'vldb': 3923, 'measured': 3924, 'vectorization': 3925, 'tail': 3926, 'shilling': 3927, 'profit': 3928, 'prima': 3929, 'airphys': 3930, 'wheel': 3931, 'encompass': 3932, 'radar': 3933, 'microcomputer': 3934, 'distributive': 3935, 'stereotype': 3936, 'cinematic': 3937, 'weather': 3938, 'forecasts': 3939, 'codd': 3940, 'fp': 3941, 'residual': 3942, 'wall': 3943, 'abnormality': 3944, 'recording': 3945, 'reasons': 3946, 'roll': 3947, 'requires': 3948, 'accelerate': 3949, 'lifting': 3950, 'srl': 3951, 'pathfinder': 3952, 'holmes': 3953, 'enity': 3954, 'satisfy': 3955, 'certain': 3956, 'topss': 3957, 'nonstop': 3958, 'players': 3959, 'disruptions': 3960, 'discoveries': 3961, 'trie': 3962, 'tokens': 3963, 'hierarchic': 3964, 'truthful': 3965, 'climbing': 3966, 'slices': 3967, 'successive': 3968, 'updated': 3969, 'simplicity': 3970, 'prospects': 3971, 'token': 3972, 'partitions': 3973, 'metaphors': 3974, 'securely': 3975, 'embracing': 3976, 'warping': 3977, 'markup': 3978, 'xxl': 3979, 'implicitly': 3980, 'centroid': 3981, 'pcfg': 3982, 'rethinking': 3983, 'eca': 3984, 'ida': 3985, 'euclidean': 3986, 'mereological': 3987, 'insertion': 3988, 'restoration': 3989, 'semitic': 3990, 'odometry': 3991, 'id': 3992, 'exogenous': 3993, 'markovian': 3994, 'navigator': 3995, 'black': 3996, 'ride': 3997, 'xslt': 3998, '4th': 3999, 'achievements': 4000, 'xrpc': 4001, 'photographs': 4002, 'container': 4003, 'reviewers': 4004, 'isomorphisms': 4005, 'prove': 4006, 'url': 4007, 'cliques': 4008, 'efficacy': 4009, 'reexamining': 4010, 'complementary': 4011, 'fourth': 4012, 'polysemy': 4013, 'man': 4014, 'repeats': 4015, 'repeat': 4016, 'yahoos': 4017, 'rough': 4018, 'insights': 4019, 'close': 4020, 'splines': 4021, 'also': 4022, 'necessary': 4023, 'weakest': 4024, 'sufficient': 4025, 'comic': 4026, 'surrogate': 4027, 'synergistic': 4028, 'commentary': 4029, 'recompilation': 4030, 'water': 4031, 'repetition': 4032, 'crawl': 4033, 'marked': 4034, 'problematic': 4035, 'deferred': 4036, 'inferential': 4037, 'cpus': 4038, 'unify': 4039, 'multiview': 4040, 'enforce': 4041, 'se': 4042, 'ramifications': 4043, 'qualifications': 4044, 'smash': 4045, 'interruptions': 4046, 'configurable': 4047, 'sigmod': 4048, 'j2ee': 4049, 'normality': 4050, 'literate': 4051, 'designer': 4052, 'dags': 4053, 'tiered': 4054, 'marking': 4055, 'rural': 4056, 'th': 4057, 'netflix': 4058, 'prize': 4059, 'unifies': 4060, 'audit': 4061, 'parent': 4062, 'unaware': 4063, 'gsp': 4064, 'mixin': 4065, 'windowed': 4066, 'interrupted': 4067, 'musical': 4068, 'ancient': 4069, 'mrfs': 4070, 'triple': 4071, 'beginners': 4072, 'harder': 4073, 'having': 4074, 'surprising': 4075, 'protection': 4076, 'restful': 4077, 'contrasting': 4078, 'earley': 4079, 'cryptanalysis': 4080, 'consciousness': 4081, 'widening': 4082, 'contraction': 4083, 'clickstreams': 4084, 'successes': 4085, 'oov': 4086, 'compute': 4087, 'generics': 4088, 'oracle8i': 4089, 'binarization': 4090, 'apache': 4091, 'phylogenetic': 4092, 'humming': 4093, 'epic': 4094, 'homogeneous': 4095, 'coordinated': 4096, 'backdoor': 4097, 'upon': 4098, 'assist': 4099, 'retaining': 4100, 'configurations': 4101, 'apparent': 4102, 'book': 4103, 'gestalt': 4104, 'indonesian': 4105, 'salient': 4106, 'deadline': 4107, 'predictability': 4108, 'preserves': 4109, 'being': 4110, 'monads': 4111, 'probing': 4112, 'away': 4113, 'homepage': 4114, 'begin': 4115, 'permanent': 4116, 'morph': 4117, 'kinds': 4118, 'compilability': 4119, 'seek': 4120, 'death': 4121, 'inconsistencies': 4122, 'integrative': 4123, 'condition': 4124, 'realisation': 4125, 'selected': 4126, 'cohesive': 4127, 'bracketed': 4128, 'observing': 4129, 'adtrees': 4130, 'winwin': 4131, 'hopfield': 4132, 'existence': 4133, 'rss': 4134, 'stm': 4135, 'inventories': 4136, 'interleaved': 4137, 'allens': 4138, 'plsi': 4139, 'bilexical': 4140, 'extent': 4141, 'combating': 4142, 'air': 4143, 'recommend': 4144, 'assumption': 4145, 'matcher': 4146, 'powered': 4147, 'segmented': 4148, 'unsegmented': 4149, 'stanford': 4150, 'emphasizing': 4151, 'signs': 4152, 'geotagging': 4153, 'serf': 4154, 'secret': 4155, 'format': 4156, 'box': 4157, 'titles': 4158, 'advancement': 4159, 'taggers': 4160, 'asknet': 4161, 'species': 4162, 'meet': 4163, 'fail': 4164, 'personalize': 4165, 'onboard': 4166, 'penn': 4167, 'multigram': 4168, 'sigma': 4169, 'misses': 4170, 'contradiction': 4171, 'exam': 4172, 'coming': 4173, 'age': 4174, 'xtract': 4175, '2002': 4176, 'japan': 4177, 'occurrences': 4178, 'entries': 4179, 'icon': 4180, 'timeline': 4181, 'movement': 4182, 'urban': 4183, 'city': 4184, 'looking': 4185, 'glass': 4186, 'front': 4187, 'cardinalities': 4188, 'reconciliation': 4189, 'blocks': 4190, 'scales': 4191, 'ends': 4192, 'preventing': 4193, 'learns': 4194, 'isolated': 4195, '0': 4196, 'constructivist': 4197, 'compress': 4198, 'interleaving': 4199, 'dissimilarity': 4200, 'moment': 4201, 'delegation': 4202, 'desires': 4203, 'intentions': 4204, 'invariance': 4205, 'reviewing': 4206, 'crisis': 4207, 'currying': 4208, 'reservoir': 4209, 'tale': 4210, 'multicomputer': 4211, 'winning': 4212, 'senseclusters': 4213, 'asymmetry': 4214, 'wrappers': 4215, 'transferring': 4216, 'vocabularies': 4217, 'crowdsourcing': 4218, 'controllability': 4219, 'longest': 4220, 'canadian': 4221, 'traveller': 4222, 'move': 4223, 'joining': 4224, 'deducing': 4225, 'mcmc': 4226, 'minimally': 4227, 'solvers': 4228, 'created': 4229, 'separate': 4230, 'borealis': 4231, 'accounts': 4232, 'frequencies': 4233, 'respect': 4234, 'untrusted': 4235, 'iid': 4236, 'seeing': 4237, 'dbo': 4238, 'delaying': 4239, 'photos': 4240, 'isnt': 4241, 'slot': 4242, 'fielded': 4243, 'neighboring': 4244, 'orthographic': 4245, 'kanji': 4246, 'determinism': 4247, 'contingency': 4248, 'strips': 4249, 'thing': 4250, 'genomes': 4251, 'pspace': 4252, 'mined': 4253, 'apples': 4254, 'agility': 4255, 'confusion': 4256, 'working': 4257, 'obtaining': 4258, 'affine': 4259, 'equalities': 4260, 'sonar': 4261, 'electrical': 4262, 'dtds': 4263, 'hungarian': 4264, 'calculations': 4265, 'risky': 4266, 'modulo': 4267, 'recorded': 4268, 'ner': 4269, 'sphere': 4270, 'loose': 4271, 'golog': 4272, 'surveillance': 4273, 'keep': 4274, 'systemic': 4275, 'intensity': 4276, 'calibration': 4277, 'adapt': 4278, 'expansions': 4279, 'monotone': 4280, 'shiq': 4281, 'primitive': 4282, 'influences': 4283, 'agglutinative': 4284, 'mirroring': 4285, 'urbana': 4286, 'champaign': 4287, 'needed': 4288, 'vr': 4289, 'throughput': 4290, 'scrolling': 4291, 'hardness': 4292, 'limitations': 4293, 'plausible': 4294, 'reformulations': 4295, 'fluent': 4296, 'marker': 4297, 'artifacts': 4298, 'clips': 4299, 'intonation': 4300, 'rufus': 4301, 'texas': 4302, 'contours': 4303, 'voted': 4304, 'labelling': 4305, 'larger': 4306, 'artists': 4307, 'contact': 4308, 'ancestors': 4309, 'grna': 4310, 'multiobjective': 4311, 'sealed': 4312, 'initialization': 4313, 'lead': 4314, 'explanatory': 4315, 'hyperparameter': 4316, 'copying': 4317, 'compliant': 4318, 'elastic': 4319, 'visible': 4320, 'employing': 4321, 'backward': 4322, 'recursively': 4323, 'narrative': 4324, 'ticket': 4325, 'allowing': 4326, 'debates': 4327, 'spots': 4328, 'emergence': 4329, 'matter': 4330, 'u': 4331, 'obtain': 4332, 'pools': 4333, 'vertically': 4334, 'browsers': 4335, 'refresh': 4336, 'equal': 4337, 'incorporation': 4338, 'mesh': 4339, 'supply': 4340, 'cope': 4341, 'fill': 4342, 'decomposable': 4343, 'lesson': 4344, 'tablet': 4345, 'spanning': 4346, 'dissimilarities': 4347, 'bea': 4348, 'oblivious': 4349, '2nd': 4350, 'spread': 4351, 'c45': 4352, 'oar': 4353, 'tolerance': 4354, 'r3': 4355, 'dynalab': 4356, 'check': 4357, 'multiplicative': 4358, 'dutch': 4359, 'cis': 4360, 'described': 4361, 'gr8': 4362, 'executive': 4363, 'twitter': 4364, 'faster': 4365, 'upper': 4366, 'nonlocal': 4367, 'facial': 4368, 'photo': 4369, 'things': 4370, 'multiuser': 4371, 'collusion': 4372, 'trenches': 4373, 'czech': 4374, 'grammatically': 4375, 'pro': 4376, 'automaton': 4377, 'memex': 4378, 'cfg': 4379, 'shading': 4380, 'aggregations': 4381, 'structurally': 4382, 'landmarks': 4383, 'lineage': 4384, 'compounds': 4385, 'adjuncts': 4386, 'substitutions': 4387, 'personalised': 4388, 'damia': 4389, 'fit': 4390, 'sm3': 4391, 'toolbox': 4392, 'separating': 4393, 'roots': 4394, 'aggregated': 4395, 'combinational': 4396, 'canonical': 4397, 'objectives': 4398, 'pulse': 4399, 'fad': 4400, 'adaptively': 4401, 'addressable': 4402, 'introduce': 4403, 'recapture': 4404, 'fluency': 4405, 'metarules': 4406, 'neat': 4407, 'storytelling': 4408, 'terminal': 4409, 'votes': 4410, 'institute': 4411, 'prefetch': 4412, 'aspectj': 4413, 'forums': 4414, 'shedding': 4415, 'intuition': 4416, 'neuroevolution': 4417, 'psi': 4418, 'calculation': 4419, 'swoogle': 4420, 'professional': 4421, 'patr': 4422, 'commutativity': 4423, 'anchors': 4424, 'conventional': 4425, 'outerjoin': 4426, 'agglomerative': 4427, 'contingent': 4428, 'flight': 4429, 'insensitive': 4430, 'usable': 4431, 'additional': 4432, 'kaleidoscope': 4433, '15': 4434, 'raw': 4435, 'matchmaking': 4436, 'posts': 4437, 'synchronizing': 4438, 'usefulness': 4439, 'overflows': 4440, 'precedence': 4441, 'conformance': 4442, 'reflective': 4443, 'clash': 4444, 'intuitions': 4445, 'vulnerabilities': 4446, 'textes': 4447, 'lexique': 4448, '80': 4449, 'rebuild': 4450, 'dining': 4451, 'directly': 4452, 'backed': 4453, 'postprocessing': 4454, 'encoded': 4455, '2d': 4456, 'beam': 4457, 'consequences': 4458, 'opponent': 4459, 'outreach': 4460, 'wish': 4461, 'targeting': 4462, 'audiovideo': 4463, 'mac': 4464, 'asymmetrical': 4465, 'ds': 4466, 'nodose': 4467, 'rigid': 4468, 'morpheus': 4469, 'scan': 4470, 'pl': 4471, 'thanks': 4472, 'anonymization': 4473, 'newsgroups': 4474, 'synonyms': 4475, 'guidance': 4476, 'polyphonic': 4477, 'mongolian': 4478, 'exploit': 4479, 'lp': 4480, 'norms': 4481, 'multirelational': 4482, 'ambient': 4483, 'untagged': 4484, 'symbols': 4485, 'avoid': 4486, 'guaranteeing': 4487, 'weblog': 4488, '7': 4489, 'six': 4490, 'essay': 4491, 'positioning': 4492, 'deployed': 4493, 'tenth': 4494, 'revising': 4495, 'themed': 4496, 'histories': 4497, 'trio': 4498, 'theres': 4499, 'taming': 4500, 'funnel': 4501, 'nombank': 4502, 'queuing': 4503, 'collected': 4504, 'denial': 4505, 'zooming': 4506, 'proposing': 4507, 'paid': 4508, 'imperatives': 4509, 'alphanumeric': 4510, 'watermarking': 4511, 'isomorphic': 4512, 'replicator': 4513, 'selectional': 4514, 'x86': 4515, 'sg': 4516, 'ternary': 4517, 'sampler': 4518, 'dp': 4519, 'multikey': 4520, 'stretching': 4521, 'clearing': 4522, 'fidelity': 4523, 'imposition': 4524, 'sector': 4525, 'biases': 4526, 'assessments': 4527, 'curb': 4528, 'engagement': 4529, 'chess': 4530, 'approximators': 4531, 'redesign': 4532, 'bushy': 4533, 'feasible': 4534, 'anticipation': 4535, 'assess': 4536, 'threading': 4537, 'ungrammatical': 4538, 'organic': 4539, 'licensing': 4540, 'sirius': 4541, 'formalizing': 4542, 'dominator': 4543, 'cuts': 4544, 'detector': 4545, 'interpersonal': 4546, 'cleanroom': 4547, 'oversubscribed': 4548, 'highlight': 4549, 'phrasing': 4550, 'categorized': 4551, 'broker': 4552, '2009': 4553, 'shortcut': 4554, 'flux': 4555, 'references': 4556, 'featuring': 4557, 'formalized': 4558, 'clientserver': 4559, 'websites': 4560, 'dtls': 4561, 'dataspot': 4562, 'applicability': 4563, 'since': 4564, 'vliw': 4565, 'body': 4566, 'adhoc': 4567, 'raid5': 4568, 'captcha': 4569, 'healing': 4570, 'attempt': 4571, 'duplicates': 4572, 'patients': 4573, 'programmable': 4574, 'animating': 4575, 'wait': 4576, 'fisher': 4577, 'brute': 4578, 'recruitment': 4579, 'cite': 4580, 'scholarly': 4581, 'stacking': 4582, 'copyright': 4583, 'seamless': 4584, 'buy': 4585, 'whitebox': 4586, 'fuzzing': 4587, 'receptive': 4588, 'anyway': 4589, 'caches': 4590, 'sparql': 4591, 'immersive': 4592, 'spamming': 4593, 'bookmarking': 4594, 'numbering': 4595, 'effortless': 4596, 'funbase': 4597, 'feaspar': 4598, 'scenic': 4599, 'webanywhere': 4600, 'screen': 4601, 'exsearch': 4602, 'barter': 4603, 'aol': 4604, 'cryptanalytic': 4605, 'pseudorandom': 4606, 'nonexistence': 4607, 'usually': 4608, 'manipulate': 4609, 'contradictory': 4610, 'revival': 4611, 'mouse': 4612, 'rim': 4613, 'bsr': 4614, 'teg': 4615, 'localisation': 4616, 'blood': 4617, 'transfusion': 4618, 'porting': 4619, 'roadmap': 4620, 'members': 4621, 'survive': 4622, 'outlines': 4623, 'archived': 4624, 'span': 4625, 'envisioning': 4626, 'itineraries': 4627, 'wellmade': 4628, 't4sql': 4629, 'performamatics': 4630, 'taj': 4631, 'reorderable': 4632, 'freespan': 4633, 'jukebox': 4634, 'benign': 4635, 'racesallusing': 4636, 'dantes': 4637, 'decreased': 4638, 'rdbv1': 4639, 'inline': 4640, 'trains': 4641, 'marketed': 4642, 'denali': 4643, 'lexeme': 4644, 'computationaily': 4645, 'everything': 4646, 's81': 4647, 'zoomuserviews': 4648, 'latency': 4649, 'gess': 4650, 'interactively': 4651, 'wordnets': 4652, 'unbundling': 4653, 'psst': 4654, 'political': 4655, 'outcomes': 4656, 'hospital': 4657, 'disjoint': 4658, 'poor': 4659, 'cognates': 4660, 'added': 4661, 'abuse': 4662, 'signing': 4663, 'rsa': 4664, 'monkeys': 4665, 'millennial': 4666, 'classificatory': 4667, 'hyperbf': 4668, 'ipse': 4669, 'anyone': 4670, 'precluding': 4671, 'saiu': 4672, 'nrrc': 4673, 'bfnumdocs': 4674, 'thor': 4675, 'cmradar': 4676, 'pronunciations': 4677, 'wysiwyg': 4678, 'forwarding': 4679, 'shake': 4680, 'bake': 4681, 'paraccel': 4682, 'medusa': 4683, 'xsds': 4684, 'morphographemic': 4685, 'nonconcatenative': 4686, 'redefinitions': 4687, 'encountered': 4688, 'supercompilation': 4689, 'contrastive': 4690, 'encapsualtion': 4691, 'computerised': 4692, 'express': 4693, 'transposed': 4694, 'jasmin': 4695, 'societal': 4696, 'memoryless': 4697, 'polyphony': 4698, 'divergences': 4699, 'outsourced': 4700, 'bypass': 4701, 'aerospace': 4702, 'neumann': 4703, 'quantminer': 4704, 'micmac': 4705, 'microprogram': 4706, 'adon': 4707, 'experiencer': 4708, 'proquel': 4709, 'php': 4710, 'sqlxnf': 4711, 'reinforcing': 4712, 'cutting': 4713, '8th': 4714, 'manuals': 4715, 'neptune': 4716, 'netserf': 4717, 'medialife': 4718, 'chronicle': 4719, 'sin': 4720, 'algovista': 4721, 'doubly': 4722, 'biin': 4723, 'evaluability': 4724, 'serfing': 4725, 'cabob': 4726, 'fpgas': 4727, 'subtasks': 4728, 'fcl': 4729, 'tribute': 4730, 'memorial': 4731, 'fractionation': 4732, 'refractionation': 4733, 'swarm': 4734, 'adnoun': 4735, 'supernode': 4736, 'hypertalk': 4737, 'overture': 4738, 'flocks': 4739, 'set®': 4740, 'deformable': 4741, 'lrpd': 4742, 'pinwheel': 4743, 'sides': 4744, 'coin': 4745, 'anorexic': 4746, 'paranoids': 4747, 'semiautomatic': 4748, 'bb1': 4749, 'orkut': 4750, 'transductions': 4751, 'hyperqueries': 4752, 'immix': 4753, 'mutator': 4754, 'equi': 4755, 'personalisation': 4756, 'telecommunications': 4757, 'invalidation': 4758, 'cam': 4759, 'jazz': 4760, 'impure': 4761, 'reformatting': 4762, 'header': 4763, 'interferring': 4764, 'emulator': 4765, 'helpful': 4766, 'biclustering': 4767, 'pcfgs': 4768, 'machinima': 4769, 'impressionrank': 4770, 'sectioning': 4771, 'regex': 4772, 'card': 4773, 'swarms': 4774, 'defensive': 4775, 'climate': 4776, 'carefully': 4777, 'swizzling': 4778, 'webware': 4779, 'letter': 4780, 'especial': 4781, '1991': 4782, 'incentives': 4783, 'granularities': 4784, 'analogic': 4785, 'locker': 4786, 'extensiblerule': 4787, 'passenger': 4788, 'airline': 4789, 'apportioning': 4790, 'baffling': 4791, 'factual': 4792, 'situationactivation': 4793, 'bimodal': 4794, 'fingerprinting': 4795, 'gregress': 4796, 'ohsumed': 4797, 'hol': 4798, 'metapher': 4799, 'sniafl': 4800, 'period': 4801, 'compensations': 4802, 'overseas': 4803, 'discord': 4804, 'ablation': 4805, 'shadowed': 4806, 'predilection': 4807, 'topigraphy': 4808, 'vita': 4809, 'dlfm': 4810, 'boxing': 4811, 'symbology': 4812, 'arrangement': 4813, 'ensembling': 4814, 'affiliated': 4815, 'biwtl': 4816, 'useless': 4817, 'statistice': 4818, 'aspiration': 4819, 'cnn': 4820, 'idiolectic': 4821, 'doctor': 4822, 'matches': 4823, 'ao': 4824, 'sei': 4825, 'repartitioning': 4826, 'inspecting': 4827, 'placing': 4828, 'intensities': 4829, 'lars': 4830, 'recommenders': 4831, 'lexicalising': 4832, 'hat': 4833, 'diagrama': 4834, 'turbo': 4835, 'charging': 4836, 'spontaneously': 4837, 'dxq': 4838, 'dust': 4839, 'microeconomic': 4840, 'warp': 4841, 'routine': 4842, 'gio': 4843, 'cubetree': 4844, 'sesame': 4845, 'deceptively': 4846, 'ures': 4847, 'methodological': 4848, 'trey': 4849, 'tempus': 4850, 'fugit': 4851, 'winrdbi': 4852, 'refitting': 4853, 'slides': 4854, 'tabletpc': 4855, 'uncertainties': 4856, 'demonizing': 4857, 'symbol': 4858, 'sri': 4859, 'carpenter': 4860, 'representativeness': 4861, 'walkthroughs': 4862, 'icicles': 4863, 'ratios': 4864, 'abbreviations': 4865, 'dataplorer': 4866, 'edict': 4867, 'bumps': 4868, 'curvature': 4869, 'zodiac': 4870, 'federation': 4871, 'cim': 4872, 'migrating': 4873, 'electronics': 4874, 'quark': 4875, 'resampling': 4876, 'financially': 4877, 'encina': 4878, 'db2xml': 4879, 'representationalist': 4880, 'adlads': 4881, 'upperbounds': 4882, 'streamglobe': 4883, 'youre': 4884, 'turnstile': 4885, 'linda': 4886, 'spmt': 4887, 'rpj': 4888, 'admit': 4889, 'conspiracy': 4890, 'pid': 4891, 'plow': 4892, 'instrumentation': 4893, 'hyperfairness': 4894, 'monadic': 4895, 'eql': 4896, 'bounce': 4897, 'advertisements': 4898, 'slim': 4899, 'adequate': 4900, 'polylingual': 4901, 'spotsigs': 4902, 'melbourne': 4903, 'individualism': 4904, 'parameterizable': 4905, 'balance': 4906, 'vickrey': 4907, 'exchanges': 4908, 'chase': 4909, 'framenet': 4910, 'loadstore': 4911, 'solves': 4912, 'semiconductor': 4913, 'crosslingual': 4914, 'inside': 4915, 'giuku': 4916, 'utilities': 4917, 'camouflaged': 4918, 'horting': 4919, 'hatches': 4920, 'egg': 4921, 'exclaim': 4922, 'eden': 4923, 'cohersion': 4924, 'rated': 4925, 'master': 4926, 'substrate': 4927, 'davis': 4928, 'putnam': 4929, 'outerplanar': 4930, 'central': 4931, 'tip': 4932, 'informix': 4933, 'artdb': 4934, 'taxation': 4935, 'sustainable': 4936, 'chillers': 4937, 'functionally': 4938, 'rstar': 4939, 'concentration': 4940, 'ming': 4941, 'statix': 4942, 'automatized': 4943, 'dances': 4944, 'cause': 4945, 'checklist': 4946, 'nah': 4947, 'syndrome': 4948, 'sinuhe': 4949, 'ado': 4950, 'mediating': 4951, 'orientated': 4952, 'scarce': 4953, 'dialogic': 4954, 'walrus': 4955, 'redo': 4956, 'tolerating': 4957, 'disagreement': 4958, 'rapidity': 4959, 'started': 4960, 'p2cast': 4961, 'patching': 4962, 'symrnetric': 4963, 'rlsc': 4964, 'agony': 4965, 'interform': 4966, 'gas': 4967, 'turbine': 4968, 'proliant': 4969, 'multimode': 4970, 'summarize': 4971, 'universe': 4972, 'vista': 4973, 'mapgraph': 4974, 'labelled': 4975, 'cpcv': 4976, 'generations': 4977, 'overcome': 4978, 'developmentevolution': 4979, 'deeper': 4980, 'qrelx': 4981, 'geospatially': 4982, 'photograph': 4983, 'perf': 4984, 'bloomjoin': 4985, 'teapot': 4986, 'beaten': 4987, 'subword': 4988, 'critics': 4989, 'substantional': 4990, 'enclosing': 4991, 'balls': 4992, 'emoticons': 4993, 'eyed': 4994, 'stereo': 4995, 'archjava': 4996, 'crossing': 4997, 'controller': 4998, 'assembler': 4999, 'mrdsm': 5000, 'timer': 5001, 'alerters': 5002, 'lob': 5003, 'talisman': 5004, 'un': 5005, 'système': 5006, 'gouverné': 5007, 'lois': 5008, 'linguistiques': 5009, 'pour': 5010, 'traitement': 5011, 'langue': 5012, 'naturelle': 5013, 'mcs': 5014, 'reconstruct': 5015, 'ascription': 5016, 'dynamo': 5017, 'moded': 5018, 'prime': 5019, 'implicate': 5020, 'quantifiable': 5021, 'chatty': 5022, 'renderman': 5023, 'kernelizing': 5024, 'pls': 5025, 'memoization': 5026, 'fax': 5027, 'proda': 5028, 'ink': 5029, 'taco': 5030, 'statisticalscientific': 5031, 'bnchmark': 5032, 'ulixes': 5033, 'gpx': 5034, 'paradise': 5035, 'occasions': 5036, 'factorial': 5037, 'cgcexplorer': 5038, 'treedt': 5039, 'sdss': 5040, 'skyserver': 5041, 'exercising': 5042, 'handy': 5043, 'trac': 5044, 'selforganizing': 5045, 'reuters': 5046, 'poison': 5047, 'pills': 5048, 'miqis': 5049, 'chained': 5050, 'subdialogues': 5051, 'virtualized': 5052, 'seismic': 5053, 'treisman': 5054, 'workshops': 5055, 'rewards': 5056, 'hypothesized': 5057, 'asserting': 5058, 'preemptive': 5059, 'deoptimization': 5060, 'adms±': 5061, 'workstation': 5062, 'mainframe': 5063, 'gorder': 5064, '17th': 5065, 'inex': 5066, 'ferry': 5067, 'optics': 5068, 'infeasible': 5069, 'stanislavskian': 5070, 'dualminer': 5071, 'lung': 5072, 'markerless': 5073, 'gating': 5074, 'radiotherapy': 5075, 'cybercivics': 5076, 'gunsat': 5077, 'aktionsarten': 5078, 'gsat': 5079, 'urgent': 5080, 'subseries': 5081, 'movers': 5082, 'topp': 5083, 'comfort': 5084, 'korea': 5085, 'coa': 5086, 'patents': 5087, 'artemis': 5088, 'lagrangian': 5089, 'tails': 5090, 'struggles': 5091, 'recompression': 5092, 'carousel': 5093, 'morpiiemes': 5094, 'bellman': 5095, 'piloted': 5096, 'rmses': 5097, 'presenters': 5098, 'remembering': 5099, 'jule': 5100, 'neuro': 5101, 'muse': 5102, 'tricks': 5103, 'traps': 5104, 'initiating': 5105, 'opsm': 5106, 'epdl': 5107, 'dirty': 5108, 'contained': 5109, 'animated': 5110, 'winmagic': 5111, 'compilable': 5112, 'delicious': 5113, 'xquisite': 5114, 'multitext': 5115, 'pomdp': 5116, 'aviation': 5117, 'rolex': 5118, 'navigable': 5119, 'simplifications': 5120, 'isotonic': 5121, 'programing': 5122, 'worm': 5123, 'discs': 5124, 'glue': 5125, 'carbohydrate': 5126, 'multirobot': 5127, 'eggyolk': 5128, 'sorts': 5129, 'fm91': 5130, 'ocam': 5131, 'spinning': 5132, 'italian': 5133, 'dbcache': 5134, 'splice': 5135, 'doing': 5136, 'satellite': 5137, 'whiteboard': 5138, 'acting': 5139, 'cd': 5140, 'rom': 5141, 'rainforest': 5142, 'requiring': 5143, 'privatizing': 5144, 'thine': 5145, 'enemy': 5146, 'champion': 5147, 'ut': 5148, 'arlington': 5149, 'whisper': 5150, 'retina': 5151, 'anchorwoman': 5152, 'verifier': 5153, 'modularizing': 5154, 'codescriptive': 5155, 'feedforward': 5156, 'timesten': 5157, 'optional': 5158, 'koref': 5159, 'gossip': 5160, 'slow': 5161, 'illumination': 5162, 'odd': 5163, 'coordinators': 5164, 'responders': 5165, 'shakespeare': 5166, 'explication': 5167, 'articulatory': 5168, 'opening': 5169, 'eyes': 5170, 'armor': 5171, 'los': 5172, 'angeles': 5173, 'airport': 5174, 'cone': 5175, 'sqlb': 5176, 'consumers': 5177, 'hydra': 5178, 'auv': 5179, 'desktops': 5180, 'motif': 5181, 'gr2': 5182, 'trigger': 5183, 'shopsmart': 5184, 'crfs': 5185, 'lk': 5186, 'pier': 5187, 'luby': 5188, 'rackoff': 5189, 'negotiators': 5190, 'win': 5191, 'arbus': 5192, 'iphones': 5193, 'phones': 5194, 'oh': 5195, 'advertise': 5196, 'inexact': 5197, 'publications': 5198, 'speechlanguage': 5199, 'spellchecking': 5200, 'autocorrection': 5201, 'inspector': 5202, 'fringe': 5203, 'saving': 5204, 'warning': 5205, 'vulnerability': 5206, 'orderings': 5207, 'radically': 5208, 'statechart': 5209, 'valuable': 5210, 'compared': 5211, 'own': 5212, 'armed': 5213, 'presuppositional': 5214, 'pdms': 5215, 'shard': 5216, 'laura': 5217, 'her': 5218, 'algorithmics': 5219, 'cui': 5220, 'spark': 5221, 'beacond': 5222, 'counterexample': 5223, 'xseq': 5224, 'campaign': 5225, 'informatively': 5226, 'meinongian': 5227, 'pintos': 5228, 'prescription': 5229, 'admission': 5230, 'underspecification': 5231, 'transitivity': 5232, 'foregrounding': 5233, 'summarising': 5234, 'noa': 5235, 'normative': 5236, 'congruences': 5237, 'topologically': 5238, 'fpga': 5239, 'tower': 5240, 'straw': 5241, 'hypotheticals': 5242, 'holder': 5243, 'conventions': 5244, 'filing': 5245, 'stripes': 5246, 'tuned': 5247, 'complementarities': 5248, 'tdlambda': 5249, 'eligibility': 5250, 'further': 5251, 'topaz': 5252, 'parallelizer': 5253, 'sanitization': 5254, 'terminator': 5255, 'unrestrictd': 5256, 'gapping': 5257, 'rely': 5258, 'bigsur': 5259, 'koda': 5260, 'enumerating': 5261, 'popel': 5262, 'counters': 5263, 'sale': 5264, 'scrap': 5265, 'triggering': 5266, 'florid': 5267, 'centred': 5268, 'incompletely': 5269, 'boltzrank': 5270, 'maximize': 5271, 'matesek': 5272, 'ring': 5273, 'sarms': 5274, 'cocomo': 5275, 'uflip': 5276, 'staggered': 5277, 'statestep': 5278, 'cm': 5279, 'eves': 5280, 'tp': 5281, 'counterfactual': 5282, 'conditioning': 5283, 'inferred': 5284, 'decompose': 5285, 'vault': 5286, 'ibe': 5287, 'confidential': 5288, 'drafting': 5289, 'pods': 5290, 'nominals': 5291, 'pylonic': 5292, 'eeg': 5293, 'epileptic': 5294, 'seizures': 5295, 'cacheportal': 5296, 'hosted': 5297, 'dsdt': 5298, 'durable': 5299, 'xvm': 5300, 'credibility': 5301, 'brier': 5302, 'potentialities': 5303, 'reducers': 5304, 'redus': 5305, 'swifft': 5306, 'fft': 5307, 'unicorn': 5308, 'seasonality': 5309, 'facile': 5310, 'simulators': 5311, 'parlog': 5312, 'superoperators': 5313, 'screamer': 5314, 'deserialization': 5315, 'fl': 5316, 'cayuga': 5317, 'dstributed': 5318, 'genealogy': 5319, 'ideas': 5320, 'vietnamese': 5321, 'isalog': 5322, 'amongst': 5323, 'vital': 5324, 'randomizing': 5325, 'virtualization': 5326, 'ims': 5327, 'impedance': 5328, 'syntagmatic': 5329, 'powerdb': 5330, 'involving': 5331, 'abstaining': 5332, 'totally': 5333, 'recrawl': 5334, 'dark': 5335, 'sgs': 5336, 'uncontrollable': 5337, 'cockpit': 5338, 'senior': 5339, 'concatenative': 5340, 'morphotactics': 5341, 'affects': 5342, 'giving': 5343, 'omt': 5344, 'scaffolding': 5345, 'flexibility': 5346, 'pane': 5347, 'residues': 5348, 'orchestrating': 5349, 'multicore': 5350, 'muvis': 5351, 'motivations': 5352, 'inspiring': 5353, 'pursue': 5354, 'chatbots': 5355, 'imt': 5356, 'pathologies': 5357, 'cooperate': 5358, 'sparq2l': 5359, 'rendezvous': 5360, 'penalized': 5361, 'determinant': 5362, 'amalgamating': 5363, 'viper': 5364, 'jmocha': 5365, 'bc': 5366, 'opponents': 5367, 'origins': 5368, 'suppressing': 5369, 'trainable': 5370, 'finders': 5371, 'adams': 5372, 'alliances': 5373, 'multilayered': 5374, 'aer': 5375, 'warnings': 5376, 'threats': 5377, 'idm': 5378, 'reap': 5379, 'corroborate': 5380, 'mutually': 5381, 'establishment': 5382, 'hybridized': 5383, 'locksmith': 5384, 'challenged': 5385, 'qcsp': 5386, 'nonprofits': 5387, 'shoqd': 5388, 'forcing': 5389, 'testability': 5390, 'maximally': 5391, 'pinpointing': 5392, 'dedicated': 5393, 'qursed': 5394, 'restructured': 5395, 'agreements': 5396, 'essentials': 5397, 'bucketing': 5398, 'wheat': 5399, 'voxelwise': 5400, 'resonance': 5401, 'canlogs': 5402, 'gate': 5403, 'seasons': 5404, 'farm': 5405, 'looks': 5406, 'taxis': 5407, 'lime': 5408, 'ups': 5409, 'downs': 5410, 'preposition': 5411, 'esl': 5412, 'trobe': 5413, 'poliqarp': 5414, 'indexer': 5415, 'palka': 5416, 'sifting': 5417, 'sda': 5418, 'cai': 5419, 'superlatives': 5420, 'meetings': 5421, 'csrs': 5422, 'excon': 5423, 'advocating': 5424, 'webview': 5425, 'hyperbolic': 5426, 'plane': 5427, 'adheat': 5428, 'ecosystem': 5429, 'sustainability': 5430, 'blockwise': 5431, 'landscan': 5432, 'alerter': 5433, 'referent': 5434, 'datarace': 5435, 'deadlocks': 5436, 'realizations': 5437, 'interact': 5438, 'scm': 5439, 'scored': 5440, 'expanded': 5441, 'charalign': 5442, 'byte': 5443, 'screens': 5444, 'recasting': 5445, 'sigcse': 5446, 'knack': 5447, '11g': 5448, 'cvdb': 5449, '2004': 5450, 'attracting': 5451, 'keeping': 5452, 'brightest': 5453, 'experienced': 5454, 'hddbs': 5455, 'countability': 5456, 'withouta': 5457, 'priori': 5458, 'personalizing': 5459, 'wip': 5460, 'intellimedia': 5461, 'wsqdsq': 5462, 'interfacile': 5463, 'rasp': 5464, 'asam': 5465, 'odx': 5466, 'oodbs': 5467, 'vyrd': 5468, 'ccal': 5469, 'questionnaire': 5470, 'trailfinding': 5471, 'logistics': 5472, 'debug': 5473, 'associational': 5474, 'flowcharts': 5475, 'blending': 5476, 'tcoz': 5477, 'algol': 5478, 'ecr': 5479, 'tasktracker': 5480, 'majsat': 5481, 'mierucompiler': 5482, 'ironing': 5483, 'clotho': 5484, 'awaredav': 5485, 'rollups': 5486, 'leveled': 5487, 'pundit': 5488, 'gcx': 5489, 'defacto': 5490, 'incident': 5491, 'commanders': 5492, 'overconstrained': 5493, 'resilient': 5494, 'propagator': 5495, 'sequel': 5496, 'might': 5497, 'thinker': 5498, 'agency': 5499, 'closegraph': 5500, 'turk': 5501, 'junit': 5502, 'gauss': 5503, 'unbalanced': 5504, 'saying': 5505, 'already': 5506, 'capitalized': 5507, 'fintime': 5508, 'exits': 5509, 'reopening': 5510, 'song': 5511, 'tapping': 5512, 'nearly': 5513, 'geominer': 5514, 'coevolving': 5515, 'mice': 5516, 'rewritings': 5517, 'laundering': 5518, 'fabrication': 5519, 'tangible': 5520, 'creativity': 5521, 'dnf': 5522, 'needle': 5523, 'invasive': 5524, 'actuated': 5525, 'detectioncorrection': 5526, 'casee': 5527, 'rediscovering': 5528, 'passion': 5529, 'beauty': 5530, 'joy': 5531, 'awe': 5532, 'continued': 5533, 'webdiplomat': 5534, 'multilist': 5535, 'affiliation': 5536, 'ford': 5537, 'xpathxslt': 5538, 'poogle': 5539, 'lrt': 5540, 'ip': 5541, 'jibiki': 5542, 'lexalp': 5543, 'interbase': 5544, 'ergonomics': 5545, 'siebel': 5546, 'mechanizing': 5547, 'sage': 5548, 'sqout': 5549, 'workblench': 5550, 'dbis': 5551, 'variations': 5552, 'forensic': 5553, 'tampering': 5554, 'dereference': 5555, 'mppm': 5556, 'consolution': 5557, 'www2004': 5558, 'lowell': 5559, 'misclassification': 5560, 'pcb': 5561, 'drilling': 5562, 'redefining': 5563, 'paraphrase': 5564, 'ungreedy': 5565, 'probalistic': 5566, 'evil': 5567, 'flexibly': 5568, 'mergepurge': 5569, 'captioned': 5570, 'mathfind': 5571, 'rights': 5572, 'duties': 5573, 'accessed': 5574, 'scr': 5575, 'uqlips': 5576, 'centralization': 5577, 'whither': 5578, '21': 5579, 'dart': 5580, 'wiki': 5581, 'svg': 5582, 'continous': 5583, 'visiprog': 5584, 'inherently': 5585, 'brooks': 5586, 'coopware': 5587, 'masters': 5588, 'families': 5589, 'timegraphs': 5590, 'suboptimal': 5591, 'singleton': 5592, 'microprogramming': 5593, 'watch': 5594, 'reminding': 5595, 'idiomatic': 5596, 'rel': 5597, 'laterally': 5598, 'spiking': 5599, 'neurons': 5600, 'relying': 5601, 'lof': 5602, 'gnu': 5603, 'mobide': 5604, 'cybertech': 5605, 'sensible': 5606, 'biosurveillance': 5607, 'indexicals': 5608, 'demonstratives': 5609, 'egalitarist': 5610, 'incommensurable': 5611, 'concolic': 5612, 'missed': 5613, 'actual': 5614, 'gamps': 5615, 'amplitude': 5616, 'compaction': 5617, 'overlays': 5618, 'papyrus': 5619, '6th': 5620, 'setl': 5621, 'renaissance': 5622, 'unitran': 5623, 'superior': 5624, 'hgdm': 5625, 'ac': 5626, 'apis': 5627, 'siren': 5628, 'hyperrectangle': 5629, 'declustered': 5630, 'deafault': 5631, 'angular': 5632, 'reputable': 5633, 'servents': 5634, 'subtask': 5635, 'extrapolation': 5636, 'jeroo': 5637, 'majority': 5638, 'aliases': 5639, 'pengi': 5640, 'rivaling': 5641, 'professionals': 5642, 'fusing': 5643, 'communicative': 5644, 'mips': 5645, 'snitch': 5646, 'paste': 5647, 'tickets': 5648, 'terminals': 5649, 'occam': 5650, 'gamma': 5651, 'schems': 5652, 'scratch': 5653, 'alphasort': 5654, 'interfacing': 5655, 'colorblind': 5656, 'coallocation': 5657, 'collaborations': 5658, 'punctuated': 5659, 'trips': 5660, 'valuation': 5661, 'sqlem': 5662, 'emergency': 5663, 'triage': 5664, 'wrong': 5665, 'waves': 5666, 'redesigning': 5667, 'plackett': 5668, 'luce': 5669, 'multimediaminer': 5670, 'emperical': 5671, 'redux': 5672, 'qsf': 5673, 'attacking': 5674, 'decipherment': 5675, 'entrans': 5676, 'edsc': 5677, 'vectorial': 5678, 'exprim': 5679, 'rivage': 5680, 'orthotics': 5681, 'custom': 5682, 'reassignment': 5683, 'realization': 5684, 'weaknesses': 5685, 'incoherency': 5686, 'aggregators': 5687, 'obsolescent': 5688, 'warlock': 5689, 'batmobile': 5690, 'taxi': 5691, 'synergy': 5692, 'cpoe': 5693, 'eel': 5694, 'stimuli': 5695, 'syntemic': 5696, 'fg': 5697, 'minute': 5698, 'later': 5699, 'socp': 5700, 'interpreternative': 5701, 'sensitivities': 5702, 'thermodynamics': 5703, 'eddies': 5704, 'xl': 5705, 'expose': 5706, 'cs2cs7': 5707, 'following': 5708, 'validated': 5709, 'tab': 5710, 'emphasis': 5711, 'promising': 5712, 'wring': 5713, 'dry': 5714, 'sellers': 5715, 'buyers': 5716, 'shill': 5717, 'fees': 5718, '200': 5719, 'cmerun': 5720, 'tapestry': 5721, 'maneuvering': 5722, 'obstacles': 5723, 'quadtree': 5724, 'vc': 5725, 'exceptional': 5726, 'deliberation': 5727, 'thousands': 5728, 'archaeological': 5729, 'selc': 5730, 'playback': 5731, 'continuity': 5732, 'pooled': 5733, 'slavic': 5734, 'condensed': 5735, 'dtps': 5736, 'tcsps': 5737, 'truecasing': 5738, '78': 5739, 'preceding': 5740, 'ethernet': 5741, 'multigraphs': 5742, 'phonetic': 5743, 'omes': 5744, 'webkhoj': 5745, 'lsl': 5746, 'selector': 5747, 'componentware': 5748, 'requirementsassurances': 5749, 'hadoop': 5750, 'netnews': 5751, 'mdm': 5752, 'mbdp': 5753, 'subsetting': 5754, 'superposition': 5755, 'discotect': 5756, 'traveled': 5757, 'baccalaureate': 5758, 'sustain': 5759, 'ghost': 5760, 'introspective': 5761, 'bitwidth': 5762, 'multipurpose': 5763, 'indeterminancy': 5764, 'memeta': 5765, 'mutable': 5766, 'ss': 5767, 'translingual': 5768, 'sos': 5769, 'evolve': 5770, 'irregularity': 5771, 'hamming': 5772, 'skoll': 5773, 'scaffolded': 5774, 'rbe': 5775, 'productions': 5776, 'reductions': 5777, 'phantom': 5778, 'predicative': 5779, 'demands': 5780, 'explosion': 5781, 'bunsetsu': 5782, 'hough': 5783, 'enable': 5784, 'petroglyphs': 5785, 'swiss': 5786, 'listener': 5787, 'reader': 5788, 'exterminator': 5789, 'biographical': 5790, 'independently': 5791, 'safeguard': 5792, 'uc': 5793, 'simlist': 5794, 'lexikon': 5795, 'helps': 5796, 'indic': 5797, 'train': 5798, 'interchange': 5799, 'imaged': 5800, 'pdf': 5801, 'biotech': 5802, 'translated': 5803, 'micronet': 5804, 'hypercubes': 5805, 'instantiations': 5806, 'kcat': 5807, 'intervention': 5808, 'darshak': 5809, 'degrading': 5810, 'animator': 5811, 'cl': 5812, 'researchs': 5813, 'fastest': 5814, 'odyssey': 5815, 's5': 5816, 'microfeature': 5817, 'rices': 5818, 'quicklink': 5819, 'heart': 5820, 'decaying': 5821, 'vanity': 5822, 'querylog': 5823, 'bundles': 5824, 'delexical': 5825, 'usenet': 5826, 'gral': 5827, 'c2c': 5828, 'cool': 5829, 'machiavelli': 5830, 'border': 5831, 'redistribution': 5832, 'broaden': 5833, 'resistance': 5834, 'relocation': 5835, 'wirelessmobile': 5836, 'metadatabase': 5837, 'rensselaer': 5838, 'engineer': 5839, 'pepx': 5840, 'burden': 5841, 'collinearity': 5842, 'nonnumeric': 5843, 'correctly': 5844, 'picnics': 5845, 'kittens': 5846, 'wigs': 5847, 'g': 5848, 'goat': 5849, 'sqlmx': 5850, 'jerpa': 5851, 'cloze': 5852, 'temperature': 5853, '3w': 5854, 'stereotypes': 5855, 'sddm': 5856, 'cypress': 5857, 'taker': 5858, 'verbalizes': 5859, 'practicum': 5860, 'perusing': 5861, 'videodisk': 5862, 'sematically': 5863, 'bell': 5864, 'hebrew': 5865, 'secureblox': 5866, 'shoulders': 5867, 'giants': 5868, 'ansisparc': 5869, 'eigenmaps': 5870, 'honors': 5871, 'adapter': 5872, 'sigmoids': 5873, 'frequently': 5874, 'iloc': 5875, 'mtr': 5876, 'corporation': 5877, 'hong': 5878, 'kong': 5879, 'tiled': 5880, 'minimising': 5881, 'automobile': 5882, 'sealing': 5883, 'eve': 5884, 'radixzip': 5885, 'menus': 5886, 'rock': 5887, 'contributed': 5888, 'rankcut': 5889, 'rewriter': 5890, 'neuroimagery': 5891, 'pop': 5892, 'maritime': 5893, 'cracked': 5894, 'amelioration': 5895, 'arieskvl': 5896, 'multiaction': 5897, 'webviews': 5898, 'ocfs': 5899, 'glr': 5900, 'hundreds': 5901, 'interlisp': 5902, 'paving': 5903, 'diligent': 5904, 'eight': 5905, 'scc': 5906, 'dcc': 5907, 'implicature': 5908, 'rbf': 5909, 'weesa': 5910, 'dblearn': 5911, 'xinuwu': 5912, 'xinu': 5913, 'csis': 5914, 'deconstructing': 5915, 'diacritics': 5916, 'clue': 5917, 'returned': 5918, 'semint': 5919, 'rao': 5920, 'blackwellised': 5921, 'writable': 5922, 'disclosure': 5923, 'hippocratic': 5924, 'abridged': 5925, 'historically': 5926, 'colleges': 5927, 'objectbase': 5928, 'ucair': 5929, 'toolbar': 5930, 'remora': 5931, 'triangulated': 5932, 'metaphoric': 5933, 'coercion': 5934, '21st': 5935, 'mindset': 5936, 'cyberporn': 5937, 'chicago': 5938, 'lognormal': 5939, 'erasure': 5940, 'nusmv': 5941, 'slm': 5942, 'arboreal': 5943, 'prow': 5944, 'shipping': 5945, 'astronomy': 5946, 'serving': 5947, 'submitted': 5948, 'manuscripts': 5949, 'questionanswering': 5950, 'misconceptions': 5951, 'todays': 5952, 'hypercard': 5953, 'accommodating': 5954, 'follower': 5955, 'offset': 5956, 'multiaccess': 5957, 'assets': 5958, 'toys': 5959, 'aboutness': 5960, 'gaze': 5961, 'extractive': 5962, 'udfs': 5963, 'invalidity': 5964, 'allocating': 5965, 'eliminate': 5966, 'trnon': 5967, 'ansductive': 5968, 'airweb': 5969, 'decorrelation': 5970, 'lookups': 5971, 'founded': 5972, 'reasoner': 5973, 'itself': 5974, 'enthusiasm': 5975, 'cook': 5976, 'pet': 5977, 'erroneous': 5978, 'coko': 5979, 'allocator': 5980, 'shifting': 5981, 'agatha': 5982, 'christie': 5983, 'leads': 5984, 'geodesic': 5985, 'boosted': 5986, 'diathesis': 5987, 'alternations': 5988, 'combinators': 5989, 'ariescsa': 5990, 'tribes': 5991, 'knit': 5992, 'employment': 5993, 'montagues': 5994, 'dragon': 5995, 'hunters': 5996, 'nnow': 5997, 'nurbs': 5998, 'minijava': 5999, 'samos': 6000, 'growing': 6001, 'cord': 6002, 'appraoch': 6003, 'ntcir': 6004, 'strongest': 6005, 'disorder': 6006, 'suitable': 6007, 'tridirectional': 6008, 'monothetic': 6009, 'practive': 6010, 'reactions': 6011, 'applicable': 6012, 'pens': 6013, 'shuffling': 6014, 'stacked': 6015, 'deck': 6016, 'vlkdbs': 6017, 'intermodule': 6018, 'supervaluation': 6019, 'inland': 6020, 'monic': 6021, 'multicluster': 6022, 'grafting': 6023, 'comex': 6024, 'commodities': 6025, 'finance': 6026, 'suspects': 6027, 'laws': 6028, 'shrinking': 6029, 'diameters': 6030, 'academically': 6031, 'vrifa': 6032, 'nomogram': 6033, 'radial': 6034, 'lrbf': 6035, 'pathfinding': 6036, 'sitemaps': 6037, 'above': 6038, 'duty': 6039, 'lhrs': 6040, 'overtly': 6041, 'uddi': 6042, 'registries': 6043, 'regrets': 6044, 'observability': 6045, 'mood': 6046, 'til': 6047, 'sofis': 6048, 'replace': 6049, 'wsj': 6050, 'mainteinability': 6051, 'transportable': 6052, 'iterators': 6053, 'readable': 6054, 'filename': 6055, 'nul': 6056, 'maxsat': 6057, 'modification': 6058, 'hahacronym': 6059, 'invocation': 6060, 'ptime': 6061, 'coercive': 6062, 'descriptiveness': 6063, 'caseframe': 6064, 'late': 6065, 'ce2': 6066, 'commandtalk': 6067, 'harry': 6068, 'met': 6069, 'harri': 6070, 'hunter': 6071, 'gatherer': 6072, 'socqet': 6073, 'yap3': 6074, 'seurat': 6075, 'earlier': 6076, 'disciplined': 6077, 'icse99': 6078, 'bifocal': 6079, 'microsurgery': 6080, 'nugget': 6081, 'consolidation': 6082, 'naturalistic': 6083, 'nonstationary': 6084, 'stamps': 6085, 'esa': 6086, 'rays': 6087, 'neurorule': 6088, 'skeptical': 6089, 'lifelog': 6090, 'bgp': 6091, 'lens': 6092, 'joysticks': 6093, 'mippets': 6094, 'dbir': 6095, 'standalone': 6096, 'uncooperative': 6097, 'suspend': 6098, 'resume': 6099, 'rotating': 6100, 'odeview': 6101, 'updatability': 6102, 'malm': 6103, 'old': 6104, 'pharse': 6105, 'progres': 6106, 'scaleable': 6107, 'pessimistic': 6108, 'bt': 6109, 'branched': 6110, 'did': 6111, 'trax': 6112, 'ifo': 6113, 'definites': 6114, 'toy': 6115, 'arm': 6116, 'emperiment': 6117, 'authorizations': 6118, 'lexicalist': 6119, 'icelandic': 6120, 'ruralcafe': 6121, 'w': 6122, 'pan': 6123, 'cb': 6124, 'ranksql': 6125, 'potts': 6126, 'mft': 6127, 'caramel': 6128, 'curry': 6129, 'howard': 6130, 'differentially': 6131, 'contenders': 6132, 'deobfuscation': 6133, 'preconditioned': 6134, 'algres': 6135, 'chimera': 6136, 'onion': 6137, 'kidney': 6138, 'magead': 6139, 'dialects': 6140, 'transmutation': 6141, 'mccs': 6142, 'didactic': 6143, 'dialectic': 6144, 'headline': 6145, 'intertask': 6146, 'exr': 6147, 'pivotunpivot': 6148, 'lapses': 6149, 'resumption': 6150, 'loads': 6151, 'tempoexpress': 6152, 'expressivity': 6153, 'tempo': 6154, 'impacts': 6155, 'reproduction': 6156, 'ica': 6157, 'wizards': 6158, 'wikispeedia': 6159, 'starving': 6160, 'hitting': 6161, 'kriegspiel': 6162, 'metapositions': 6163, 'harm': 6164, 'mismatch': 6165, 'lama': 6166, 'absolute': 6167, 'pennies': 6168, 'touch': 6169, 'restricting': 6170, 'aquery': 6171, 'pqc': 6172, 'matchsim': 6173, 'superdatabases': 6174, 'protel': 6175, 'umlanalyzer': 6176, 'satcsp': 6177, 'expander': 6178, 'nesc': 6179, 'pact': 6180, 'delinearization': 6181, 'break': 6182, 'multiloop': 6183, 'specificity': 6184, 'amnesic': 6185, 'snefru': 6186, 'transcripts': 6187, 'polyhedra': 6188, 'underapproximation': 6189, 'hyrex': 6190, 'rehist': 6191, 'bundle': 6192, 'fire': 6193, 'bm25': 6194, 'csql': 6195, 'dynamicity': 6196, 'bilvideo': 6197, 'contemplate': 6198, 'columnsort': 6199, 'subgroups': 6200, 'golden': 6201, 'controversies': 6202, 'syncro': 6203, 'lilithmodula': 6204, 'knows': 6205, 'sovereign': 6206, 'lossy': 6207, 'stamped': 6208, 'smartback': 6209, 'recallprecision': 6210, 'quickmig': 6211, 'diagnosers': 6212, 'controlflow': 6213, 'lack': 6214, 'linux': 6215, 'tapes': 6216, 'hold': 6217, 'investing': 6218, 'featherweight': 6219, 'exposing': 6220, 'internals': 6221, 'leo': 6222, 'db2s': 6223, 'tic': 6224, 'toe': 6225, 'tba': 6226, 'gloss': 6227, 'pointless': 6228, 'pda': 6229, 'tucking': 6230, 'rcc': 6231, 'cycs': 6232, 'xsb': 6233, 'operability': 6234, 'interruptible': 6235, 'insure': 6236, 'granting': 6237, 'cky': 6238, 'instantaneous': 6239, 'anything': 6240, 'worth': 6241, 'crimson': 6242, 'flexrecs': 6243, 'contacts': 6244, 'belong': 6245, 'theft': 6246, 'ellipsoid': 6247, 'rankboost': 6248, 'facet': 6249, 'landscapes': 6250, 'functor': 6251, 'perm': 6252, 'cpr': 6253, 'molecules': 6254, 'flaws': 6255, 'clare': 6256, 'briefings': 6257, 'protdb': 6258, 'cyclone': 6259, 'interventional': 6260, 'pull': 6261, 'rogue': 6262, 'segmental': 6263, 'jitter': 6264, 'eccles': 6265, 'achievent': 6266, 'israeli': 6267, 'neighborhoods': 6268, 'unlocking': 6269, 'awarding': 6270, 'verifiable': 6271, 'allocated': 6272, 'develop': 6273, 'tutorials': 6274, 'mariko': 6275, 'talks': 6276, 'siegfried': 6277, 'japanesegerman': 6278, 'warriors': 6279, 'phobes': 6280, 'attitude': 6281, 'easiest': 6282, 'ridl': 6283, 'bearing': 6284, 'imputing': 6285, 'spatiotemporalspatiotemporal': 6286, 'reversal': 6287, 'utile': 6288, 'distinctions': 6289, 'outside': 6290, 'chiron': 6291, 'simfusion': 6292, 'warfare': 6293, 'expanding': 6294, 'pivot': 6295, 'inaccessible': 6296, 'foci': 6297, 'intersystem': 6298, 'gated': 6299, 'multipipeline': 6300, 'triangle': 6301, 'utaclir': 6302, 'toponym': 6303, 'birch': 6304, 'iepad': 6305, 'collative': 6306, 'straightforward': 6307, 'xmldb': 6308, 'breakout': 6309, 'remember': 6310, 'think': 6311, 'executions': 6312, 'paintingclass': 6313, 'sometimes': 6314, 'aggregating': 6315, 'jpredictor': 6316, 'ecrins86': 6317, 'lets': 6318, 'transient': 6319, 'compensating': 6320, 'picodmbs': 6321, 'smartcard': 6322, 'adapters': 6323, 'tailored': 6324, 'ggraphlog': 6325, 'transpose': 6326, 'demystified': 6327, 'florida': 6328, 'vambam': 6329, 'omnidirectional': 6330, 'kc3': 6331, 'mash': 6332, 'opinionated': 6333, 'kinematic': 6334, 'articulated': 6335, 'slca': 6336, 'aptitude': 6337, 'attains': 6338, 'blast': 6339, 'guarded': 6340, 'redirection': 6341, 'gmine': 6342, 'fixing': 6343, 'polynominal': 6344, 'packet': 6345, 'tpm': 6346, 'informality': 6347, 'boredom': 6348, 'consolidating': 6349, 'pachinko': 6350, 'testtube': 6351, 'parses': 6352, 'satellites': 6353, 'knownet': 6354, 'champagne': 6355, 'tulips': 6356, 'teachable': 6357, 'axis': 6358, 'concomitant': 6359, 'medethex': 6360, 'dyc': 6361, 'javanet': 6362, 'opinionminer': 6363, 'luckiness': 6364, 'prefectching': 6365, 'aroma': 6366, 'hepatitis': 6367, 'quantities': 6368, 'amateurs': 6369, 'premodifiers': 6370, 'revel8or': 6371, 'professionalism': 6372, 'transtrl': 6373, 'locator': 6374, 'rethink': 6375, 'segmentations': 6376, 'democratic': 6377, 'lexicographic': 6378, 'consultation': 6379, 'abbreviation': 6380, 'cla': 6381, 'perturbation': 6382, 'lemma': 6383, 'adaptability': 6384, 'quarks': 6385, 'trustrank': 6386, 'goldilocks': 6387, 'opaque': 6388, 'shangri': 6389, 'reve': 6390, 'participatory': 6391, 'hierachy': 6392, 'crocopat': 6393, 'integers': 6394, 'vipas': 6395, 'galileo': 6396, 'our': 6397, 'extents': 6398, 'exposed': 6399, 'attibute': 6400, 'diversifying': 6401, 'omissions': 6402, 'blas': 6403, 'mammography': 6404, 'isolate': 6405, 'ossd': 6406, 'ldiff': 6407, 'differencing': 6408, 'accelerometer': 6409, 'smdp': 6410, 'homomorphisms': 6411, 'residency': 6412, 'sytems': 6413, 'biosystematics': 6414, 'ofs': 6415, 'odp': 6416, 'sciencecraft': 6417, 'eo': 6418, 'componential': 6419, 'ergodic': 6420, 'tension': 6421, 'reals': 6422, 'merrier': 6423, 'mini': 6424, 'disease': 6425, 'reflexive': 6426, 'cham': 6427, 'eclipse': 6428, 'demaq': 6429, 'orion': 6430, 'postscript': 6431, 'videoreach': 6432, 'enrichment': 6433, 'paraconsistency': 6434, 'chronologies': 6435, 'raster': 6436, 'fictitious': 6437, 'continuum': 6438, 'ficsr': 6439, 'eedback': 6440, 'nonistency': 6441, 'esolution': 6442, 'misaligned': 6443, 'ofcourse': 6444, 'materials': 6445, 'soat': 6446, 'peanut': 6447, 'gallery': 6448, 'assessor': 6449, 'lyapunov': 6450, 'clonetracker': 6451, 'pp': 6452, 'treebanking': 6453, 'blazing': 6454, 'lies': 6455, 'synonymy': 6456, 'eager': 6457, 'books': 6458, 'meronyms': 6459, 'unique': 6460, 'passed': 6461, 'restructure': 6462, 'linkages': 6463, 'sql3': 6464, 'uncorrelated': 6465, 'indiana': 6466, 'purdue': 6467, 'convoy': 6468, 'alice': 6469, 'walkthrough': 6470, 'trail': 6471, 'cutex': 6472, 'lemonade': 6473, 'bright': 6474, 'dr': 6475, 'eventtrigger': 6476, 'unibase': 6477, 'newspaper': 6478, 'xmem': 6479, 'hyperstorm': 6480, 'administering': 6481, 'convolutional': 6482, 'linkclus': 6483, 'identically': 6484, 'progxe': 6485, 'telcordias': 6486, 'unanchored': 6487, 'ignorant': 6488, 'xqbe': 6489, 'correlational': 6490, 'itinerary': 6491, 'beg': 6492, 'cardio': 6493, 'vascular': 6494, 'app': 6495, 'olympic': 6496, 'equestrian': 6497, 'experiential': 6498, 'roadrunner': 6499, 'suitability': 6500, 'kinesthetic': 6501, 'documented': 6502, 'refinements': 6503, 'converter': 6504, 'semirings': 6505, 'definability': 6506, 'piece': 6507, 'addressed': 6508, '5': 6509, 'iwpse': 6510, 'soon': 6511, 'abbreviated': 6512, 'marie': 6513, 'decoder': 6514, 'resolutions': 6515, '1000': 6516, 'commute': 6517, 'potters': 6518, 'dsl': 6519, 'ssc2': 6520, 'skeletons': 6521, 'reproducing': 6522, 'myerson': 6523, 'satterthwaite': 6524, 'impossibility': 6525, 'unweighted': 6526, 'labelers': 6527, 'relaxations': 6528, 'selectors': 6529, 'behaviosites': 6530, 'parasitic': 6531, 'infection': 6532, 'relocating': 6533, 'rerankeverything': 6534, 'mindreader': 6535, 'ultimate': 6536, 'cautious': 6537, 'surfer': 6538, 'joulesort': 6539, 'nero': 6540, 'importing': 6541, 'casting': 6542, 'accumulative': 6543, 'rework': 6544, 'yago': 6545, 'billiards': 6546, 'guesstimate': 6547, 'curing': 6548, '1tn': 6549, 'autocompletion': 6550, 'tolerate': 6551, 'linearizable': 6552, 'snowball': 6553, 'elu': 6554, 'cal': 6555, 'aggie': 6556, 'matic': 6557, 'cybersecurity': 6558, 'glory': 6559, 'contestants': 6560, 'contests': 6561, 'topcodercom': 6562, 'always': 6563, 'appc': 6564, 'enrich': 6565, 'attributio': 6566, 'hypercode': 6567, 'serv': 6568, 'seen': 6569, 'crosslinguistic': 6570, 'motivate': 6571, 'bargaining': 6572, 'become': 6573, 'disaggregation': 6574, 'webcq': 6575, 'psycho': 6576, 'engineered': 6577, 'arizona': 6578, 'tdts': 6579, 'blackboards': 6580, 'hedged': 6581, 'purpors': 6582, 'igrid': 6583, 'gateway': 6584, 'truncations': 6585, 'thresher': 6586, 'unwrapping': 6587, 'wavefront': 6588, 'granular': 6589, 'braid': 6590, 'lag': 6591, 'reasonably': 6592, 'consul': 6593, 'aptness': 6594, 'cast': 6595, 'cleanly': 6596, 'messy': 6597, 'mv3r': 6598, 'timestamp': 6599, 'ondux': 6600, 'supersense': 6601, 'lisfs': 6602, 'mock': 6603, 'trials': 6604, 'asymptotically': 6605, 'qbf': 6606, 'anisotropic': 6607, 'xor': 6608, 'aktionsart': 6609, 'fighting': 6610, 'mixins': 6611, 'inclination': 6612, 'geared': 6613, 'manifest': 6614, 'pwa': 6615, 'sssalpha': 6616, 'debit': 6617, 'found': 6618, 'lexnet': 6619, 'dynamical': 6620, 'basedatabase': 6621, 'appropriateness': 6622, 'handheld': 6623, 'accomodation': 6624, 'multiterm': 6625, 'mca': 6626, 'explorations': 6627, 'probabilitstic': 6628, 'vivid': 6629, 'clarity': 6630, 'unteachable': 6631, 'verifiers': 6632, 'ilog': 6633, 'awa': 6634, 'cassm': 6635, 'whips': 6636, 'cease': 6637, 'because': 6638, 'ignored': 6639, 'relativised': 6640, 'nba': 6641, 'multigranularity': 6642, 'fittest': 6643, 'survives': 6644, 'xcfs': 6645, 'flavers': 6646, 'negations': 6647, 'contradictions': 6648, 'vispedia': 6649, 'deficiencies': 6650, 'borders': 6651, 'spot': 6652, 'compostion': 6653, 'tell': 6654, 'turnover': 6655, 'transliterations': 6656, 'schemr': 6657, 'payoff': 6658, 'xrules': 6659, 'deals': 6660, 'unsuspecting': 6661, 'audience': 6662, 'explain': 6663, 'discover': 6664, 'realizational': 6665, 'dirt': 6666, 'sbtdiscovery': 6667, 'asynchronously': 6668, 'leaf': 6669, 'pangloss': 6670, 'hadoopdb': 6671, 'optimising': 6672, 'governed': 6673, 'calendars': 6674, 'layering': 6675, 'april': 6676, 'madbot': 6677, 'ihmms': 6678, 'cabinet': 6679, 'sprint': 6680, 'eiffel': 6681, 'conserved': 6682, 'thetenthstrand': 6683, 'ethicaldebates': 6684, 'tiling': 6685, 'checkers': 6686, 'diva': 6687, 'liptus': 6688, 'treat': 6689, 'eclectic': 6690, 'invisible': 6691, 'capital': 6692, 'relates': 6693, 'lurking': 6694, 'sake': 6695, 'themselves': 6696, 'sinhala': 6697, 'grapheme': 6698, 'schwa': 6699, 'epenthesis': 6700, 'hisbase': 6701, 'priming': 6702, 'alarms': 6703, 'actionable': 6704, 'volatile': 6705, 'checkpoint': 6706, 'unparsing': 6707, 'rdfxml': 6708, 'homonymy': 6709, 'authorities': 6710, 'hubs': 6711, 'runways': 6712, 'extremal': 6713, 'baskets': 6714, 'singer': 6715, 'mp3': 6716, 'subregularities': 6717, 'prosody': 6718, 'friends': 6719, 'determinization': 6720, 'phased': 6721, 'delocalisation': 6722, 'replanning': 6723, 'attractiveness': 6724, 'multiprocessing': 6725, 'proximus': 6726, 'attributed': 6727, 'perceptrons': 6728, 'wam': 6729, 'contemporary': 6730, 'journals': 6731, 'immc': 6732, 'brittleness': 6733, 'blackout': 6734, 'anywhere': 6735, 'remove': 6736, 'bottlenecks': 6737, 'derbys': 6738, 'bbm': 6739, 'petabyte': 6740, 'handlinh': 6741, 'immediate': 6742, 'phishing': 6743, 'emails': 6744, 'illiterate': 6745, 'lh': 6746, 'reed': 6747, 'solomon': 6748, 'street': 6749, 'journal': 6750, 'linearizability': 6751, 'lsa': 6752, 'soundness': 6753, 'masked': 6754, 'dip': 6755, 'punctuation': 6756, 'ask': 6757, 'groupwise': 6758, 'extremum': 6759, 'associationrules': 6760, 'ct': 6761, 'personnel': 6762, 'acceptability': 6763, 'option': 6764, 'drill': 6765, 'degrade': 6766, 'sie': 6767, 'obi': 6768, 'serpent': 6769, 'viewsystem': 6770, 'exhibit': 6771, 'critter': 6772, 'agricultural': 6773, 'fmri': 6774, 'volcano': 6775, 'contra': 6776, 'xvcl': 6777, 'dot': 6778, 'watson': 6779, 'tele': 6780, 'professor': 6781, 'pesto': 6782, 'querybrowser': 6783, 'principals': 6784, 'oz': 6785, 'mglair': 6786, 'scaleless': 6787, 'semmo': 6788, 'multiplayer': 6789, 'row': 6790, 'laplace': 6791, 'albep': 6792, 'caption': 6793, 'stand': 6794, 'synchronizable': 6795, 'preach': 6796, 'predefined': 6797, 'polarized': 6798, 'kiss': 6799, 'powers': 6800, 'aadds': 6801, 'cmu': 6802, 'rover': 6803, 'schematically': 6804, 'centralized': 6805, 'crowdreranking': 6806, 'mmtk': 6807, 'individualized': 6808, 'forgiving': 6809, 'cream': 6810, 'valuepetri': 6811, 'china': 6812, 'practicioners': 6813, 'managed': 6814, 'ecu': 6815, 'vindicated': 6816, 'cot': 6817, 'detecton': 6818, 'overfitting': 6819, 'emerge': 6820, 'verbosity': 6821, '25': 6822, 'rise': 6823, 'fall': 6824, 'salton': 6825, 'award': 6826, 'tactic': 6827, 'gpsm': 6828, 'dissolution': 6829, 'extremely': 6830, 'fibring': 6831, 'gputerasort': 6832, 'unpartitioned': 6833, 'holonic': 6834, 'pedestrian': 6835, 'rqafqi': 6836, 'indeterminate': 6837, 'constructor': 6838, 'carpediem': 6839, 'ssl': 6840, 'coarticulation': 6841, 'separable': 6842, 'ceteris': 6843, 'paribus': 6844, 'mocha': 6845, 'alternating': 6846, 'jeroboam': 6847, 'epilepsy': 6848, 's3': 6849, 'xpress': 6850, 'queriable': 6851, 'textured': 6852, 'bits': 6853, 'termsets': 6854, 'dataset': 6855, 'bacteria': 6856, 'cultures': 6857, 'scattering': 6858, 'shifts': 6859, 'samuel': 6860, 'amarel': 6861, 'cbse': 6862, 'datacycle': 6863, '1978': 6864, 'cst': 6865, 'citizens': 6866, 'psycholinguistically': 6867, 'parafac2': 6868, 'mpf': 6869, 'stars': 6870, 'coocurrences': 6871, 'import': 6872, 'denoising': 6873, 'autoencoders': 6874, 'tabling': 6875, 'quadrupedal': 6876, 'locomotion': 6877, 'multitheme': 6878, 'markovsemi': 6879, 'destinations': 6880, 'nondirectional': 6881, 'labor': 6882, 'characteristic': 6883, 'ddos': 6884, 'identified': 6885, 'reused': 6886, 'neighbourhood': 6887, 'broadband': 6888, 'v3': 6889, 'analog': 6890, 'keypoints': 6891, 'sister': 6892, 'reclustering': 6893, '3se': 6894, 'widely': 6895, 'proclamation': 6896, 'elaborate': 6897, 'anf': 6898, 'sammie': 6899, 'television': 6900, 'radio': 6901, 'aems': 6902, 'codds': 6903, 'reformulated': 6904, 'appear': 6905, 'posting': 6906, 'degradation': 6907, 'determined': 6908, 'elision': 6909, 'curio': 6910, 'reviving': 6911, 'fertility': 6912, 'compositions': 6913, 'hdp': 6914, 'concentric': 6915, 'hyperspaces': 6916, 'modula': 6917, 'labellings': 6918, 'cse': 6919, 'volunteers': 6920, 'hillsborough': 6921, 'county': 6922, 'district': 6923, 'transsformation': 6924, 'dolce': 6925, 'unsound': 6926, 'automateddistributed': 6927, 'multiresolution': 6928, 'mrf': 6929, 'theta': 6930, 'socially': 6931, 'here': 6932, 'pskip': 6933, 'scribble': 6934, 'alikes': 6935, 'chorochronos': 6936, 'folklore': 6937, 'confirmed': 6938, 'widl': 6939, 'inconcert': 6940, 'archive': 6941, 'sqlmed': 6942, 'tenant': 6943, 'telephone': 6944, 'journey': 6945, 'simplifier': 6946, 'gotolessness': 6947, 'infomix': 6948, 'prague': 6949, 'mima': 6950, 'innovation': 6951, 'interim': 6952, 'acmieee': 6953, 'despite': 6954, 'imbalance': 6955, 'stress': 6956, 'realizing': 6957, 'directors': 6958, 'implication': 6959, 'factorizations': 6960, 'datajoiner': 6961, 'collecting': 6962, 'ocean': 6963, 'conservant': 6964, 'multitale': 6965, 'bookmark': 6966, 'designated': 6967, 'sash': 6968, 'sportscast': 6969, 'weblab': 6970, 'hyperthesis': 6971, 'spell': 6972, 'crops': 6973, 'soil': 6974, 'situational': 6975, 'presupposition': 6976, 'socratic': 6977, 'exegesis': 6978, 'wake': 6979, 'wlan': 6980, 'repeating': 6981, 'aries': 6982, 'intractability': 6983, 'faces': 6984, 'kap': 6985, 'greediness': 6986, 'memm': 6987, 'segregation': 6988, 'dat': 6989, 'dd': 6990, 'chameleon': 6991, 'spiteful': 6992, 'xmill': 6993, 'majorization': 6994, 'instantiation': 6995, 'ailp': 6996, 'p3vi': 6997, 'mtw06': 6998, 'inequality': 6999, 'listening': 7000, 'provisions': 7001, 'operationally': 7002, 'multibuffer': 7003, 'transposition': 7004, 'statsnowball': 7005, 'dumber': 7006, 'speeddating': 7007, 'systematically': 7008, 'triangulation': 7009, 'plop': 7010, 'ghostdb': 7011, 'leaks': 7012, 'continually': 7013, 'sensory': 7014, 'nico': 7015, 'habermanns': 7016, 'saps': 7017, 'nonmonotonicity': 7018, 'batching': 7019, 'rearrangement': 7020, 'bags': 7021, 'inexperienced': 7022, 'spiral': 7023, 'beat': 7024, 'queens': 7025, 'machined': 7026, 'rrxf': 7027, 'punjabi': 7028, 'speaking': 7029, 'food': 7030, 'complaints': 7031, 'lore': 7032, 'soquet': 7033, 'crosscutting': 7034, 'rp': 7035, 'liveclassifier': 7036, 'atis': 7037, 'leave': 7038, 'said': 7039, 'snif': 7040, 'sniffing': 7041, 'autocorrelation': 7042, 'topographic': 7043, 'dpop': 7044, 'dcop': 7045, 'datametadata': 7046, 'append': 7047, 'pres': 7048, 'upside': 7049, 'drosophila': 7050, 'capping': 7051, 'judges': 7052, 'exchangeable': 7053, 'drawn': 7054, 'praire': 7055, 'databasenetwork': 7056, 'phoneticsphonology': 7057, 'bird': 7058, 'hisa': 7059, 'committees': 7060, 'understandable': 7061, 'dalí': 7062, 'quantum': 7063, 'fa': 7064, 'metamodeling': 7065, 'noticing': 7066, 'costing': 7067, 'expressed': 7068, 'crosslanguage': 7069, 'ciphertext': 7070, 'allophonic': 7071, 'phonotactic': 7072, 'deployers': 7073, 'prompt': 7074, 'coma': 7075, 'unmodified': 7076, 'backoff': 7077, 'administrators': 7078, 'believable': 7079, 'tourism': 7080, 'prose': 7081, 'generalizaiton': 7082, 'cafeobj': 7083, 'regularised': 7084, 'wishful': 7085, 'viable': 7086, 'handprinted': 7087, 'practicing': 7088, 'judo': 7089, 'boards': 7090, 'essays': 7091, 'jisdos': 7092, 'icp': 7093, 'nonrigid': 7094, 'guis': 7095, 'shrex': 7096, 'appliances': 7097, 'dhts': 7098, 'j2me': 7099, 'heat': 7100, 'candidates': 7101, 'atom': 7102, 'customized': 7103, 'bundling': 7104, 'bregman': 7105, 'dpls': 7106, 'pol': 7107, 'around': 7108, 'seller': 7109, 'brazilian': 7110, 'dependences': 7111, 'omega': 7112, 'galax': 7113, 'partitionings': 7114, 'hop': 7115, 'amcr': 7116, 'dispatching': 7117, 'epos': 7118, 'byzantine': 7119, 'generals': 7120, 'magma': 7121, 'dominating': 7122, 'profitably': 7123, 'sed': 7124, 'prf': 7125, 'lends': 7126, 'intersections': 7127, 'mis': 7128, 'dumping': 7129, 'simrank': 7130, 'clickgraph': 7131, 'unlevel': 7132, 'chronology': 7133, 'newswires': 7134, 'bleu': 7135, 'fluxplayer': 7136, 'vowels': 7137, 'quest': 7138, 'viewers': 7139, 'analogue': 7140, 'declaration': 7141, 'closer': 7142, 'wordmeanings': 7143, 'sleeved': 7144, 'coclustering': 7145, 'blacklists': 7146, 'malicious': 7147, 'escape': 7148, 'polyglot': 7149, 'interrelationship': 7150, 'avionics': 7151, 'churn': 7152, 'finalization': 7153, 'readings': 7154, 'writes': 7155, 'viztree': 7156, 'wakashi': 7157, 'perceptually': 7158, 'efis': 7159, 'paramodulation': 7160, 'controllable': 7161, 'osamt': 7162, 'oqlt': 7163, 'conditioned': 7164, 'ballot': 7165, 'sincerity': 7166, 'proofness': 7167, 'diophantine': 7168, 'adverbials': 7169, 'refreshment': 7170, 'diverging': 7171, 'chi': 7172, 'validity': 7173, 'subgroup': 7174, 'nestream': 7175, 'intuitive': 7176, 'jarap': 7177, 'semcog': 7178, 'huberized': 7179, 'visitor': 7180, 'boomerang': 7181, 'resourceful': 7182, 'lenses': 7183, 'surviving': 7184, 'multiparadigm': 7185, 'idefix': 7186, 'browserank': 7187, 'consideration': 7188, 'eroc': 7189, 'neato': 7190, 'hosts': 7191, 'usind': 7192, 'installations': 7193, 'anycast': 7194, 'cdns': 7195, 'ferret': 7196, 'filestore': 7197, 'stdl': 7198, 'clide': 7199, 'defection': 7200, 'calculi': 7201, 'dancing': 7202, 'endearing': 7203, 'caede': 7204, 'multitasking': 7205, 'embdedded': 7206, 'traits': 7207, 'guaranteed': 7208, 'errorperformance': 7209, 'rippling': 7210, 'hub': 7211, 'groves': 7212, 'disproportionate': 7213, 'interventions': 7214, 'narrowing': 7215, 'ginga': 7216, 'tangent': 7217, 'sourcing': 7218, 'reloaded': 7219, 'encapsulated': 7220, 'smil': 7221, 'experimenting': 7222, 'revisits': 7223, 'seeding': 7224, 'underpinnings': 7225, 'taggerlemmatiser': 7226, 'collision': 7227, 'calibrated': 7228, 'maxq': 7229, 'mudular': 7230, 'workstyle': 7231, 'hotspots': 7232, 'fgp': 7233, 'kohonen': 7234, 'possibility': 7235, 'cascades': 7236, 'forgettings': 7237, 'ariel': 7238, 'ppcp': 7239, 'clear': 7240, 'supertagging': 7241, 'claim': 7242, 'mathematicians': 7243, 'pymk': 7244, 'friend': 7245, 'myspace': 7246, 'midas': 7247, 'periods': 7248, 'distinction': 7249, 'twittermonitor': 7250, 'reformulating': 7251, 'primes': 7252, 'drivers': 7253, 'assessors': 7254, 'mistakes': 7255, 'dipra': 7256, 'idef1': 7257, 'pearsons': 7258, 'considering': 7259, 'agglutinativity': 7260, 'spacing': 7261, 'correlativity': 7262, 'obliviousness': 7263, 'hallucination': 7264, 'tioga': 7265, 'drjava': 7266, 'pedagogic': 7267, 'educating': 7268, 'superarchitects': 7269, 'min': 7270, 'disabled': 7271, 'children': 7272, 'commercially': 7273, 'prenominal': 7274, 'bet': 7275, 'humancomputer': 7276, 'pubmed': 7277, 'hopper': 7278, 'visits': 7279, 'collocated': 7280, 'ugv': 7281, 'blurring': 7282, 'produces': 7283, 'artistic': 7284, 'calligraphy': 7285, 'fred': 7286, 'csurf': 7287, 'institutional': 7288, 'multipaging': 7289, 'momis': 7290, 'ssd': 7291, 'deeds': 7292, 'thetis': 7293, 'timeout': 7294, 'judgmental': 7295, 'dewild': 7296, 'cards': 7297, 'formalizations': 7298, 'marcus': 7299, 'cxhist': 7300, 'scavenger': 7301, 'unranked': 7302, 'semrank': 7303, 'destructors': 7304, 'finalizers': 7305, 'imecho': 7306, 'writers': 7307, 'potentiality': 7308, 'fulltext': 7309, 'retaliate': 7310, 'shooter': 7311, 'consisting': 7312, 'jive': 7313, 'jove': 7314, 'happens': 7315, 'retrievability': 7316, 'genesis': 7317, 'sliced': 7318, 'whirl': 7319, 'araneus': 7320, 'amount': 7321, 'disparity': 7322, 'anticipatory': 7323, 'multistage': 7324, 'weve': 7325, 'been': 7326, 'requirementsdesign': 7327, 'ucms': 7328, 'vsams': 7329, 'doritos': 7330, 'cylindrical': 7331, 'smoothed': 7332, 'rainbow': 7333, 'actiview': 7334, 'supersql': 7335, 'augmentative': 7336, 'hownet': 7337, 'pardes': 7338, 'proto': 7339, 'bistratal': 7340, 'subsentential': 7341, 'regularly': 7342, 'citri': 7343, 'modifier': 7344, 'disima': 7345, 'oddessy': 7346, 'programme': 7347, 'guides': 7348, 'patchwork': 7349, 'profiled': 7350, 'datablitz': 7351, 'maximizationminimization': 7352, 'gulf': 7353, 'deryaft': 7354, 'wt10g': 7355, 'proteins': 7356, 'thou': 7357, 'shalt': 7358, 'covet': 7359, 'thy': 7360, 'cake': 7361, 'wordform': 7362, 'aac': 7363, 'montage': 7364, 'queryable': 7365, 'kbse': 7366, 'checkmate': 7367, 'cornering': 7368, 'checked': 7369, 'cooccurrence': 7370, 'serpentine': 7371, 'drives': 7372, 'sentinel': 7373, 'tone': 7374, 'jazzmatch': 7375, 'introducng': 7376, 'kb': 7377, 'dj': 7378, 'fabric': 7379, 'augeas': 7380, 'authoritativeness': 7381, 'creepy': 7382, 'desired': 7383, 'foral': 7384, 'tweeted': 7385, 'gf': 7386, 'weaker': 7387, 'universality': 7388, 'diag': 7389, '1n': 7390, 'adventures': 7391, 'prompter': 7392, 'intelligibility': 7393, 'rcx': 7394, 'understand': 7395, 'qualification': 7396, 'toolset': 7397, 'tedi': 7398, 'marshaling': 7399, 'carrying': 7400, 'commitlsn': 7401, 'latching': 7402, 'synchronizer': 7403, 'ppm': 7404, 'caterogization': 7405, 'itaca': 7406, 'kbs': 7407, 'diluting': 7408, 'acid': 7409, 'projecting': 7410, 'weekday': 7411, 'thumbnail': 7412, 'mariposa': 7413, 'orchestral': 7414, 'accompaniment': 7415, 'lexica': 7416, 'morphologically': 7417, 'coexistence': 7418, 'reman': 7419, 'saliency': 7420, 'unconcerned': 7421, 'heritage': 7422, 'microcomputers': 7423, 'traveling': 7424, 'salesman': 7425, 'mint': 7426, 'separability': 7427, 'retieval': 7428, 'linearly': 7429, 'pagesim': 7430, 'aimilarity': 7431, 'permutations': 7432, 'governors': 7433, 'ubidata': 7434, 'expertconsultation': 7435, 'kl': 7436, 'butterfly\\x99': 7437, 'testo': 7438, 'ag': 7439, 'proteome': 7440, 'analyst': 7441, 'seeded': 7442, 'codebooks': 7443, 'habitats': 7444, 'adam': 7445, 'untyped': 7446, 'degraded': 7447, 'arbitrarily': 7448, 'gaining': 7449, 'tour': 7450, 'retroactive': 7451, 'namur': 7452, 'retrievals': 7453, 'hifi': 7454, 'fan': 7455, 'unite': 7456, 'mhp': 7457, 'idtv': 7458, 'presentable': 7459, 'underspecified': 7460, 'cascade': 7461, 'ranks': 7462, 'generalising': 7463, 'equijoins': 7464, 'apt': 7465, 'ois': 7466, 'numeral': 7467, 'episodic': 7468, 'iv': 7469, 'shuttle': 7470, 'tscan': 7471, 'tasking': 7472, 'emt': 7473, 'imperfectly': 7474, 'xtag': 7475, 'nexusscout': 7476, 'symmetries': 7477, 'margins': 7478, 'incoherent': 7479, 'degress': 7480, 'liquid': 7481, 'schedulable': 7482, 'daml': 7483, 'received': 7484, 'amazoncom': 7485, 'helpfulness': 7486, 'gpgpu': 7487, 'subtransitive': 7488, 'agreement': 7489, 'mearf': 7490, 'stencils': 7491, 'bengali': 7492, 'greek': 7493, 'deciding': 7494, 'stateless': 7495, 'pigeons': 7496, 'abducing': 7497, 'conclusions': 7498, 'split': 7499, 'clocks': 7500, 'thoughts': 7501, 'octopus': 7502, 'modality': 7503, 'planck': 7504, 'iconism': 7505, 'gains': 7506, 'scheduled': 7507, 'revi': 7508, 'warranty': 7509, 'goodwill': 7510, 'rdfpeers': 7511, 'ur': 7512, 'metaprogramming': 7513, 'deixis': 7514, 'formats': 7515, 'chatbot': 7516, 'fruit': 7517, 'embryo': 7518, 'webcrow': 7519, 'crossword': 7520, 'everyday': 7521, 'sketches': 7522, 'neuroscience': 7523, 'semiparametric': 7524, 'concatenation': 7525, 'precursor': 7526, 'traveler': 7527, 'multiversioned': 7528, 'generalisation': 7529, 'distortion': 7530, 'pape': 7531, 'printing': 7532, 'congestion': 7533, 'existentially': 7534, 'shine': 7535, 'id3': 7536, 'authentic': 7537, 'chat': 7538, 'room': 7539, 'recovered': 7540, 'proximal': 7541, 'rounding': 7542, 'geoplot': 7543, 'knowing': 7544, 'topicrank': 7545, 'bluetooth': 7546, 'nesting': 7547, 'football': 7548, 'moses': 7549, 'arisenisr': 7550, 'sharc': 7551, 'completing': 7552, 'dvss': 7553, 'ionterfaces': 7554, 'visibly': 7555, 'sounding': 7556, 'unpacking': 7557, 'bioscience': 7558, 'opac': 7559, 'permit': 7560, 'disciplines': 7561, 'catalogue': 7562, 'icons': 7563, 'objecttask': 7564, 'imds': 7565, 'naos': 7566, 'datascope': 7567, 'spices': 7568, 'murax': 7569, 'mix': 7570, 'domino': 7571, 'undertow': 7572, 'tms': 7573, 'ebay': 7574, 'docqs': 7575, 'aqax': 7576, 'randomised': 7577, 'interpretable': 7578, 'cops': 7579, 'gila': 7580, 'aggregaterank': 7581, 'men': 7582, 'richer': 7583, 'psychological': 7584, 'patches': 7585, 'isis': 7586, 'customizability': 7587, 'c2': 7588, 'matchbox': 7589, 'cmic': 7590, 'shot': 7591, 'tense': 7592, 'crf': 7593, 'opt': 7594, 'extend': 7595, 'sided': 7596, 'computationally': 7597, 'bdi': 7598, 'smoqe': 7599, 'fist': 7600, 'korat': 7601, 'winners': 7602, 'listwise': 7603, 'unfolding': 7604, 'submodular': 7605, 'classifications': 7606, 'snugglebug': 7607, 'simulate': 7608, 'tangram': 7609, 'recom': 7610, 'vgm': 7611, 'khufu': 7612, 'generativediscriminative': 7613, 'javaxxxl': 7614, 'semdiff': 7615, 'att': 7616, 'netweaver': 7617, 'graphplans': 7618, 'maybms': 7619, 'clustra': 7620, 'telecom': 7621, 'hodfa': 7622, 'homogenizing': 7623, 'kdms': 7624, 'krisys': 7625, 'csv': 7626, 'datacubes': 7627, 'planetary': 7628, 'webml': 7629, 'vip': 7630, 'vml': 7631, 'underrepresented': 7632, 'multicriteria': 7633, 'blosom': 7634, 'reconsidered': 7635, 'bordaconsensus': 7636, 'calin': 7637, 'logarithmic': 7638, 'assertional': 7639, 'munin': 7640, 'electromyographic': 7641, 'findings': 7642, 'nooksack': 7643, 'falls': 7644, 'hydroelectric': 7645, 'station': 7646, 'xanadue': 7647, 'arity': 7648, 'kalman': 7649, 'iliad': 7650, 'oklahoma': 7651, 'fetching': 7652, 'nondeterminism': 7653, 'shadowing': 7654, 'ware': 7655, 'vibe': 7656, 'geotagged': 7657, 'inexpressivity': 7658, 'monad': 7659, 'transformers': 7660, 'myportal': 7661, 'menu': 7662, 'vimsys': 7663, 'aptly': 7664, 'summarizatiion': 7665, 'gai': 7666, 'tomita': 7667, 'exquex': 7668, 'geoenvironmental': 7669, 'mismatched': 7670, 'turn': 7671, 'demonstrations': 7672, 'citations': 7673, 'oracles': 7674, 'triples': 7675, 'subscribed': 7676, 'proportion': 7677, 'transportation': 7678, 'forgotten': 7679, 'connective': 7680, 'loaded': 7681, 'xel': 7682, 'hollands': 7683, 'congruence': 7684, 'considered': 7685, 'graduated': 7686, 'exposure': 7687, 'zoning': 7688, 'chemistry': 7689, 'illustrated': 7690, 'er': 7691, 'twicpen': 7692, 'held': 7693, 'scanner': 7694, 'rete': 7695, 'inclusions': 7696, 'textmole': 7697, 'reconstructive': 7698, 'hyperlink': 7699, 'eventually': 7700, 'kit': 7701, 'hyspirit': 7702, 'picky': 7703, 'dsps': 7704, 'cssv': 7705, 'recsplorer': 7706, 'demeter': 7707, 'keyphrases': 7708, 'fashion': 7709, 'wearable': 7710, 'ddc': 7711, 'genres': 7712, 'lisp7o': 7713, '40': 7714, 'i4e': 7715, 'genie': 7716, 'raising': 7717, 'directionality': 7718, 'basenp': 7719, 'besoins': 7720, 'lexicaux': 7721, 'lumiere': 7722, 'lanalyse': 7723, 'statistique': 7724, 'projet': 7725, 'bref': 7726, 'bdlex': 7727, 'francais': 7728, 'ecrit': 7729, 'et': 7730, 'crafted': 7731, 'cocqa': 7732, 'eurotra': 7733, 'factorizing': 7734, 'ipodlinux': 7735, 'os': 7736, 'penalties': 7737, 'hyperparamodulation': 7738, 'cleansing': 7739, 'crowded': 7740, 'cooccurance': 7741, 'majic': 7742, 'matlab': 7743, 'responsiveness': 7744, 'inquiry': 7745, 'broader': 7746, 'recycling': 7747, 'axiom': 7748, 'failsafe': 7749, 'floor': 7750, 'ebg': 7751, 'limeds': 7752, 'lincks': 7753, 'delayre': 7754, 'eracer': 7755, 'miniconference': 7756, 'paraphraser': 7757, 'entityrank': 7758, 'holistically': 7759, 'cgi': 7760, 'modperl': 7761, 'plangoal': 7762, 'laminar': 7763, 'lifestyle': 7764, 'ilsa': 7765, 'idbd': 7766, 'dbtg': 7767, 'monitors': 7768, 'clir': 7769, 'unsuccessful': 7770, 'expedite': 7771, 'acquire': 7772, 'investigaton': 7773, 'competitions': 7774, 'sell': 7775, 'conditionally': 7776, 'advertisement': 7777, 'popfed': 7778, 'instace': 7779, 'amn': 7780, 'laser': 7781, 'memoizer': 7782, 'ict': 7783, 'enriched': 7784, 'limit': 7785, 'spirit': 7786, 'diagnoses': 7787, 'terraserver': 7788, 'barriers': 7789, 'widespread': 7790, 'pbfilter': 7791, 'tirs': 7792, 'waller': 7793, 'kraft': 7794, 'triplet': 7795, 'regional': 7796, 'promise': 7797, 'perils': 7798, 'likelihoods': 7799, 'dictations': 7800, 'bind': 7801, 'topx': 7802, 'dare': 7803, 'weathra': 7804, 'interrupt': 7805, 'teacher': 7806, 'honorifics': 7807, 'recur': 7808, 'equation': 7809, 'dm': 7810, 'pict': 7811, 'overloading': 7812, 'ccgs': 7813, 'raised': 7814, 'stereotrust': 7815, 'taxonomical': 7816, 'featureide': 7817, 'apprentice': 7818, 'scsl': 7819, 'sox': 7820, 'insite': 7821, 'demon': 7822, 'authorization': 7823, 'lotos': 7824, 'doc': 7825, 'prob': 7826, 'maxn': 7827, 'brained': 7828, 'morphing': 7829, 'rhode': 7830, 'boosts': 7831, 'sac': 7832, 'cleanliness': 7833, 'cdn': 7834, 'zones': 7835, 'comes': 7836, '94': 7837, 'tpr': 7838, 'altricial': 7839, 'precocial': 7840, 'intro': 7841, 'compatibilities': 7842, 'synonym': 7843, 'diabetic': 7844, 'cuber': 7845, 'subsystems': 7846, 'spectroscopy': 7847, 'eigenspaces': 7848, 'mugi': 7849, 'wap': 7850, 'restore': 7851, 'detective': 7852, 'defeating': 7853, 'enforced': 7854, 'xtream': 7855, 'hdsampler': 7856, 'teleputing': 7857, 'corev': 7858, 'averaged': 7859, 'mlcs': 7860, 'urdu': 7861, 'tinycasper': 7862, 'routes': 7863, 'perpetual': 7864, 'cc2001': 7865, 'cited': 7866, 'inection': 7867, 'quantized': 7868, 'parsercompiler': 7869, 'v8': 7870, '4': 7871, 'sintesi': 7872, 'honesty': 7873, 'marketplaces': 7874, 'nonemptiness': 7875, 'scannerless': 7876, 'nslr1': 7877, 'recognizers': 7878, 'lmrp': 7879, 'quickstart': 7880, 'ltrules': 7881, 'rose': 7882, 'retail': 7883, 'outlet': 7884, 'precomputed': 7885, 'mss': 7886, 'mus': 7887, 'cyberwar': 7888, 'harmless': 7889, 'arsa': 7890, 'impediments': 7891, 'ops5': 7892, 'undesired': 7893, 'grammer': 7894, 'arising': 7895, 'invert': 7896, 'realism': 7897, 'hrdm': 7898, 'lifespans': 7899, 'surrogates': 7900, 'comprehensions': 7901, 'tradeoff': 7902, 'unpredictable': 7903, 'loanwords': 7904, 'leaming': 7905, 'yoopick': 7906, 'sports': 7907, 'arcs': 7908, 'rapidly': 7909, '2pxminer': 7910, 'openrulebench': 7911, 'presenter': 7912, 'lecturing': 7913, 'hugin': 7914, 'universes': 7915, 'phrasetable': 7916, 'medians': 7917, 'insanity': 7918, 'himotoki': 7919, 'diagonal': 7920, 'nightmare': 7921, 'mlisp2': 7922, 'multifractals': 7923, 'nonmontonic': 7924, 'traitor': 7925, 'comprehensible': 7926, 'fzi': 7927, 'karlsruhe': 7928, 'dfr': 7929, 'setups': 7930, 'satisficing': 7931, 'prisoner': 7932, 'webquilt': 7933, 'offics': 7934, 'telling': 7935, 'toggle': 7936, 'pebm': 7937, 'homomorphism': 7938, 'downward': 7939, 'upward': 7940, 'cfls': 7941, 'stencil': 7942, 'distinctness': 7943, 'dqp': 7944, 'sybase': 7945, 'ase': 7946, 'congolog': 7947, 'investigations': 7948, 'marriage': 7949, 'indexation': 7950, 'lapprentissage': 7951, 'pronomial': 7952, 'mud': 7953, 'damage': 7954, 'quarantine': 7955, 'mission': 7956, 'minesweeper': 7957, 'cocoviz': 7958, 'vizql': 7959, 'simdb': 7960, 'replies': 7961, 'contextualization': 7962, 'unorganized': 7963, 'empower': 7964, 'privileged': 7965, 'bantu': 7966, 'psychsim': 7967, 'threat': 7968, 'dcube': 7969, 'wa': 7970, 'disguised': 7971, 'encounter': 7972, 'cws': 7973, 'colorful': 7974, 'factorisation': 7975, 'diffuse': 7976, 'failing': 7977, 'hearsay': 7978, 'reallocation': 7979, 'cpm': 7980, 'wlans': 7981, 'deadliner': 7982, 'niche': 7983, 'velodrome': 7984, 'drastic': 7985, 'sequentially': 7986, 'numericalvectors': 7987, 'published': 7988, 'confluence': 7989, 'mangers': 7990, 'synthesized': 7991, 'dispositions': 7992, 'converses': 7993, 'pumping': 7994, 'lemmas': 7995, 'forth': 7996, 'tuple': 7997, 'homogeneity': 7998, 'wdas': 7999, '2006': 8000, 'frontal': 8001, 'print': 8002, 'feistel': 8003, 'rounds': 8004, 'equip': 8005, 'tourists': 8006, 'travelogues': 8007, 'prepare': 8008, 'martlet': 8009, 'abstracted': 8010, 'parallelisation': 8011, 'inc': 8012, 'rubric': 8013, 'longitudinal': 8014, 'tagmark': 8015, 'estimations': 8016, 'chianti': 8017, 'printed': 8018, 'twigs': 8019, 'undecidable': 8020, 'rdbvms': 8021, 'skeleton': 8022, 'forensics': 8023, 'permanents': 8024, 'polytopes': 8025, 'multidisciplinary': 8026, 'youtube': 8027, 'spc': 8028, 'cwb': 8029, 'interchangeabilities': 8030, 'resolve': 8031, 'venture': 8032, 'threesomes': 8033, 'blame': 8034, 'methodical': 8035, 'fasttrack': 8036, 'dolap07': 8037, 'fcvw': 8038, 'plug': 8039, 'csd': 8040, 'uoc': 8041, 'inconsisent': 8042, 'seth': 8043, 'gc': 8044, 'ilp': 8045, 'compressive': 8046, 'solo': 8047, 'orthosis': 8048, 'perturb': 8049, 'interruptable': 8050, 'career': 8051, 'disentangling': 8052, 'called': 8053, 'punctuality': 8054, 'hierarchyscan': 8055, 'flexpath': 8056, 'surveys': 8057, 'autotagging': 8058, 'closurize': 8059, 'concentrate': 8060, 'magical': 8061, 'coil': 8062, 'cognate': 8063, 'orthography': 8064, 'workfile': 8065, 'mergesorts': 8066, 'dignosis': 8067, 'alibi': 8068, 'timestamping': 8069, 'wiser': 8070, 'deliberative': 8071, 'apprenticeship': 8072, 'meme': 8073, 'cycle': 8074, 'advantage': 8075, 'nf': 8076, 'voronoi': 8077, 'ditributed': 8078, 'raddle': 8079, 'consultant': 8080, 'lid': 8081, 'never': 8082, 'spotfire': 8083, 'ale': 8084, 'assume': 8085, 'svd': 8086, 'houston': 8087, 'oxygen': 8088, 'tank': 8089, 'ariesim': 8090, 'broken': 8091, 'plural': 8092, 'billion': 8093, 'synthetic': 8094, 'embeddings': 8095, 'extenders': 8096, 'flattening': 8097, 'grocery': 8098, 'merits': 8099, 'smallest': 8100, 'lcas': 8101, 'humanoid': 8102, 'gemini': 8103, 'advertisers': 8104, 'marion': 8105, 'retargetable': 8106, 'networkweb': 8107, 'others': 8108, 'esp': 8109, 'quota': 8110, 'statement': 8111, 'dlv': 8112, 'agora': 8113, 'atm': 8114, 'dely': 8115, 'pmi': 8116, 'noncorrecting': 8117, 'cubeexplorer': 8118, 'partitional': 8119, 'simplify': 8120, 'deckard': 8121, 'transcription': 8122, 'opium': 8123, 'installuninstall': 8124, 'generational': 8125, 'validator': 8126, 'grassmann': 8127, 'preferable': 8128, 'gameboy': 8129, 'homebrew': 8130, 'metho': 8131, 'metaclasses': 8132, 'provisioning': 8133, 'unreliable': 8134, 'substitutability': 8135, 'csiec': 8136, 'bootstrapped': 8137, 'codecrawler': 8138, 'pepsys': 8139, 'ntjfsatnot': 8140, 'downdate': 8141, 'commands': 8142, 'diet': 8143, 'foks': 8144, 'scavenging': 8145, 'concerning': 8146, 'purposeful': 8147, 'dossier': 8148, 'contraints': 8149, 'alen': 8150, 'calculating': 8151, 'quirky': 8152, 'sor': 8153, 'sagas': 8154, 'navigations': 8155, 'hinting': 8156, 'indexable': 8157, 'pla': 8158, 'nlhe': 8159, 'village': 8160, 'conways': 8161, 'datasplash': 8162, 'bagger': 8163, 'extends': 8164, 'generalizes': 8165, 'pasta': 8166, '3s': 8167, 'brooklyn': 8168, 'teenage': 8169, 'persons': 8170, 'dementia': 8171, 'cognitively': 8172, 'describe': 8173, 'rigel': 8174, 'prospective': 8175, 'assumeguarantee': 8176, 'verisoft': 8177, 'montague': 8178, 'restarting': 8179, 'codesign': 8180, 'odesew': 8181, 'pddl': 8182, 'naturally': 8183, 'provable': 8184, 'ituned': 8185, 'lost': 8186, 'gpu': 8187, 'socializing': 8188, 'uksearch': 8189, 'storylines': 8190, 'reality': 8191, 'leadership': 8192, 'metareasoning': 8193, 'orden': 8194, 'volatility': 8195, 'empowering': 8196, 'millenium': 8197, 'mad': 8198, 'abe': 8199, 'hps': 8200, 'xas': 8201, 'componentized': 8202, 'lexemes': 8203, 'idarex': 8204, 'discernment': 8205, 'reconnaissance': 8206, 'worldwide': 8207, 'telescope': 8208, 'scramble': 8209, 'encrypt': 8210, 'falcon': 8211, 'psr': 8212, 'jkarelrobot': 8213, 'monologue': 8214, 'accadian': 8215, 'mul': 8216, 'green': 8217, 'illustration': 8218, 'corel': 8219, 'pipe': 8220, 'fork': 8221, 'resoution': 8222, 'danaphore': 8223, 'partir': 8224, 'dun': 8225, 'grammaire': 8226, 'verbes': 8227, 'anaphoriques': 8228, 'sparsely': 8229, 'btrees': 8230, 'mrd': 8231, 'mistake': 8232, 'sending': 8233, 'capable': 8234, 'federations': 8235, 'immigration': 8236, 'bolasso': 8237, 'maintainers': 8238, 'utilize': 8239, 'knapsack': 8240, 'kda': 8241, 'chaotic': 8242, 'expense': 8243, 'reimbursement': 8244, 'subroutines': 8245, 'goethe': 8246, 'hypersurfaces': 8247, 'quantity': 8248, 'hyperspread': 8249, 'cbir': 8250, 'quad': 8251, 'password': 8252, 'salts': 8253, '3dstring': 8254, 'voxelized': 8255, 'recognizer': 8256, 'garlic': 8257, 'flavor': 8258, 'duping': 8259, 'quasigroup': 8260, 'fostering': 8261, 'niagaracq': 8262, 'rendered': 8263, 'doodle': 8264, 'persuasive': 8265, 'aod': 8266, 'tiie': 8267, 'hal': 8268, 'sprinkling': 8269, 'yields': 8270, 'restoring': 8271, 'interpretive': 8272, 'weiner': 8273, 'presenting': 8274, 'microkernels': 8275, 'submodule': 8276, 'nitpick': 8277, 'quotations': 8278, 'inserted': 8279, 'arena': 8280, 'infusion': 8281, 'trick': 8282, 'rpref': 8283, 'bpref': 8284, 'due': 8285, 'ccured': 8286, 'retrofitting': 8287, 'asilomar': 8288, 'isolating': 8289, 'claremont': 8290, 'passwords': 8291, 'absence': 8292, 'cursive': 8293, 'charting': 8294, 'depths': 8295, 'bdd': 8296, 'polytime': 8297, 'schedulers': 8298, 'planarisation': 8299, 'stl': 8300, 'sardsrn': 8301, 'winnowing': 8302, 'subexpression': 8303, 'unknowns': 8304, 'prevent': 8305, 'stages': 8306, 'horizontally': 8307, 'rings': 8308, 'misconfigured': 8309, 'quantative': 8310, 'trackers': 8311, 'mercy': 8312, 'turings': 8313, 'dream': 8314, 'sndocrank': 8315, 'parsetalk': 8316, 'nonrecursive': 8317, 'heavy': 8318, 'tailed': 8319, 'dewey': 8320, 'gp': 8321, 'lvm': 8322, 'dempster': 8323, 'shafers': 8324, 'mirror': 8325, 'moby': 8326, 'disco': 8327, 'novo': 8328, 'gogo': 8329, 'mallows': 8330, 'tge': 8331, 'tlinks': 8332, 'legged': 8333, 'spicy': 8334, 'chomsky': 8335, 'diderichsen': 8336, 'progressing': 8337, 'sim': 8338, 'keyhole': 8339, 'robotstxt': 8340, 'mpsocs': 8341, 'comment': 8342, 'undirected': 8343, 'sgl': 8344, 'asymmetrically': 8345, 'collocational': 8346, 'unconditional': 8347, 'jumps': 8348, 'stick': 8349, 'i11': 8350, 'replicability': 8351, 'peg': 8352, 'towers': 8353, 'hanoi': 8354, 'grabber': 8355, 'quickstore': 8356, 'circumspective': 8357, 'inclusive': 8358, 'myopia': 8359, 'hill': 8360, 'sessionlock': 8361, 'eavesdropping': 8362, 'egs': 8363, 'kana': 8364, 'expressional': 8365, 'uninteresting': 8366, 'pdl': 8367, 'datapath': 8368, 'revisted': 8369, 'projectron': 8370, 'portlet': 8371, 'tbt': 8372, 'interating': 8373, 'normalisation': 8374, 'sums': 8375, 'customes': 8376, 'port': 8377, 'singapore': 8378, 'psa': 8379, 'dualising': 8380, 'quiescene': 8381, 'sacrifices': 8382, 'ransac': 8383, 'cylinders': 8384, 'ball': 8385, 'lham': 8386, '8': 8387, 'flowgraphs': 8388, 'tensorial': 8389, 'flick': 8390, 'idl': 8391, 'graphscope': 8392, 'lean': 8393, 'alep': 8394, 'routines': 8395, 'concernlines': 8396, 'occurring': 8397, 'erknn': 8398, 'behaved': 8399, 'psiphi': 8400, 'norm': 8401, 'locus': 8402, 'ray': 8403, 'forces': 8404, 'mbrs': 8405, 'rhythms': 8406, 'megaprogramming': 8407, 'once': 8408, 'kemeny': 8409, 'eigentransfer': 8410, 'combinatorical': 8411, 'queues': 8412, 'asp': 8413, 'initiator': 8414, 'gateways': 8415, 'mr': 8416, 'substrings': 8417, 'lrk': 8418, 'graduating': 8419, 'beamforming': 8420, 'destructive': 8421, 'bot': 8422, 'instantiating': 8423, 'coefficients': 8424, 'senselearner': 8425, 'mereology': 8426, 'modularized': 8427, 'multicontainer': 8428, 'contracting': 8429, 'ebusiness': 8430, 'bridger': 8431, 'edition': 8432, 'impression': 8433, 'nonprofit': 8434, 'housing': 8435, 'objectrelational': 8436, 'hibernate': 8437, 'edm': 8438, 'binaries': 8439, 'autopilot': 8440, 'fleet': 8441, 'counterexamples': 8442, 'uninterrupted': 8443, 'peta': 8444, 'geospatial': 8445, 'esc': 8446, 'mitosis': 8447, 'yam': 8448, 'informativeness': 8449, 'coresets': 8450, 'granger': 8451, 'make3d': 8452, 'stholes': 8453, 'pacer': 8454, 'races': 8455, 'theontologies': 8456, 'fclust': 8457, 'qualified': 8458, 'reflect': 8459, 'transversals': 8460, 'hardening': 8461, 'backend': 8462, 'nonground': 8463, 'nationwide': 8464, 'phoebus': 8465, 'pad': 8466, 'blackbox': 8467, 'carnot': 8468, 'weibull': 8469, 'dwell': 8470, 'bnn': 8471, 'reconceptualizing': 8472, 'isetl': 8473, 'overspecified': 8474, 'victoria': 8475, 'wellington': 8476, 'cork': 8477, 'confirmations': 8478, 'facets': 8479, 'kabiria': 8480, 'stakeholder': 8481, 'inegration': 8482, 'harnessing': 8483, 'manageable': 8484, 'searchersystem': 8485, 'pfs': 8486, 'sleep': 8487, 'peace': 8488, 'pseudolikelihood': 8489, 'gdr': 8490, 'restraints': 8491, 'attract': 8492, 'mc': 8493, 'telegraphic': 8494, 'leap': 8495, 'believe': 8496, 'soap': 8497, 'maintainability': 8498, 'xcon': 8499, 'modalities': 8500, 'alitheia': 8501, 'chord': 8502, 'curated': 8503, 'judgment': 8504, 'excerpts': 8505, 'tijah': 8506, 'dataflows': 8507, 'xmdvtool': 8508, 'iskodor': 8509, 'paragraphs': 8510, 'composable': 8511, 'trusted': 8512, 'mostly': 8513, 'inking': 8514, 'multifactor': 8515, 'tods': 8516, 'alt': 8517, 'je': 8518, 'menory': 8519, 'agna': 8520, 'orgenization': 8521, 'dpmis': 8522, 'reflections': 8523, 'boyce': 8524, 'squared': 8525, 'tmss': 8526, 'protected': 8527, 'corrections': 8528, 'hourly': 8529, 'mpeg': 8530, 'dance': 8531, 'roccer': 8532, 'insecure': 8533, 'enactability': 8534, 'alternation': 8535, 'oops': 8536, 'faciltity': 8537, 'offloading': 8538, 'zbroker': 8539, 'z3950': 8540, '¬1nf': 8541, 'occupancy': 8542, 'releases': 8543, 'synergies': 8544, 'sehas': 8545, 'propagated': 8546, 'unmasking': 8547, 'lc3uarch': 8548, 'lc': 8549, 'microarchitecture': 8550, 'faqs': 8551, 'semisupervised': 8552, 'coevolved': 8553, 'specialists': 8554, 'consistently': 8555, 'conjuncts': 8556, 'utilizations': 8557, 'diagrammatic': 8558, 'sunny': 8559, 'sibling': 8560, 'haemo': 8561, 'dialysis': 8562, 'jiljuliette': 8563, 'evicted': 8564, 'smaller': 8565, 'eventualities': 8566, 'immigrant': 8567, 'questionbank': 8568, 'jan': 8569, 'janninks': 8570, 'cold': 8571, 'hypernym': 8572, 'boost': 8573, 'precondition': 8574, 'cclisp\\x99': 8575, 'ipsc\\x99': 8576, 'mohca': 8577, 'anaphors': 8578, 'reactivity': 8579, 'hmms': 8580, 'moved': 8581, 'liteminutes': 8582, 'minutes': 8583, 'extensionality': 8584, 'intensionality': 8585, 'authorial': 8586, 'ttd': 8587, 'inspectors': 8588, 'produced': 8589, 'cart': 8590, 'workspaces': 8591, 'alloy': 8592, 'magazine': 8593, 'tam': 8594, 'jeli': 8595, 'promoters': 8596, 'jun': 8597, 'idrqr': 8598, 'qr': 8599, 'exel': 8600, 'vexed': 8601, 'turmoil': 8602, 'locale': 8603, 'share': 8604, 'swarming': 8605, 'lexicase': 8606, 'thrashing': 8607, 'facetnet': 8608, 'evolutions': 8609, 'dct': 8610, 'irisnet': 8611, 'aircraft': 8612, 'xqgen': 8613, 'consonant': 8614, 'interdependent': 8615, 'indexical': 8616, 'collapsed': 8617, 'crystal': 8618, 'landing': 8619, 'malpha': 8620, 'ethnicity': 8621, 'subgoals': 8622, 'predetermined': 8623, 'lotus': 8624, 'tastier': 8625, 'grammatico': 8626, 'laying': 8627, 'webcluster': 8628, 'committee': 8629, 'verificatino': 8630, 'efforts': 8631, 'callassist': 8632, 'criminals': 8633, 'duplicated': 8634, 'soping': 8635, 'impersonate': 8636, 'apl': 8637, 'pseudoword': 8638, 'html2rss': 8639, 'upml': 8640, 'mmr': 8641, 'advertiser': 8642, 'adfactors': 8643, 'ants': 8644, 'fortran': 8645, '90': 8646, 'imputations': 8647, 'inertia': 8648, 'unstable': 8649, 'backtrack': 8650, 'csi': 8651, '1998': 8652, 'styled': 8653, 'picsdesk': 8654, 'occams': 8655, 'razor': 8656, 'got': 8657, 'sharper': 8658, 'microbial': 8659, 'img': 8660, 'plain': 8661, 'ansix3sparc': 8662, 'descriptor': 8663, 'ictd': 8664, 'periodically': 8665, 'compose': 8666, 'pq': 8667, 'surprise': 8668, 'jointree': 8669, 'atomate': 8670, 'unanticipated': 8671, 'eurolang': 8672, 'homer': 8673, 'cbmir': 8674, 'mimic': 8675, 'system370': 8676, 'bicycling': 8677, 'proves': 8678, 'downloading': 8679, 'fsa': 8680, 'chips': 8681, 'paragon': 8682, 'servicing': 8683, 'tye': 8684, 'gimmick': 8685, 'listings': 8686, 'starts': 8687, 'hux': 8688, 'schemacentric': 8689, 'vm': 8690, 'steiner': 8691, 'minimips': 8692, 'tributaries': 8693, 'deltas': 8694, 'recrawling': 8695, 'caprera': 8696, 'parity': 8697, 'upgrade': 8698, 'degradations': 8699, 'rebuilds': 8700, 'mature': 8701, 'drinking': 8702, 'firehose': 8703, 'quiver': 8704, 'colorectal': 8705, 'ineffectiveness': 8706, 'umist': 8707, 'reconfiguration': 8708, 'decomposed': 8709, 'visualizaiton': 8710, 'copies': 8711, 'bloat': 8712, 'variants': 8713, 'idle': 8714, 'agm': 8715, 'javas': 8716, 'parsable': 8717, 'symchaff': 8718, 'smarter': 8719, 'geromesuite': 8720, 'constrain': 8721, 'senserelate': 8722, 'targetword': 8723, 'deas': 8724, 'georgia': 8725, 'computes': 8726, 'purely': 8727, 'ordinary': 8728, 'symbolico': 8729, 'documentary': 8730, 'interrogation': 8731, 'explicitly': 8732, 'telemeetings': 8733, 'liter': 8734, 'mismatches': 8735, 'statecharts': 8736, 'gestalts': 8737, 'outline': 8738, 'differently': 8739, 'kbmss': 8740, 'expertclerk': 8741, 'navigating': 8742, 'shoppers': 8743, 'buying': 8744, 'reefs': 8745, 'itopn': 8746, 'approximately': 8747, 'inequal': 8748, 'accumulation': 8749, 'interplay': 8750, 'moral': 8751, 'luposdate': 8752, 'discriminants': 8753, 'contstruct': 8754, 'weaver': 8755, 'remotely': 8756, 'sensed': 8757, 'geophysical': 8758, 'sushi': 8759, 'surfing': 8760, 'wysiwyt': 8761, 'evaluators': 8762, 'integrates': 8763, 'pr': 8764, 'cords': 8765, 'cogram': 8766, 'alcogram': 8767, 'placements': 8768, 'survival': 8769, 'critically': 8770, 'vec': 8771, 'xqforms': 8772, 'derivations': 8773, 'cadena': 8774, 'tulsa': 8775, 'amd': 8776, 'athlon': 8777, 'predator': 8778, 'kato': 8779, 'deploying': 8780, 'genomics': 8781, 'affordable': 8782, 'msn': 8783, 'sr': 8784, 'bpel': 8785, 'realities': 8786, 'neighbourhoods': 8787, 'scriptease': 8788, 'conspectus': 8789, 'nonprocedural': 8790, 'ucgs': 8791, 'mfis': 8792, 'peripheral': 8793, 'foveal': 8794, 'osprey': 8795, 'autonomously': 8796, 'semantifying': 8797, 'tricolor': 8798, 'infocrystal': 8799, 'unplugged': 8800, 'mergesort': 8801, 'aim': 8802, 'parameterised': 8803, 'bitmaps': 8804, 'sigir': 8805, 'proceedings': 8806, 'fractured': 8807, 'mirrors': 8808, 'calligraphic': 8809, 'consortium': 8810, 'permissions': 8811, 'aide': 8812, 'vocal': 8813, 'oraclizable': 8814, 'kahns': 8815, 'ipp': 8816, 'hedge': 8817, 'adls': 8818, 'coincidence': 8819, 'synthesizer': 8820, 'denormalization': 8821, 'lexicography': 8822, 'bitbots': 8823, 'rebound': 8824, 'sorter': 8825, 'infers': 8826, 'biasing': 8827, 'familiarity': 8828, 'inhomogeneous': 8829, 'pba': 8830, 'unplanned': 8831, 'deviations': 8832, 'simultaneously': 8833, 'bracketing': 8834, 'epci': 8835, 'potentially': 8836, 'infringement': 8837, 'hcc': 8838, 'undecomposable': 8839, 'shuffle': 8840, 'crossover': 8841, 'rescoring': 8842, 'ccc': 8843, 'incorporated': 8844, 'symp': 8845, 'plight': 8846, 'coca': 8847, 'seminal': 8848, 'metaheuristic': 8849, 'ideographic': 8850, 'latin': 8851, 'gpus': 8852, 'reservation': 8853, 'traceback': 8854, 'cheshire': 8855, 'wll': 8856, 'lemmatization': 8857, 'citeseer': 8858, 'interlinking': 8859, 'rhist': 8860, 'reu': 8861, 'sdoc': 8862, 'vistrails': 8863, 'deferring': 8864, 'mpe': 8865, 'lots': 8866, 'ticks': 8867, 'billions': 8868, 'trades': 8869, 'quotes': 8870, 'characterising': 8871, 'gazpacho': 8872, 'rash': 8873, 'occurence': 8874, 'calysto': 8875, 'ns2': 8876, 'searchable': 8877, 'classpects': 8878, 'programmability': 8879, 'stereographics': 8880, 'proust': 8881, 'onyx': 8882, 'constantly': 8883, 'moments': 8884, 'dijkstras': 8885, 'xspect': 8886, 'xlink': 8887, 'interchangeability': 8888, 'dummy': 8889, 'complementation': 8890, 'haplo': 8891, 'replets': 8892, 'upending': 8893, 'uncanny': 8894, 'valley': 8895, 'upgrading': 8896, 'ipsi': 8897, 'worked': 8898, 'didnt': 8899, 'naga': 8900, 'deviant': 8901, 'instrumented': 8902, 'discoverability': 8903, 'airfare': 8904, 'minimize': 8905, 'breakpoints': 8906, 'brand': 8907, 'gigabits': 8908, 'gem': 8909, 'cur': 8910, 'ucc': 8911, 'metadeliberation': 8912, 'logicist': 8913, 'multipotential': 8914, 'comparsion': 8915, 'schemascope': 8916, 'statisticallinguistic': 8917, 'gists': 8918, 'youserv': 8919, 'computed': 8920, 'invitational': 8921, 'arpansf': 8922, 'indormation': 8923, 'cbr': 8924, 'drive': 8925, 'war': 8926, 'hyperbase': 8927, 'interchangeable': 8928, 'autofeed': 8929, 'webfeeds': 8930, 'proportions': 8931, 'mereotopology': 8932, 'multivalued': 8933, 'disequilibration': 8934, 'persian': 8935, 'fagin': 8936, 'epistatic': 8937, 'hy': 8938, 'hygraph': 8939, 'halsteads': 8940, 'python': 8941, 'deadlines': 8942, 'driving': 8943, 'switched': 8944, 'outcome': 8945, 'scratchpad': 8946, 'sensemaking': 8947, 'subproblems': 8948, 'periodical': 8949, 'discriminators': 8950, 'bitam': 8951, 'admixture': 8952, 'dormant': 8953, 'corollary': 8954, 'intermittent': 8955, 'yesterday': 8956, 'minds': 8957, 'distinguish': 8958, 'gentzen': 8959, 'formel': 8960, 'complements': 8961, 'pitfalls': 8962, 'spice': 8963, 'critic': 8964, 'childrens': 8965, 'guardians': 8966, 'columbia': 8967, 'ids': 8968, 'monochromatic': 8969, 'bichromatic': 8970, 'on2l': 8971, 'quotient': 8972, 'composed': 8973, 'downside': 8974, 'weird': 8975, 'ttp': 8976, 'ngram': 8977, 'xarch': 8978, 'deviants': 8979, 'innovations': 8980, 'taga': 8981, 'agentcities': 8982, 'folds': 8983, 'infused': 8984, 'aspera': 8985, 'generalizations': 8986, 'especially': 8987, 'bdioctl': 8988, 'obstacle': 8989, 'monocular': 8990, 'nd': 8991, 'detail': 8992, 'plot': 8993, 'ensuring': 8994, 'privileges': 8995, 'rescue': 8996, 'relaxing': 8997, 'blockmodels': 8998, 'relatedness': 8999, 'interdependencies': 9000, 'pramatics': 9001, 'annealing': 9002, 'travelling': 9003, 'declarations': 9004, 'freeform': 9005, 'alternate': 9006, 'rekeying': 9007, 'triggered': 9008, 'sounds': 9009, 'unboxed': 9010, 'jinn': 9011, 'sqldata': 9012, '05': 9013, 'ufos': 9014, 'artful': 9015, 'ot': 9016, 'produce': 9017, 'localizing': 9018, 'homotopy': 9019, 'pianists': 9020, 'perceptive': 9021, 'explore': 9022, 'elevation': 9023, 'watchman': 9024, 'mujava': 9025, '1994': 9026, 'honest': 9027, 'southern': 9028, 'earthquake': 9029, 'asset': 9030, 'sl5': 9031, 'redwoods': 9032, 'reflection': 9033, 'ood': 9034, 'beginning': 9035, 'severities': 9036, 'restrictive': 9037, 'metaclustering': 9038, 'textal\\x99': 9039, 'crystallographic': 9040, 'timestamped': 9041, 'ldap': 9042, 'timely': 9043, 'suade': 9044, 'ary': 9045, 'ice': 9046, 'frank': 9047, 'predominant': 9048, 'comparatives': 9049, 'speculations': 9050, 'xquec': 9051, 'bibnetminer': 9052, 'largest': 9053, 'networkever': 9054, 'arnetminer': 9055, 'multithreading': 9056, 'fdm': 9057, 'faithful': 9058, 'nltk': 9059, 'ebag': 9060, 'conquers': 9061, 'plurals': 9062, 'taped': 9063, 'highlighting': 9064, 'disputed': 9065, 'claims': 9066, 'featurehouse': 9067, 'deciphering': 9068, 'affecting': 9069, 'infominer': 9070, 'mechanized': 9071, 'unobtrusive': 9072, 'xmas': 9073, 'incomparability': 9074, 'pyramid': 9075, 'indias': 9076, 'scrambled': 9077, 'senteces': 9078, 'synthesising': 9079, 'true': 9080, 'factopinion': 9081, 'marginalized': 9082, 'quel': 9083, 'stroke': 9084, 'eighth': 9085, 'dolap05': 9086, 'voicemail': 9087, 'annodomini': 9088, 'planningscheduling': 9089, 'privacygrid': 9090, 'objectstore': 9091, 'monolinguals': 9092, 'wifi': 9093, 'hypercuboid': 9094, 'othello': 9095, 'hardest': 9096, 'ceal': 9097, 'pylighter': 9098, 'highlighter': 9099, 'feeds': 9100, 'infosphere': 9101, 'mashuphub': 9102, 'desk': 9103, 'quantificational': 9104, 'tendum': 9105, 'releasing': 9106, 'privately': 9107, 'scatter': 9108, 'aida': 9109, 'topologies': 9110, 'lan': 9111, 'preview': 9112, 'thumbnails': 9113, 'parallax': 9114, 'relevancy': 9115, 'turst': 9116, 'strict': 9117, 'reorganizing': 9118, 'conic': 9119, 'smo': 9120, 'textplanning': 9121, 'pit': 9122, 'bursty': 9123, 'kalchas': 9124, 'crd': 9125, 'ecoinformatics': 9126, 'constructorsets': 9127, 'prolearn': 9128, 'itrails': 9129, 'advisory': 9130, 'endangered': 9131, 'caused': 9132, 'particles': 9133, 'disjointness': 9134, 'trimming': 9135, 'mentor': 9136, 'netprobe': 9137, 'ws': 9138, 'catalognet': 9139, 'peering': 9140, 'easier': 9141, 'typology': 9142, 'interference': 9143, 'embodied': 9144, 'compensation': 9145, 'movemine': 9146, 'secrecy': 9147, 'artoo': 9148, 'weboql': 9149, 'webs': 9150, 'parenthesis': 9151, 'resets': 9152, 'conjugate': 9153, 'noninterference': 9154, 'eliminability': 9155, 'pooling': 9156, 'nonnumerical': 9157, 'recruiting': 9158, 'bestcut': 9159, 'earchivarius': 9160, 'scott': 9161, 'tetris': 9162, 'vmodel': 9163, 'mrm': 9164, 'button': 9165, 'extracts': 9166, 'wider': 9167, 'switch': 9168, 'practically': 9169, 'cloud': 9170, 'these': 9171, 'ncr': 9172, '3700': 9173, 'clickthroughs': 9174, 'vstrails': 9175, 'incorporate': 9176, 'para': 9177, 'rectangles': 9178, 'maya': 9179, 'dispatch': 9180, 'designers': 9181, 'animalscript': 9182, 'differentiation': 9183, 'darpa': 9184, 'communicator': 9185, 'dbminer': 9186, 'nonparallel': 9187, 'subverting': 9188, 'sdp': 9189, 'qp': 9190, 'adjectival': 9191, 'mailer': 9192, 'irregular': 9193, 'ole': 9194, 'metagrammar': 9195, 'lca': 9196, 'proqid': 9197, 'corresponding': 9198, 'accuracies': 9199, 'nominalisations': 9200, 'partnership': 9201, 'webucation': 9202, 'flsa': 9203, 'vacationing': 9204, 'iso': 9205, '9001': 9206, 'mpsbr': 9207, 'cmmi': 9208, 'bl': 9209, 'informaticas': 9210, 'pathway': 9211, 'choreography': 9212, 'eniam': 9213, 'avoidable': 9214, 'refutations': 9215, 'pain': 9216, 'radford': 9217, 'replicating': 9218, 'subjects': 9219, 'preh': 9220, 'assuming': 9221, 'cisc': 9222, 'registers': 9223, 'sting': 9224, 'bernstein': 9225, 'timelines': 9226, 'prospector': 9227, 'irs': 9228, 'lingol': 9229, 'vhdl': 9230, 'cloaking': 9231, 'attempts': 9232, 'catch': 9233, 'battle': 9234, 'owners': 9235, 'academics': 9236, 'unsearchmo': 9237, 'securities': 9238, 'convenience': 9239, 'unannotated': 9240, 'gems': 9241, 'biomarker': 9242, 'snarpy': 9243, 'kr': 9244, 'pyro': 9245, 'ix': 9246, 'doll': 9247, 'gplag': 9248, 'economical': 9249, 'revisionintegration': 9250, 'codewords': 9251, 'protect': 9252, 'corrective': 9253, 'inflected': 9254, 'anniversary': 9255, 'plastics': 9256, 'ram': 9257, 'dates': 9258, 'amilcare': 9259, 'apple': 9260, 'splicing': 9261, 'misordered': 9262, 'hyperion': 9263, 'ipac': 9264, 'bigram': 9265, 'fatigue': 9266, 'handhelds': 9267, 'spells': 9268, 'done': 9269, 'educe': 9270, 'partitionable': 9271, 'switchable': 9272, 'paired': 9273, 'sizing': 9274, 'toss': 9275, 'tax': 9276, 'theorist': 9277, 'trada': 9278, 'darmstadt': 9279, 'browse': 9280, 'recover': 9281, 'nonextensive': 9282, 'wosq': 9283, 'nomograms': 9284, 'emailsift': 9285, 'disclosing': 9286, 'anonymized': 9287, 'instructor': 9288, 'compactly': 9289, 'ltags': 9290, 'enaction': 9291, 'bloggers': 9292, 'nic': 9293, 'independant': 9294, 'nogoods': 9295, 'yinyang': 9296, 'glueqos': 9297, 'sweeten': 9298, 'swings': 9299, 'critac': 9300, 'proofreading': 9301, 'dtgolog': 9302, 'alert': 9303, 'rationalizability': 9304, 'decoupled': 9305, 'flowgraph': 9306, 'pradigms': 9307, 'encarta': 9308, 'siphon': 9309, 'webcrawler': 9310, 'responding': 9311, 'empathetic': 9312, 'companion': 9313, 'eco': 9314, 'places': 9315, 'predicated': 9316, 'starvation': 9317, 'commuting': 9318, 'multilogue': 9319, 'benchmarks': 9320, 'bmd': 9321}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "helbdUizF2un",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "outputId": "03fc1400-cd1f-428b-f953-7a2ae9578c71"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1234, shuffle=False)\n",
        "X_train2, X_test2 = train_test_split(np.array(train2), test_size=0.2, random_state=1234, shuffle=False)\n",
        "\n",
        "print(X_train[:5])\n",
        "print(X_train.shape)\n",
        "print(X_test[:5])\n",
        "print(X_train2[:5])\n",
        "print(X_test2[:5])\n",
        "\n",
        "print(type(X_train))\n",
        "print(type(X_train2))\n",
        "print(type(Y_train))\n",
        "\n",
        "print(X_train2.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0    0    0    0    0    0    0    0  132  247  402    2\n",
            "   834    9  126    5    8  161]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0   44\n",
            "  2099 1325   61    4  415   58]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0 1865   63  213\n",
            "  4596  478    2 1866 1444  622]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0 4597\n",
            "     3  262    9   18   51   15]\n",
            " [   0    0    0    0 1038  531   30  214    2  429 1228    5   45  545\n",
            "     5    6  122    2  132   32]]\n",
            "(10223, 20)\n",
            "[[   0    0    0    0    0    0    0    0    0    0    0    0   69  233\n",
            "   149   12 1242   96 1598   34]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0   28   68\n",
            "     1   38   78    6   41  232]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0 2704 1915   61\n",
            "     1 8428 2531    4 1686  173]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0   13   44\n",
            "  1062    7   65  865  250  112]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0  890 1654\n",
            "  3327 1058    5   54  475   41]]\n",
            "[[1.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.03333333]\n",
            " [0.         1.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.06666667]\n",
            " [0.14285714 0.85714286 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.23333333]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         1.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.13333333]]\n",
            "[[0.         0.         1.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.03333333]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.        ]]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "(10223, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYGj9gsCKmYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MAKE A SECOND DATA SPLIT\n",
        "X_train_, X_test_, Y_train_, Y_test_ = train_test_split(X, Y, test_size=0.2, random_state=245, shuffle=True)\n",
        "X_train2_, X_test2_ = train_test_split(np.array(train2), test_size=0.2, random_state=245, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-e50l29Hg3p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "7564c8c4-7bd3-41c7-be08-9d490f9ccf17"
      },
      "source": [
        "print(Y_train[:5])\n",
        "print(Y_test[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]]\n",
            "[[0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tVCkJNtr1kUq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "ceb72e9a-e279-456c-e397-1ab51a767436"
      },
      "source": [
        "# tokenize new data for Kaggle upload\n",
        "X_new = tokenizer.texts_to_sequences(test.title)\n",
        "X_new = pad_sequences(X_new, maxlen=20)\n",
        "X_new[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    3,  482,    8,   32,   15,    1,  117,   66],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "        1591,  130,  758,   20,   66,    1, 1407,  295,  307],\n",
              "       [   0,    0,    0,    0,    0,    0,   95,    4,  120,    2,   35,\n",
              "          21,  693, 2005, 6187,    1,   24,    2,  463,  166],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,  378,  229,  793,    1,   47,  278,  399,   14],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,   47,  202,  302,  519],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,  107,   10,  320,  284,  285,   33,  929,  593],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,   76,  299, 8308],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0, 1923,  287, 5096,   33, 1457, 1855,  189],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    3,\n",
              "         107,    4, 4608,  148,   53,    1,  305,  216,   25],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,  378,  159,  620,  377, 1261,    4,  206]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKUSQm62IR9l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "f3cff2ca-5bd6-4796-b899-e4cf4095e918"
      },
      "source": [
        "# trying to find dictionary length (for the whole labelled set tokenized)\n",
        "print(len(X_train))\n",
        "print(np.amax(X)) \n",
        "np.amax(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10223\n",
            "9321\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9321"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZS9fSpdIg3W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "61f08df4-3e43-4936-ceaa-fac9b73d3108"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0 ...    5    8  161]\n",
            " [   0    0    0 ...    4  415   58]\n",
            " [   0    0    0 ... 1866 1444  622]\n",
            " ...\n",
            " [   0    0    0 ...   64    4  206]\n",
            " [   0    0    0 ...   14 2086  314]\n",
            " [   0    0    0 ...    5   38   29]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBsJGIy4xH9N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3822a2db-60d0-4d52-d55b-e42c3099342a"
      },
      "source": [
        "# dict_len = max(max(X_train)) # for only X_train tokenized\n",
        "dict_len = np.amax(X)\n",
        "print(dict_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O--othcolipK",
        "colab_type": "text"
      },
      "source": [
        "## Making results reproducible with keras\n",
        "\n",
        "Will repeat this setting seed exercise before each model run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHKjEiuTU19z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from https://keras.io/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n",
        "# I replaced tf.set_random_seed with tf.compat.v1.set_random_seed (the former did not work)\n",
        "# the same change in tf.compat.v1.ConfigProto\n",
        "\n",
        "# The below is necessary for starting Numpy generated random numbers\n",
        "# in a well-defined initial state.\n",
        "np.random.seed(42)\n",
        "\n",
        "# The below is necessary for starting core Python generated random numbers\n",
        "# in a well-defined state.\n",
        "random.seed(12345)\n",
        "\n",
        "# Force TensorFlow to use single thread.\n",
        "# Multiple threads are a potential source of non-reproducible results.\n",
        "# For further details, see: https://stackoverflow.com/questions/42022950/\n",
        "\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "\n",
        "# from keras import backend as K\n",
        "\n",
        "# The below tf.set_random_seed() will make random number generation\n",
        "# in the TensorFlow backend have a well-defined initial state.\n",
        "# For further details, see:\n",
        "# https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
        "\n",
        "# tf.set_random_seed(1234) # this is not working\n",
        "tf.compat.v1.set_random_seed(1234)\n",
        "# sess = tf.compat.v1.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "# K.set_session(sess)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIyIe7miw4hM",
        "colab_type": "text"
      },
      "source": [
        "# 3. Using only own article titles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYlGfUpMqe7I",
        "colab_type": "text"
      },
      "source": [
        "## LSTM\n",
        "\n",
        "Trying a bunch of LSTM models with different optimizers. RMSprop wins the battle and is used thereafter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhQtabXq-5A-",
        "colab_type": "text"
      },
      "source": [
        "### LSTM with ADAM\n",
        "\n",
        "First, trying smaller than default lr with various num_baches for a basic model. Smaller lr (0.0001) works worse than default + takes more epochs => abandoned. Higher lr (0.01) also works worse. Batch size = 64 seems to result in decent accuracy and fast training, go with it.\n",
        "\n",
        "Trying different architectures with basic one-layer LSTM. Not much effect after emb=64 and LSTM hu = 64."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m4dHKZTozZST"
      },
      "source": [
        "##### Optimizing LR and batch for Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mhv83r6hzZSY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "49aff1df-3a30-4200-af2b-d120277ea113"
      },
      "source": [
        "# defaut: keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "# THIS IS ADAM, NOT ADAGRAD\n",
        "\n",
        "lr = [0.0001]\n",
        "\n",
        "batch = [16, 32, 64]\n",
        "for i in lr:\n",
        "  for j in batch:\n",
        "    print('lr:',i,' batch:',j,'----Adagrad')\n",
        "    np.random.seed(42)\n",
        "    random.seed(12345)\n",
        "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                  inter_op_parallelism_threads=1)\n",
        "    tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "    model = Sequential() \n",
        "    model.add(Embedding(dict_len + 1, output_dim=128)) \n",
        "    model.add(LSTM(128, dropout=0.2)) \n",
        "    model.add(Dense(5, activation=\"softmax\"))  \n",
        "    adam = optimizers.Adam(lr=i)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    # Train the model\n",
        "    model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=j, epochs=10) \n",
        "    model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lr: 0.0001  batch: 16 ----Adagrad\n",
            "Epoch 1/10\n",
            "639/639 [==============================] - 25s 39ms/step - loss: 1.5448 - accuracy: 0.3442 - val_loss: 1.3737 - val_accuracy: 0.4675\n",
            "Epoch 2/10\n",
            "639/639 [==============================] - 25s 39ms/step - loss: 1.1011 - accuracy: 0.5838 - val_loss: 0.9449 - val_accuracy: 0.6565\n",
            "Epoch 3/10\n",
            "639/639 [==============================] - 24s 38ms/step - loss: 0.8053 - accuracy: 0.7091 - val_loss: 0.8451 - val_accuracy: 0.6874\n",
            "Epoch 4/10\n",
            "639/639 [==============================] - 24s 38ms/step - loss: 0.6543 - accuracy: 0.7716 - val_loss: 0.7968 - val_accuracy: 0.7034\n",
            "Epoch 5/10\n",
            "639/639 [==============================] - 25s 39ms/step - loss: 0.5635 - accuracy: 0.8062 - val_loss: 0.7858 - val_accuracy: 0.7097\n",
            "Epoch 6/10\n",
            "639/639 [==============================] - 25s 39ms/step - loss: 0.4919 - accuracy: 0.8317 - val_loss: 0.7772 - val_accuracy: 0.7101\n",
            "Epoch 7/10\n",
            "639/639 [==============================] - 25s 39ms/step - loss: 0.4341 - accuracy: 0.8516 - val_loss: 0.8047 - val_accuracy: 0.7148\n",
            "Epoch 8/10\n",
            "639/639 [==============================] - 24s 38ms/step - loss: 0.3875 - accuracy: 0.8712 - val_loss: 0.8164 - val_accuracy: 0.7097\n",
            "Epoch 9/10\n",
            "639/639 [==============================] - 24s 38ms/step - loss: 0.3443 - accuracy: 0.8858 - val_loss: 0.8385 - val_accuracy: 0.7097\n",
            "Epoch 10/10\n",
            "639/639 [==============================] - 24s 38ms/step - loss: 0.3048 - accuracy: 0.9001 - val_loss: 0.8770 - val_accuracy: 0.7046\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 0.8777 - accuracy: 0.7046\n",
            "lr: 0.0001  batch: 32 ----Adagrad\n",
            "Epoch 1/10\n",
            "320/320 [==============================] - 14s 44ms/step - loss: 1.5751 - accuracy: 0.3092 - val_loss: 1.5388 - val_accuracy: 0.3811\n",
            "Epoch 2/10\n",
            "320/320 [==============================] - 14s 42ms/step - loss: 1.3510 - accuracy: 0.4944 - val_loss: 1.1270 - val_accuracy: 0.5743\n",
            "Epoch 3/10\n",
            "320/320 [==============================] - 14s 42ms/step - loss: 0.9567 - accuracy: 0.6389 - val_loss: 0.9299 - val_accuracy: 0.6420\n",
            "Epoch 4/10\n",
            "320/320 [==============================] - 13s 42ms/step - loss: 0.7804 - accuracy: 0.7254 - val_loss: 0.8583 - val_accuracy: 0.6858\n",
            "Epoch 5/10\n",
            "320/320 [==============================] - 13s 42ms/step - loss: 0.6660 - accuracy: 0.7686 - val_loss: 0.8183 - val_accuracy: 0.6882\n",
            "Epoch 6/10\n",
            "320/320 [==============================] - 14s 42ms/step - loss: 0.5810 - accuracy: 0.7991 - val_loss: 0.8123 - val_accuracy: 0.6972\n",
            "Epoch 7/10\n",
            "320/320 [==============================] - 14s 44ms/step - loss: 0.5157 - accuracy: 0.8206 - val_loss: 0.8188 - val_accuracy: 0.6960\n",
            "Epoch 8/10\n",
            "320/320 [==============================] - 14s 43ms/step - loss: 0.4668 - accuracy: 0.8464 - val_loss: 0.8123 - val_accuracy: 0.6987\n",
            "Epoch 9/10\n",
            "320/320 [==============================] - 14s 42ms/step - loss: 0.4240 - accuracy: 0.8571 - val_loss: 0.8414 - val_accuracy: 0.6980\n",
            "Epoch 10/10\n",
            "320/320 [==============================] - 14s 42ms/step - loss: 0.3830 - accuracy: 0.8752 - val_loss: 0.8364 - val_accuracy: 0.7046\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.8364 - accuracy: 0.7046\n",
            "lr: 0.0001  batch: 64 ----Adagrad\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 11s 71ms/step - loss: 1.5858 - accuracy: 0.2854 - val_loss: 1.5665 - val_accuracy: 0.3110\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 11s 68ms/step - loss: 1.5293 - accuracy: 0.4089 - val_loss: 1.4579 - val_accuracy: 0.4444\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 11s 69ms/step - loss: 1.2505 - accuracy: 0.5401 - val_loss: 1.0816 - val_accuracy: 0.5579\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 11s 69ms/step - loss: 0.9597 - accuracy: 0.6320 - val_loss: 0.9559 - val_accuracy: 0.6354\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 11s 69ms/step - loss: 0.8197 - accuracy: 0.7067 - val_loss: 0.9102 - val_accuracy: 0.6514\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 11s 70ms/step - loss: 0.7151 - accuracy: 0.7542 - val_loss: 0.8774 - val_accuracy: 0.6866\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 11s 69ms/step - loss: 0.6358 - accuracy: 0.7860 - val_loss: 0.8423 - val_accuracy: 0.6995\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 11s 69ms/step - loss: 0.5720 - accuracy: 0.8105 - val_loss: 0.8245 - val_accuracy: 0.6886\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 11s 70ms/step - loss: 0.5256 - accuracy: 0.8235 - val_loss: 0.8377 - val_accuracy: 0.6909\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 11s 69ms/step - loss: 0.4798 - accuracy: 0.8397 - val_loss: 0.8187 - val_accuracy: 0.6984\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 0.8186 - accuracy: 0.6984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEwYNx47jn34",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "ccc1f48b-3571-4328-928d-65bde9b91a3d"
      },
      "source": [
        "# defaut: keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "\n",
        "lr = [0.001]\n",
        "\n",
        "batch = [16, 32, 64]\n",
        "for i in lr:\n",
        "  for j in batch:\n",
        "    print('lr:',i,' batch:',j,'----Adam')\n",
        "    np.random.seed(42)\n",
        "    random.seed(12345)\n",
        "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                  inter_op_parallelism_threads=1)\n",
        "    tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "    model = Sequential() \n",
        "    model.add(Embedding(dict_len + 1, output_dim=128)) \n",
        "    model.add(LSTM(128, dropout=0.2)) \n",
        "    model.add(Dense(5, activation=\"softmax\"))  \n",
        "    adam = optimizers.Adam(lr=i)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    # Train the model\n",
        "    model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=j, epochs=5) \n",
        "    model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lr: 0.001  batch: 16 ----Adam\n",
            "Epoch 1/5\n",
            "639/639 [==============================] - 25s 39ms/step - loss: 1.0115 - accuracy: 0.6142 - val_loss: 0.7497 - val_accuracy: 0.7316\n",
            "Epoch 2/5\n",
            "639/639 [==============================] - 27s 42ms/step - loss: 0.5520 - accuracy: 0.8072 - val_loss: 0.7418 - val_accuracy: 0.7300\n",
            "Epoch 3/5\n",
            "639/639 [==============================] - 25s 38ms/step - loss: 0.3635 - accuracy: 0.8736 - val_loss: 0.8773 - val_accuracy: 0.7007\n",
            "Epoch 4/5\n",
            "639/639 [==============================] - 24s 38ms/step - loss: 0.2635 - accuracy: 0.9105 - val_loss: 0.9742 - val_accuracy: 0.6984\n",
            "Epoch 5/5\n",
            "639/639 [==============================] - 24s 38ms/step - loss: 0.1997 - accuracy: 0.9308 - val_loss: 1.1125 - val_accuracy: 0.6819\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 1.1132 - accuracy: 0.6819\n",
            "lr: 0.001  batch: 32 ----Adam\n",
            "Epoch 1/5\n",
            "320/320 [==============================] - 14s 44ms/step - loss: 1.0760 - accuracy: 0.5830 - val_loss: 0.7557 - val_accuracy: 0.7238\n",
            "Epoch 2/5\n",
            "320/320 [==============================] - 14s 43ms/step - loss: 0.5775 - accuracy: 0.7982 - val_loss: 0.7467 - val_accuracy: 0.7316\n",
            "Epoch 3/5\n",
            "320/320 [==============================] - 14s 42ms/step - loss: 0.3841 - accuracy: 0.8670 - val_loss: 0.8559 - val_accuracy: 0.7042\n",
            "Epoch 4/5\n",
            "320/320 [==============================] - 14s 43ms/step - loss: 0.2767 - accuracy: 0.9073 - val_loss: 0.9410 - val_accuracy: 0.7054\n",
            "Epoch 5/5\n",
            "320/320 [==============================] - 13s 42ms/step - loss: 0.2132 - accuracy: 0.9287 - val_loss: 1.0593 - val_accuracy: 0.6905\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 1.0593 - accuracy: 0.6905\n",
            "lr: 0.001  batch: 64 ----Adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 11s 71ms/step - loss: 1.1891 - accuracy: 0.5280 - val_loss: 0.8501 - val_accuracy: 0.6901\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 11s 68ms/step - loss: 0.6367 - accuracy: 0.7777 - val_loss: 0.7404 - val_accuracy: 0.7363\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 11s 69ms/step - loss: 0.4276 - accuracy: 0.8522 - val_loss: 0.8134 - val_accuracy: 0.7179\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 11s 69ms/step - loss: 0.3152 - accuracy: 0.8939 - val_loss: 0.8542 - val_accuracy: 0.7179\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 11s 68ms/step - loss: 0.2353 - accuracy: 0.9240 - val_loss: 1.0666 - val_accuracy: 0.6929\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 1.0667 - accuracy: 0.6929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWjpXvDPilL5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "fd760fa5-9e72-4d0e-cfae-27d5ec313c33"
      },
      "source": [
        "# defaut: keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "\n",
        "lr = [0.01]\n",
        "\n",
        "batch = [16, 32, 64]\n",
        "for i in lr:\n",
        "  for j in batch:\n",
        "    print('lr:',i,' batch:',j,'----Adam')\n",
        "    np.random.seed(42)\n",
        "    random.seed(12345)\n",
        "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                  inter_op_parallelism_threads=1)\n",
        "    tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "    model = Sequential() \n",
        "    model.add(Embedding(dict_len + 1, output_dim=128)) \n",
        "    model.add(LSTM(128, dropout=0.2)) \n",
        "    model.add(Dense(5, activation=\"softmax\"))  \n",
        "    adam = optimizers.Adam(lr=i)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    # Train the model\n",
        "    model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=j, epochs=5) \n",
        "    model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lr: 0.01  batch: 16 ----Adam\n",
            "Epoch 1/5\n",
            "639/639 [==============================] - 25s 39ms/step - loss: 0.9778 - accuracy: 0.6400 - val_loss: 0.8044 - val_accuracy: 0.7132\n",
            "Epoch 2/5\n",
            "639/639 [==============================] - 25s 38ms/step - loss: 0.5415 - accuracy: 0.8127 - val_loss: 0.9089 - val_accuracy: 0.6890\n",
            "Epoch 3/5\n",
            "639/639 [==============================] - 24s 38ms/step - loss: 0.3391 - accuracy: 0.8828 - val_loss: 1.0574 - val_accuracy: 0.6882\n",
            "Epoch 4/5\n",
            "639/639 [==============================] - 24s 38ms/step - loss: 0.2617 - accuracy: 0.9069 - val_loss: 1.1373 - val_accuracy: 0.6843\n",
            "Epoch 5/5\n",
            "639/639 [==============================] - 24s 38ms/step - loss: 0.2089 - accuracy: 0.9277 - val_loss: 1.3300 - val_accuracy: 0.6729\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 1.3306 - accuracy: 0.6729\n",
            "lr: 0.01  batch: 32 ----Adam\n",
            "Epoch 1/5\n",
            "320/320 [==============================] - 14s 44ms/step - loss: 0.9669 - accuracy: 0.6365 - val_loss: 0.7613 - val_accuracy: 0.7316\n",
            "Epoch 2/5\n",
            "320/320 [==============================] - 14s 42ms/step - loss: 0.5210 - accuracy: 0.8197 - val_loss: 0.8289 - val_accuracy: 0.7128\n",
            "Epoch 3/5\n",
            "320/320 [==============================] - 14s 42ms/step - loss: 0.2882 - accuracy: 0.9028 - val_loss: 1.0558 - val_accuracy: 0.7034\n",
            "Epoch 4/5\n",
            "320/320 [==============================] - 13s 42ms/step - loss: 0.1912 - accuracy: 0.9331 - val_loss: 1.1779 - val_accuracy: 0.6870\n",
            "Epoch 5/5\n",
            "320/320 [==============================] - 14s 43ms/step - loss: 0.1366 - accuracy: 0.9499 - val_loss: 1.4191 - val_accuracy: 0.6768\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 1.4191 - accuracy: 0.6768\n",
            "lr: 0.01  batch: 64 ----Adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 11s 71ms/step - loss: 0.9624 - accuracy: 0.6329 - val_loss: 0.7617 - val_accuracy: 0.7257\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 11s 69ms/step - loss: 0.5114 - accuracy: 0.8205 - val_loss: 0.8087 - val_accuracy: 0.7101\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 11s 68ms/step - loss: 0.2904 - accuracy: 0.8997 - val_loss: 1.0626 - val_accuracy: 0.6937\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 11s 68ms/step - loss: 0.1913 - accuracy: 0.9338 - val_loss: 1.1705 - val_accuracy: 0.6901\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 11s 69ms/step - loss: 0.1067 - accuracy: 0.9636 - val_loss: 1.4274 - val_accuracy: 0.6827\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 1.4273 - accuracy: 0.6827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WIWdTrIGnXtI"
      },
      "source": [
        "#### Trying various basic (one hidden layer) architectures\n",
        "\n",
        "After emb_dim = 64 and n_hid_units = 64, no much gain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ddu6upNNyDv4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "93cd9e64-20d0-486e-8d9a-ccfbeef9734c"
      },
      "source": [
        "embed = [32,64,128]\n",
        "hidden = [64,128,256]\n",
        "drop = [0.1, 0.2, 0.3]\n",
        "for i in embed:\n",
        "  for j in hidden:\n",
        "    for k in drop:\n",
        "      print('emb_dim:',i,' hidden_dim:',j, ' drop:',k,'----adam')\n",
        "      np.random.seed(42)\n",
        "      random.seed(12345)\n",
        "      session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                    inter_op_parallelism_threads=1)\n",
        "      tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "      model = Sequential() \n",
        "      model.add(Embedding(dict_len + 1, output_dim=i)) \n",
        "      model.add(LSTM(j, dropout=k)) \n",
        "      model.add(Dense(5, activation=\"softmax\"))  \n",
        "      model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "      # Train the model\n",
        "      model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=5) \n",
        "      model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "emb_dim: 32  hidden_dim: 64  drop: 0.1 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 5s 32ms/step - loss: 1.3771 - accuracy: 0.4138 - val_loss: 0.9567 - val_accuracy: 0.5974\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 4s 22ms/step - loss: 0.7466 - accuracy: 0.7294 - val_loss: 0.7705 - val_accuracy: 0.7113\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 4s 22ms/step - loss: 0.5164 - accuracy: 0.8190 - val_loss: 0.7884 - val_accuracy: 0.7093\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 4s 22ms/step - loss: 0.3869 - accuracy: 0.8709 - val_loss: 0.7980 - val_accuracy: 0.7148\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 4s 22ms/step - loss: 0.2992 - accuracy: 0.8998 - val_loss: 0.9253 - val_accuracy: 0.7031\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.9252 - accuracy: 0.7031\n",
            "emb_dim: 32  hidden_dim: 64  drop: 0.2 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 4s 25ms/step - loss: 1.3872 - accuracy: 0.4079 - val_loss: 0.9597 - val_accuracy: 0.6021\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 4s 22ms/step - loss: 0.7609 - accuracy: 0.7228 - val_loss: 0.7738 - val_accuracy: 0.7074\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 3s 22ms/step - loss: 0.5368 - accuracy: 0.8119 - val_loss: 0.7809 - val_accuracy: 0.7074\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 3s 22ms/step - loss: 0.4093 - accuracy: 0.8600 - val_loss: 0.7850 - val_accuracy: 0.7183\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 4s 22ms/step - loss: 0.3239 - accuracy: 0.8923 - val_loss: 0.8894 - val_accuracy: 0.7074\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.8893 - accuracy: 0.7074\n",
            "emb_dim: 32  hidden_dim: 64  drop: 0.3 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 4s 24ms/step - loss: 1.4074 - accuracy: 0.3998 - val_loss: 0.9951 - val_accuracy: 0.5849\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 3s 22ms/step - loss: 0.7947 - accuracy: 0.7080 - val_loss: 0.7746 - val_accuracy: 0.7074\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.5682 - accuracy: 0.8010 - val_loss: 0.7737 - val_accuracy: 0.7121\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 4s 22ms/step - loss: 0.4460 - accuracy: 0.8441 - val_loss: 0.7910 - val_accuracy: 0.7136\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 4s 23ms/step - loss: 0.3579 - accuracy: 0.8795 - val_loss: 0.8244 - val_accuracy: 0.7175\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.8242 - accuracy: 0.7175\n",
            "emb_dim: 32  hidden_dim: 128  drop: 0.1 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 7s 47ms/step - loss: 1.3230 - accuracy: 0.4469 - val_loss: 0.9305 - val_accuracy: 0.6299\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 7s 44ms/step - loss: 0.7452 - accuracy: 0.7309 - val_loss: 0.8478 - val_accuracy: 0.6948\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 7s 44ms/step - loss: 0.5327 - accuracy: 0.8141 - val_loss: 0.7820 - val_accuracy: 0.7093\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 7s 45ms/step - loss: 0.4050 - accuracy: 0.8635 - val_loss: 0.7983 - val_accuracy: 0.7105\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 7s 44ms/step - loss: 0.3176 - accuracy: 0.8948 - val_loss: 0.9023 - val_accuracy: 0.7085\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.9025 - accuracy: 0.7085\n",
            "emb_dim: 32  hidden_dim: 128  drop: 0.2 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 1.3368 - accuracy: 0.4417 - val_loss: 0.9364 - val_accuracy: 0.6362\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 7s 45ms/step - loss: 0.7676 - accuracy: 0.7203 - val_loss: 0.8563 - val_accuracy: 0.6948\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 7s 45ms/step - loss: 0.5619 - accuracy: 0.8029 - val_loss: 0.7609 - val_accuracy: 0.7171\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 7s 45ms/step - loss: 0.4359 - accuracy: 0.8532 - val_loss: 0.7722 - val_accuracy: 0.7171\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 7s 45ms/step - loss: 0.3477 - accuracy: 0.8794 - val_loss: 0.8331 - val_accuracy: 0.7093\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.8331 - accuracy: 0.7093\n",
            "emb_dim: 32  hidden_dim: 128  drop: 0.3 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 8s 47ms/step - loss: 1.3636 - accuracy: 0.4265 - val_loss: 0.9710 - val_accuracy: 0.6189\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 7s 44ms/step - loss: 0.8010 - accuracy: 0.7079 - val_loss: 0.8603 - val_accuracy: 0.6964\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 7s 46ms/step - loss: 0.5966 - accuracy: 0.7868 - val_loss: 0.7723 - val_accuracy: 0.7156\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 8s 47ms/step - loss: 0.4716 - accuracy: 0.8366 - val_loss: 0.7546 - val_accuracy: 0.7148\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 7s 46ms/step - loss: 0.3848 - accuracy: 0.8678 - val_loss: 0.8094 - val_accuracy: 0.7105\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.8093 - accuracy: 0.7105\n",
            "emb_dim: 32  hidden_dim: 256  drop: 0.1 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 18s 112ms/step - loss: 1.3223 - accuracy: 0.4466 - val_loss: 0.9234 - val_accuracy: 0.6843\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 17s 109ms/step - loss: 0.7353 - accuracy: 0.7419 - val_loss: 0.8028 - val_accuracy: 0.7089\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 17s 108ms/step - loss: 0.5274 - accuracy: 0.8210 - val_loss: 0.8071 - val_accuracy: 0.7007\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 17s 107ms/step - loss: 0.4031 - accuracy: 0.8630 - val_loss: 0.8075 - val_accuracy: 0.7124\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 17s 107ms/step - loss: 0.3184 - accuracy: 0.8924 - val_loss: 0.9507 - val_accuracy: 0.6913\n",
            "80/80 [==============================] - 2s 21ms/step - loss: 0.9509 - accuracy: 0.6913\n",
            "emb_dim: 32  hidden_dim: 256  drop: 0.2 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 18s 110ms/step - loss: 1.3272 - accuracy: 0.4431 - val_loss: 0.9169 - val_accuracy: 0.6772\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 17s 109ms/step - loss: 0.7464 - accuracy: 0.7392 - val_loss: 0.7785 - val_accuracy: 0.7140\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 17s 107ms/step - loss: 0.5406 - accuracy: 0.8142 - val_loss: 0.7698 - val_accuracy: 0.7089\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 17s 107ms/step - loss: 0.4264 - accuracy: 0.8577 - val_loss: 0.8125 - val_accuracy: 0.7109\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 17s 107ms/step - loss: 0.3428 - accuracy: 0.8851 - val_loss: 0.8740 - val_accuracy: 0.7023\n",
            "80/80 [==============================] - 2s 21ms/step - loss: 0.8740 - accuracy: 0.7023\n",
            "emb_dim: 32  hidden_dim: 256  drop: 0.3 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 18s 110ms/step - loss: 1.3430 - accuracy: 0.4319 - val_loss: 0.9307 - val_accuracy: 0.6710\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 17s 109ms/step - loss: 0.7728 - accuracy: 0.7247 - val_loss: 0.8046 - val_accuracy: 0.7058\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 18s 110ms/step - loss: 0.5745 - accuracy: 0.8015 - val_loss: 0.7833 - val_accuracy: 0.7070\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 18s 109ms/step - loss: 0.4584 - accuracy: 0.8436 - val_loss: 0.7913 - val_accuracy: 0.7156\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 17s 107ms/step - loss: 0.3820 - accuracy: 0.8717 - val_loss: 0.8135 - val_accuracy: 0.7109\n",
            "80/80 [==============================] - 2s 21ms/step - loss: 0.8133 - accuracy: 0.7109\n",
            "emb_dim: 64  hidden_dim: 64  drop: 0.1 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 5s 30ms/step - loss: 1.2890 - accuracy: 0.4756 - val_loss: 0.8697 - val_accuracy: 0.6686\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 4s 27ms/step - loss: 0.6553 - accuracy: 0.7663 - val_loss: 0.7451 - val_accuracy: 0.7340\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 4s 27ms/step - loss: 0.4403 - accuracy: 0.8503 - val_loss: 0.7691 - val_accuracy: 0.7246\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.3191 - accuracy: 0.8954 - val_loss: 0.9304 - val_accuracy: 0.7046\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 4s 27ms/step - loss: 0.2415 - accuracy: 0.9227 - val_loss: 0.9185 - val_accuracy: 0.7038\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.9184 - accuracy: 0.7038\n",
            "emb_dim: 64  hidden_dim: 64  drop: 0.2 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 1.3036 - accuracy: 0.4669 - val_loss: 0.8814 - val_accuracy: 0.6616\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 4s 27ms/step - loss: 0.6774 - accuracy: 0.7588 - val_loss: 0.7485 - val_accuracy: 0.7308\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 4s 27ms/step - loss: 0.4658 - accuracy: 0.8403 - val_loss: 0.7569 - val_accuracy: 0.7300\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 4s 26ms/step - loss: 0.3401 - accuracy: 0.8872 - val_loss: 0.8762 - val_accuracy: 0.7085\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 4s 27ms/step - loss: 0.2643 - accuracy: 0.9126 - val_loss: 0.9137 - val_accuracy: 0.7050\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.9136 - accuracy: 0.7050\n",
            "emb_dim: 64  hidden_dim: 64  drop: 0.3 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 5s 30ms/step - loss: 1.3123 - accuracy: 0.4600 - val_loss: 0.8827 - val_accuracy: 0.6628\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 4s 27ms/step - loss: 0.6965 - accuracy: 0.7511 - val_loss: 0.7490 - val_accuracy: 0.7332\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.4940 - accuracy: 0.8299 - val_loss: 0.7672 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 4s 26ms/step - loss: 0.3706 - accuracy: 0.8715 - val_loss: 0.8665 - val_accuracy: 0.7085\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 4s 26ms/step - loss: 0.2913 - accuracy: 0.9010 - val_loss: 0.8828 - val_accuracy: 0.7074\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.8827 - accuracy: 0.7074\n",
            "emb_dim: 64  hidden_dim: 128  drop: 0.1 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 9s 54ms/step - loss: 1.2358 - accuracy: 0.4955 - val_loss: 0.8427 - val_accuracy: 0.6827\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.6675 - accuracy: 0.7646 - val_loss: 0.7771 - val_accuracy: 0.7218\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.4578 - accuracy: 0.8423 - val_loss: 0.8354 - val_accuracy: 0.7117\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.3375 - accuracy: 0.8873 - val_loss: 0.8576 - val_accuracy: 0.7109\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.2592 - accuracy: 0.9157 - val_loss: 0.9845 - val_accuracy: 0.6991\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.9846 - accuracy: 0.6991\n",
            "emb_dim: 64  hidden_dim: 128  drop: 0.2 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 9s 54ms/step - loss: 1.2608 - accuracy: 0.4886 - val_loss: 0.8660 - val_accuracy: 0.6561\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.6814 - accuracy: 0.7587 - val_loss: 0.7635 - val_accuracy: 0.7297\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.4782 - accuracy: 0.8346 - val_loss: 0.7592 - val_accuracy: 0.7324\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.3544 - accuracy: 0.8825 - val_loss: 0.8200 - val_accuracy: 0.7164\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.2796 - accuracy: 0.9070 - val_loss: 0.9604 - val_accuracy: 0.7046\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.9604 - accuracy: 0.7046\n",
            "emb_dim: 64  hidden_dim: 128  drop: 0.3 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 1.2728 - accuracy: 0.4789 - val_loss: 0.8581 - val_accuracy: 0.6729\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.7051 - accuracy: 0.7497 - val_loss: 0.7663 - val_accuracy: 0.7300\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.5055 - accuracy: 0.8267 - val_loss: 0.8016 - val_accuracy: 0.7156\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.3866 - accuracy: 0.8702 - val_loss: 0.8007 - val_accuracy: 0.7164\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.3061 - accuracy: 0.8965 - val_loss: 0.9065 - val_accuracy: 0.7156\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.9063 - accuracy: 0.7156\n",
            "emb_dim: 64  hidden_dim: 256  drop: 0.1 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 19s 120ms/step - loss: 1.2298 - accuracy: 0.4994 - val_loss: 0.8415 - val_accuracy: 0.6808\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 19s 117ms/step - loss: 0.6630 - accuracy: 0.7726 - val_loss: 0.7814 - val_accuracy: 0.7226\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 19s 119ms/step - loss: 0.4531 - accuracy: 0.8473 - val_loss: 0.7859 - val_accuracy: 0.7218\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 19s 120ms/step - loss: 0.3344 - accuracy: 0.8883 - val_loss: 0.8528 - val_accuracy: 0.7179\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 19s 118ms/step - loss: 0.2527 - accuracy: 0.9169 - val_loss: 0.9831 - val_accuracy: 0.6972\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.9831 - accuracy: 0.6972\n",
            "emb_dim: 64  hidden_dim: 256  drop: 0.2 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 19s 121ms/step - loss: 1.2406 - accuracy: 0.4953 - val_loss: 0.8572 - val_accuracy: 0.6757\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 19s 117ms/step - loss: 0.6758 - accuracy: 0.7665 - val_loss: 0.7611 - val_accuracy: 0.7269\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 19s 118ms/step - loss: 0.4752 - accuracy: 0.8379 - val_loss: 0.7741 - val_accuracy: 0.7207\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 19s 116ms/step - loss: 0.3498 - accuracy: 0.8793 - val_loss: 0.8145 - val_accuracy: 0.7203\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 19s 118ms/step - loss: 0.2728 - accuracy: 0.9111 - val_loss: 0.9593 - val_accuracy: 0.6999\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.9593 - accuracy: 0.6999\n",
            "emb_dim: 64  hidden_dim: 256  drop: 0.3 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 19s 119ms/step - loss: 1.2613 - accuracy: 0.4877 - val_loss: 0.8693 - val_accuracy: 0.6815\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 19s 117ms/step - loss: 0.6954 - accuracy: 0.7573 - val_loss: 0.7562 - val_accuracy: 0.7308\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 19s 116ms/step - loss: 0.4973 - accuracy: 0.8286 - val_loss: 0.7635 - val_accuracy: 0.7230\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 20s 122ms/step - loss: 0.3775 - accuracy: 0.8703 - val_loss: 0.7977 - val_accuracy: 0.7214\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 19s 117ms/step - loss: 0.2933 - accuracy: 0.9037 - val_loss: 0.9110 - val_accuracy: 0.7109\n",
            "80/80 [==============================] - 2s 21ms/step - loss: 0.9110 - accuracy: 0.7109\n",
            "emb_dim: 128  hidden_dim: 64  drop: 0.1 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 6s 38ms/step - loss: 1.1955 - accuracy: 0.5252 - val_loss: 0.8104 - val_accuracy: 0.6952\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.6049 - accuracy: 0.7893 - val_loss: 0.7467 - val_accuracy: 0.7300\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.3990 - accuracy: 0.8633 - val_loss: 0.8056 - val_accuracy: 0.7152\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 6s 35ms/step - loss: 0.2847 - accuracy: 0.9057 - val_loss: 0.9277 - val_accuracy: 0.7074\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 6s 35ms/step - loss: 0.2157 - accuracy: 0.9302 - val_loss: 1.0017 - val_accuracy: 0.6968\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 1.0018 - accuracy: 0.6968\n",
            "emb_dim: 128  hidden_dim: 64  drop: 0.2 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 7s 42ms/step - loss: 1.2095 - accuracy: 0.5158 - val_loss: 0.8201 - val_accuracy: 0.6874\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 6s 35ms/step - loss: 0.6201 - accuracy: 0.7802 - val_loss: 0.7465 - val_accuracy: 0.7293\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 6s 35ms/step - loss: 0.4167 - accuracy: 0.8571 - val_loss: 0.8113 - val_accuracy: 0.7113\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.3024 - accuracy: 0.9007 - val_loss: 0.8922 - val_accuracy: 0.7117\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.2298 - accuracy: 0.9244 - val_loss: 0.9582 - val_accuracy: 0.7023\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.9582 - accuracy: 0.7023\n",
            "emb_dim: 128  hidden_dim: 64  drop: 0.3 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 6s 39ms/step - loss: 1.2241 - accuracy: 0.5065 - val_loss: 0.8320 - val_accuracy: 0.6862\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.6404 - accuracy: 0.7725 - val_loss: 0.7477 - val_accuracy: 0.7332\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 6s 37ms/step - loss: 0.4414 - accuracy: 0.8481 - val_loss: 0.7993 - val_accuracy: 0.7105\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 6s 37ms/step - loss: 0.3279 - accuracy: 0.8912 - val_loss: 0.8582 - val_accuracy: 0.7132\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.2488 - accuracy: 0.9163 - val_loss: 0.9374 - val_accuracy: 0.7046\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.9373 - accuracy: 0.7046\n",
            "emb_dim: 128  hidden_dim: 128  drop: 0.1 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 11s 70ms/step - loss: 1.1742 - accuracy: 0.5385 - val_loss: 0.8435 - val_accuracy: 0.6890\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 11s 69ms/step - loss: 0.6183 - accuracy: 0.7829 - val_loss: 0.7535 - val_accuracy: 0.7312\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 11s 69ms/step - loss: 0.4092 - accuracy: 0.8599 - val_loss: 0.8502 - val_accuracy: 0.7128\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 11s 68ms/step - loss: 0.2975 - accuracy: 0.9022 - val_loss: 0.8696 - val_accuracy: 0.7144\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 11s 68ms/step - loss: 0.2214 - accuracy: 0.9287 - val_loss: 1.1798 - val_accuracy: 0.6784\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.1800 - accuracy: 0.6784\n",
            "emb_dim: 128  hidden_dim: 128  drop: 0.2 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 11s 70ms/step - loss: 1.1891 - accuracy: 0.5280 - val_loss: 0.8501 - val_accuracy: 0.6901\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 11s 67ms/step - loss: 0.6367 - accuracy: 0.7777 - val_loss: 0.7404 - val_accuracy: 0.7363\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 11s 67ms/step - loss: 0.4276 - accuracy: 0.8522 - val_loss: 0.8134 - val_accuracy: 0.7179\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 11s 67ms/step - loss: 0.3152 - accuracy: 0.8939 - val_loss: 0.8542 - val_accuracy: 0.7179\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 11s 68ms/step - loss: 0.2353 - accuracy: 0.9240 - val_loss: 1.0666 - val_accuracy: 0.6929\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.0667 - accuracy: 0.6929\n",
            "emb_dim: 128  hidden_dim: 128  drop: 0.3 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 11s 70ms/step - loss: 1.2051 - accuracy: 0.5214 - val_loss: 0.8417 - val_accuracy: 0.7031\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 11s 69ms/step - loss: 0.6552 - accuracy: 0.7683 - val_loss: 0.7410 - val_accuracy: 0.7363\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 11s 67ms/step - loss: 0.4493 - accuracy: 0.8438 - val_loss: 0.8027 - val_accuracy: 0.7183\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 11s 69ms/step - loss: 0.3349 - accuracy: 0.8901 - val_loss: 0.8256 - val_accuracy: 0.7254\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 11s 68ms/step - loss: 0.2572 - accuracy: 0.9163 - val_loss: 1.0385 - val_accuracy: 0.6937\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 1.0386 - accuracy: 0.6937\n",
            "emb_dim: 128  hidden_dim: 256  drop: 0.1 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 21s 134ms/step - loss: 1.1470 - accuracy: 0.5483 - val_loss: 0.7977 - val_accuracy: 0.6964\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 21s 131ms/step - loss: 0.6000 - accuracy: 0.7931 - val_loss: 0.7504 - val_accuracy: 0.7328\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 21s 129ms/step - loss: 0.4053 - accuracy: 0.8633 - val_loss: 0.8289 - val_accuracy: 0.7207\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 21s 129ms/step - loss: 0.2917 - accuracy: 0.9015 - val_loss: 0.8806 - val_accuracy: 0.7136\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 21s 129ms/step - loss: 0.2205 - accuracy: 0.9275 - val_loss: 1.0649 - val_accuracy: 0.6948\n",
            "80/80 [==============================] - 2s 24ms/step - loss: 1.0650 - accuracy: 0.6948\n",
            "emb_dim: 128  hidden_dim: 256  drop: 0.2 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 22s 140ms/step - loss: 1.1644 - accuracy: 0.5393 - val_loss: 0.8012 - val_accuracy: 0.7054\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 22s 137ms/step - loss: 0.6193 - accuracy: 0.7840 - val_loss: 0.7483 - val_accuracy: 0.7351\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 22s 137ms/step - loss: 0.4245 - accuracy: 0.8531 - val_loss: 0.8045 - val_accuracy: 0.7246\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 22s 136ms/step - loss: 0.3059 - accuracy: 0.8965 - val_loss: 0.8550 - val_accuracy: 0.7152\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 22s 137ms/step - loss: 0.2300 - accuracy: 0.9233 - val_loss: 1.0870 - val_accuracy: 0.6909\n",
            "80/80 [==============================] - 2s 23ms/step - loss: 1.0872 - accuracy: 0.6909\n",
            "emb_dim: 128  hidden_dim: 256  drop: 0.3 ----adam\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 22s 138ms/step - loss: 1.1765 - accuracy: 0.5302 - val_loss: 0.8297 - val_accuracy: 0.7050\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 22s 135ms/step - loss: 0.6414 - accuracy: 0.7750 - val_loss: 0.7453 - val_accuracy: 0.7324\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 22s 136ms/step - loss: 0.4471 - accuracy: 0.8449 - val_loss: 0.8119 - val_accuracy: 0.7128\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 22s 136ms/step - loss: 0.3302 - accuracy: 0.8865 - val_loss: 0.8386 - val_accuracy: 0.7199\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 22s 135ms/step - loss: 0.2500 - accuracy: 0.9165 - val_loss: 0.9997 - val_accuracy: 0.7003\n",
            "80/80 [==============================] - 2s 24ms/step - loss: 0.9998 - accuracy: 0.7003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTP9t8pJp1Lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Running the best model on the test set\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "# keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None)\n",
        "# input_dim: int > 0. Size of the vocabulary, i.e. maximum integer index + 1.\n",
        "# output_dim: int >= 0. Dimension of the dense embedding.\n",
        "model.add(Embedding(dict_len + 1, 128)) \n",
        "model.add(LSTM(128, dropout=0.2)) \n",
        "# number of classes = 5\n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epgeDNEl7-c4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "ca27a81a-7251-4536-e9c0-51f65e847f1a"
      },
      "source": [
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=5) \n",
        "model.evaluate(X_test, Y_test) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "160/160 [==============================] - 11s 70ms/step - loss: 1.1891 - accuracy: 0.5280 - val_loss: 0.8501 - val_accuracy: 0.6901\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 11s 67ms/step - loss: 0.6367 - accuracy: 0.7777 - val_loss: 0.7404 - val_accuracy: 0.7363\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 11s 67ms/step - loss: 0.4276 - accuracy: 0.8522 - val_loss: 0.8134 - val_accuracy: 0.7179\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 11s 68ms/step - loss: 0.3152 - accuracy: 0.8939 - val_loss: 0.8542 - val_accuracy: 0.7179\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 11s 68ms/step - loss: 0.2353 - accuracy: 0.9240 - val_loss: 1.0666 - val_accuracy: 0.6929\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.0667 - accuracy: 0.6929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.066733717918396, 0.6928794980049133]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1KLASHkq-Uh",
        "colab_type": "text"
      },
      "source": [
        "#### Predict on test set for kaggle (1st upload)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTvD8uPX_H_R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "599566ea-5c59-4e25-82b0-baf138cdd9d8"
      },
      "source": [
        "Y_new = model.predict_classes(X_new)\n",
        "# show the inputs and predicted outputs\n",
        "print(X_new[:5])\n",
        "for i in range(5):\n",
        "\tprint(\"X=%s, Predicted=%s\" % (X_new[i], Y_new[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 64\n",
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    3  482\n",
            "     8   32   15    1  117   66]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0 1591  130  758\n",
            "    20   66    1 1407  295  307]\n",
            " [   0    0    0    0    0    0   95    4  120    2   35   21  693 2005\n",
            "  6187    1   24    2  463  166]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0  378  229\n",
            "   793    1   47  278  399   14]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0   47  202  302  519]]\n",
            "X=[  0   0   0   0   0   0   0   0   0   0   0   0   3 482   8  32  15   1\n",
            " 117  66], Predicted=1\n",
            "X=[   0    0    0    0    0    0    0    0    0    0    0 1591  130  758\n",
            "   20   66    1 1407  295  307], Predicted=3\n",
            "X=[   0    0    0    0    0    0   95    4  120    2   35   21  693 2005\n",
            " 6187    1   24    2  463  166], Predicted=0\n",
            "X=[  0   0   0   0   0   0   0   0   0   0   0   0 378 229 793   1  47 278\n",
            " 399  14], Predicted=2\n",
            "X=[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  47 202\n",
            " 302 519], Predicted=2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUA--CFLB1Z0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test1 = pd.DataFrame(list(zip(test['id'], Y_new)), \n",
        "               columns = ['id', 'label'])\n",
        "test1\n",
        "test1.to_csv('test1.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMSUge7KHMeU",
        "colab_type": "text"
      },
      "source": [
        "### LSTM with RMSprop\n",
        "\n",
        "Overall, RMSprop performs better than Adam and will be used in all the models below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kuYtzjxtEH0",
        "colab_type": "text"
      },
      "source": [
        "##### Optimizing LR and batch for RMSprop\n",
        "\n",
        "Default lr with batch=64 gives decent results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNWz1oMDwJcH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "outputId": "a2ed7309-4cce-4e6d-94e9-6f188f3deaeb"
      },
      "source": [
        "# defaut: keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
        "\n",
        "lr = [0.01]\n",
        "# lr = [0.0001, 0.001, 0.01]\n",
        "\n",
        "batch = [16, 32, 64, 128]\n",
        "for i in lr:\n",
        "  for j in batch:\n",
        "    print('lr:',i,' batch:',j,'----RMSprop')\n",
        "    np.random.seed(42)\n",
        "    random.seed(12345)\n",
        "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                  inter_op_parallelism_threads=1)\n",
        "    tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "    model = Sequential() \n",
        "    model.add(Embedding(dict_len + 1, output_dim=128)) \n",
        "    model.add(LSTM(128, dropout=0.2)) \n",
        "    model.add(Dense(5, activation=\"softmax\"))  \n",
        "    rmsprop = optimizers.RMSprop(lr=i, rho=0.9)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
        "    # Train the model\n",
        "    model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=j, epochs=5) \n",
        "    model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lr: 0.01  batch: 16 ----RMSprop\n",
            "Epoch 1/5\n",
            "639/639 [==============================] - 20s 31ms/step - loss: 0.9812 - accuracy: 0.6375 - val_loss: 0.7886 - val_accuracy: 0.7257\n",
            "Epoch 2/5\n",
            "639/639 [==============================] - 20s 31ms/step - loss: 0.5868 - accuracy: 0.8022 - val_loss: 0.7855 - val_accuracy: 0.7281\n",
            "Epoch 3/5\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.4292 - accuracy: 0.8607 - val_loss: 0.8679 - val_accuracy: 0.7230\n",
            "Epoch 4/5\n",
            "639/639 [==============================] - 20s 31ms/step - loss: 0.3376 - accuracy: 0.8866 - val_loss: 1.0261 - val_accuracy: 0.7015\n",
            "Epoch 5/5\n",
            "639/639 [==============================] - 19s 31ms/step - loss: 0.2620 - accuracy: 0.9101 - val_loss: 1.1424 - val_accuracy: 0.7042\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.1434 - accuracy: 0.7042\n",
            "lr: 0.01  batch: 32 ----RMSprop\n",
            "Epoch 1/5\n",
            "320/320 [==============================] - 12s 36ms/step - loss: 0.9828 - accuracy: 0.6278 - val_loss: 0.7676 - val_accuracy: 0.7312\n",
            "Epoch 2/5\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.5833 - accuracy: 0.7992 - val_loss: 0.7762 - val_accuracy: 0.7297\n",
            "Epoch 3/5\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.4054 - accuracy: 0.8619 - val_loss: 0.8119 - val_accuracy: 0.7257\n",
            "Epoch 4/5\n",
            "320/320 [==============================] - 11s 36ms/step - loss: 0.2882 - accuracy: 0.9004 - val_loss: 0.9689 - val_accuracy: 0.7128\n",
            "Epoch 5/5\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.1991 - accuracy: 0.9297 - val_loss: 1.1022 - val_accuracy: 0.6976\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.1022 - accuracy: 0.6976\n",
            "lr: 0.01  batch: 64 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 10s 64ms/step - loss: 0.9934 - accuracy: 0.6259 - val_loss: 0.8034 - val_accuracy: 0.7113\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.5845 - accuracy: 0.7940 - val_loss: 0.7730 - val_accuracy: 0.7246\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 10s 62ms/step - loss: 0.3949 - accuracy: 0.8627 - val_loss: 0.8345 - val_accuracy: 0.7246\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 10s 62ms/step - loss: 0.2751 - accuracy: 0.9056 - val_loss: 1.0112 - val_accuracy: 0.7097\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.1830 - accuracy: 0.9380 - val_loss: 1.1094 - val_accuracy: 0.7034\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.1101 - accuracy: 0.7034\n",
            "lr: 0.01  batch: 128 ----RMSprop\n",
            "Epoch 1/5\n",
            "80/80 [==============================] - 8s 96ms/step - loss: 1.0273 - accuracy: 0.6073 - val_loss: 0.7586 - val_accuracy: 0.7238\n",
            "Epoch 2/5\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.5993 - accuracy: 0.7878 - val_loss: 0.7437 - val_accuracy: 0.7383\n",
            "Epoch 3/5\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.4013 - accuracy: 0.8612 - val_loss: 0.8137 - val_accuracy: 0.7250\n",
            "Epoch 4/5\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.2682 - accuracy: 0.9038 - val_loss: 1.0222 - val_accuracy: 0.7023\n",
            "Epoch 5/5\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.1678 - accuracy: 0.9430 - val_loss: 1.1995 - val_accuracy: 0.6870\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.2008 - accuracy: 0.6870\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTB8O2QSYsOQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a6fe4b08-4101-4f56-c015-5e5107123991"
      },
      "source": [
        "# defaut: keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
        "\n",
        "lr = [0.001]\n",
        "# lr = [0.0001, 0.001, 0.01]\n",
        "\n",
        "batch = [16, 32, 64, 128]\n",
        "for i in lr:\n",
        "  for j in batch:\n",
        "    print('lr:',i,' batch:',j,'----RMSprop')\n",
        "    np.random.seed(42)\n",
        "    random.seed(12345)\n",
        "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                  inter_op_parallelism_threads=1)\n",
        "    tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "    model = Sequential() \n",
        "    model.add(Embedding(dict_len + 1, output_dim=128)) \n",
        "    model.add(LSTM(128, dropout=0.2)) \n",
        "    model.add(Dense(5, activation=\"softmax\"))  \n",
        "    rmsprop = optimizers.RMSprop(lr=i, rho=0.9)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
        "    # Train the model\n",
        "    model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=j, epochs=7) \n",
        "    model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lr: 0.001  batch: 16 ----RMSprop\n",
            "Epoch 1/7\n",
            "639/639 [==============================] - 20s 31ms/step - loss: 1.0888 - accuracy: 0.5768 - val_loss: 0.8210 - val_accuracy: 0.6913\n",
            "Epoch 2/7\n",
            "639/639 [==============================] - 20s 31ms/step - loss: 0.7221 - accuracy: 0.7429 - val_loss: 0.7533 - val_accuracy: 0.7344\n",
            "Epoch 3/7\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.6196 - accuracy: 0.7845 - val_loss: 0.7437 - val_accuracy: 0.7383\n",
            "Epoch 4/7\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.5466 - accuracy: 0.8075 - val_loss: 0.7515 - val_accuracy: 0.7379\n",
            "Epoch 5/7\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.4923 - accuracy: 0.8277 - val_loss: 0.7475 - val_accuracy: 0.7398\n",
            "Epoch 6/7\n",
            "639/639 [==============================] - 20s 31ms/step - loss: 0.4423 - accuracy: 0.8486 - val_loss: 0.7765 - val_accuracy: 0.7293\n",
            "Epoch 7/7\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.4019 - accuracy: 0.8612 - val_loss: 0.8147 - val_accuracy: 0.7300\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.8148 - accuracy: 0.7300\n",
            "lr: 0.001  batch: 32 ----RMSprop\n",
            "Epoch 1/7\n",
            "320/320 [==============================] - 12s 36ms/step - loss: 1.1361 - accuracy: 0.5529 - val_loss: 0.8407 - val_accuracy: 0.6901\n",
            "Epoch 2/7\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.7232 - accuracy: 0.7415 - val_loss: 0.7593 - val_accuracy: 0.7269\n",
            "Epoch 3/7\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.6048 - accuracy: 0.7890 - val_loss: 0.7546 - val_accuracy: 0.7336\n",
            "Epoch 4/7\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.5276 - accuracy: 0.8153 - val_loss: 0.7469 - val_accuracy: 0.7379\n",
            "Epoch 5/7\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.4751 - accuracy: 0.8345 - val_loss: 0.7457 - val_accuracy: 0.7426\n",
            "Epoch 6/7\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.4262 - accuracy: 0.8524 - val_loss: 0.7701 - val_accuracy: 0.7351\n",
            "Epoch 7/7\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.3861 - accuracy: 0.8651 - val_loss: 0.8143 - val_accuracy: 0.7351\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.8143 - accuracy: 0.7351\n",
            "lr: 0.001  batch: 64 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 10s 64ms/step - loss: 1.2273 - accuracy: 0.5234 - val_loss: 0.9097 - val_accuracy: 0.6815\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 10s 62ms/step - loss: 0.7507 - accuracy: 0.7302 - val_loss: 0.7609 - val_accuracy: 0.7265\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 10s 62ms/step - loss: 0.6068 - accuracy: 0.7877 - val_loss: 0.7455 - val_accuracy: 0.7371\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.5215 - accuracy: 0.8162 - val_loss: 0.7366 - val_accuracy: 0.7441\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 10s 62ms/step - loss: 0.4624 - accuracy: 0.8383 - val_loss: 0.7482 - val_accuracy: 0.7375\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.4126 - accuracy: 0.8558 - val_loss: 0.7802 - val_accuracy: 0.7320\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 10s 63ms/step - loss: 0.3694 - accuracy: 0.8714 - val_loss: 0.8092 - val_accuracy: 0.7320\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.8092 - accuracy: 0.7320\n",
            "lr: 0.001  batch: 128 ----RMSprop\n",
            "Epoch 1/7\n",
            "80/80 [==============================] - 8s 96ms/step - loss: 1.3407 - accuracy: 0.4798 - val_loss: 0.9975 - val_accuracy: 0.6056\n",
            "Epoch 2/7\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.8482 - accuracy: 0.6964 - val_loss: 0.7961 - val_accuracy: 0.7109\n",
            "Epoch 3/7\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.6411 - accuracy: 0.7751 - val_loss: 0.7711 - val_accuracy: 0.7261\n",
            "Epoch 4/7\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.5427 - accuracy: 0.8143 - val_loss: 0.7512 - val_accuracy: 0.7289\n",
            "Epoch 5/7\n",
            "80/80 [==============================] - 7s 92ms/step - loss: 0.4710 - accuracy: 0.8384 - val_loss: 0.7591 - val_accuracy: 0.7355\n",
            "Epoch 6/7\n",
            "80/80 [==============================] - 7s 92ms/step - loss: 0.4126 - accuracy: 0.8569 - val_loss: 0.7927 - val_accuracy: 0.7242\n",
            "Epoch 7/7\n",
            "80/80 [==============================] - 7s 93ms/step - loss: 0.3661 - accuracy: 0.8728 - val_loss: 0.8499 - val_accuracy: 0.7269\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.8505 - accuracy: 0.7269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o7XnvlznoYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dc433634-286e-4511-cfc4-8e3d7cfe0b4b"
      },
      "source": [
        "# defaut: keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
        "\n",
        "lr = [0.0001]\n",
        "# lr = [0.0001, 0.001, 0.01]\n",
        "\n",
        "batch = [16, 32, 64, 128]\n",
        "for i in lr:\n",
        "  for j in batch:\n",
        "    print('lr:',i,' batch:',j,'----RMSprop')\n",
        "    np.random.seed(42)\n",
        "    random.seed(12345)\n",
        "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                  inter_op_parallelism_threads=1)\n",
        "    tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "    model = Sequential() \n",
        "    model.add(Embedding(dict_len + 1, output_dim=128)) \n",
        "    model.add(LSTM(128, dropout=0.2)) \n",
        "    model.add(Dense(5, activation=\"softmax\"))  \n",
        "    rmsprop = optimizers.RMSprop(lr=i, rho=0.9)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
        "    # Train the model\n",
        "    model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=j, epochs=30) \n",
        "    model.evaluate(X_test, Y_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lr: 0.0001  batch: 16 ----RMSprop\n",
            "Epoch 1/30\n",
            "639/639 [==============================] - 20s 31ms/step - loss: 1.5698 - accuracy: 0.3136 - val_loss: 1.5271 - val_accuracy: 0.4229\n",
            "Epoch 2/30\n",
            "639/639 [==============================] - 20s 31ms/step - loss: 1.3980 - accuracy: 0.4676 - val_loss: 1.2868 - val_accuracy: 0.5055\n",
            "Epoch 3/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 1.1434 - accuracy: 0.5522 - val_loss: 1.0842 - val_accuracy: 0.5509\n",
            "Epoch 4/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 1.0019 - accuracy: 0.6159 - val_loss: 0.9725 - val_accuracy: 0.6307\n",
            "Epoch 5/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.9032 - accuracy: 0.6629 - val_loss: 0.9144 - val_accuracy: 0.6577\n",
            "Epoch 6/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.8243 - accuracy: 0.7020 - val_loss: 0.8726 - val_accuracy: 0.6792\n",
            "Epoch 7/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.7719 - accuracy: 0.7206 - val_loss: 0.8372 - val_accuracy: 0.6882\n",
            "Epoch 8/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.7326 - accuracy: 0.7407 - val_loss: 0.8189 - val_accuracy: 0.6980\n",
            "Epoch 9/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.7043 - accuracy: 0.7496 - val_loss: 0.7956 - val_accuracy: 0.7046\n",
            "Epoch 10/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.6747 - accuracy: 0.7611 - val_loss: 0.7923 - val_accuracy: 0.7132\n",
            "Epoch 11/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.6538 - accuracy: 0.7661 - val_loss: 0.7822 - val_accuracy: 0.7191\n",
            "Epoch 12/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.6351 - accuracy: 0.7764 - val_loss: 0.7950 - val_accuracy: 0.7121\n",
            "Epoch 13/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.6149 - accuracy: 0.7803 - val_loss: 0.7832 - val_accuracy: 0.7124\n",
            "Epoch 14/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.6004 - accuracy: 0.7893 - val_loss: 0.7677 - val_accuracy: 0.7265\n",
            "Epoch 15/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.5827 - accuracy: 0.7956 - val_loss: 0.7847 - val_accuracy: 0.7226\n",
            "Epoch 16/30\n",
            "639/639 [==============================] - 23s 36ms/step - loss: 0.5713 - accuracy: 0.8010 - val_loss: 0.7808 - val_accuracy: 0.7214\n",
            "Epoch 17/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.5588 - accuracy: 0.8059 - val_loss: 0.7563 - val_accuracy: 0.7293\n",
            "Epoch 18/30\n",
            "639/639 [==============================] - 20s 31ms/step - loss: 0.5496 - accuracy: 0.8049 - val_loss: 0.7653 - val_accuracy: 0.7277\n",
            "Epoch 19/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.5366 - accuracy: 0.8150 - val_loss: 0.7532 - val_accuracy: 0.7347\n",
            "Epoch 20/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.5273 - accuracy: 0.8161 - val_loss: 0.7699 - val_accuracy: 0.7273\n",
            "Epoch 21/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.5178 - accuracy: 0.8189 - val_loss: 0.7541 - val_accuracy: 0.7300\n",
            "Epoch 22/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.5094 - accuracy: 0.8224 - val_loss: 0.7597 - val_accuracy: 0.7332\n",
            "Epoch 23/30\n",
            "639/639 [==============================] - 19s 29ms/step - loss: 0.5018 - accuracy: 0.8256 - val_loss: 0.7880 - val_accuracy: 0.7269\n",
            "Epoch 24/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.4922 - accuracy: 0.8299 - val_loss: 0.7697 - val_accuracy: 0.7293\n",
            "Epoch 25/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.4849 - accuracy: 0.8321 - val_loss: 0.7489 - val_accuracy: 0.7332\n",
            "Epoch 26/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.4743 - accuracy: 0.8312 - val_loss: 0.7795 - val_accuracy: 0.7312\n",
            "Epoch 27/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.4701 - accuracy: 0.8347 - val_loss: 0.7555 - val_accuracy: 0.7379\n",
            "Epoch 28/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.4616 - accuracy: 0.8411 - val_loss: 0.7766 - val_accuracy: 0.7336\n",
            "Epoch 29/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.4587 - accuracy: 0.8407 - val_loss: 0.7524 - val_accuracy: 0.7375\n",
            "Epoch 30/30\n",
            "639/639 [==============================] - 19s 30ms/step - loss: 0.4483 - accuracy: 0.8420 - val_loss: 0.7626 - val_accuracy: 0.7375\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.7627 - accuracy: 0.7375\n",
            "lr: 0.0001  batch: 32 ----RMSprop\n",
            "Epoch 1/30\n",
            "320/320 [==============================] - 12s 36ms/step - loss: 1.5788 - accuracy: 0.2992 - val_loss: 1.5574 - val_accuracy: 0.3775\n",
            "Epoch 2/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 1.5044 - accuracy: 0.4243 - val_loss: 1.4245 - val_accuracy: 0.4707\n",
            "Epoch 3/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 1.2976 - accuracy: 0.5136 - val_loss: 1.2021 - val_accuracy: 0.5078\n",
            "Epoch 4/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 1.1070 - accuracy: 0.5689 - val_loss: 1.0573 - val_accuracy: 0.5962\n",
            "Epoch 5/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.9976 - accuracy: 0.6151 - val_loss: 0.9907 - val_accuracy: 0.6264\n",
            "Epoch 6/30\n",
            "320/320 [==============================] - 12s 36ms/step - loss: 0.9131 - accuracy: 0.6634 - val_loss: 0.9755 - val_accuracy: 0.6256\n",
            "Epoch 7/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.8419 - accuracy: 0.6931 - val_loss: 0.9302 - val_accuracy: 0.6475\n",
            "Epoch 8/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.7844 - accuracy: 0.7184 - val_loss: 0.8509 - val_accuracy: 0.6890\n",
            "Epoch 9/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.7431 - accuracy: 0.7353 - val_loss: 0.8206 - val_accuracy: 0.6886\n",
            "Epoch 10/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.7058 - accuracy: 0.7480 - val_loss: 0.8044 - val_accuracy: 0.7054\n",
            "Epoch 11/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.6771 - accuracy: 0.7605 - val_loss: 0.7986 - val_accuracy: 0.7121\n",
            "Epoch 12/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.6529 - accuracy: 0.7704 - val_loss: 0.7982 - val_accuracy: 0.7054\n",
            "Epoch 13/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.6271 - accuracy: 0.7807 - val_loss: 0.7904 - val_accuracy: 0.7031\n",
            "Epoch 14/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.6116 - accuracy: 0.7841 - val_loss: 0.7761 - val_accuracy: 0.7203\n",
            "Epoch 15/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.5908 - accuracy: 0.7927 - val_loss: 0.7931 - val_accuracy: 0.7121\n",
            "Epoch 16/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.5745 - accuracy: 0.7989 - val_loss: 0.7757 - val_accuracy: 0.7183\n",
            "Epoch 17/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.5614 - accuracy: 0.8049 - val_loss: 0.7561 - val_accuracy: 0.7265\n",
            "Epoch 18/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.5488 - accuracy: 0.8071 - val_loss: 0.7564 - val_accuracy: 0.7265\n",
            "Epoch 19/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.5350 - accuracy: 0.8119 - val_loss: 0.7565 - val_accuracy: 0.7281\n",
            "Epoch 20/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.5251 - accuracy: 0.8175 - val_loss: 0.7623 - val_accuracy: 0.7297\n",
            "Epoch 21/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.5101 - accuracy: 0.8231 - val_loss: 0.7554 - val_accuracy: 0.7281\n",
            "Epoch 22/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.4998 - accuracy: 0.8244 - val_loss: 0.7621 - val_accuracy: 0.7363\n",
            "Epoch 23/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.4887 - accuracy: 0.8290 - val_loss: 0.7681 - val_accuracy: 0.7304\n",
            "Epoch 24/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.4795 - accuracy: 0.8350 - val_loss: 0.7840 - val_accuracy: 0.7214\n",
            "Epoch 25/30\n",
            "320/320 [==============================] - 11s 36ms/step - loss: 0.4715 - accuracy: 0.8354 - val_loss: 0.7564 - val_accuracy: 0.7324\n",
            "Epoch 26/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.4616 - accuracy: 0.8361 - val_loss: 0.7748 - val_accuracy: 0.7332\n",
            "Epoch 27/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.4562 - accuracy: 0.8436 - val_loss: 0.7568 - val_accuracy: 0.7367\n",
            "Epoch 28/30\n",
            "320/320 [==============================] - 11s 35ms/step - loss: 0.4474 - accuracy: 0.8459 - val_loss: 0.7747 - val_accuracy: 0.7316\n",
            "Epoch 29/30\n",
            "320/320 [==============================] - 12s 37ms/step - loss: 0.4387 - accuracy: 0.8474 - val_loss: 0.7544 - val_accuracy: 0.7332\n",
            "Epoch 30/30\n",
            "320/320 [==============================] - 14s 44ms/step - loss: 0.4311 - accuracy: 0.8498 - val_loss: 0.7541 - val_accuracy: 0.7371\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.7541 - accuracy: 0.7371\n",
            "lr: 0.0001  batch: 64 ----RMSprop\n",
            "Epoch 1/30\n",
            "160/160 [==============================] - 10s 64ms/step - loss: 1.5850 - accuracy: 0.2951 - val_loss: 1.5696 - val_accuracy: 0.3658\n",
            "Epoch 2/30\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 1.5516 - accuracy: 0.3934 - val_loss: 1.5289 - val_accuracy: 0.4272\n",
            "Epoch 3/30\n",
            "160/160 [==============================] - 10s 62ms/step - loss: 1.4677 - accuracy: 0.4498 - val_loss: 1.4016 - val_accuracy: 0.4292\n",
            "Epoch 4/30\n",
            "160/160 [==============================] - 10s 62ms/step - loss: 1.3068 - accuracy: 0.5254 - val_loss: 1.2347 - val_accuracy: 0.5450\n",
            "Epoch 5/30\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 1.1462 - accuracy: 0.5668 - val_loss: 1.1250 - val_accuracy: 0.5634\n",
            "Epoch 6/30\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 1.0392 - accuracy: 0.5999 - val_loss: 1.0278 - val_accuracy: 0.6146\n",
            "Epoch 7/30\n",
            "160/160 [==============================] - 10s 62ms/step - loss: 0.9604 - accuracy: 0.6369 - val_loss: 0.9823 - val_accuracy: 0.6405\n",
            "Epoch 8/30\n",
            "160/160 [==============================] - 10s 60ms/step - loss: 0.8984 - accuracy: 0.6741 - val_loss: 0.9373 - val_accuracy: 0.6577\n",
            "Epoch 9/30\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.8447 - accuracy: 0.7028 - val_loss: 0.9151 - val_accuracy: 0.6487\n",
            "Epoch 10/30\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.7918 - accuracy: 0.7207 - val_loss: 0.8680 - val_accuracy: 0.6851\n",
            "Epoch 11/30\n",
            "160/160 [==============================] - 10s 62ms/step - loss: 0.7487 - accuracy: 0.7347 - val_loss: 0.8447 - val_accuracy: 0.6952\n",
            "Epoch 12/30\n",
            "160/160 [==============================] - 10s 62ms/step - loss: 0.7127 - accuracy: 0.7514 - val_loss: 0.8387 - val_accuracy: 0.6882\n",
            "Epoch 13/30\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.6800 - accuracy: 0.7652 - val_loss: 0.8362 - val_accuracy: 0.6776\n",
            "Epoch 14/30\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.6537 - accuracy: 0.7703 - val_loss: 0.8036 - val_accuracy: 0.7007\n",
            "Epoch 15/30\n",
            "160/160 [==============================] - 10s 62ms/step - loss: 0.6286 - accuracy: 0.7760 - val_loss: 0.8051 - val_accuracy: 0.6991\n",
            "Epoch 16/30\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.6080 - accuracy: 0.7862 - val_loss: 0.7961 - val_accuracy: 0.7085\n",
            "Epoch 17/30\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.5931 - accuracy: 0.7943 - val_loss: 0.7705 - val_accuracy: 0.7164\n",
            "Epoch 18/30\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.5755 - accuracy: 0.7955 - val_loss: 0.7688 - val_accuracy: 0.7144\n",
            "Epoch 19/30\n",
            "160/160 [==============================] - 10s 62ms/step - loss: 0.5604 - accuracy: 0.8034 - val_loss: 0.7695 - val_accuracy: 0.7207\n",
            "Epoch 20/30\n",
            "160/160 [==============================] - 10s 62ms/step - loss: 0.5427 - accuracy: 0.8127 - val_loss: 0.7691 - val_accuracy: 0.7144\n",
            "Epoch 21/30\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.5296 - accuracy: 0.8159 - val_loss: 0.7727 - val_accuracy: 0.7140\n",
            "Epoch 22/30\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.5164 - accuracy: 0.8213 - val_loss: 0.7679 - val_accuracy: 0.7250\n",
            "Epoch 23/30\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.5030 - accuracy: 0.8270 - val_loss: 0.7765 - val_accuracy: 0.7175\n",
            "Epoch 24/30\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.4897 - accuracy: 0.8302 - val_loss: 0.7749 - val_accuracy: 0.7148\n",
            "Epoch 25/30\n",
            "160/160 [==============================] - 10s 62ms/step - loss: 0.4824 - accuracy: 0.8292 - val_loss: 0.7630 - val_accuracy: 0.7242\n",
            "Epoch 26/30\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.4687 - accuracy: 0.8355 - val_loss: 0.7767 - val_accuracy: 0.7203\n",
            "Epoch 27/30\n",
            "160/160 [==============================] - 10s 62ms/step - loss: 0.4636 - accuracy: 0.8400 - val_loss: 0.7597 - val_accuracy: 0.7265\n",
            "Epoch 28/30\n",
            "160/160 [==============================] - 10s 62ms/step - loss: 0.4527 - accuracy: 0.8415 - val_loss: 0.7713 - val_accuracy: 0.7265\n",
            "Epoch 29/30\n",
            "160/160 [==============================] - 10s 62ms/step - loss: 0.4431 - accuracy: 0.8462 - val_loss: 0.7644 - val_accuracy: 0.7234\n",
            "Epoch 30/30\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.4334 - accuracy: 0.8481 - val_loss: 0.7663 - val_accuracy: 0.7246\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.7661 - accuracy: 0.7246\n",
            "lr: 0.0001  batch: 128 ----RMSprop\n",
            "Epoch 1/30\n",
            "80/80 [==============================] - 8s 96ms/step - loss: 1.5911 - accuracy: 0.2917 - val_loss: 1.5760 - val_accuracy: 0.3016\n",
            "Epoch 2/30\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 1.5679 - accuracy: 0.3713 - val_loss: 1.5597 - val_accuracy: 0.3815\n",
            "Epoch 3/30\n",
            "80/80 [==============================] - 7s 90ms/step - loss: 1.5419 - accuracy: 0.4023 - val_loss: 1.5265 - val_accuracy: 0.4053\n",
            "Epoch 4/30\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 1.4890 - accuracy: 0.4591 - val_loss: 1.4569 - val_accuracy: 0.4687\n",
            "Epoch 5/30\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 1.3838 - accuracy: 0.5048 - val_loss: 1.3342 - val_accuracy: 0.5121\n",
            "Epoch 6/30\n",
            "80/80 [==============================] - 7s 94ms/step - loss: 1.2621 - accuracy: 0.5499 - val_loss: 1.2201 - val_accuracy: 0.5509\n",
            "Epoch 7/30\n",
            "80/80 [==============================] - 7s 92ms/step - loss: 1.1452 - accuracy: 0.5810 - val_loss: 1.1427 - val_accuracy: 0.5673\n",
            "Epoch 8/30\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 1.0626 - accuracy: 0.5963 - val_loss: 1.0881 - val_accuracy: 0.5665\n",
            "Epoch 9/30\n",
            "80/80 [==============================] - 7s 92ms/step - loss: 1.0055 - accuracy: 0.6174 - val_loss: 1.0360 - val_accuracy: 0.6013\n",
            "Epoch 10/30\n",
            "80/80 [==============================] - 7s 92ms/step - loss: 0.9513 - accuracy: 0.6418 - val_loss: 0.9864 - val_accuracy: 0.6334\n",
            "Epoch 11/30\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.9075 - accuracy: 0.6670 - val_loss: 0.9645 - val_accuracy: 0.6514\n",
            "Epoch 12/30\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.8632 - accuracy: 0.6895 - val_loss: 0.9348 - val_accuracy: 0.6491\n",
            "Epoch 13/30\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.8149 - accuracy: 0.7159 - val_loss: 0.8988 - val_accuracy: 0.6655\n",
            "Epoch 14/30\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.7775 - accuracy: 0.7303 - val_loss: 0.8864 - val_accuracy: 0.6671\n",
            "Epoch 15/30\n",
            "80/80 [==============================] - 7s 92ms/step - loss: 0.7449 - accuracy: 0.7415 - val_loss: 0.8559 - val_accuracy: 0.6897\n",
            "Epoch 16/30\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.7128 - accuracy: 0.7538 - val_loss: 0.8483 - val_accuracy: 0.6999\n",
            "Epoch 17/30\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.6853 - accuracy: 0.7614 - val_loss: 0.8415 - val_accuracy: 0.6847\n",
            "Epoch 18/30\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.6579 - accuracy: 0.7702 - val_loss: 0.8250 - val_accuracy: 0.7019\n",
            "Epoch 19/30\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.6379 - accuracy: 0.7809 - val_loss: 0.8108 - val_accuracy: 0.7015\n",
            "Epoch 20/30\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.6180 - accuracy: 0.7847 - val_loss: 0.8184 - val_accuracy: 0.6890\n",
            "Epoch 21/30\n",
            "80/80 [==============================] - 7s 90ms/step - loss: 0.5987 - accuracy: 0.7944 - val_loss: 0.7966 - val_accuracy: 0.7027\n",
            "Epoch 22/30\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.5799 - accuracy: 0.8003 - val_loss: 0.8062 - val_accuracy: 0.7140\n",
            "Epoch 23/30\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.5644 - accuracy: 0.8024 - val_loss: 0.7956 - val_accuracy: 0.7046\n",
            "Epoch 24/30\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.5512 - accuracy: 0.8097 - val_loss: 0.7962 - val_accuracy: 0.6964\n",
            "Epoch 25/30\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.5401 - accuracy: 0.8099 - val_loss: 0.7856 - val_accuracy: 0.7089\n",
            "Epoch 26/30\n",
            "80/80 [==============================] - 7s 92ms/step - loss: 0.5207 - accuracy: 0.8163 - val_loss: 0.7880 - val_accuracy: 0.7113\n",
            "Epoch 27/30\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.5117 - accuracy: 0.8244 - val_loss: 0.7715 - val_accuracy: 0.7187\n",
            "Epoch 28/30\n",
            "80/80 [==============================] - 7s 91ms/step - loss: 0.4985 - accuracy: 0.8241 - val_loss: 0.7855 - val_accuracy: 0.7167\n",
            "Epoch 29/30\n",
            "80/80 [==============================] - 7s 92ms/step - loss: 0.4882 - accuracy: 0.8335 - val_loss: 0.7759 - val_accuracy: 0.7148\n",
            "Epoch 30/30\n",
            "80/80 [==============================] - 7s 92ms/step - loss: 0.4742 - accuracy: 0.8346 - val_loss: 0.7768 - val_accuracy: 0.7210\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.7769 - accuracy: 0.7210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ6TAzmXl2oM",
        "colab_type": "text"
      },
      "source": [
        "#### Trying various basic (one hidden layer) architectures\n",
        "\n",
        "Slight trend to growing valid. accuracy with increased emb and hidden dims."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OG5elm0fHDs_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e55d17c8-d693-412b-eabe-2c092ea7693b"
      },
      "source": [
        "embed = [32,64,128]\n",
        "hidden = [64,128,256]\n",
        "drop = [0, 0.1, 0.2, 0.3]\n",
        "for i in embed:\n",
        "  for j in hidden:\n",
        "    for k in drop:\n",
        "      print('emb_dim:',i,' hidden_dim:',j, ' drop:',k,'----RMSprop')\n",
        "      np.random.seed(42)\n",
        "      random.seed(12345)\n",
        "      session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                    inter_op_parallelism_threads=1)\n",
        "      tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "      model = Sequential() \n",
        "      model.add(Embedding(dict_len + 1, output_dim=i)) \n",
        "      model.add(LSTM(j, dropout=k)) \n",
        "      model.add(Dense(5, activation=\"softmax\"))  \n",
        "      model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "      model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=7) \n",
        "      model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "emb_dim: 32  hidden_dim: 64  drop: 0 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 3s 22ms/step - loss: 1.4046 - accuracy: 0.4062 - val_loss: 1.0870 - val_accuracy: 0.5646\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.9025 - accuracy: 0.6645 - val_loss: 0.8483 - val_accuracy: 0.6714\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.6947 - accuracy: 0.7523 - val_loss: 0.7841 - val_accuracy: 0.7066\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.5924 - accuracy: 0.7889 - val_loss: 0.7771 - val_accuracy: 0.7148\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.5224 - accuracy: 0.8178 - val_loss: 0.7396 - val_accuracy: 0.7340\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.4708 - accuracy: 0.8353 - val_loss: 0.7413 - val_accuracy: 0.7238\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.4269 - accuracy: 0.8534 - val_loss: 0.8439 - val_accuracy: 0.7254\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.8438 - accuracy: 0.7254\n",
            "emb_dim: 32  hidden_dim: 64  drop: 0.1 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 4s 22ms/step - loss: 1.4154 - accuracy: 0.4041 - val_loss: 1.1124 - val_accuracy: 0.5630\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.9264 - accuracy: 0.6512 - val_loss: 0.8616 - val_accuracy: 0.6628\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.7200 - accuracy: 0.7429 - val_loss: 0.7980 - val_accuracy: 0.6987\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.6173 - accuracy: 0.7819 - val_loss: 0.7669 - val_accuracy: 0.7171\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.5479 - accuracy: 0.8100 - val_loss: 0.7417 - val_accuracy: 0.7308\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.4990 - accuracy: 0.8258 - val_loss: 0.7373 - val_accuracy: 0.7261\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.4524 - accuracy: 0.8426 - val_loss: 0.8228 - val_accuracy: 0.7312\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.8227 - accuracy: 0.7312\n",
            "emb_dim: 32  hidden_dim: 64  drop: 0.2 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 4s 22ms/step - loss: 1.4302 - accuracy: 0.3948 - val_loss: 1.1282 - val_accuracy: 0.5634\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.9572 - accuracy: 0.6368 - val_loss: 0.8824 - val_accuracy: 0.6534\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.7443 - accuracy: 0.7299 - val_loss: 0.8039 - val_accuracy: 0.6972\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.6409 - accuracy: 0.7704 - val_loss: 0.7561 - val_accuracy: 0.7164\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.5734 - accuracy: 0.7985 - val_loss: 0.7404 - val_accuracy: 0.7297\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.5256 - accuracy: 0.8155 - val_loss: 0.7315 - val_accuracy: 0.7308\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.4788 - accuracy: 0.8335 - val_loss: 0.7876 - val_accuracy: 0.7351\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.7875 - accuracy: 0.7351\n",
            "emb_dim: 32  hidden_dim: 64  drop: 0.3 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 4s 22ms/step - loss: 1.4445 - accuracy: 0.3913 - val_loss: 1.1533 - val_accuracy: 0.5618\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.9875 - accuracy: 0.6211 - val_loss: 0.8993 - val_accuracy: 0.6573\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.7762 - accuracy: 0.7175 - val_loss: 0.8156 - val_accuracy: 0.6917\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.6740 - accuracy: 0.7566 - val_loss: 0.7865 - val_accuracy: 0.7034\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.6048 - accuracy: 0.7883 - val_loss: 0.7451 - val_accuracy: 0.7273\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.5578 - accuracy: 0.8049 - val_loss: 0.7280 - val_accuracy: 0.7320\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.5150 - accuracy: 0.8189 - val_loss: 0.7850 - val_accuracy: 0.7289\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.7850 - accuracy: 0.7289\n",
            "emb_dim: 32  hidden_dim: 128  drop: 0 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 7s 44ms/step - loss: 1.3526 - accuracy: 0.4420 - val_loss: 1.0136 - val_accuracy: 0.5908\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 7s 42ms/step - loss: 0.8659 - accuracy: 0.6854 - val_loss: 0.8256 - val_accuracy: 0.6917\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 7s 42ms/step - loss: 0.6853 - accuracy: 0.7549 - val_loss: 0.7742 - val_accuracy: 0.7121\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 7s 42ms/step - loss: 0.5885 - accuracy: 0.7924 - val_loss: 0.7714 - val_accuracy: 0.7203\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 7s 42ms/step - loss: 0.5178 - accuracy: 0.8167 - val_loss: 0.7498 - val_accuracy: 0.7234\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 7s 42ms/step - loss: 0.4656 - accuracy: 0.8393 - val_loss: 0.7485 - val_accuracy: 0.7261\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 7s 43ms/step - loss: 0.4207 - accuracy: 0.8564 - val_loss: 0.7914 - val_accuracy: 0.7312\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.7915 - accuracy: 0.7312\n",
            "emb_dim: 32  hidden_dim: 128  drop: 0.1 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 7s 45ms/step - loss: 1.3888 - accuracy: 0.4377 - val_loss: 1.0658 - val_accuracy: 0.5861\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 7s 42ms/step - loss: 0.9107 - accuracy: 0.6652 - val_loss: 0.8438 - val_accuracy: 0.6878\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 7s 43ms/step - loss: 0.7222 - accuracy: 0.7390 - val_loss: 0.7777 - val_accuracy: 0.7109\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 7s 44ms/step - loss: 0.6222 - accuracy: 0.7822 - val_loss: 0.7717 - val_accuracy: 0.7160\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 7s 43ms/step - loss: 0.5515 - accuracy: 0.8084 - val_loss: 0.7408 - val_accuracy: 0.7312\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 7s 44ms/step - loss: 0.5019 - accuracy: 0.8250 - val_loss: 0.7339 - val_accuracy: 0.7312\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 7s 43ms/step - loss: 0.4543 - accuracy: 0.8425 - val_loss: 0.7754 - val_accuracy: 0.7371\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.7755 - accuracy: 0.7371\n",
            "emb_dim: 32  hidden_dim: 128  drop: 0.2 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 7s 45ms/step - loss: 1.3785 - accuracy: 0.4265 - val_loss: 1.0589 - val_accuracy: 0.6052\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 7s 43ms/step - loss: 0.9183 - accuracy: 0.6555 - val_loss: 0.8590 - val_accuracy: 0.6776\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 7s 43ms/step - loss: 0.7447 - accuracy: 0.7309 - val_loss: 0.7855 - val_accuracy: 0.7019\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 7s 43ms/step - loss: 0.6448 - accuracy: 0.7728 - val_loss: 0.7816 - val_accuracy: 0.7171\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 7s 42ms/step - loss: 0.5772 - accuracy: 0.7960 - val_loss: 0.7437 - val_accuracy: 0.7332\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 7s 43ms/step - loss: 0.5275 - accuracy: 0.8167 - val_loss: 0.7339 - val_accuracy: 0.7312\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 7s 43ms/step - loss: 0.4844 - accuracy: 0.8324 - val_loss: 0.7558 - val_accuracy: 0.7379\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.7558 - accuracy: 0.7379\n",
            "emb_dim: 32  hidden_dim: 128  drop: 0.3 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 1.4082 - accuracy: 0.4178 - val_loss: 1.0898 - val_accuracy: 0.5861\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 7s 47ms/step - loss: 0.9478 - accuracy: 0.6463 - val_loss: 0.8681 - val_accuracy: 0.6674\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 7s 43ms/step - loss: 0.7738 - accuracy: 0.7220 - val_loss: 0.7916 - val_accuracy: 0.6991\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 7s 43ms/step - loss: 0.6772 - accuracy: 0.7589 - val_loss: 0.7813 - val_accuracy: 0.7093\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 7s 44ms/step - loss: 0.6127 - accuracy: 0.7840 - val_loss: 0.7463 - val_accuracy: 0.7273\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 7s 44ms/step - loss: 0.5649 - accuracy: 0.8029 - val_loss: 0.7344 - val_accuracy: 0.7316\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 7s 43ms/step - loss: 0.5260 - accuracy: 0.8142 - val_loss: 0.7498 - val_accuracy: 0.7347\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.7498 - accuracy: 0.7347\n",
            "emb_dim: 32  hidden_dim: 256  drop: 0 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 17s 108ms/step - loss: 1.3428 - accuracy: 0.4540 - val_loss: 1.0193 - val_accuracy: 0.6440\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 17s 104ms/step - loss: 0.8470 - accuracy: 0.6981 - val_loss: 0.8155 - val_accuracy: 0.7015\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 17s 106ms/step - loss: 0.6700 - accuracy: 0.7646 - val_loss: 0.7654 - val_accuracy: 0.7191\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 17s 104ms/step - loss: 0.5732 - accuracy: 0.7983 - val_loss: 0.7454 - val_accuracy: 0.7336\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 17s 105ms/step - loss: 0.5069 - accuracy: 0.8213 - val_loss: 0.7469 - val_accuracy: 0.7261\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 17s 106ms/step - loss: 0.4556 - accuracy: 0.8427 - val_loss: 0.7703 - val_accuracy: 0.7191\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 17s 106ms/step - loss: 0.4094 - accuracy: 0.8586 - val_loss: 0.7964 - val_accuracy: 0.7300\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.7963 - accuracy: 0.7300\n",
            "emb_dim: 32  hidden_dim: 256  drop: 0.1 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 17s 109ms/step - loss: 1.3633 - accuracy: 0.4401 - val_loss: 1.0395 - val_accuracy: 0.6260\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 17s 106ms/step - loss: 0.8651 - accuracy: 0.6899 - val_loss: 0.8279 - val_accuracy: 0.6972\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 17s 107ms/step - loss: 0.6919 - accuracy: 0.7583 - val_loss: 0.7627 - val_accuracy: 0.7250\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 17s 109ms/step - loss: 0.5939 - accuracy: 0.7912 - val_loss: 0.7636 - val_accuracy: 0.7312\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 17s 107ms/step - loss: 0.5296 - accuracy: 0.8151 - val_loss: 0.7466 - val_accuracy: 0.7254\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 17s 107ms/step - loss: 0.4815 - accuracy: 0.8315 - val_loss: 0.7669 - val_accuracy: 0.7265\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 17s 106ms/step - loss: 0.4358 - accuracy: 0.8498 - val_loss: 0.7785 - val_accuracy: 0.7320\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.7784 - accuracy: 0.7320\n",
            "emb_dim: 32  hidden_dim: 256  drop: 0.2 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 18s 109ms/step - loss: 1.3766 - accuracy: 0.4263 - val_loss: 1.0562 - val_accuracy: 0.6420\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 17s 106ms/step - loss: 0.8922 - accuracy: 0.6766 - val_loss: 0.8298 - val_accuracy: 0.6964\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 17s 108ms/step - loss: 0.7209 - accuracy: 0.7427 - val_loss: 0.7652 - val_accuracy: 0.7179\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 17s 106ms/step - loss: 0.6243 - accuracy: 0.7793 - val_loss: 0.7584 - val_accuracy: 0.7273\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 17s 106ms/step - loss: 0.5624 - accuracy: 0.8008 - val_loss: 0.7374 - val_accuracy: 0.7281\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 17s 107ms/step - loss: 0.5118 - accuracy: 0.8187 - val_loss: 0.7389 - val_accuracy: 0.7383\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 17s 105ms/step - loss: 0.4702 - accuracy: 0.8371 - val_loss: 0.7647 - val_accuracy: 0.7351\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.7646 - accuracy: 0.7351\n",
            "emb_dim: 32  hidden_dim: 256  drop: 0.3 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 17s 109ms/step - loss: 1.4010 - accuracy: 0.4147 - val_loss: 1.1083 - val_accuracy: 0.6154\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 17s 106ms/step - loss: 0.9348 - accuracy: 0.6601 - val_loss: 0.8473 - val_accuracy: 0.6757\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 17s 106ms/step - loss: 0.7543 - accuracy: 0.7324 - val_loss: 0.7796 - val_accuracy: 0.7101\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 17s 106ms/step - loss: 0.6593 - accuracy: 0.7649 - val_loss: 0.7557 - val_accuracy: 0.7242\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 17s 107ms/step - loss: 0.5992 - accuracy: 0.7856 - val_loss: 0.7437 - val_accuracy: 0.7277\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 17s 106ms/step - loss: 0.5527 - accuracy: 0.8065 - val_loss: 0.7327 - val_accuracy: 0.7336\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 17s 107ms/step - loss: 0.5128 - accuracy: 0.8207 - val_loss: 0.7494 - val_accuracy: 0.7347\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.7493 - accuracy: 0.7347\n",
            "emb_dim: 64  hidden_dim: 64  drop: 0 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 4s 24ms/step - loss: 1.3140 - accuracy: 0.4698 - val_loss: 0.9584 - val_accuracy: 0.6412\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 3s 22ms/step - loss: 0.7901 - accuracy: 0.7173 - val_loss: 0.7754 - val_accuracy: 0.7144\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 4s 22ms/step - loss: 0.6150 - accuracy: 0.7819 - val_loss: 0.7621 - val_accuracy: 0.7210\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.5228 - accuracy: 0.8162 - val_loss: 0.7646 - val_accuracy: 0.7281\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 3s 22ms/step - loss: 0.4576 - accuracy: 0.8427 - val_loss: 0.7381 - val_accuracy: 0.7308\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 4s 22ms/step - loss: 0.4068 - accuracy: 0.8600 - val_loss: 0.7678 - val_accuracy: 0.7254\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 3s 22ms/step - loss: 0.3645 - accuracy: 0.8730 - val_loss: 0.8440 - val_accuracy: 0.7242\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.8441 - accuracy: 0.7242\n",
            "emb_dim: 64  hidden_dim: 64  drop: 0.1 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 4s 25ms/step - loss: 1.3275 - accuracy: 0.4645 - val_loss: 0.9757 - val_accuracy: 0.6346\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 4s 23ms/step - loss: 0.8106 - accuracy: 0.7088 - val_loss: 0.7799 - val_accuracy: 0.7089\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 4s 23ms/step - loss: 0.6314 - accuracy: 0.7772 - val_loss: 0.7701 - val_accuracy: 0.7175\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 4s 23ms/step - loss: 0.5408 - accuracy: 0.8090 - val_loss: 0.7549 - val_accuracy: 0.7285\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 4s 23ms/step - loss: 0.4785 - accuracy: 0.8363 - val_loss: 0.7271 - val_accuracy: 0.7344\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 4s 23ms/step - loss: 0.4275 - accuracy: 0.8533 - val_loss: 0.7554 - val_accuracy: 0.7289\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 4s 23ms/step - loss: 0.3880 - accuracy: 0.8648 - val_loss: 0.8131 - val_accuracy: 0.7261\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.8131 - accuracy: 0.7261\n",
            "emb_dim: 64  hidden_dim: 64  drop: 0.2 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 4s 25ms/step - loss: 1.3424 - accuracy: 0.4533 - val_loss: 1.0031 - val_accuracy: 0.6056\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 4s 23ms/step - loss: 0.8370 - accuracy: 0.6985 - val_loss: 0.7861 - val_accuracy: 0.7046\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 4s 23ms/step - loss: 0.6573 - accuracy: 0.7675 - val_loss: 0.7658 - val_accuracy: 0.7128\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 4s 23ms/step - loss: 0.5670 - accuracy: 0.8003 - val_loss: 0.7518 - val_accuracy: 0.7300\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 4s 23ms/step - loss: 0.5076 - accuracy: 0.8232 - val_loss: 0.7280 - val_accuracy: 0.7383\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 4s 22ms/step - loss: 0.4565 - accuracy: 0.8400 - val_loss: 0.7488 - val_accuracy: 0.7312\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 4s 23ms/step - loss: 0.4194 - accuracy: 0.8548 - val_loss: 0.7953 - val_accuracy: 0.7312\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.7952 - accuracy: 0.7312\n",
            "emb_dim: 64  hidden_dim: 64  drop: 0.3 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 4s 25ms/step - loss: 1.3555 - accuracy: 0.4463 - val_loss: 1.0157 - val_accuracy: 0.6068\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 4s 22ms/step - loss: 0.8575 - accuracy: 0.6871 - val_loss: 0.7971 - val_accuracy: 0.7023\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 4s 23ms/step - loss: 0.6801 - accuracy: 0.7578 - val_loss: 0.7609 - val_accuracy: 0.7160\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 4s 22ms/step - loss: 0.5923 - accuracy: 0.7906 - val_loss: 0.7541 - val_accuracy: 0.7257\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 4s 23ms/step - loss: 0.5308 - accuracy: 0.8167 - val_loss: 0.7249 - val_accuracy: 0.7320\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 4s 23ms/step - loss: 0.4816 - accuracy: 0.8303 - val_loss: 0.7436 - val_accuracy: 0.7324\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 4s 24ms/step - loss: 0.4491 - accuracy: 0.8445 - val_loss: 0.7944 - val_accuracy: 0.7297\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.7945 - accuracy: 0.7297\n",
            "emb_dim: 64  hidden_dim: 128  drop: 0 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 1.2559 - accuracy: 0.4971 - val_loss: 0.9268 - val_accuracy: 0.6444\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 7s 47ms/step - loss: 0.7755 - accuracy: 0.7227 - val_loss: 0.7812 - val_accuracy: 0.7152\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 7s 46ms/step - loss: 0.6162 - accuracy: 0.7832 - val_loss: 0.7565 - val_accuracy: 0.7308\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 7s 46ms/step - loss: 0.5262 - accuracy: 0.8143 - val_loss: 0.7613 - val_accuracy: 0.7375\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 7s 46ms/step - loss: 0.4614 - accuracy: 0.8398 - val_loss: 0.7575 - val_accuracy: 0.7347\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 7s 46ms/step - loss: 0.4104 - accuracy: 0.8590 - val_loss: 0.7790 - val_accuracy: 0.7246\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 7s 47ms/step - loss: 0.3664 - accuracy: 0.8758 - val_loss: 0.8289 - val_accuracy: 0.7293\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.8288 - accuracy: 0.7293\n",
            "emb_dim: 64  hidden_dim: 128  drop: 0.1 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 1.2728 - accuracy: 0.4866 - val_loss: 0.9817 - val_accuracy: 0.6639\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.7962 - accuracy: 0.7163 - val_loss: 0.7917 - val_accuracy: 0.7023\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 8s 47ms/step - loss: 0.6367 - accuracy: 0.7757 - val_loss: 0.7553 - val_accuracy: 0.7289\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 8s 47ms/step - loss: 0.5471 - accuracy: 0.8069 - val_loss: 0.7606 - val_accuracy: 0.7347\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.4841 - accuracy: 0.8316 - val_loss: 0.7538 - val_accuracy: 0.7320\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 8s 47ms/step - loss: 0.4349 - accuracy: 0.8495 - val_loss: 0.7624 - val_accuracy: 0.7308\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.3921 - accuracy: 0.8654 - val_loss: 0.8101 - val_accuracy: 0.7289\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.8100 - accuracy: 0.7289\n",
            "emb_dim: 64  hidden_dim: 128  drop: 0.2 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 1.2910 - accuracy: 0.4770 - val_loss: 1.0100 - val_accuracy: 0.6592\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.8217 - accuracy: 0.7069 - val_loss: 0.7995 - val_accuracy: 0.6991\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.6604 - accuracy: 0.7699 - val_loss: 0.7602 - val_accuracy: 0.7242\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.5702 - accuracy: 0.7995 - val_loss: 0.7522 - val_accuracy: 0.7351\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.5099 - accuracy: 0.8225 - val_loss: 0.7494 - val_accuracy: 0.7379\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.4631 - accuracy: 0.8408 - val_loss: 0.7542 - val_accuracy: 0.7359\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 8s 47ms/step - loss: 0.4201 - accuracy: 0.8554 - val_loss: 0.8040 - val_accuracy: 0.7300\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.8040 - accuracy: 0.7300\n",
            "emb_dim: 64  hidden_dim: 128  drop: 0.3 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 1.3109 - accuracy: 0.4728 - val_loss: 1.0070 - val_accuracy: 0.6412\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.8473 - accuracy: 0.6958 - val_loss: 0.8121 - val_accuracy: 0.6948\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 8s 47ms/step - loss: 0.6836 - accuracy: 0.7608 - val_loss: 0.7627 - val_accuracy: 0.7234\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.5959 - accuracy: 0.7922 - val_loss: 0.7509 - val_accuracy: 0.7375\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.5372 - accuracy: 0.8130 - val_loss: 0.7462 - val_accuracy: 0.7351\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.4906 - accuracy: 0.8308 - val_loss: 0.7463 - val_accuracy: 0.7363\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 8s 47ms/step - loss: 0.4500 - accuracy: 0.8439 - val_loss: 0.7777 - val_accuracy: 0.7406\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.7776 - accuracy: 0.7406\n",
            "emb_dim: 64  hidden_dim: 256  drop: 0 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 19s 116ms/step - loss: 1.2814 - accuracy: 0.5020 - val_loss: 0.9757 - val_accuracy: 0.6581\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 19s 116ms/step - loss: 0.7813 - accuracy: 0.7261 - val_loss: 0.7842 - val_accuracy: 0.7101\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 19s 119ms/step - loss: 0.6163 - accuracy: 0.7833 - val_loss: 0.7570 - val_accuracy: 0.7281\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 18s 112ms/step - loss: 0.5263 - accuracy: 0.8149 - val_loss: 0.7473 - val_accuracy: 0.7359\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 18s 115ms/step - loss: 0.4618 - accuracy: 0.8388 - val_loss: 0.7600 - val_accuracy: 0.7285\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 18s 114ms/step - loss: 0.4118 - accuracy: 0.8555 - val_loss: 0.7930 - val_accuracy: 0.7254\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 18s 113ms/step - loss: 0.3671 - accuracy: 0.8696 - val_loss: 0.8189 - val_accuracy: 0.7297\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.8187 - accuracy: 0.7297\n",
            "emb_dim: 64  hidden_dim: 256  drop: 0.1 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 19s 116ms/step - loss: 1.2572 - accuracy: 0.4972 - val_loss: 0.9430 - val_accuracy: 0.6647\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 18s 113ms/step - loss: 0.7842 - accuracy: 0.7273 - val_loss: 0.7839 - val_accuracy: 0.7132\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 18s 113ms/step - loss: 0.6271 - accuracy: 0.7838 - val_loss: 0.7518 - val_accuracy: 0.7332\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 18s 113ms/step - loss: 0.5412 - accuracy: 0.8092 - val_loss: 0.7346 - val_accuracy: 0.7383\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 18s 112ms/step - loss: 0.4785 - accuracy: 0.8318 - val_loss: 0.7467 - val_accuracy: 0.7347\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 18s 113ms/step - loss: 0.4288 - accuracy: 0.8504 - val_loss: 0.7831 - val_accuracy: 0.7265\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 18s 114ms/step - loss: 0.3868 - accuracy: 0.8643 - val_loss: 0.8015 - val_accuracy: 0.7332\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.8013 - accuracy: 0.7332\n",
            "emb_dim: 64  hidden_dim: 256  drop: 0.2 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 18s 116ms/step - loss: 1.2638 - accuracy: 0.4910 - val_loss: 0.9245 - val_accuracy: 0.6514\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 18s 113ms/step - loss: 0.8036 - accuracy: 0.7188 - val_loss: 0.7934 - val_accuracy: 0.7089\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 18s 114ms/step - loss: 0.6483 - accuracy: 0.7752 - val_loss: 0.7572 - val_accuracy: 0.7289\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 18s 113ms/step - loss: 0.5629 - accuracy: 0.8025 - val_loss: 0.7367 - val_accuracy: 0.7387\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 18s 114ms/step - loss: 0.5041 - accuracy: 0.8229 - val_loss: 0.7377 - val_accuracy: 0.7363\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 18s 113ms/step - loss: 0.4559 - accuracy: 0.8415 - val_loss: 0.7730 - val_accuracy: 0.7265\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 18s 115ms/step - loss: 0.4153 - accuracy: 0.8528 - val_loss: 0.7810 - val_accuracy: 0.7387\n",
            "80/80 [==============================] - 2s 22ms/step - loss: 0.7808 - accuracy: 0.7387\n",
            "emb_dim: 64  hidden_dim: 256  drop: 0.3 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 18s 115ms/step - loss: 1.2822 - accuracy: 0.4847 - val_loss: 0.9465 - val_accuracy: 0.6506\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 18s 113ms/step - loss: 0.8206 - accuracy: 0.7102 - val_loss: 0.7979 - val_accuracy: 0.7089\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 18s 113ms/step - loss: 0.6647 - accuracy: 0.7672 - val_loss: 0.7645 - val_accuracy: 0.7297\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 18s 113ms/step - loss: 0.5836 - accuracy: 0.7955 - val_loss: 0.7437 - val_accuracy: 0.7344\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 18s 114ms/step - loss: 0.5262 - accuracy: 0.8167 - val_loss: 0.7386 - val_accuracy: 0.7332\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 18s 113ms/step - loss: 0.4796 - accuracy: 0.8310 - val_loss: 0.7659 - val_accuracy: 0.7297\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 18s 113ms/step - loss: 0.4418 - accuracy: 0.8447 - val_loss: 0.7669 - val_accuracy: 0.7398\n",
            "80/80 [==============================] - 2s 21ms/step - loss: 0.7668 - accuracy: 0.7398\n",
            "emb_dim: 128  hidden_dim: 64  drop: 0 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 5s 30ms/step - loss: 1.2042 - accuracy: 0.5260 - val_loss: 0.8735 - val_accuracy: 0.6733\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.7145 - accuracy: 0.7471 - val_loss: 0.7469 - val_accuracy: 0.7261\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.5641 - accuracy: 0.8033 - val_loss: 0.7525 - val_accuracy: 0.7281\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.4784 - accuracy: 0.8319 - val_loss: 0.7593 - val_accuracy: 0.7347\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.4142 - accuracy: 0.8553 - val_loss: 0.7770 - val_accuracy: 0.7340\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.3622 - accuracy: 0.8739 - val_loss: 0.8016 - val_accuracy: 0.7265\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.3197 - accuracy: 0.8904 - val_loss: 0.8934 - val_accuracy: 0.7128\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.8934 - accuracy: 0.7128\n",
            "emb_dim: 128  hidden_dim: 64  drop: 0.1 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 5s 33ms/step - loss: 1.2161 - accuracy: 0.5217 - val_loss: 0.8822 - val_accuracy: 0.6667\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 5s 30ms/step - loss: 0.7271 - accuracy: 0.7397 - val_loss: 0.7535 - val_accuracy: 0.7210\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 5s 30ms/step - loss: 0.5793 - accuracy: 0.7954 - val_loss: 0.7555 - val_accuracy: 0.7269\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 5s 31ms/step - loss: 0.4961 - accuracy: 0.8254 - val_loss: 0.7538 - val_accuracy: 0.7371\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 5s 30ms/step - loss: 0.4330 - accuracy: 0.8480 - val_loss: 0.7752 - val_accuracy: 0.7355\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 5s 30ms/step - loss: 0.3825 - accuracy: 0.8670 - val_loss: 0.8018 - val_accuracy: 0.7281\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 5s 30ms/step - loss: 0.3421 - accuracy: 0.8809 - val_loss: 0.8706 - val_accuracy: 0.7144\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.8706 - accuracy: 0.7144\n",
            "emb_dim: 128  hidden_dim: 64  drop: 0.2 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 7s 43ms/step - loss: 1.2335 - accuracy: 0.5101 - val_loss: 0.8968 - val_accuracy: 0.6510\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 5s 30ms/step - loss: 0.7484 - accuracy: 0.7322 - val_loss: 0.7611 - val_accuracy: 0.7171\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 5s 31ms/step - loss: 0.5992 - accuracy: 0.7897 - val_loss: 0.7547 - val_accuracy: 0.7246\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 5s 30ms/step - loss: 0.5174 - accuracy: 0.8158 - val_loss: 0.7538 - val_accuracy: 0.7359\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 5s 30ms/step - loss: 0.4560 - accuracy: 0.8408 - val_loss: 0.7606 - val_accuracy: 0.7371\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 5s 31ms/step - loss: 0.4078 - accuracy: 0.8562 - val_loss: 0.7812 - val_accuracy: 0.7332\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 5s 30ms/step - loss: 0.3679 - accuracy: 0.8721 - val_loss: 0.8391 - val_accuracy: 0.7195\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.8391 - accuracy: 0.7195\n",
            "emb_dim: 128  hidden_dim: 64  drop: 0.3 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 5s 33ms/step - loss: 1.2552 - accuracy: 0.4991 - val_loss: 0.9184 - val_accuracy: 0.6408\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 5s 31ms/step - loss: 0.7725 - accuracy: 0.7232 - val_loss: 0.7748 - val_accuracy: 0.7132\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 5s 31ms/step - loss: 0.6230 - accuracy: 0.7793 - val_loss: 0.7574 - val_accuracy: 0.7257\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 5s 30ms/step - loss: 0.5434 - accuracy: 0.8073 - val_loss: 0.7565 - val_accuracy: 0.7344\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 5s 31ms/step - loss: 0.4822 - accuracy: 0.8311 - val_loss: 0.7511 - val_accuracy: 0.7379\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 5s 31ms/step - loss: 0.4369 - accuracy: 0.8446 - val_loss: 0.7635 - val_accuracy: 0.7351\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 5s 31ms/step - loss: 0.3975 - accuracy: 0.8615 - val_loss: 0.8273 - val_accuracy: 0.7246\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.8273 - accuracy: 0.7246\n",
            "emb_dim: 128  hidden_dim: 128  drop: 0 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 10s 64ms/step - loss: 1.1936 - accuracy: 0.5399 - val_loss: 0.9003 - val_accuracy: 0.6960\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 10s 62ms/step - loss: 0.7128 - accuracy: 0.7463 - val_loss: 0.7494 - val_accuracy: 0.7308\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 10s 63ms/step - loss: 0.5690 - accuracy: 0.8007 - val_loss: 0.7471 - val_accuracy: 0.7387\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.4808 - accuracy: 0.8306 - val_loss: 0.7474 - val_accuracy: 0.7390\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.4168 - accuracy: 0.8550 - val_loss: 0.7807 - val_accuracy: 0.7336\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.3640 - accuracy: 0.8726 - val_loss: 0.8111 - val_accuracy: 0.7257\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 10s 62ms/step - loss: 0.3192 - accuracy: 0.8893 - val_loss: 0.8629 - val_accuracy: 0.7214\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.8630 - accuracy: 0.7214\n",
            "emb_dim: 128  hidden_dim: 128  drop: 0.1 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 11s 66ms/step - loss: 1.2007 - accuracy: 0.5324 - val_loss: 0.8979 - val_accuracy: 0.6897\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 10s 63ms/step - loss: 0.7271 - accuracy: 0.7404 - val_loss: 0.7546 - val_accuracy: 0.7257\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 10s 64ms/step - loss: 0.5841 - accuracy: 0.7948 - val_loss: 0.7458 - val_accuracy: 0.7398\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 10s 63ms/step - loss: 0.4958 - accuracy: 0.8241 - val_loss: 0.7447 - val_accuracy: 0.7379\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 10s 63ms/step - loss: 0.4351 - accuracy: 0.8482 - val_loss: 0.7608 - val_accuracy: 0.7359\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 10s 63ms/step - loss: 0.3833 - accuracy: 0.8651 - val_loss: 0.7972 - val_accuracy: 0.7324\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 10s 62ms/step - loss: 0.3400 - accuracy: 0.8801 - val_loss: 0.8371 - val_accuracy: 0.7222\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.8371 - accuracy: 0.7222\n",
            "emb_dim: 128  hidden_dim: 128  drop: 0.2 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 11s 66ms/step - loss: 1.2273 - accuracy: 0.5234 - val_loss: 0.9097 - val_accuracy: 0.6815\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 10s 63ms/step - loss: 0.7507 - accuracy: 0.7302 - val_loss: 0.7609 - val_accuracy: 0.7265\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 10s 64ms/step - loss: 0.6068 - accuracy: 0.7877 - val_loss: 0.7455 - val_accuracy: 0.7371\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 10s 64ms/step - loss: 0.5215 - accuracy: 0.8162 - val_loss: 0.7366 - val_accuracy: 0.7441\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 10s 64ms/step - loss: 0.4624 - accuracy: 0.8383 - val_loss: 0.7482 - val_accuracy: 0.7375\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 10s 63ms/step - loss: 0.4126 - accuracy: 0.8558 - val_loss: 0.7802 - val_accuracy: 0.7320\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 10s 63ms/step - loss: 0.3694 - accuracy: 0.8714 - val_loss: 0.8092 - val_accuracy: 0.7320\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.8092 - accuracy: 0.7320\n",
            "emb_dim: 128  hidden_dim: 128  drop: 0.3 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 10s 65ms/step - loss: 1.2556 - accuracy: 0.5070 - val_loss: 0.9190 - val_accuracy: 0.6463\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 10s 63ms/step - loss: 0.7794 - accuracy: 0.7208 - val_loss: 0.7744 - val_accuracy: 0.7156\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 10s 63ms/step - loss: 0.6332 - accuracy: 0.7781 - val_loss: 0.7488 - val_accuracy: 0.7351\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 10s 63ms/step - loss: 0.5470 - accuracy: 0.8069 - val_loss: 0.7421 - val_accuracy: 0.7414\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 10s 63ms/step - loss: 0.4892 - accuracy: 0.8294 - val_loss: 0.7344 - val_accuracy: 0.7422\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 10s 63ms/step - loss: 0.4447 - accuracy: 0.8436 - val_loss: 0.7563 - val_accuracy: 0.7347\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 11s 66ms/step - loss: 0.4019 - accuracy: 0.8607 - val_loss: 0.7841 - val_accuracy: 0.7387\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.7841 - accuracy: 0.7387\n",
            "emb_dim: 128  hidden_dim: 256  drop: 0 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 21s 129ms/step - loss: 1.1622 - accuracy: 0.5543 - val_loss: 0.8862 - val_accuracy: 0.6882\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 21s 129ms/step - loss: 0.7126 - accuracy: 0.7523 - val_loss: 0.7481 - val_accuracy: 0.7289\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 21s 129ms/step - loss: 0.5665 - accuracy: 0.8014 - val_loss: 0.7498 - val_accuracy: 0.7332\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 21s 129ms/step - loss: 0.4784 - accuracy: 0.8325 - val_loss: 0.7467 - val_accuracy: 0.7437\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 21s 129ms/step - loss: 0.4162 - accuracy: 0.8550 - val_loss: 0.7769 - val_accuracy: 0.7328\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 21s 129ms/step - loss: 0.3620 - accuracy: 0.8737 - val_loss: 0.8254 - val_accuracy: 0.7246\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 21s 129ms/step - loss: 0.3160 - accuracy: 0.8918 - val_loss: 0.8582 - val_accuracy: 0.7222\n",
            "80/80 [==============================] - 2s 24ms/step - loss: 0.8582 - accuracy: 0.7222\n",
            "emb_dim: 128  hidden_dim: 256  drop: 0.1 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 21s 132ms/step - loss: 1.1768 - accuracy: 0.5470 - val_loss: 0.8677 - val_accuracy: 0.6835\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 21s 130ms/step - loss: 0.7202 - accuracy: 0.7454 - val_loss: 0.7512 - val_accuracy: 0.7297\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 21s 131ms/step - loss: 0.5773 - accuracy: 0.7977 - val_loss: 0.7492 - val_accuracy: 0.7304\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 21s 130ms/step - loss: 0.4918 - accuracy: 0.8273 - val_loss: 0.7413 - val_accuracy: 0.7418\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 21s 130ms/step - loss: 0.4332 - accuracy: 0.8494 - val_loss: 0.7777 - val_accuracy: 0.7293\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 21s 131ms/step - loss: 0.3802 - accuracy: 0.8660 - val_loss: 0.8074 - val_accuracy: 0.7265\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 21s 133ms/step - loss: 0.3351 - accuracy: 0.8838 - val_loss: 0.8434 - val_accuracy: 0.7285\n",
            "80/80 [==============================] - 2s 24ms/step - loss: 0.8434 - accuracy: 0.7285\n",
            "emb_dim: 128  hidden_dim: 256  drop: 0.2 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 22s 135ms/step - loss: 1.2097 - accuracy: 0.5353 - val_loss: 0.8895 - val_accuracy: 0.6851\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 21s 132ms/step - loss: 0.7470 - accuracy: 0.7377 - val_loss: 0.7592 - val_accuracy: 0.7281\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 22s 135ms/step - loss: 0.6024 - accuracy: 0.7888 - val_loss: 0.7529 - val_accuracy: 0.7277\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 21s 132ms/step - loss: 0.5190 - accuracy: 0.8178 - val_loss: 0.7392 - val_accuracy: 0.7422\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 21s 132ms/step - loss: 0.4587 - accuracy: 0.8380 - val_loss: 0.7660 - val_accuracy: 0.7308\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 21s 132ms/step - loss: 0.4095 - accuracy: 0.8567 - val_loss: 0.7877 - val_accuracy: 0.7293\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 21s 132ms/step - loss: 0.3635 - accuracy: 0.8712 - val_loss: 0.8136 - val_accuracy: 0.7308\n",
            "80/80 [==============================] - 2s 24ms/step - loss: 0.8135 - accuracy: 0.7308\n",
            "emb_dim: 128  hidden_dim: 256  drop: 0.3 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 21s 133ms/step - loss: 1.2088 - accuracy: 0.5269 - val_loss: 0.8884 - val_accuracy: 0.6835\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 21s 132ms/step - loss: 0.7642 - accuracy: 0.7318 - val_loss: 0.7686 - val_accuracy: 0.7226\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 21s 131ms/step - loss: 0.6212 - accuracy: 0.7822 - val_loss: 0.7602 - val_accuracy: 0.7277\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 21s 131ms/step - loss: 0.5394 - accuracy: 0.8102 - val_loss: 0.7420 - val_accuracy: 0.7433\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 21s 132ms/step - loss: 0.4806 - accuracy: 0.8338 - val_loss: 0.7472 - val_accuracy: 0.7324\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 21s 130ms/step - loss: 0.4339 - accuracy: 0.8486 - val_loss: 0.7782 - val_accuracy: 0.7297\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 21s 131ms/step - loss: 0.3905 - accuracy: 0.8632 - val_loss: 0.8209 - val_accuracy: 0.7269\n",
            "80/80 [==============================] - 2s 25ms/step - loss: 0.8208 - accuracy: 0.7269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xejQKFqZrsw0",
        "colab_type": "text"
      },
      "source": [
        "#### Predict on test set for kaggle (2nd upload)\n",
        "\n",
        "72.085% on Kaggle vs 74.41% here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4CiSia6HwW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Running the best model on the test set\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model2 = Sequential() \n",
        "model2.add(Embedding(dict_len + 1, 128)) # adding trainable=True does not change thre result, trainable by default?\n",
        "model2.add(LSTM(128, dropout=0.2)) \n",
        "# number of classes = 5\n",
        "model2.add(Dense(5, activation=\"softmax\"))  \n",
        "model2.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H58q2cmFIBi3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "f485b60e-d5e6-4566-f7b1-4f872b53ff87"
      },
      "source": [
        "# Train the model\n",
        "model2.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=4) \n",
        "model2.evaluate(X_test, Y_test) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "160/160 [==============================] - 11s 66ms/step - loss: 1.2273 - accuracy: 0.5234 - val_loss: 0.9097 - val_accuracy: 0.6815\n",
            "Epoch 2/4\n",
            "160/160 [==============================] - 10s 64ms/step - loss: 0.7507 - accuracy: 0.7302 - val_loss: 0.7609 - val_accuracy: 0.7265\n",
            "Epoch 3/4\n",
            "160/160 [==============================] - 10s 64ms/step - loss: 0.6068 - accuracy: 0.7877 - val_loss: 0.7455 - val_accuracy: 0.7371\n",
            "Epoch 4/4\n",
            "160/160 [==============================] - 10s 63ms/step - loss: 0.5215 - accuracy: 0.8162 - val_loss: 0.7366 - val_accuracy: 0.7441\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.7365 - accuracy: 0.7441\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7365121841430664, 0.7441314458847046]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyC6D0mVyk5I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "c7ad16c3-a478-4fcf-f6f9-35444c7c3a39"
      },
      "source": [
        "Y_test_pred = model2.predict_classes(X_test)\n",
        "Y_test_df = pd.DataFrame(Y_test)\n",
        "Y_test_categ = Y_test_df.idxmax(axis=1)\n",
        "confusion_matrix(Y_test_categ,Y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[374, 104,  67,  18,  25],\n",
              "       [ 70, 466,  20,  27,   5],\n",
              "       [ 47,  25, 405,  42,  41],\n",
              "       [  9,  28,  40, 410,  15],\n",
              "       [ 25,   1,  34,  11, 247]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcHWsV6hy7tZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "0df29d48-8ccd-47a9-b1a6-a1084e5949a4"
      },
      "source": [
        "print(Y_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw-kaJjfy9e8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "92544141-b780-4284-f859-1f3febba01f4"
      },
      "source": [
        "print(Y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4 3 2 ... 2 2 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Cw0NFLAIBye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "45fc0cf1-7316-4863-cd08-ee2809e1f8c2"
      },
      "source": [
        "Y_new2 = model2.predict_classes(X_new)\n",
        "# show the inputs and predicted outputs\n",
        "print(X_new[:5])\n",
        "for i in range(5):\n",
        "\tprint(\"X=%s, Predicted=%s\" % (X_new[i], Y_new2[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    3  482\n",
            "     8   32   15    1  117   66]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0 1591  130  758\n",
            "    20   66    1 1407  295  307]\n",
            " [   0    0    0    0    0    0   95    4  120    2   35   21  693 2005\n",
            "  6187    1   24    2  463  166]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0  378  229\n",
            "   793    1   47  278  399   14]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0   47  202  302  519]]\n",
            "X=[  0   0   0   0   0   0   0   0   0   0   0   0   3 482   8  32  15   1\n",
            " 117  66], Predicted=1\n",
            "X=[   0    0    0    0    0    0    0    0    0    0    0 1591  130  758\n",
            "   20   66    1 1407  295  307], Predicted=1\n",
            "X=[   0    0    0    0    0    0   95    4  120    2   35   21  693 2005\n",
            " 6187    1   24    2  463  166], Predicted=0\n",
            "X=[  0   0   0   0   0   0   0   0   0   0   0   0 378 229 793   1  47 278\n",
            " 399  14], Predicted=2\n",
            "X=[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  47 202\n",
            " 302 519], Predicted=2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1UH2QUvICEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test2 = pd.DataFrame(list(zip(test['id'], Y_new2)), \n",
        "               columns = ['id', 'label'])\n",
        "test2\n",
        "test2.to_csv('test2.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEJl50Vx5gtL",
        "colab_type": "text"
      },
      "source": [
        "###LSTM w 2 layers, doubling hidden_units in the second one\n",
        "\n",
        "No gain vs 1-layer LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjEIueYlIB9l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9b595830-17e6-4089-f3e5-a039f385a7fb"
      },
      "source": [
        "embed = [128]\n",
        "hidden = [64,128,256]\n",
        "drop = [0, 0.1, 0.2]\n",
        "# optim = ['adam','RMSprop']\n",
        "for i in embed:\n",
        "  for j in hidden:\n",
        "    for k in drop:\n",
        "      # for l in optim:\n",
        "      # print('emb_dim: ',i,' hidden_dim: ',j, ' drop: ',k, ' optim: ',l)\n",
        "      print('emb_dim:',i,' hidden_dim:',j, ' drop:',k,'----RMSprop')\n",
        "      np.random.seed(42)\n",
        "      random.seed(12345)\n",
        "      session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                    inter_op_parallelism_threads=1)\n",
        "      tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "      model = Sequential() \n",
        "      model.add(Embedding(dict_len + 1, output_dim=i)) \n",
        "      model.add(LSTM(j, dropout=k, recurrent_dropout=0.1, return_sequences=True))\n",
        "      model.add(LSTM(j*2, dropout=k, recurrent_dropout=0.1)) \n",
        "      model.add(Dense(5, activation=\"softmax\"))  \n",
        "      model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "      # Train the model\n",
        "      model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=5) \n",
        "      model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "emb_dim: 128  hidden_dim: 64  drop: 0 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 17s 107ms/step - loss: 1.2005 - accuracy: 0.5063 - val_loss: 0.8927 - val_accuracy: 0.6737\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 16s 102ms/step - loss: 0.7358 - accuracy: 0.7362 - val_loss: 0.7685 - val_accuracy: 0.7179\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 16s 103ms/step - loss: 0.5843 - accuracy: 0.7909 - val_loss: 0.7500 - val_accuracy: 0.7277\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 16s 103ms/step - loss: 0.4949 - accuracy: 0.8240 - val_loss: 0.7609 - val_accuracy: 0.7351\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 17s 104ms/step - loss: 0.4259 - accuracy: 0.8536 - val_loss: 0.7902 - val_accuracy: 0.7304\n",
            "80/80 [==============================] - 1s 11ms/step - loss: 0.7902 - accuracy: 0.7304\n",
            "emb_dim: 128  hidden_dim: 64  drop: 0.1 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 20s 123ms/step - loss: 1.2122 - accuracy: 0.5003 - val_loss: 0.9012 - val_accuracy: 0.6631\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 19s 120ms/step - loss: 0.7551 - accuracy: 0.7268 - val_loss: 0.7771 - val_accuracy: 0.7113\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 19s 120ms/step - loss: 0.5980 - accuracy: 0.7860 - val_loss: 0.7527 - val_accuracy: 0.7254\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 19s 121ms/step - loss: 0.5101 - accuracy: 0.8184 - val_loss: 0.7613 - val_accuracy: 0.7285\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 19s 121ms/step - loss: 0.4421 - accuracy: 0.8440 - val_loss: 0.7787 - val_accuracy: 0.7293\n",
            "80/80 [==============================] - 1s 11ms/step - loss: 0.7787 - accuracy: 0.7293\n",
            "emb_dim: 128  hidden_dim: 64  drop: 0.2 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 19s 121ms/step - loss: 1.2331 - accuracy: 0.4900 - val_loss: 0.9100 - val_accuracy: 0.6600\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 19s 118ms/step - loss: 0.7721 - accuracy: 0.7186 - val_loss: 0.7809 - val_accuracy: 0.7132\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 19s 118ms/step - loss: 0.6119 - accuracy: 0.7838 - val_loss: 0.7496 - val_accuracy: 0.7269\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 19s 120ms/step - loss: 0.5269 - accuracy: 0.8113 - val_loss: 0.7591 - val_accuracy: 0.7328\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 19s 120ms/step - loss: 0.4618 - accuracy: 0.8367 - val_loss: 0.7758 - val_accuracy: 0.7344\n",
            "80/80 [==============================] - 1s 11ms/step - loss: 0.7758 - accuracy: 0.7344\n",
            "emb_dim: 128  hidden_dim: 128  drop: 0 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 45s 279ms/step - loss: 1.1658 - accuracy: 0.5290 - val_loss: 0.8633 - val_accuracy: 0.6811\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 44s 277ms/step - loss: 0.7062 - accuracy: 0.7481 - val_loss: 0.7453 - val_accuracy: 0.7324\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 44s 277ms/step - loss: 0.5587 - accuracy: 0.8037 - val_loss: 0.7397 - val_accuracy: 0.7363\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 44s 278ms/step - loss: 0.4683 - accuracy: 0.8362 - val_loss: 0.7595 - val_accuracy: 0.7359\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 44s 278ms/step - loss: 0.3979 - accuracy: 0.8588 - val_loss: 0.8033 - val_accuracy: 0.7234\n",
            "80/80 [==============================] - 2s 26ms/step - loss: 0.8032 - accuracy: 0.7234\n",
            "emb_dim: 128  hidden_dim: 128  drop: 0.1 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 48s 301ms/step - loss: 1.1804 - accuracy: 0.5172 - val_loss: 0.8711 - val_accuracy: 0.6729\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 48s 300ms/step - loss: 0.7306 - accuracy: 0.7389 - val_loss: 0.7544 - val_accuracy: 0.7242\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 48s 300ms/step - loss: 0.5778 - accuracy: 0.7967 - val_loss: 0.7404 - val_accuracy: 0.7320\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 48s 298ms/step - loss: 0.4882 - accuracy: 0.8283 - val_loss: 0.7481 - val_accuracy: 0.7332\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 48s 297ms/step - loss: 0.4177 - accuracy: 0.8498 - val_loss: 0.7868 - val_accuracy: 0.7269\n",
            "80/80 [==============================] - 2s 26ms/step - loss: 0.7867 - accuracy: 0.7269\n",
            "emb_dim: 128  hidden_dim: 128  drop: 0.2 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 48s 298ms/step - loss: 1.1889 - accuracy: 0.5113 - val_loss: 0.8805 - val_accuracy: 0.6796\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 47s 296ms/step - loss: 0.7381 - accuracy: 0.7364 - val_loss: 0.7549 - val_accuracy: 0.7250\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 48s 297ms/step - loss: 0.5904 - accuracy: 0.7940 - val_loss: 0.7443 - val_accuracy: 0.7297\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 47s 295ms/step - loss: 0.5034 - accuracy: 0.8204 - val_loss: 0.7449 - val_accuracy: 0.7320\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 47s 295ms/step - loss: 0.4338 - accuracy: 0.8460 - val_loss: 0.7722 - val_accuracy: 0.7320\n",
            "80/80 [==============================] - 2s 28ms/step - loss: 0.7721 - accuracy: 0.7320\n",
            "emb_dim: 128  hidden_dim: 256  drop: 0 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 142s 887ms/step - loss: 1.1787 - accuracy: 0.5195 - val_loss: 0.8549 - val_accuracy: 0.6909\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 142s 891ms/step - loss: 0.7001 - accuracy: 0.7489 - val_loss: 0.7359 - val_accuracy: 0.7316\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 143s 891ms/step - loss: 0.5481 - accuracy: 0.8086 - val_loss: 0.7623 - val_accuracy: 0.7320\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 143s 891ms/step - loss: 0.4566 - accuracy: 0.8389 - val_loss: 0.7798 - val_accuracy: 0.7367\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 143s 891ms/step - loss: 0.3850 - accuracy: 0.8649 - val_loss: 0.8254 - val_accuracy: 0.7261\n",
            "80/80 [==============================] - 10s 126ms/step - loss: 0.8254 - accuracy: 0.7261\n",
            "emb_dim: 128  hidden_dim: 256  drop: 0.1 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 148s 926ms/step - loss: 1.1902 - accuracy: 0.5144 - val_loss: 0.8588 - val_accuracy: 0.6882\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 148s 923ms/step - loss: 0.7191 - accuracy: 0.7425 - val_loss: 0.7466 - val_accuracy: 0.7261\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 149s 931ms/step - loss: 0.5659 - accuracy: 0.8021 - val_loss: 0.7540 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 149s 933ms/step - loss: 0.4765 - accuracy: 0.8320 - val_loss: 0.7751 - val_accuracy: 0.7379\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 149s 928ms/step - loss: 0.4064 - accuracy: 0.8548 - val_loss: 0.7998 - val_accuracy: 0.7336\n",
            "80/80 [==============================] - 10s 128ms/step - loss: 0.7999 - accuracy: 0.7336\n",
            "emb_dim: 128  hidden_dim: 256  drop: 0.2 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 148s 924ms/step - loss: 1.2304 - accuracy: 0.4934 - val_loss: 0.8732 - val_accuracy: 0.6768\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 147s 921ms/step - loss: 0.7462 - accuracy: 0.7339 - val_loss: 0.7594 - val_accuracy: 0.7183\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 147s 921ms/step - loss: 0.5947 - accuracy: 0.7920 - val_loss: 0.7520 - val_accuracy: 0.7238\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 147s 920ms/step - loss: 0.5029 - accuracy: 0.8226 - val_loss: 0.7583 - val_accuracy: 0.7398\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 147s 919ms/step - loss: 0.4330 - accuracy: 0.8465 - val_loss: 0.7794 - val_accuracy: 0.7308\n",
            "80/80 [==============================] - 10s 122ms/step - loss: 0.7793 - accuracy: 0.7308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E1B9mXbO5y10"
      },
      "source": [
        "###Bi-LSTM "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuOgCcbRalRA",
        "colab_type": "text"
      },
      "source": [
        "#### With 2 layers, doubling hidden_units in the second one\n",
        "\n",
        "No gain vs one-layer LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "padoFM3LaBR6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "75d3c22b-6b88-4fbf-c3ad-ce88bcf620f3"
      },
      "source": [
        "embed = [128]\n",
        "hidden = [64,128,256]\n",
        "drop = [0, 0.1, 0.2]\n",
        "# optim = ['adam','RMSprop']\n",
        "for i in embed:\n",
        "  for j in hidden:\n",
        "    for k in drop:\n",
        "      # for l in optim:\n",
        "      # print('emb_dim: ',i,' hidden_dim: ',j, ' drop: ',k, ' optim: ',l)\n",
        "      print('emb_dim:',i,' hidden_dim:',j, ' drop:',k,'----RMSprop')\n",
        "      np.random.seed(42)\n",
        "      random.seed(12345)\n",
        "      session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                    inter_op_parallelism_threads=1)\n",
        "      tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "      model = Sequential() \n",
        "      model.add(Embedding(dict_len + 1, output_dim=i)) \n",
        "      model.add(Bidirectional(LSTM(j, dropout=k, recurrent_dropout=0.1, return_sequences=True)))\n",
        "      model.add(Bidirectional(LSTM(j*2, dropout=k, recurrent_dropout=0.1))) \n",
        "      model.add(Dense(5, activation=\"softmax\"))  \n",
        "      model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "      # Train the model\n",
        "      model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=5) \n",
        "      model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "emb_dim: 128  hidden_dim: 64  drop: 0 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 36s 228ms/step - loss: 1.0897 - accuracy: 0.5615 - val_loss: 0.8242 - val_accuracy: 0.7027\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 36s 224ms/step - loss: 0.6882 - accuracy: 0.7567 - val_loss: 0.7650 - val_accuracy: 0.7269\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 36s 224ms/step - loss: 0.5561 - accuracy: 0.8067 - val_loss: 0.7366 - val_accuracy: 0.7375\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 35s 221ms/step - loss: 0.4653 - accuracy: 0.8377 - val_loss: 0.7847 - val_accuracy: 0.7402\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 35s 221ms/step - loss: 0.3940 - accuracy: 0.8632 - val_loss: 0.8228 - val_accuracy: 0.7277\n",
            "80/80 [==============================] - 2s 23ms/step - loss: 0.8228 - accuracy: 0.7277\n",
            "emb_dim: 128  hidden_dim: 64  drop: 0.1 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 42s 262ms/step - loss: 1.1065 - accuracy: 0.5522 - val_loss: 0.8085 - val_accuracy: 0.7054\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 0.6953 - accuracy: 0.7519 - val_loss: 0.7627 - val_accuracy: 0.7257\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 0.5608 - accuracy: 0.8035 - val_loss: 0.7376 - val_accuracy: 0.7351\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 0.4715 - accuracy: 0.8375 - val_loss: 0.7880 - val_accuracy: 0.7324\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 0.4006 - accuracy: 0.8614 - val_loss: 0.8100 - val_accuracy: 0.7273\n",
            "80/80 [==============================] - 2s 22ms/step - loss: 0.8100 - accuracy: 0.7273\n",
            "emb_dim: 128  hidden_dim: 64  drop: 0.2 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 42s 263ms/step - loss: 1.1067 - accuracy: 0.5549 - val_loss: 0.8088 - val_accuracy: 0.7038\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 0.7098 - accuracy: 0.7471 - val_loss: 0.7754 - val_accuracy: 0.7144\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 41s 255ms/step - loss: 0.5743 - accuracy: 0.8011 - val_loss: 0.7430 - val_accuracy: 0.7363\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 41s 256ms/step - loss: 0.4873 - accuracy: 0.8302 - val_loss: 0.7751 - val_accuracy: 0.7383\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 41s 258ms/step - loss: 0.4176 - accuracy: 0.8542 - val_loss: 0.8059 - val_accuracy: 0.7242\n",
            "80/80 [==============================] - 2s 23ms/step - loss: 0.8059 - accuracy: 0.7242\n",
            "emb_dim: 128  hidden_dim: 128  drop: 0 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 107s 669ms/step - loss: 1.1326 - accuracy: 0.5448 - val_loss: 0.8260 - val_accuracy: 0.7042\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 107s 667ms/step - loss: 0.6964 - accuracy: 0.7535 - val_loss: 0.7785 - val_accuracy: 0.7148\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 107s 667ms/step - loss: 0.5566 - accuracy: 0.8057 - val_loss: 0.7553 - val_accuracy: 0.7363\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 106s 660ms/step - loss: 0.4616 - accuracy: 0.8396 - val_loss: 0.7900 - val_accuracy: 0.7363\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 106s 662ms/step - loss: 0.3914 - accuracy: 0.8625 - val_loss: 0.8321 - val_accuracy: 0.7195\n",
            "80/80 [==============================] - 5s 67ms/step - loss: 0.8321 - accuracy: 0.7195\n",
            "emb_dim: 128  hidden_dim: 128  drop: 0.1 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 117s 730ms/step - loss: 1.1048 - accuracy: 0.5494 - val_loss: 0.8240 - val_accuracy: 0.6980\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 117s 733ms/step - loss: 0.6962 - accuracy: 0.7544 - val_loss: 0.7603 - val_accuracy: 0.7218\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 117s 730ms/step - loss: 0.5571 - accuracy: 0.8050 - val_loss: 0.7623 - val_accuracy: 0.7238\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 118s 735ms/step - loss: 0.4676 - accuracy: 0.8377 - val_loss: 0.8043 - val_accuracy: 0.7300\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 118s 736ms/step - loss: 0.4011 - accuracy: 0.8603 - val_loss: 0.8355 - val_accuracy: 0.7207\n",
            "80/80 [==============================] - 5s 68ms/step - loss: 0.8356 - accuracy: 0.7207\n",
            "emb_dim: 128  hidden_dim: 128  drop: 0.2 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 117s 733ms/step - loss: 1.1571 - accuracy: 0.5248 - val_loss: 0.8524 - val_accuracy: 0.6905\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 116s 726ms/step - loss: 0.7201 - accuracy: 0.7475 - val_loss: 0.7720 - val_accuracy: 0.7167\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 117s 730ms/step - loss: 0.5757 - accuracy: 0.7997 - val_loss: 0.7547 - val_accuracy: 0.7210\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 117s 730ms/step - loss: 0.4860 - accuracy: 0.8315 - val_loss: 0.7792 - val_accuracy: 0.7351\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 117s 731ms/step - loss: 0.4172 - accuracy: 0.8525 - val_loss: 0.8225 - val_accuracy: 0.7121\n",
            "80/80 [==============================] - 5s 68ms/step - loss: 0.8226 - accuracy: 0.7121\n",
            "emb_dim: 128  hidden_dim: 256  drop: 0 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 345s 2s/step - loss: 1.2195 - accuracy: 0.5067 - val_loss: 0.8496 - val_accuracy: 0.6874\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 337s 2s/step - loss: 0.7235 - accuracy: 0.7420 - val_loss: 0.7783 - val_accuracy: 0.7230\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 326s 2s/step - loss: 0.5676 - accuracy: 0.8036 - val_loss: 0.7529 - val_accuracy: 0.7293\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 330s 2s/step - loss: 0.4653 - accuracy: 0.8385 - val_loss: 0.7954 - val_accuracy: 0.7281\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 339s 2s/step - loss: 0.3882 - accuracy: 0.8634 - val_loss: 0.8155 - val_accuracy: 0.7210\n",
            "80/80 [==============================] - 23s 285ms/step - loss: 0.8156 - accuracy: 0.7210\n",
            "emb_dim: 128  hidden_dim: 256  drop: 0.1 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 342s 2s/step - loss: 1.1982 - accuracy: 0.5063 - val_loss: 0.8592 - val_accuracy: 0.6831\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 337s 2s/step - loss: 0.7314 - accuracy: 0.7342 - val_loss: 0.7870 - val_accuracy: 0.7128\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 338s 2s/step - loss: 0.5758 - accuracy: 0.8009 - val_loss: 0.7658 - val_accuracy: 0.7167\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 340s 2s/step - loss: 0.4761 - accuracy: 0.8358 - val_loss: 0.8019 - val_accuracy: 0.7230\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 339s 2s/step - loss: 0.4000 - accuracy: 0.8607 - val_loss: 0.8261 - val_accuracy: 0.7140\n",
            "80/80 [==============================] - 22s 278ms/step - loss: 0.8261 - accuracy: 0.7140\n",
            "emb_dim: 128  hidden_dim: 256  drop: 0.2 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 338s 2s/step - loss: 1.2124 - accuracy: 0.5033 - val_loss: 0.8421 - val_accuracy: 0.6882\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 336s 2s/step - loss: 0.7324 - accuracy: 0.7379 - val_loss: 0.7718 - val_accuracy: 0.7187\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 336s 2s/step - loss: 0.5804 - accuracy: 0.7977 - val_loss: 0.7425 - val_accuracy: 0.7277\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 335s 2s/step - loss: 0.4823 - accuracy: 0.8303 - val_loss: 0.7928 - val_accuracy: 0.7293\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 335s 2s/step - loss: 0.4070 - accuracy: 0.8583 - val_loss: 0.8052 - val_accuracy: 0.7250\n",
            "80/80 [==============================] - 22s 271ms/step - loss: 0.8051 - accuracy: 0.7250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkOt2-KOasJE",
        "colab_type": "text"
      },
      "source": [
        "#### With 5 layers, trying different emb_dim, hid_dim and dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFULZptHQCIz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "78b51c00-3614-4e3a-f00b-0b77a20c5173"
      },
      "source": [
        "embed = [100,200,300]\n",
        "hidden = [50,100,150,200]\n",
        "drop = [0, 0.1, 0.2]\n",
        "for i in embed:\n",
        "  for j in hidden:\n",
        "    for k in drop:\n",
        "      print('emb_dim:',i,' hidden_dim:',j, ' drop:',k,'----RMSprop')\n",
        "      np.random.seed(42)\n",
        "      random.seed(12345)\n",
        "      session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                    inter_op_parallelism_threads=1)\n",
        "      tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "      model = Sequential() \n",
        "      model.add(Embedding(dict_len + 1, output_dim=i)) \n",
        "      model.add(Bidirectional(LSTM(j, dropout=k, return_sequences=True)))\n",
        "      model.add(Bidirectional(LSTM(j, dropout=k, return_sequences=True)))\n",
        "      model.add(Bidirectional(LSTM(j, dropout=k, return_sequences=True)))\n",
        "      model.add(Bidirectional(LSTM(j, dropout=k, return_sequences=True)))\n",
        "      model.add(Bidirectional(LSTM(j, dropout=k))) \n",
        "      model.add(Dense(5, activation=\"softmax\"))  \n",
        "      model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "      # Train the model\n",
        "      model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=5) \n",
        "      model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "emb_dim: 100  hidden_dim: 50  drop: 0 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 27s 170ms/step - loss: 1.1696 - accuracy: 0.5151 - val_loss: 0.8724 - val_accuracy: 0.6745\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 24s 149ms/step - loss: 0.7411 - accuracy: 0.7364 - val_loss: 0.8159 - val_accuracy: 0.7034\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 24s 149ms/step - loss: 0.5999 - accuracy: 0.7922 - val_loss: 0.7843 - val_accuracy: 0.7218\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 24s 149ms/step - loss: 0.5161 - accuracy: 0.8240 - val_loss: 0.7938 - val_accuracy: 0.7226\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 24s 148ms/step - loss: 0.4533 - accuracy: 0.8493 - val_loss: 0.8528 - val_accuracy: 0.7140\n",
            "80/80 [==============================] - 2s 23ms/step - loss: 0.8528 - accuracy: 0.7140\n",
            "emb_dim: 100  hidden_dim: 50  drop: 0.1 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 30s 185ms/step - loss: 1.2038 - accuracy: 0.4898 - val_loss: 0.9191 - val_accuracy: 0.6557\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 26s 164ms/step - loss: 0.7792 - accuracy: 0.7245 - val_loss: 0.8115 - val_accuracy: 0.7007\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 26s 164ms/step - loss: 0.6234 - accuracy: 0.7814 - val_loss: 0.8011 - val_accuracy: 0.7207\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 26s 164ms/step - loss: 0.5364 - accuracy: 0.8170 - val_loss: 0.7853 - val_accuracy: 0.7246\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 26s 165ms/step - loss: 0.4667 - accuracy: 0.8398 - val_loss: 0.8407 - val_accuracy: 0.7101\n",
            "80/80 [==============================] - 2s 23ms/step - loss: 0.8407 - accuracy: 0.7101\n",
            "emb_dim: 100  hidden_dim: 50  drop: 0.2 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 29s 183ms/step - loss: 1.2304 - accuracy: 0.4704 - val_loss: 1.0443 - val_accuracy: 0.6076\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 26s 165ms/step - loss: 0.7940 - accuracy: 0.7137 - val_loss: 0.8156 - val_accuracy: 0.7027\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 26s 164ms/step - loss: 0.6376 - accuracy: 0.7772 - val_loss: 0.7965 - val_accuracy: 0.7167\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 26s 163ms/step - loss: 0.5480 - accuracy: 0.8119 - val_loss: 0.7810 - val_accuracy: 0.7285\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 26s 164ms/step - loss: 0.4803 - accuracy: 0.8363 - val_loss: 0.8346 - val_accuracy: 0.7128\n",
            "80/80 [==============================] - 2s 22ms/step - loss: 0.8346 - accuracy: 0.7128\n",
            "emb_dim: 100  hidden_dim: 100  drop: 0 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 63s 393ms/step - loss: 1.2623 - accuracy: 0.4505 - val_loss: 0.9378 - val_accuracy: 0.6424\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 60s 374ms/step - loss: 0.8022 - accuracy: 0.7130 - val_loss: 0.8778 - val_accuracy: 0.6827\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 60s 374ms/step - loss: 0.6398 - accuracy: 0.7782 - val_loss: 0.7841 - val_accuracy: 0.7167\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 60s 377ms/step - loss: 0.5413 - accuracy: 0.8166 - val_loss: 0.7954 - val_accuracy: 0.7261\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 60s 375ms/step - loss: 0.4679 - accuracy: 0.8403 - val_loss: 0.8356 - val_accuracy: 0.7105\n",
            "80/80 [==============================] - 4s 45ms/step - loss: 0.8356 - accuracy: 0.7105\n",
            "emb_dim: 100  hidden_dim: 100  drop: 0.1 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 67s 421ms/step - loss: 1.3016 - accuracy: 0.4259 - val_loss: 0.9491 - val_accuracy: 0.6428\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 65s 405ms/step - loss: 0.8416 - accuracy: 0.6897 - val_loss: 0.8824 - val_accuracy: 0.6694\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 65s 407ms/step - loss: 0.6575 - accuracy: 0.7713 - val_loss: 0.7744 - val_accuracy: 0.7226\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 66s 410ms/step - loss: 0.5608 - accuracy: 0.8094 - val_loss: 0.7817 - val_accuracy: 0.7300\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 66s 410ms/step - loss: 0.4846 - accuracy: 0.8313 - val_loss: 0.8136 - val_accuracy: 0.7132\n",
            "80/80 [==============================] - 4s 51ms/step - loss: 0.8136 - accuracy: 0.7132\n",
            "emb_dim: 100  hidden_dim: 100  drop: 0.2 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 68s 423ms/step - loss: 1.2887 - accuracy: 0.4383 - val_loss: 0.9613 - val_accuracy: 0.6408\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 65s 404ms/step - loss: 0.8539 - accuracy: 0.6860 - val_loss: 0.8812 - val_accuracy: 0.6721\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 65s 407ms/step - loss: 0.6677 - accuracy: 0.7670 - val_loss: 0.7685 - val_accuracy: 0.7254\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 65s 405ms/step - loss: 0.5671 - accuracy: 0.8090 - val_loss: 0.7757 - val_accuracy: 0.7293\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 65s 405ms/step - loss: 0.4977 - accuracy: 0.8308 - val_loss: 0.8115 - val_accuracy: 0.7101\n",
            "80/80 [==============================] - 4s 50ms/step - loss: 0.8115 - accuracy: 0.7101\n",
            "emb_dim: 100  hidden_dim: 150  drop: 0 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 124s 778ms/step - loss: 1.2551 - accuracy: 0.4549 - val_loss: 0.9235 - val_accuracy: 0.6479\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 122s 763ms/step - loss: 0.8199 - accuracy: 0.7010 - val_loss: 0.8340 - val_accuracy: 0.6929\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 122s 763ms/step - loss: 0.6466 - accuracy: 0.7747 - val_loss: 0.7842 - val_accuracy: 0.7218\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 123s 772ms/step - loss: 0.5497 - accuracy: 0.8131 - val_loss: 0.7989 - val_accuracy: 0.7261\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 123s 768ms/step - loss: 0.4751 - accuracy: 0.8351 - val_loss: 0.8109 - val_accuracy: 0.7246\n",
            "80/80 [==============================] - 9s 115ms/step - loss: 0.8110 - accuracy: 0.7246\n",
            "emb_dim: 100  hidden_dim: 150  drop: 0.1 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 129s 807ms/step - loss: 1.2817 - accuracy: 0.4526 - val_loss: 0.9338 - val_accuracy: 0.6514\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 131s 820ms/step - loss: 0.8357 - accuracy: 0.6943 - val_loss: 0.8966 - val_accuracy: 0.6674\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 127s 793ms/step - loss: 0.6546 - accuracy: 0.7753 - val_loss: 0.7827 - val_accuracy: 0.7218\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 126s 787ms/step - loss: 0.5594 - accuracy: 0.8097 - val_loss: 0.7855 - val_accuracy: 0.7394\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 126s 789ms/step - loss: 0.4877 - accuracy: 0.8312 - val_loss: 0.7977 - val_accuracy: 0.7316\n",
            "80/80 [==============================] - 9s 116ms/step - loss: 0.7977 - accuracy: 0.7316\n",
            "emb_dim: 100  hidden_dim: 150  drop: 0.2 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 133s 833ms/step - loss: 1.3290 - accuracy: 0.4101 - val_loss: 1.0143 - val_accuracy: 0.6033\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 128s 799ms/step - loss: 0.8807 - accuracy: 0.6760 - val_loss: 0.8668 - val_accuracy: 0.6764\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 129s 805ms/step - loss: 0.6819 - accuracy: 0.7628 - val_loss: 0.7993 - val_accuracy: 0.7156\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 129s 807ms/step - loss: 0.5799 - accuracy: 0.8005 - val_loss: 0.7837 - val_accuracy: 0.7332\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 132s 823ms/step - loss: 0.5069 - accuracy: 0.8237 - val_loss: 0.8038 - val_accuracy: 0.7234\n",
            "80/80 [==============================] - 9s 119ms/step - loss: 0.8038 - accuracy: 0.7234\n",
            "emb_dim: 100  hidden_dim: 200  drop: 0 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 208s 1s/step - loss: 1.3278 - accuracy: 0.4331 - val_loss: 0.9321 - val_accuracy: 0.6424\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 199s 1s/step - loss: 0.8190 - accuracy: 0.7095 - val_loss: 0.8350 - val_accuracy: 0.6897\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 198s 1s/step - loss: 0.6384 - accuracy: 0.7794 - val_loss: 0.7969 - val_accuracy: 0.7160\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 200s 1s/step - loss: 0.5450 - accuracy: 0.8170 - val_loss: 0.8244 - val_accuracy: 0.7187\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 196s 1s/step - loss: 0.4669 - accuracy: 0.8420 - val_loss: 0.8207 - val_accuracy: 0.7136\n",
            "80/80 [==============================] - 16s 194ms/step - loss: 0.8206 - accuracy: 0.7136\n",
            "emb_dim: 100  hidden_dim: 200  drop: 0.1 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 211s 1s/step - loss: 1.3730 - accuracy: 0.4145 - val_loss: 1.0012 - val_accuracy: 0.6342\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 204s 1s/step - loss: 0.8911 - accuracy: 0.6691 - val_loss: 0.8690 - val_accuracy: 0.6811\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 204s 1s/step - loss: 0.6853 - accuracy: 0.7628 - val_loss: 0.7818 - val_accuracy: 0.7214\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 210s 1s/step - loss: 0.5719 - accuracy: 0.8075 - val_loss: 0.8129 - val_accuracy: 0.7254\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 199s 1s/step - loss: 0.4987 - accuracy: 0.8323 - val_loss: 0.7978 - val_accuracy: 0.7097\n",
            "80/80 [==============================] - 15s 193ms/step - loss: 0.7978 - accuracy: 0.7097\n",
            "emb_dim: 100  hidden_dim: 200  drop: 0.2 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 208s 1s/step - loss: 1.3475 - accuracy: 0.4197 - val_loss: 1.1352 - val_accuracy: 0.5348\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 210s 1s/step - loss: 0.8855 - accuracy: 0.6666 - val_loss: 0.8509 - val_accuracy: 0.6882\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 211s 1s/step - loss: 0.6736 - accuracy: 0.7635 - val_loss: 0.7906 - val_accuracy: 0.7160\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 211s 1s/step - loss: 0.5691 - accuracy: 0.8056 - val_loss: 0.7986 - val_accuracy: 0.7187\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 211s 1s/step - loss: 0.4939 - accuracy: 0.8319 - val_loss: 0.7768 - val_accuracy: 0.7183\n",
            "80/80 [==============================] - 16s 199ms/step - loss: 0.7768 - accuracy: 0.7183\n",
            "emb_dim: 200  hidden_dim: 50  drop: 0 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 32s 201ms/step - loss: 1.1424 - accuracy: 0.5229 - val_loss: 0.8548 - val_accuracy: 0.6788\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 29s 181ms/step - loss: 0.7194 - accuracy: 0.7453 - val_loss: 0.7752 - val_accuracy: 0.7175\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 29s 181ms/step - loss: 0.5781 - accuracy: 0.8031 - val_loss: 0.7648 - val_accuracy: 0.7230\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 29s 181ms/step - loss: 0.4949 - accuracy: 0.8345 - val_loss: 0.7934 - val_accuracy: 0.7308\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 29s 181ms/step - loss: 0.4215 - accuracy: 0.8564 - val_loss: 0.8137 - val_accuracy: 0.7218\n",
            "80/80 [==============================] - 2s 25ms/step - loss: 0.8137 - accuracy: 0.7218\n",
            "emb_dim: 200  hidden_dim: 50  drop: 0.1 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 36s 223ms/step - loss: 1.1802 - accuracy: 0.4936 - val_loss: 0.8378 - val_accuracy: 0.6827\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 33s 203ms/step - loss: 0.7262 - accuracy: 0.7475 - val_loss: 0.8131 - val_accuracy: 0.7058\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 32s 203ms/step - loss: 0.5875 - accuracy: 0.7993 - val_loss: 0.7607 - val_accuracy: 0.7269\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 33s 205ms/step - loss: 0.5009 - accuracy: 0.8315 - val_loss: 0.7849 - val_accuracy: 0.7308\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 33s 205ms/step - loss: 0.4250 - accuracy: 0.8543 - val_loss: 0.8288 - val_accuracy: 0.7179\n",
            "80/80 [==============================] - 2s 26ms/step - loss: 0.8288 - accuracy: 0.7179\n",
            "emb_dim: 200  hidden_dim: 50  drop: 0.2 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 36s 226ms/step - loss: 1.2135 - accuracy: 0.4748 - val_loss: 0.8818 - val_accuracy: 0.6639\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 33s 207ms/step - loss: 0.7611 - accuracy: 0.7293 - val_loss: 0.7887 - val_accuracy: 0.7132\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 38s 240ms/step - loss: 0.6173 - accuracy: 0.7865 - val_loss: 0.7536 - val_accuracy: 0.7246\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 33s 207ms/step - loss: 0.5255 - accuracy: 0.8232 - val_loss: 0.7783 - val_accuracy: 0.7332\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 33s 205ms/step - loss: 0.4519 - accuracy: 0.8424 - val_loss: 0.8037 - val_accuracy: 0.7254\n",
            "80/80 [==============================] - 2s 26ms/step - loss: 0.8037 - accuracy: 0.7254\n",
            "emb_dim: 200  hidden_dim: 100  drop: 0 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 73s 458ms/step - loss: 1.2408 - accuracy: 0.4621 - val_loss: 0.8901 - val_accuracy: 0.6718\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 71s 442ms/step - loss: 0.7528 - accuracy: 0.7311 - val_loss: 0.7992 - val_accuracy: 0.7140\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 71s 443ms/step - loss: 0.6005 - accuracy: 0.7933 - val_loss: 0.7722 - val_accuracy: 0.7191\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 71s 443ms/step - loss: 0.5076 - accuracy: 0.8294 - val_loss: 0.7894 - val_accuracy: 0.7281\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 71s 442ms/step - loss: 0.4284 - accuracy: 0.8508 - val_loss: 0.8395 - val_accuracy: 0.7218\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.8396 - accuracy: 0.7218\n",
            "emb_dim: 200  hidden_dim: 100  drop: 0.1 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 77s 484ms/step - loss: 1.2984 - accuracy: 0.4196 - val_loss: 0.9927 - val_accuracy: 0.5775\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 76s 478ms/step - loss: 0.7889 - accuracy: 0.7153 - val_loss: 0.8259 - val_accuracy: 0.7027\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 74s 462ms/step - loss: 0.6197 - accuracy: 0.7890 - val_loss: 0.7616 - val_accuracy: 0.7254\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 74s 460ms/step - loss: 0.5231 - accuracy: 0.8256 - val_loss: 0.7807 - val_accuracy: 0.7359\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 73s 458ms/step - loss: 0.4469 - accuracy: 0.8443 - val_loss: 0.8200 - val_accuracy: 0.7238\n",
            "80/80 [==============================] - 4s 56ms/step - loss: 0.8201 - accuracy: 0.7238\n",
            "emb_dim: 200  hidden_dim: 100  drop: 0.2 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 77s 479ms/step - loss: 1.2998 - accuracy: 0.4330 - val_loss: 0.9436 - val_accuracy: 0.6354\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 73s 456ms/step - loss: 0.7955 - accuracy: 0.7153 - val_loss: 0.8306 - val_accuracy: 0.7058\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 73s 458ms/step - loss: 0.6178 - accuracy: 0.7921 - val_loss: 0.7581 - val_accuracy: 0.7300\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 74s 459ms/step - loss: 0.5227 - accuracy: 0.8225 - val_loss: 0.7774 - val_accuracy: 0.7398\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 77s 481ms/step - loss: 0.4449 - accuracy: 0.8510 - val_loss: 0.8238 - val_accuracy: 0.7285\n",
            "80/80 [==============================] - 4s 55ms/step - loss: 0.8241 - accuracy: 0.7285\n",
            "emb_dim: 200  hidden_dim: 150  drop: 0 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 134s 839ms/step - loss: 1.2248 - accuracy: 0.4983 - val_loss: 0.8849 - val_accuracy: 0.6729\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 131s 820ms/step - loss: 0.7693 - accuracy: 0.7309 - val_loss: 0.7923 - val_accuracy: 0.7077\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 133s 831ms/step - loss: 0.6003 - accuracy: 0.7969 - val_loss: 0.8058 - val_accuracy: 0.7167\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 132s 822ms/step - loss: 0.5050 - accuracy: 0.8314 - val_loss: 0.8108 - val_accuracy: 0.7234\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 135s 844ms/step - loss: 0.4200 - accuracy: 0.8577 - val_loss: 0.8540 - val_accuracy: 0.7050\n",
            "80/80 [==============================] - 10s 128ms/step - loss: 0.8541 - accuracy: 0.7050\n",
            "emb_dim: 200  hidden_dim: 150  drop: 0.1 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 136s 852ms/step - loss: 1.2504 - accuracy: 0.4787 - val_loss: 0.9375 - val_accuracy: 0.6577\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 134s 839ms/step - loss: 0.7922 - accuracy: 0.7197 - val_loss: 0.8017 - val_accuracy: 0.7093\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 134s 838ms/step - loss: 0.6194 - accuracy: 0.7900 - val_loss: 0.7904 - val_accuracy: 0.7214\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 137s 859ms/step - loss: 0.5215 - accuracy: 0.8229 - val_loss: 0.8029 - val_accuracy: 0.7320\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 134s 836ms/step - loss: 0.4390 - accuracy: 0.8530 - val_loss: 0.8482 - val_accuracy: 0.7210\n",
            "80/80 [==============================] - 10s 127ms/step - loss: 0.8483 - accuracy: 0.7210\n",
            "emb_dim: 200  hidden_dim: 150  drop: 0.2 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 137s 854ms/step - loss: 1.2648 - accuracy: 0.4672 - val_loss: 0.9314 - val_accuracy: 0.6671\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 135s 841ms/step - loss: 0.8123 - accuracy: 0.7117 - val_loss: 0.8086 - val_accuracy: 0.7070\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 136s 851ms/step - loss: 0.6339 - accuracy: 0.7852 - val_loss: 0.7985 - val_accuracy: 0.7156\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 135s 843ms/step - loss: 0.5292 - accuracy: 0.8225 - val_loss: 0.8066 - val_accuracy: 0.7304\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 136s 850ms/step - loss: 0.4474 - accuracy: 0.8498 - val_loss: 0.8210 - val_accuracy: 0.7152\n",
            "80/80 [==============================] - 10s 125ms/step - loss: 0.8210 - accuracy: 0.7152\n",
            "emb_dim: 200  hidden_dim: 200  drop: 0 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 199s 1s/step - loss: 1.3513 - accuracy: 0.4031 - val_loss: 0.9675 - val_accuracy: 0.6205\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 200s 1s/step - loss: 0.8078 - accuracy: 0.7104 - val_loss: 0.8669 - val_accuracy: 0.6721\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 193s 1s/step - loss: 0.6303 - accuracy: 0.7831 - val_loss: 0.8129 - val_accuracy: 0.7105\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 192s 1s/step - loss: 0.5312 - accuracy: 0.8231 - val_loss: 0.8454 - val_accuracy: 0.7175\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 196s 1s/step - loss: 0.4551 - accuracy: 0.8436 - val_loss: 0.8135 - val_accuracy: 0.7152\n",
            "80/80 [==============================] - 16s 201ms/step - loss: 0.8134 - accuracy: 0.7152\n",
            "emb_dim: 200  hidden_dim: 200  drop: 0.1 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 204s 1s/step - loss: 1.3076 - accuracy: 0.4439 - val_loss: 0.9776 - val_accuracy: 0.6299\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 200s 1s/step - loss: 0.8038 - accuracy: 0.7068 - val_loss: 0.8661 - val_accuracy: 0.6929\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 203s 1s/step - loss: 0.6332 - accuracy: 0.7796 - val_loss: 0.7757 - val_accuracy: 0.7191\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 201s 1s/step - loss: 0.5332 - accuracy: 0.8201 - val_loss: 0.8274 - val_accuracy: 0.7183\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 204s 1s/step - loss: 0.4601 - accuracy: 0.8420 - val_loss: 0.8565 - val_accuracy: 0.7031\n",
            "80/80 [==============================] - 16s 202ms/step - loss: 0.8566 - accuracy: 0.7031\n",
            "emb_dim: 200  hidden_dim: 200  drop: 0.2 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 208s 1s/step - loss: 1.3491 - accuracy: 0.3980 - val_loss: 0.9701 - val_accuracy: 0.6256\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 203s 1s/step - loss: 0.8499 - accuracy: 0.6860 - val_loss: 0.8962 - val_accuracy: 0.6718\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 205s 1s/step - loss: 0.6579 - accuracy: 0.7719 - val_loss: 0.7849 - val_accuracy: 0.7124\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 205s 1s/step - loss: 0.5557 - accuracy: 0.8130 - val_loss: 0.8141 - val_accuracy: 0.7164\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 202s 1s/step - loss: 0.4764 - accuracy: 0.8400 - val_loss: 0.8279 - val_accuracy: 0.7195\n",
            "80/80 [==============================] - 16s 200ms/step - loss: 0.8279 - accuracy: 0.7195\n",
            "emb_dim: 300  hidden_dim: 50  drop: 0 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 35s 216ms/step - loss: 1.1528 - accuracy: 0.5106 - val_loss: 0.8414 - val_accuracy: 0.6995\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 31s 195ms/step - loss: 0.7120 - accuracy: 0.7519 - val_loss: 0.7911 - val_accuracy: 0.7121\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 31s 195ms/step - loss: 0.5624 - accuracy: 0.8090 - val_loss: 0.7993 - val_accuracy: 0.7156\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 31s 195ms/step - loss: 0.4708 - accuracy: 0.8429 - val_loss: 0.8111 - val_accuracy: 0.7359\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 32s 200ms/step - loss: 0.3973 - accuracy: 0.8678 - val_loss: 0.8657 - val_accuracy: 0.7077\n",
            "80/80 [==============================] - 4s 54ms/step - loss: 0.8659 - accuracy: 0.7077\n",
            "emb_dim: 300  hidden_dim: 50  drop: 0.1 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 38s 238ms/step - loss: 1.1892 - accuracy: 0.4821 - val_loss: 0.8540 - val_accuracy: 0.6835\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 35s 221ms/step - loss: 0.7341 - accuracy: 0.7417 - val_loss: 0.8159 - val_accuracy: 0.7011\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 35s 220ms/step - loss: 0.5833 - accuracy: 0.8002 - val_loss: 0.7688 - val_accuracy: 0.7265\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 35s 221ms/step - loss: 0.4905 - accuracy: 0.8357 - val_loss: 0.7860 - val_accuracy: 0.7324\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 35s 222ms/step - loss: 0.4183 - accuracy: 0.8563 - val_loss: 0.8543 - val_accuracy: 0.7117\n",
            "80/80 [==============================] - 2s 28ms/step - loss: 0.8544 - accuracy: 0.7117\n",
            "emb_dim: 300  hidden_dim: 50  drop: 0.2 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 39s 246ms/step - loss: 1.1597 - accuracy: 0.5159 - val_loss: 0.8313 - val_accuracy: 0.6987\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 36s 222ms/step - loss: 0.7362 - accuracy: 0.7432 - val_loss: 0.8126 - val_accuracy: 0.7077\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 36s 224ms/step - loss: 0.5892 - accuracy: 0.7984 - val_loss: 0.7641 - val_accuracy: 0.7273\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 36s 223ms/step - loss: 0.4981 - accuracy: 0.8333 - val_loss: 0.7886 - val_accuracy: 0.7293\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 36s 226ms/step - loss: 0.4272 - accuracy: 0.8535 - val_loss: 0.8388 - val_accuracy: 0.7132\n",
            "80/80 [==============================] - 2s 28ms/step - loss: 0.8388 - accuracy: 0.7132\n",
            "emb_dim: 300  hidden_dim: 100  drop: 0 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 76s 475ms/step - loss: 1.2011 - accuracy: 0.4897 - val_loss: 0.8997 - val_accuracy: 0.6616\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 73s 455ms/step - loss: 0.7601 - accuracy: 0.7287 - val_loss: 0.7997 - val_accuracy: 0.7156\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 77s 482ms/step - loss: 0.5988 - accuracy: 0.7929 - val_loss: 0.7841 - val_accuracy: 0.7156\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 73s 456ms/step - loss: 0.5059 - accuracy: 0.8295 - val_loss: 0.8020 - val_accuracy: 0.7332\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 72s 453ms/step - loss: 0.4217 - accuracy: 0.8547 - val_loss: 0.8445 - val_accuracy: 0.7222\n",
            "80/80 [==============================] - 5s 57ms/step - loss: 0.8446 - accuracy: 0.7222\n",
            "emb_dim: 300  hidden_dim: 100  drop: 0.1 ----RMSprop\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 80s 499ms/step - loss: 1.2532 - accuracy: 0.4564 - val_loss: 0.8962 - val_accuracy: 0.6678\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 77s 480ms/step - loss: 0.7836 - accuracy: 0.7217 - val_loss: 0.8510 - val_accuracy: 0.6890\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - ETA: 0s - loss: 0.6067 - accuracy: 0.7956"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-bb840970e467>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RMSprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m    810\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 step_num=step):\n\u001b[1;32m   1017\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1019\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjkV9eGHOmU0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "0613b66b-bf6d-48da-8765-72014b747bae"
      },
      "source": [
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len + 1, output_dim=128)) \n",
        "model.add(Bidirectional(LSTM(128, dropout=0.2, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(128, dropout=0.2, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(128, dropout=0.2, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(128, dropout=0.2, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(128, dropout=0.2, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(128, dropout=0.2, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(128, dropout=0.2, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(128, dropout=0.2, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(128, dropout=0.2, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(128, dropout=0.2))) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=5) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "160/160 [==============================] - 210s 1s/step - loss: 1.4795 - accuracy: 0.3110 - val_loss: 1.3255 - val_accuracy: 0.3560\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 206s 1s/step - loss: 1.2127 - accuracy: 0.4469 - val_loss: 1.2860 - val_accuracy: 0.4218\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 205s 1s/step - loss: 1.0059 - accuracy: 0.5737 - val_loss: 0.9670 - val_accuracy: 0.6049\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 205s 1s/step - loss: 0.8276 - accuracy: 0.6859 - val_loss: 0.9068 - val_accuracy: 0.6459\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 205s 1s/step - loss: 0.6916 - accuracy: 0.7604 - val_loss: 0.9316 - val_accuracy: 0.6796\n",
            "80/80 [==============================] - 16s 195ms/step - loss: 0.9318 - accuracy: 0.6796\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.931806743144989, 0.6795774698257446]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vzn_nhwYoxo5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "ca60dea2-973d-46d7-b4fb-86feedf7f75a"
      },
      "source": [
        "# Very bad try :)\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len + 1, output_dim=256)) \n",
        "model.add(Bidirectional(LSTM(50, dropout=0.2, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(50, dropout=0.2, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(50, dropout=0.2, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(50, dropout=0.2, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(50, dropout=0.2, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(50, dropout=0.2, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(50, dropout=0.2, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(50, dropout=0.2, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(50, dropout=0.2, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(50, dropout=0.2))) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=10) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "160/160 [==============================] - 65s 404ms/step - loss: 1.3267 - accuracy: 0.4003 - val_loss: 1.0912 - val_accuracy: 0.4918\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 58s 360ms/step - loss: 0.9581 - accuracy: 0.6136 - val_loss: 0.9278 - val_accuracy: 0.6416\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 57s 358ms/step - loss: 0.7870 - accuracy: 0.7121 - val_loss: 0.8791 - val_accuracy: 0.6682\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 57s 358ms/step - loss: 0.6809 - accuracy: 0.7676 - val_loss: 0.9011 - val_accuracy: 0.6784\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 57s 359ms/step - loss: 0.5926 - accuracy: 0.8057 - val_loss: 0.8878 - val_accuracy: 0.6874\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 57s 357ms/step - loss: 0.5115 - accuracy: 0.8365 - val_loss: 0.8318 - val_accuracy: 0.7164\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 57s 356ms/step - loss: 0.4423 - accuracy: 0.8601 - val_loss: 0.9221 - val_accuracy: 0.7074\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 57s 355ms/step - loss: 0.3893 - accuracy: 0.8795 - val_loss: 0.9950 - val_accuracy: 0.6995\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 57s 356ms/step - loss: 0.3452 - accuracy: 0.8961 - val_loss: 1.0051 - val_accuracy: 0.6972\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 60s 376ms/step - loss: 0.3043 - accuracy: 0.9130 - val_loss: 1.0297 - val_accuracy: 0.6761\n",
            "80/80 [==============================] - 4s 45ms/step - loss: 1.0297 - accuracy: 0.6761\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0297123193740845, 0.6760563254356384]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFiToX38wQRM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "outputId": "d6a234f2-4f45-45e5-9cb2-f2ec794b05e5"
      },
      "source": [
        "# Why no gain vs simple LSTM (emb=128,hu=128) which gives 74.41%???\n",
        "# Too high dropout?\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len + 1, output_dim=128)) \n",
        "model.add(Bidirectional(LSTM(100, dropout=0.5, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(200, dropout=0.5, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(300, dropout=0.5, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(400, dropout=0.5, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(500, dropout=0.5))) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=10) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "160/160 [==============================] - 424s 3s/step - loss: 1.4709 - accuracy: 0.3329 - val_loss: 1.1774 - val_accuracy: 0.4577\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 412s 3s/step - loss: 1.0545 - accuracy: 0.5805 - val_loss: 1.0432 - val_accuracy: 0.5849\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 425s 3s/step - loss: 0.8056 - accuracy: 0.7088 - val_loss: 0.8082 - val_accuracy: 0.7034\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 416s 3s/step - loss: 0.6713 - accuracy: 0.7632 - val_loss: 0.7882 - val_accuracy: 0.7207\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 408s 3s/step - loss: 0.5910 - accuracy: 0.7943 - val_loss: 0.7604 - val_accuracy: 0.7375\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 410s 3s/step - loss: 0.5310 - accuracy: 0.8184 - val_loss: 0.7840 - val_accuracy: 0.7297\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 408s 3s/step - loss: 0.4904 - accuracy: 0.8349 - val_loss: 0.8605 - val_accuracy: 0.7167\n",
            "Epoch 8/10\n",
            "122/160 [=====================>........] - ETA: 1:29 - loss: 0.4464 - accuracy: 0.8514"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-b6b5b5f711ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RMSprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    784\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkVzYjONYRnZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "f89289f8-4f0b-441e-ef2a-fdb727b49b98"
      },
      "source": [
        "# so low...\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len + 1, output_dim=128)) \n",
        "model.add(Bidirectional(LSTM(128, dropout=0.2, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(256, dropout=0.2, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(512, dropout=0.2))) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=5) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "160/160 [==============================] - 263s 2s/step - loss: 1.2669 - accuracy: 0.4769 - val_loss: 0.9212 - val_accuracy: 0.6588\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 264s 2s/step - loss: 0.8101 - accuracy: 0.7030 - val_loss: 0.8219 - val_accuracy: 0.7031\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 265s 2s/step - loss: 0.6467 - accuracy: 0.7697 - val_loss: 0.7895 - val_accuracy: 0.7109\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 264s 2s/step - loss: 0.5385 - accuracy: 0.8132 - val_loss: 0.8013 - val_accuracy: 0.7238\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 267s 2s/step - loss: 0.4592 - accuracy: 0.8420 - val_loss: 0.8130 - val_accuracy: 0.7136\n",
            "80/80 [==============================] - 17s 209ms/step - loss: 0.8131 - accuracy: 0.7136\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8130871057510376, 0.7136150002479553]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5W_z0Vm1LoM9",
        "colab_type": "text"
      },
      "source": [
        "## GRU model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c2iyZAEICRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ba09e994-ffb3-4510-e879-6e259113fd63"
      },
      "source": [
        "embed = [32,64,128]\n",
        "hidden = [64,128,256]\n",
        "drop = [0, 0.1, 0.2, 0.3]\n",
        "for i in embed:\n",
        "  for j in hidden:\n",
        "    for k in drop:\n",
        "      print('emb_dim:',i,' hidden_dim:',j, ' drop:',k,'----RMSprop')\n",
        "      np.random.seed(42)\n",
        "      random.seed(12345)\n",
        "      session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                    inter_op_parallelism_threads=1)\n",
        "      tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "      model = Sequential() \n",
        "      model.add(Embedding(dict_len + 1, output_dim=i)) \n",
        "      model.add(GRU(j, dropout=k)) \n",
        "      model.add(Dense(5, activation=\"softmax\"))  \n",
        "      model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "      # Train the model\n",
        "      model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=7) \n",
        "      model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "emb_dim: 32  hidden_dim: 64  drop: 0 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 1.3809 - accuracy: 0.4405 - val_loss: 1.0540 - val_accuracy: 0.6146\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.8531 - accuracy: 0.6901 - val_loss: 0.8065 - val_accuracy: 0.6937\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.6603 - accuracy: 0.7632 - val_loss: 0.7495 - val_accuracy: 0.7207\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.5663 - accuracy: 0.8021 - val_loss: 0.7385 - val_accuracy: 0.7320\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.5013 - accuracy: 0.8250 - val_loss: 0.7604 - val_accuracy: 0.7277\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.4506 - accuracy: 0.8453 - val_loss: 0.7725 - val_accuracy: 0.7312\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.4077 - accuracy: 0.8606 - val_loss: 0.8103 - val_accuracy: 0.7246\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.8104 - accuracy: 0.7246\n",
            "emb_dim: 32  hidden_dim: 64  drop: 0.1 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 1.3977 - accuracy: 0.4256 - val_loss: 1.1032 - val_accuracy: 0.5978\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.8892 - accuracy: 0.6799 - val_loss: 0.8192 - val_accuracy: 0.6921\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.6840 - accuracy: 0.7534 - val_loss: 0.7520 - val_accuracy: 0.7191\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.5899 - accuracy: 0.7916 - val_loss: 0.7357 - val_accuracy: 0.7328\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.5246 - accuracy: 0.8169 - val_loss: 0.7456 - val_accuracy: 0.7304\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.4780 - accuracy: 0.8354 - val_loss: 0.7638 - val_accuracy: 0.7328\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.4355 - accuracy: 0.8473 - val_loss: 0.8048 - val_accuracy: 0.7222\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.8049 - accuracy: 0.7222\n",
            "emb_dim: 32  hidden_dim: 64  drop: 0.2 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 1.4061 - accuracy: 0.4164 - val_loss: 1.1155 - val_accuracy: 0.5814\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.9015 - accuracy: 0.6667 - val_loss: 0.8250 - val_accuracy: 0.6890\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.7078 - accuracy: 0.7449 - val_loss: 0.7579 - val_accuracy: 0.7179\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.6175 - accuracy: 0.7796 - val_loss: 0.7422 - val_accuracy: 0.7293\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.5542 - accuracy: 0.8047 - val_loss: 0.7409 - val_accuracy: 0.7336\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.5095 - accuracy: 0.8231 - val_loss: 0.7642 - val_accuracy: 0.7324\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.4673 - accuracy: 0.8382 - val_loss: 0.7933 - val_accuracy: 0.7269\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.7934 - accuracy: 0.7269\n",
            "emb_dim: 32  hidden_dim: 64  drop: 0.3 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 1.4338 - accuracy: 0.4021 - val_loss: 1.1686 - val_accuracy: 0.5458\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 3s 16ms/step - loss: 0.9452 - accuracy: 0.6548 - val_loss: 0.8467 - val_accuracy: 0.6858\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 3s 17ms/step - loss: 0.7407 - accuracy: 0.7340 - val_loss: 0.7715 - val_accuracy: 0.7152\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.6519 - accuracy: 0.7689 - val_loss: 0.7420 - val_accuracy: 0.7273\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.5882 - accuracy: 0.7919 - val_loss: 0.7389 - val_accuracy: 0.7312\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.5451 - accuracy: 0.8089 - val_loss: 0.7663 - val_accuracy: 0.7269\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.5049 - accuracy: 0.8238 - val_loss: 0.7828 - val_accuracy: 0.7300\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.7829 - accuracy: 0.7300\n",
            "emb_dim: 32  hidden_dim: 128  drop: 0 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 6s 37ms/step - loss: 1.3033 - accuracy: 0.4770 - val_loss: 0.9533 - val_accuracy: 0.6416\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 6s 35ms/step - loss: 0.7858 - accuracy: 0.7204 - val_loss: 0.7860 - val_accuracy: 0.7132\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 6s 35ms/step - loss: 0.6302 - accuracy: 0.7765 - val_loss: 0.7518 - val_accuracy: 0.7304\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 6s 35ms/step - loss: 0.5407 - accuracy: 0.8107 - val_loss: 0.7549 - val_accuracy: 0.7410\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 6s 35ms/step - loss: 0.4799 - accuracy: 0.8331 - val_loss: 0.7676 - val_accuracy: 0.7402\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 6s 35ms/step - loss: 0.4305 - accuracy: 0.8490 - val_loss: 0.7790 - val_accuracy: 0.7316\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 6s 35ms/step - loss: 0.3872 - accuracy: 0.8669 - val_loss: 0.8305 - val_accuracy: 0.7285\n",
            "80/80 [==============================] - 0s 6ms/step - loss: 0.8306 - accuracy: 0.7285\n",
            "emb_dim: 32  hidden_dim: 128  drop: 0.1 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 6s 37ms/step - loss: 1.3180 - accuracy: 0.4651 - val_loss: 0.9679 - val_accuracy: 0.6307\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 6s 35ms/step - loss: 0.8160 - accuracy: 0.7089 - val_loss: 0.7929 - val_accuracy: 0.7144\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.6557 - accuracy: 0.7687 - val_loss: 0.7566 - val_accuracy: 0.7254\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 6s 35ms/step - loss: 0.5660 - accuracy: 0.8017 - val_loss: 0.7539 - val_accuracy: 0.7406\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.5054 - accuracy: 0.8249 - val_loss: 0.7573 - val_accuracy: 0.7402\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.4598 - accuracy: 0.8414 - val_loss: 0.7753 - val_accuracy: 0.7340\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.4201 - accuracy: 0.8541 - val_loss: 0.7988 - val_accuracy: 0.7344\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.7988 - accuracy: 0.7344\n",
            "emb_dim: 32  hidden_dim: 128  drop: 0.2 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 6s 38ms/step - loss: 1.3310 - accuracy: 0.4576 - val_loss: 0.9866 - val_accuracy: 0.6283\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 6s 35ms/step - loss: 0.8258 - accuracy: 0.7045 - val_loss: 0.7987 - val_accuracy: 0.7066\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 6s 35ms/step - loss: 0.6722 - accuracy: 0.7610 - val_loss: 0.7640 - val_accuracy: 0.7238\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 6s 35ms/step - loss: 0.5863 - accuracy: 0.7943 - val_loss: 0.7507 - val_accuracy: 0.7394\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.5286 - accuracy: 0.8154 - val_loss: 0.7501 - val_accuracy: 0.7394\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.4840 - accuracy: 0.8339 - val_loss: 0.7662 - val_accuracy: 0.7347\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 6s 35ms/step - loss: 0.4466 - accuracy: 0.8452 - val_loss: 0.7823 - val_accuracy: 0.7316\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.7823 - accuracy: 0.7316\n",
            "emb_dim: 32  hidden_dim: 128  drop: 0.3 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 6s 37ms/step - loss: 1.3597 - accuracy: 0.4427 - val_loss: 1.0305 - val_accuracy: 0.6099\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 6s 35ms/step - loss: 0.8631 - accuracy: 0.6844 - val_loss: 0.8080 - val_accuracy: 0.7019\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.7054 - accuracy: 0.7461 - val_loss: 0.7864 - val_accuracy: 0.7183\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.6210 - accuracy: 0.7839 - val_loss: 0.7551 - val_accuracy: 0.7367\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.5647 - accuracy: 0.8028 - val_loss: 0.7436 - val_accuracy: 0.7355\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.5211 - accuracy: 0.8170 - val_loss: 0.7694 - val_accuracy: 0.7289\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.4858 - accuracy: 0.8301 - val_loss: 0.7655 - val_accuracy: 0.7363\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.7654 - accuracy: 0.7363\n",
            "emb_dim: 32  hidden_dim: 256  drop: 0 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 14s 85ms/step - loss: 1.2659 - accuracy: 0.4850 - val_loss: 0.9156 - val_accuracy: 0.6608\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 13s 83ms/step - loss: 0.7858 - accuracy: 0.7198 - val_loss: 0.7948 - val_accuracy: 0.7031\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 13s 83ms/step - loss: 0.6375 - accuracy: 0.7777 - val_loss: 0.7714 - val_accuracy: 0.7269\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 13s 83ms/step - loss: 0.5487 - accuracy: 0.8069 - val_loss: 0.7519 - val_accuracy: 0.7379\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 13s 83ms/step - loss: 0.4821 - accuracy: 0.8306 - val_loss: 0.7735 - val_accuracy: 0.7332\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 13s 84ms/step - loss: 0.4314 - accuracy: 0.8514 - val_loss: 0.7925 - val_accuracy: 0.7308\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 13s 82ms/step - loss: 0.3845 - accuracy: 0.8690 - val_loss: 0.8393 - val_accuracy: 0.7308\n",
            "80/80 [==============================] - 1s 16ms/step - loss: 0.8391 - accuracy: 0.7308\n",
            "emb_dim: 32  hidden_dim: 256  drop: 0.1 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 14s 85ms/step - loss: 1.2830 - accuracy: 0.4728 - val_loss: 0.9288 - val_accuracy: 0.6534\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 13s 83ms/step - loss: 0.8039 - accuracy: 0.7104 - val_loss: 0.7989 - val_accuracy: 0.7015\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 14s 85ms/step - loss: 0.6573 - accuracy: 0.7678 - val_loss: 0.7618 - val_accuracy: 0.7273\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 13s 84ms/step - loss: 0.5708 - accuracy: 0.7993 - val_loss: 0.7451 - val_accuracy: 0.7383\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 13s 83ms/step - loss: 0.5029 - accuracy: 0.8222 - val_loss: 0.7688 - val_accuracy: 0.7297\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 13s 83ms/step - loss: 0.4556 - accuracy: 0.8414 - val_loss: 0.7830 - val_accuracy: 0.7293\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 13s 84ms/step - loss: 0.4173 - accuracy: 0.8549 - val_loss: 0.8163 - val_accuracy: 0.7273\n",
            "80/80 [==============================] - 1s 16ms/step - loss: 0.8162 - accuracy: 0.7273\n",
            "emb_dim: 32  hidden_dim: 256  drop: 0.2 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 14s 86ms/step - loss: 1.2950 - accuracy: 0.4631 - val_loss: 0.9758 - val_accuracy: 0.6428\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 13s 84ms/step - loss: 0.8287 - accuracy: 0.6987 - val_loss: 0.8002 - val_accuracy: 0.7019\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 0.6894 - accuracy: 0.7548 - val_loss: 0.7683 - val_accuracy: 0.7179\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 13s 82ms/step - loss: 0.6038 - accuracy: 0.7869 - val_loss: 0.7571 - val_accuracy: 0.7285\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 13s 82ms/step - loss: 0.5369 - accuracy: 0.8121 - val_loss: 0.7657 - val_accuracy: 0.7238\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 13s 83ms/step - loss: 0.4919 - accuracy: 0.8303 - val_loss: 0.7673 - val_accuracy: 0.7316\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 13s 83ms/step - loss: 0.4560 - accuracy: 0.8419 - val_loss: 0.7889 - val_accuracy: 0.7324\n",
            "80/80 [==============================] - 1s 15ms/step - loss: 0.7888 - accuracy: 0.7324\n",
            "emb_dim: 32  hidden_dim: 256  drop: 0.3 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 13s 84ms/step - loss: 1.3193 - accuracy: 0.4522 - val_loss: 0.9710 - val_accuracy: 0.6346\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 13s 82ms/step - loss: 0.8585 - accuracy: 0.6854 - val_loss: 0.8090 - val_accuracy: 0.6921\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 13s 82ms/step - loss: 0.7208 - accuracy: 0.7425 - val_loss: 0.7710 - val_accuracy: 0.7195\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 13s 82ms/step - loss: 0.6353 - accuracy: 0.7735 - val_loss: 0.7481 - val_accuracy: 0.7316\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 13s 82ms/step - loss: 0.5737 - accuracy: 0.8004 - val_loss: 0.7632 - val_accuracy: 0.7238\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 13s 82ms/step - loss: 0.5271 - accuracy: 0.8142 - val_loss: 0.7868 - val_accuracy: 0.7250\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 13s 83ms/step - loss: 0.4965 - accuracy: 0.8264 - val_loss: 0.7610 - val_accuracy: 0.7324\n",
            "80/80 [==============================] - 1s 16ms/step - loss: 0.7610 - accuracy: 0.7324\n",
            "emb_dim: 64  hidden_dim: 64  drop: 0 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 3s 22ms/step - loss: 1.2590 - accuracy: 0.5032 - val_loss: 0.9033 - val_accuracy: 0.6596\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.7491 - accuracy: 0.7294 - val_loss: 0.7727 - val_accuracy: 0.7132\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.6032 - accuracy: 0.7870 - val_loss: 0.7561 - val_accuracy: 0.7242\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.5203 - accuracy: 0.8188 - val_loss: 0.7522 - val_accuracy: 0.7367\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.4590 - accuracy: 0.8402 - val_loss: 0.7747 - val_accuracy: 0.7277\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 3s 20ms/step - loss: 0.4102 - accuracy: 0.8613 - val_loss: 0.8105 - val_accuracy: 0.7148\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.3692 - accuracy: 0.8733 - val_loss: 0.8451 - val_accuracy: 0.7199\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.8452 - accuracy: 0.7199\n",
            "emb_dim: 64  hidden_dim: 64  drop: 0.1 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 4s 23ms/step - loss: 1.2810 - accuracy: 0.4926 - val_loss: 0.9223 - val_accuracy: 0.6545\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.7661 - accuracy: 0.7205 - val_loss: 0.7751 - val_accuracy: 0.7101\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.6192 - accuracy: 0.7823 - val_loss: 0.7592 - val_accuracy: 0.7222\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.5381 - accuracy: 0.8116 - val_loss: 0.7508 - val_accuracy: 0.7336\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 3s 22ms/step - loss: 0.4808 - accuracy: 0.8348 - val_loss: 0.7586 - val_accuracy: 0.7351\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 3s 22ms/step - loss: 0.4322 - accuracy: 0.8516 - val_loss: 0.7885 - val_accuracy: 0.7230\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.3899 - accuracy: 0.8672 - val_loss: 0.8174 - val_accuracy: 0.7265\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.8175 - accuracy: 0.7265\n",
            "emb_dim: 64  hidden_dim: 64  drop: 0.2 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 4s 24ms/step - loss: 1.3009 - accuracy: 0.4781 - val_loss: 0.9425 - val_accuracy: 0.6432\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.7891 - accuracy: 0.7118 - val_loss: 0.7830 - val_accuracy: 0.7074\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.6407 - accuracy: 0.7735 - val_loss: 0.7699 - val_accuracy: 0.7167\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.5605 - accuracy: 0.8043 - val_loss: 0.7502 - val_accuracy: 0.7359\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.5051 - accuracy: 0.8229 - val_loss: 0.7530 - val_accuracy: 0.7355\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.4568 - accuracy: 0.8440 - val_loss: 0.7772 - val_accuracy: 0.7261\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.4190 - accuracy: 0.8551 - val_loss: 0.8055 - val_accuracy: 0.7281\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.8055 - accuracy: 0.7281\n",
            "emb_dim: 64  hidden_dim: 64  drop: 0.3 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 4s 23ms/step - loss: 1.3223 - accuracy: 0.4690 - val_loss: 0.9660 - val_accuracy: 0.6389\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.8171 - accuracy: 0.7002 - val_loss: 0.7951 - val_accuracy: 0.6991\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.6649 - accuracy: 0.7652 - val_loss: 0.7761 - val_accuracy: 0.7136\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.5841 - accuracy: 0.7982 - val_loss: 0.7496 - val_accuracy: 0.7328\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.5328 - accuracy: 0.8147 - val_loss: 0.7487 - val_accuracy: 0.7351\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.4895 - accuracy: 0.8303 - val_loss: 0.7640 - val_accuracy: 0.7289\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 3s 21ms/step - loss: 0.4514 - accuracy: 0.8466 - val_loss: 0.7854 - val_accuracy: 0.7332\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.7854 - accuracy: 0.7332\n",
            "emb_dim: 64  hidden_dim: 128  drop: 0 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 6s 40ms/step - loss: 1.1940 - accuracy: 0.5276 - val_loss: 0.8624 - val_accuracy: 0.6831\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 6s 38ms/step - loss: 0.7290 - accuracy: 0.7396 - val_loss: 0.7678 - val_accuracy: 0.7218\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 6s 39ms/step - loss: 0.5980 - accuracy: 0.7896 - val_loss: 0.7560 - val_accuracy: 0.7257\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 6s 38ms/step - loss: 0.5164 - accuracy: 0.8205 - val_loss: 0.7495 - val_accuracy: 0.7351\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 6s 38ms/step - loss: 0.4521 - accuracy: 0.8423 - val_loss: 0.7761 - val_accuracy: 0.7273\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 6s 39ms/step - loss: 0.4016 - accuracy: 0.8629 - val_loss: 0.8059 - val_accuracy: 0.7187\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 6s 40ms/step - loss: 0.3569 - accuracy: 0.8776 - val_loss: 0.8377 - val_accuracy: 0.7183\n",
            "80/80 [==============================] - 0s 6ms/step - loss: 0.8377 - accuracy: 0.7183\n",
            "emb_dim: 64  hidden_dim: 128  drop: 0.1 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 7s 42ms/step - loss: 1.2116 - accuracy: 0.5197 - val_loss: 0.8712 - val_accuracy: 0.6811\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 6s 39ms/step - loss: 0.7479 - accuracy: 0.7348 - val_loss: 0.7730 - val_accuracy: 0.7242\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 6s 39ms/step - loss: 0.6150 - accuracy: 0.7817 - val_loss: 0.7526 - val_accuracy: 0.7261\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 6s 39ms/step - loss: 0.5322 - accuracy: 0.8145 - val_loss: 0.7427 - val_accuracy: 0.7367\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 6s 39ms/step - loss: 0.4713 - accuracy: 0.8345 - val_loss: 0.7652 - val_accuracy: 0.7304\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 6s 40ms/step - loss: 0.4214 - accuracy: 0.8587 - val_loss: 0.7871 - val_accuracy: 0.7250\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 6s 39ms/step - loss: 0.3796 - accuracy: 0.8696 - val_loss: 0.8110 - val_accuracy: 0.7234\n",
            "80/80 [==============================] - 0s 6ms/step - loss: 0.8110 - accuracy: 0.7234\n",
            "emb_dim: 64  hidden_dim: 128  drop: 0.2 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 7s 42ms/step - loss: 1.2287 - accuracy: 0.5116 - val_loss: 0.8823 - val_accuracy: 0.6753\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 7s 41ms/step - loss: 0.7650 - accuracy: 0.7257 - val_loss: 0.7782 - val_accuracy: 0.7230\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 6s 40ms/step - loss: 0.6329 - accuracy: 0.7753 - val_loss: 0.7503 - val_accuracy: 0.7293\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 7s 41ms/step - loss: 0.5524 - accuracy: 0.8064 - val_loss: 0.7362 - val_accuracy: 0.7355\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 7s 41ms/step - loss: 0.4940 - accuracy: 0.8252 - val_loss: 0.7548 - val_accuracy: 0.7281\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 6s 40ms/step - loss: 0.4454 - accuracy: 0.8474 - val_loss: 0.7676 - val_accuracy: 0.7308\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 6s 40ms/step - loss: 0.4074 - accuracy: 0.8579 - val_loss: 0.7904 - val_accuracy: 0.7340\n",
            "80/80 [==============================] - 0s 6ms/step - loss: 0.7904 - accuracy: 0.7340\n",
            "emb_dim: 64  hidden_dim: 128  drop: 0.3 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 7s 43ms/step - loss: 1.2489 - accuracy: 0.5037 - val_loss: 0.8974 - val_accuracy: 0.6667\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 6s 40ms/step - loss: 0.7881 - accuracy: 0.7152 - val_loss: 0.7893 - val_accuracy: 0.7171\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 6s 40ms/step - loss: 0.6573 - accuracy: 0.7664 - val_loss: 0.7586 - val_accuracy: 0.7254\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 6s 40ms/step - loss: 0.5768 - accuracy: 0.7946 - val_loss: 0.7343 - val_accuracy: 0.7336\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 6s 41ms/step - loss: 0.5168 - accuracy: 0.8170 - val_loss: 0.7523 - val_accuracy: 0.7304\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 6s 40ms/step - loss: 0.4757 - accuracy: 0.8366 - val_loss: 0.7539 - val_accuracy: 0.7390\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 6s 40ms/step - loss: 0.4406 - accuracy: 0.8475 - val_loss: 0.7711 - val_accuracy: 0.7359\n",
            "80/80 [==============================] - 0s 6ms/step - loss: 0.7711 - accuracy: 0.7359\n",
            "emb_dim: 64  hidden_dim: 256  drop: 0 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 1.1686 - accuracy: 0.5393 - val_loss: 0.8547 - val_accuracy: 0.6819\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 14s 89ms/step - loss: 0.7267 - accuracy: 0.7420 - val_loss: 0.7639 - val_accuracy: 0.7222\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 14s 90ms/step - loss: 0.5901 - accuracy: 0.7953 - val_loss: 0.7536 - val_accuracy: 0.7300\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 14s 89ms/step - loss: 0.5078 - accuracy: 0.8210 - val_loss: 0.7514 - val_accuracy: 0.7371\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 0.4425 - accuracy: 0.8436 - val_loss: 0.7795 - val_accuracy: 0.7328\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 14s 90ms/step - loss: 0.3914 - accuracy: 0.8639 - val_loss: 0.8179 - val_accuracy: 0.7297\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 15s 91ms/step - loss: 0.3471 - accuracy: 0.8802 - val_loss: 0.8574 - val_accuracy: 0.7304\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.8573 - accuracy: 0.7304\n",
            "emb_dim: 64  hidden_dim: 256  drop: 0.1 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 15s 91ms/step - loss: 1.1819 - accuracy: 0.5305 - val_loss: 0.8626 - val_accuracy: 0.6776\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 14s 89ms/step - loss: 0.7441 - accuracy: 0.7334 - val_loss: 0.7680 - val_accuracy: 0.7218\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 14s 90ms/step - loss: 0.6076 - accuracy: 0.7875 - val_loss: 0.7563 - val_accuracy: 0.7257\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 14s 89ms/step - loss: 0.5247 - accuracy: 0.8149 - val_loss: 0.7457 - val_accuracy: 0.7418\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 14s 89ms/step - loss: 0.4623 - accuracy: 0.8389 - val_loss: 0.7738 - val_accuracy: 0.7308\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 14s 90ms/step - loss: 0.4152 - accuracy: 0.8552 - val_loss: 0.8051 - val_accuracy: 0.7336\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 15s 91ms/step - loss: 0.3731 - accuracy: 0.8688 - val_loss: 0.8300 - val_accuracy: 0.7320\n",
            "80/80 [==============================] - 1s 16ms/step - loss: 0.8300 - accuracy: 0.7320\n",
            "emb_dim: 64  hidden_dim: 256  drop: 0.2 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 15s 94ms/step - loss: 1.2043 - accuracy: 0.5201 - val_loss: 0.8704 - val_accuracy: 0.6768\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 14s 90ms/step - loss: 0.7619 - accuracy: 0.7248 - val_loss: 0.7794 - val_accuracy: 0.7148\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 14s 90ms/step - loss: 0.6269 - accuracy: 0.7807 - val_loss: 0.7542 - val_accuracy: 0.7238\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 15s 91ms/step - loss: 0.5477 - accuracy: 0.8065 - val_loss: 0.7387 - val_accuracy: 0.7402\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 14s 90ms/step - loss: 0.4866 - accuracy: 0.8317 - val_loss: 0.7615 - val_accuracy: 0.7304\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 14s 90ms/step - loss: 0.4406 - accuracy: 0.8437 - val_loss: 0.7877 - val_accuracy: 0.7277\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 0.4023 - accuracy: 0.8584 - val_loss: 0.8044 - val_accuracy: 0.7371\n",
            "80/80 [==============================] - 1s 17ms/step - loss: 0.8044 - accuracy: 0.7371\n",
            "emb_dim: 64  hidden_dim: 256  drop: 0.3 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 15s 94ms/step - loss: 1.2254 - accuracy: 0.5074 - val_loss: 0.8836 - val_accuracy: 0.6792\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 14s 90ms/step - loss: 0.7800 - accuracy: 0.7201 - val_loss: 0.7859 - val_accuracy: 0.7121\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 14s 91ms/step - loss: 0.6465 - accuracy: 0.7734 - val_loss: 0.7551 - val_accuracy: 0.7246\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 14s 91ms/step - loss: 0.5676 - accuracy: 0.7974 - val_loss: 0.7367 - val_accuracy: 0.7390\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 14s 90ms/step - loss: 0.5080 - accuracy: 0.8225 - val_loss: 0.7536 - val_accuracy: 0.7398\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 15s 91ms/step - loss: 0.4684 - accuracy: 0.8362 - val_loss: 0.7601 - val_accuracy: 0.7359\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 0.4316 - accuracy: 0.8499 - val_loss: 0.7820 - val_accuracy: 0.7398\n",
            "80/80 [==============================] - 1s 16ms/step - loss: 0.7820 - accuracy: 0.7398\n",
            "emb_dim: 128  hidden_dim: 64  drop: 0 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 1.1642 - accuracy: 0.5550 - val_loss: 0.8388 - val_accuracy: 0.6800\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 4s 26ms/step - loss: 0.6829 - accuracy: 0.7561 - val_loss: 0.7422 - val_accuracy: 0.7285\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 4s 26ms/step - loss: 0.5480 - accuracy: 0.8067 - val_loss: 0.7570 - val_accuracy: 0.7308\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 4s 26ms/step - loss: 0.4641 - accuracy: 0.8373 - val_loss: 0.7463 - val_accuracy: 0.7367\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 4s 26ms/step - loss: 0.4023 - accuracy: 0.8612 - val_loss: 0.7928 - val_accuracy: 0.7269\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 4s 25ms/step - loss: 0.3507 - accuracy: 0.8807 - val_loss: 0.8393 - val_accuracy: 0.7132\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 4s 26ms/step - loss: 0.3088 - accuracy: 0.8944 - val_loss: 0.8653 - val_accuracy: 0.7136\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.8652 - accuracy: 0.7136\n",
            "emb_dim: 128  hidden_dim: 64  drop: 0.1 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 5s 31ms/step - loss: 1.1860 - accuracy: 0.5465 - val_loss: 0.8514 - val_accuracy: 0.6757\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 5s 33ms/step - loss: 0.7000 - accuracy: 0.7488 - val_loss: 0.7438 - val_accuracy: 0.7261\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 5s 30ms/step - loss: 0.5640 - accuracy: 0.8014 - val_loss: 0.7576 - val_accuracy: 0.7304\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 5s 29ms/step - loss: 0.4818 - accuracy: 0.8305 - val_loss: 0.7430 - val_accuracy: 0.7387\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.4221 - accuracy: 0.8541 - val_loss: 0.7798 - val_accuracy: 0.7300\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.3719 - accuracy: 0.8739 - val_loss: 0.8203 - val_accuracy: 0.7195\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.3300 - accuracy: 0.8866 - val_loss: 0.8463 - val_accuracy: 0.7183\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.8461 - accuracy: 0.7183\n",
            "emb_dim: 128  hidden_dim: 64  drop: 0.2 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 5s 31ms/step - loss: 1.2091 - accuracy: 0.5377 - val_loss: 0.8672 - val_accuracy: 0.6706\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.7179 - accuracy: 0.7433 - val_loss: 0.7512 - val_accuracy: 0.7214\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 5s 30ms/step - loss: 0.5819 - accuracy: 0.7948 - val_loss: 0.7629 - val_accuracy: 0.7308\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.5033 - accuracy: 0.8263 - val_loss: 0.7411 - val_accuracy: 0.7390\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.4456 - accuracy: 0.8443 - val_loss: 0.7710 - val_accuracy: 0.7297\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.3954 - accuracy: 0.8639 - val_loss: 0.8035 - val_accuracy: 0.7210\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.3578 - accuracy: 0.8753 - val_loss: 0.8237 - val_accuracy: 0.7195\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.8236 - accuracy: 0.7195\n",
            "emb_dim: 128  hidden_dim: 64  drop: 0.3 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 5s 30ms/step - loss: 1.2315 - accuracy: 0.5252 - val_loss: 0.8827 - val_accuracy: 0.6608\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.7406 - accuracy: 0.7338 - val_loss: 0.7576 - val_accuracy: 0.7199\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 4s 27ms/step - loss: 0.6046 - accuracy: 0.7871 - val_loss: 0.7658 - val_accuracy: 0.7265\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.5261 - accuracy: 0.8184 - val_loss: 0.7389 - val_accuracy: 0.7375\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.4698 - accuracy: 0.8367 - val_loss: 0.7616 - val_accuracy: 0.7344\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 5s 29ms/step - loss: 0.4223 - accuracy: 0.8519 - val_loss: 0.7899 - val_accuracy: 0.7257\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 0.3860 - accuracy: 0.8647 - val_loss: 0.7998 - val_accuracy: 0.7242\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.7997 - accuracy: 0.7242\n",
            "emb_dim: 128  hidden_dim: 128  drop: 0 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 1.1122 - accuracy: 0.5725 - val_loss: 0.8132 - val_accuracy: 0.7046\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.6734 - accuracy: 0.7630 - val_loss: 0.7353 - val_accuracy: 0.7328\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.5415 - accuracy: 0.8111 - val_loss: 0.7446 - val_accuracy: 0.7367\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 0.4570 - accuracy: 0.8400 - val_loss: 0.7492 - val_accuracy: 0.7387\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.3960 - accuracy: 0.8625 - val_loss: 0.8058 - val_accuracy: 0.7269\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.3457 - accuracy: 0.8784 - val_loss: 0.8340 - val_accuracy: 0.7238\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.3033 - accuracy: 0.8946 - val_loss: 0.8765 - val_accuracy: 0.7152\n",
            "80/80 [==============================] - 1s 6ms/step - loss: 0.8765 - accuracy: 0.7152\n",
            "emb_dim: 128  hidden_dim: 128  drop: 0.1 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 9s 55ms/step - loss: 1.1289 - accuracy: 0.5634 - val_loss: 0.8287 - val_accuracy: 0.7038\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.6899 - accuracy: 0.7544 - val_loss: 0.7389 - val_accuracy: 0.7328\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.5596 - accuracy: 0.8048 - val_loss: 0.7420 - val_accuracy: 0.7398\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.4765 - accuracy: 0.8340 - val_loss: 0.7421 - val_accuracy: 0.7422\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.4151 - accuracy: 0.8548 - val_loss: 0.7907 - val_accuracy: 0.7328\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 9s 54ms/step - loss: 0.3675 - accuracy: 0.8714 - val_loss: 0.8130 - val_accuracy: 0.7238\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.3255 - accuracy: 0.8856 - val_loss: 0.8435 - val_accuracy: 0.7257\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.8434 - accuracy: 0.7257\n",
            "emb_dim: 128  hidden_dim: 128  drop: 0.2 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 1.1452 - accuracy: 0.5563 - val_loss: 0.8419 - val_accuracy: 0.7027\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.7031 - accuracy: 0.7501 - val_loss: 0.7439 - val_accuracy: 0.7285\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.5744 - accuracy: 0.7990 - val_loss: 0.7440 - val_accuracy: 0.7398\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.4943 - accuracy: 0.8265 - val_loss: 0.7394 - val_accuracy: 0.7410\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.4371 - accuracy: 0.8456 - val_loss: 0.7801 - val_accuracy: 0.7308\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.3899 - accuracy: 0.8643 - val_loss: 0.7956 - val_accuracy: 0.7277\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.3524 - accuracy: 0.8753 - val_loss: 0.8275 - val_accuracy: 0.7308\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.8274 - accuracy: 0.7308\n",
            "emb_dim: 128  hidden_dim: 128  drop: 0.3 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 9s 55ms/step - loss: 1.1648 - accuracy: 0.5460 - val_loss: 0.8545 - val_accuracy: 0.6937\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.7220 - accuracy: 0.7427 - val_loss: 0.7487 - val_accuracy: 0.7285\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.5971 - accuracy: 0.7905 - val_loss: 0.7539 - val_accuracy: 0.7316\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.5213 - accuracy: 0.8175 - val_loss: 0.7371 - val_accuracy: 0.7410\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.4641 - accuracy: 0.8352 - val_loss: 0.7671 - val_accuracy: 0.7371\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.4192 - accuracy: 0.8523 - val_loss: 0.7771 - val_accuracy: 0.7355\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.3820 - accuracy: 0.8665 - val_loss: 0.7961 - val_accuracy: 0.7340\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.7960 - accuracy: 0.7340\n",
            "emb_dim: 128  hidden_dim: 256  drop: 0 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 17s 104ms/step - loss: 1.1422 - accuracy: 0.5721 - val_loss: 0.8421 - val_accuracy: 0.6768\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 16s 102ms/step - loss: 0.6991 - accuracy: 0.7538 - val_loss: 0.7472 - val_accuracy: 0.7336\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 16s 102ms/step - loss: 0.5643 - accuracy: 0.8027 - val_loss: 0.7473 - val_accuracy: 0.7375\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 16s 100ms/step - loss: 0.4765 - accuracy: 0.8343 - val_loss: 0.7452 - val_accuracy: 0.7449\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 16s 100ms/step - loss: 0.4099 - accuracy: 0.8559 - val_loss: 0.7948 - val_accuracy: 0.7293\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 16s 101ms/step - loss: 0.3541 - accuracy: 0.8767 - val_loss: 0.8241 - val_accuracy: 0.7261\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 17s 104ms/step - loss: 0.3031 - accuracy: 0.8947 - val_loss: 0.8871 - val_accuracy: 0.7203\n",
            "80/80 [==============================] - 2s 19ms/step - loss: 0.8870 - accuracy: 0.7203\n",
            "emb_dim: 128  hidden_dim: 256  drop: 0.1 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 17s 104ms/step - loss: 1.1242 - accuracy: 0.5647 - val_loss: 0.8242 - val_accuracy: 0.6874\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 16s 100ms/step - loss: 0.7049 - accuracy: 0.7478 - val_loss: 0.7443 - val_accuracy: 0.7336\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 16s 102ms/step - loss: 0.5731 - accuracy: 0.8015 - val_loss: 0.7462 - val_accuracy: 0.7379\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 16s 101ms/step - loss: 0.4885 - accuracy: 0.8298 - val_loss: 0.7436 - val_accuracy: 0.7441\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 17s 109ms/step - loss: 0.4239 - accuracy: 0.8501 - val_loss: 0.7860 - val_accuracy: 0.7312\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 16s 102ms/step - loss: 0.3702 - accuracy: 0.8719 - val_loss: 0.8176 - val_accuracy: 0.7304\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 16s 101ms/step - loss: 0.3229 - accuracy: 0.8882 - val_loss: 0.8610 - val_accuracy: 0.7257\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.8609 - accuracy: 0.7257\n",
            "emb_dim: 128  hidden_dim: 256  drop: 0.2 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 17s 105ms/step - loss: 1.1281 - accuracy: 0.5644 - val_loss: 0.8403 - val_accuracy: 0.6862\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 16s 103ms/step - loss: 0.7170 - accuracy: 0.7456 - val_loss: 0.7498 - val_accuracy: 0.7281\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 17s 104ms/step - loss: 0.5866 - accuracy: 0.7955 - val_loss: 0.7528 - val_accuracy: 0.7355\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 17s 104ms/step - loss: 0.5048 - accuracy: 0.8248 - val_loss: 0.7415 - val_accuracy: 0.7445\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 16s 103ms/step - loss: 0.4442 - accuracy: 0.8411 - val_loss: 0.7750 - val_accuracy: 0.7340\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 17s 103ms/step - loss: 0.3911 - accuracy: 0.8658 - val_loss: 0.7984 - val_accuracy: 0.7300\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 17s 104ms/step - loss: 0.3477 - accuracy: 0.8781 - val_loss: 0.8341 - val_accuracy: 0.7324\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.8339 - accuracy: 0.7324\n",
            "emb_dim: 128  hidden_dim: 256  drop: 0.3 ----RMSprop\n",
            "Epoch 1/7\n",
            "160/160 [==============================] - 17s 107ms/step - loss: 1.1402 - accuracy: 0.5562 - val_loss: 0.8320 - val_accuracy: 0.6815\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 17s 103ms/step - loss: 0.7347 - accuracy: 0.7366 - val_loss: 0.7519 - val_accuracy: 0.7210\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 16s 103ms/step - loss: 0.6058 - accuracy: 0.7881 - val_loss: 0.7487 - val_accuracy: 0.7355\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 17s 104ms/step - loss: 0.5297 - accuracy: 0.8127 - val_loss: 0.7372 - val_accuracy: 0.7449\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 17s 103ms/step - loss: 0.4680 - accuracy: 0.8318 - val_loss: 0.7600 - val_accuracy: 0.7367\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 16s 102ms/step - loss: 0.4218 - accuracy: 0.8524 - val_loss: 0.7837 - val_accuracy: 0.7367\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 17s 103ms/step - loss: 0.3782 - accuracy: 0.8683 - val_loss: 0.8126 - val_accuracy: 0.7308\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 0.8125 - accuracy: 0.7308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG1BIwzVnBTt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "6a25f5a2-70e1-4401-b97a-8202136f10ef"
      },
      "source": [
        "# best simple GRU, no GloVe\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len + 1, output_dim=128, name=\"Embedding\"))  \n",
        "model.add(GRU(256, dropout=0.3, name=\"GRU\")) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=4) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "160/160 [==============================] - 17s 104ms/step - loss: 1.1402 - accuracy: 0.5562 - val_loss: 0.8320 - val_accuracy: 0.6815\n",
            "Epoch 2/4\n",
            "160/160 [==============================] - 17s 103ms/step - loss: 0.7347 - accuracy: 0.7366 - val_loss: 0.7519 - val_accuracy: 0.7210\n",
            "Epoch 3/4\n",
            "160/160 [==============================] - 16s 103ms/step - loss: 0.6058 - accuracy: 0.7881 - val_loss: 0.7487 - val_accuracy: 0.7355\n",
            "Epoch 4/4\n",
            "160/160 [==============================] - 16s 103ms/step - loss: 0.5297 - accuracy: 0.8127 - val_loss: 0.7372 - val_accuracy: 0.7449\n",
            "80/80 [==============================] - 1s 19ms/step - loss: 0.7370 - accuracy: 0.7449\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7370414137840271, 0.7449139356613159]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AI9EGOix0-wp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "2dbe48cb-f64f-4da9-a54a-4c338713e956"
      },
      "source": [
        "# GRU(256)\n",
        "Y_test_pred = model.predict_classes(X_test)\n",
        "Y_test_df = pd.DataFrame(Y_test)\n",
        "Y_test_categ = Y_test_df.idxmax(axis=1)\n",
        "confusion_matrix(Y_test_categ,Y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[403,  91,  58,  14,  22],\n",
              "       [ 77, 459,  25,  22,   5],\n",
              "       [ 56,  26, 400,  38,  40],\n",
              "       [ 13,  29,  44, 402,  14],\n",
              "       [ 33,   2,  32,  11, 240]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YOXbsb_q1QVF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "c7ad16c3-a478-4fcf-f6f9-35444c7c3a39"
      },
      "source": [
        "# LSTM-128 RMSprop\n",
        "Y_test_pred = model2.predict_classes(X_test)\n",
        "Y_test_df = pd.DataFrame(Y_test)\n",
        "Y_test_categ = Y_test_df.idxmax(axis=1)\n",
        "confusion_matrix(Y_test_categ,Y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[374, 104,  67,  18,  25],\n",
              "       [ 70, 466,  20,  27,   5],\n",
              "       [ 47,  25, 405,  42,  41],\n",
              "       [  9,  28,  40, 410,  15],\n",
              "       [ 25,   1,  34,  11, 247]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsJAeGR2b_T2",
        "colab_type": "text"
      },
      "source": [
        "## Models with and without GloVe\n",
        "\n",
        "Overall, accuracy with GloVe is smaller than without keeping everything else constant (and allowing GloVe embeddings to train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkNtcy-2OgI1",
        "colab_type": "text"
      },
      "source": [
        "#### Getting GloVe data and matching it to our text.\n",
        "\n",
        "Due to technical difficulties, the file was uploaded manually from the local computer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJzWG2tIg71k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "bad05d10-d0ce-4f8b-c0e4-ab6e3b37c2b6"
      },
      "source": [
        "# From https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html \n",
        "embeddings_index = {}\n",
        "f = open('glove.6B.100d.txt')\n",
        "# f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 65\n",
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgM5bakyd4Mw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "outputId": "5f6cd9d0-b372-4a36-a769-94999466b47c"
      },
      "source": [
        "# Filter GloVE vectors to specific task \n",
        "def filter_glove(vocabulary_dict, glove_dict, wordvec_dim=100): \n",
        "  # Create a matrix to store the vectors \n",
        "  # 0 in vocabulary is reserved for padding    \n",
        "  embedding_matrix = np.zeros((len(vocabulary_dict) + 1, wordvec_dim)) \n",
        "  for word, i in vocabulary_dict.items():\n",
        "    embedding_vector = glove_dict.get(word) \n",
        "    if embedding_vector is not None:             \n",
        "      # words not found in the glove_dict will be all-zeros.             \n",
        "      embedding_matrix[i] = embedding_vector\n",
        "\n",
        "  return embedding_matrix\n",
        "\n",
        "emb_mat = filter_glove(vocabulary_dict=word_index, glove_dict=embeddings_index)\n",
        "print(emb_mat[:10])\n",
        "plt.plot(emb_mat.sum(axis=1))\n",
        "plt.show()\n",
        "plt.hist(emb_mat.sum(axis=1))\n",
        "plt.show()\n",
        "(emb_mat.sum(axis=1)==0).sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD7CAYAAACPDORaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngiAIPkaEvCAIgo8RIS8IguBj/h9p0QyB72KIUQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGQSS1DmDQJI69/8B/PYmSJyiL5AAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1432"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcRYW3dnPglW",
        "colab_type": "text"
      },
      "source": [
        "#### Multi-layer models\n",
        "\n",
        "With GloVe, somewhat better, but does not beat simple models above.\n",
        "\n",
        "Smaller (64 everywhere, 4 epochs) - 0.7269\n",
        "\n",
        "Larger (128 everywhere, 4 epochs) - 0.7300\n",
        "\n",
        "With Glove, smaller (64 everywhere, 9 epochs) - 0.7363\n",
        "\n",
        "With Glove, larger (128 everywhere, 11 epochs) - 0.7320 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihNpZP_nY2S0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "59f1c5c0-ef6f-400a-aecd-9f8b503dd1e1"
      },
      "source": [
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len + 1, output_dim=128)) \n",
        "model.add(Dense(128, activation='relu', name=\"Dense1\")) \n",
        "model.add(Dropout(rate=0.25)) \n",
        "model.add(LSTM(64, return_sequences=True, dropout=0.15, name=\"LSTM\")) \n",
        "model.add(GRU(64, return_sequences=False, dropout=0.15, name=\"GRU\")) \n",
        "model.add(Dense(64, name=\"Dense2\")) \n",
        "model.add(Dropout(rate=0.25)) \n",
        "model.add(Dense(32, name=\"Dense3\")) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=10) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "160/160 [==============================] - 9s 57ms/step - loss: 1.2399 - accuracy: 0.4771 - val_loss: 0.9397 - val_accuracy: 0.6416\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 9s 53ms/step - loss: 0.7857 - accuracy: 0.7154 - val_loss: 0.7758 - val_accuracy: 0.7250\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.6039 - accuracy: 0.7896 - val_loss: 0.7769 - val_accuracy: 0.7218\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.5088 - accuracy: 0.8217 - val_loss: 0.7927 - val_accuracy: 0.7269\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.4314 - accuracy: 0.8519 - val_loss: 0.8006 - val_accuracy: 0.7230\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.3755 - accuracy: 0.8725 - val_loss: 0.8606 - val_accuracy: 0.7136\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.3348 - accuracy: 0.8850 - val_loss: 0.9206 - val_accuracy: 0.7097\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.2981 - accuracy: 0.8965 - val_loss: 1.0497 - val_accuracy: 0.6984\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.2664 - accuracy: 0.9084 - val_loss: 1.0032 - val_accuracy: 0.7062\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.2520 - accuracy: 0.9172 - val_loss: 1.0635 - val_accuracy: 0.6933\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.0634 - accuracy: 0.6933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0634212493896484, 0.693270742893219]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_anCEnB_bmMw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "4b095e31-f9bf-4f25-cbdb-33f8541ae7d2"
      },
      "source": [
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len + 1, output_dim=128)) \n",
        "model.add(Dense(128, activation='relu', name=\"Dense1\")) \n",
        "model.add(Dropout(rate=0.25)) \n",
        "model.add(LSTM(128, return_sequences=True, dropout=0.15, name=\"LSTM\")) \n",
        "model.add(GRU(128, return_sequences=False, dropout=0.15, name=\"GRU\")) \n",
        "model.add(Dense(64, name=\"Dense2\")) \n",
        "model.add(Dropout(rate=0.25)) \n",
        "model.add(Dense(32, name=\"Dense3\")) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=10) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "160/160 [==============================] - 18s 112ms/step - loss: 1.1814 - accuracy: 0.5187 - val_loss: 0.8764 - val_accuracy: 0.6909\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 17s 109ms/step - loss: 0.7437 - accuracy: 0.7366 - val_loss: 0.7643 - val_accuracy: 0.7187\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 17s 109ms/step - loss: 0.5937 - accuracy: 0.7962 - val_loss: 0.7642 - val_accuracy: 0.7210\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 17s 107ms/step - loss: 0.5015 - accuracy: 0.8265 - val_loss: 0.8001 - val_accuracy: 0.7300\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 18s 110ms/step - loss: 0.4300 - accuracy: 0.8500 - val_loss: 0.8042 - val_accuracy: 0.7261\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 17s 108ms/step - loss: 0.3736 - accuracy: 0.8682 - val_loss: 0.8351 - val_accuracy: 0.7210\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 18s 110ms/step - loss: 0.3293 - accuracy: 0.8858 - val_loss: 0.9160 - val_accuracy: 0.7164\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 18s 110ms/step - loss: 0.3004 - accuracy: 0.8991 - val_loss: 1.0306 - val_accuracy: 0.6980\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 17s 109ms/step - loss: 0.2675 - accuracy: 0.9112 - val_loss: 1.0087 - val_accuracy: 0.7031\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 18s 109ms/step - loss: 0.2465 - accuracy: 0.9186 - val_loss: 1.0573 - val_accuracy: 0.6894\n",
            "80/80 [==============================] - 1s 14ms/step - loss: 1.0571 - accuracy: 0.6894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.057132601737976, 0.6893583536148071]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89NxM_chbSTq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "c7729f0d-07f1-4539-8a2d-126a5479f693"
      },
      "source": [
        "# from DataCamp example, using pre-trained gloVe embeddings\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len + 1, output_dim=100, trainable=True,                       \n",
        "                    embeddings_initializer=Constant(emb_mat),                       \n",
        "                    input_length=20, name=\"Embedding\"))  \n",
        "model.add(Dense(128, activation='relu', name=\"Dense1\")) \n",
        "model.add(Dropout(rate=0.25)) \n",
        "model.add(LSTM(64, return_sequences=True, dropout=0.15, name=\"LSTM\")) \n",
        "model.add(GRU(64, return_sequences=False, dropout=0.15, name=\"GRU\")) \n",
        "model.add(Dense(64, name=\"Dense2\")) \n",
        "model.add(Dropout(rate=0.25)) \n",
        "model.add(Dense(32, name=\"Dense3\")) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=20) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 1.2301 - accuracy: 0.4977 - val_loss: 0.9351 - val_accuracy: 0.6408\n",
            "Epoch 2/20\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.9486 - accuracy: 0.6433 - val_loss: 0.8585 - val_accuracy: 0.6729\n",
            "Epoch 3/20\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.8423 - accuracy: 0.6876 - val_loss: 0.7844 - val_accuracy: 0.7074\n",
            "Epoch 4/20\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.7644 - accuracy: 0.7189 - val_loss: 0.7624 - val_accuracy: 0.7160\n",
            "Epoch 5/20\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 0.7044 - accuracy: 0.7452 - val_loss: 0.7536 - val_accuracy: 0.7113\n",
            "Epoch 6/20\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 0.6542 - accuracy: 0.7622 - val_loss: 0.7394 - val_accuracy: 0.7289\n",
            "Epoch 7/20\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.6081 - accuracy: 0.7829 - val_loss: 0.7714 - val_accuracy: 0.7214\n",
            "Epoch 8/20\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 0.5773 - accuracy: 0.7936 - val_loss: 0.7494 - val_accuracy: 0.7300\n",
            "Epoch 9/20\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.5433 - accuracy: 0.8074 - val_loss: 0.7338 - val_accuracy: 0.7363\n",
            "Epoch 10/20\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.5093 - accuracy: 0.8193 - val_loss: 0.7571 - val_accuracy: 0.7289\n",
            "Epoch 11/20\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.4769 - accuracy: 0.8278 - val_loss: 0.7562 - val_accuracy: 0.7355\n",
            "Epoch 12/20\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.4415 - accuracy: 0.8436 - val_loss: 0.8507 - val_accuracy: 0.7175\n",
            "Epoch 13/20\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.4249 - accuracy: 0.8496 - val_loss: 0.8198 - val_accuracy: 0.7285\n",
            "Epoch 14/20\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.3906 - accuracy: 0.8616 - val_loss: 0.8705 - val_accuracy: 0.7269\n",
            "Epoch 15/20\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.3677 - accuracy: 0.8716 - val_loss: 0.8710 - val_accuracy: 0.7242\n",
            "Epoch 16/20\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.3494 - accuracy: 0.8784 - val_loss: 0.8978 - val_accuracy: 0.7164\n",
            "Epoch 17/20\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.3313 - accuracy: 0.8853 - val_loss: 0.8746 - val_accuracy: 0.7234\n",
            "Epoch 18/20\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 0.3114 - accuracy: 0.8903 - val_loss: 0.9238 - val_accuracy: 0.7191\n",
            "Epoch 19/20\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 0.2891 - accuracy: 0.9004 - val_loss: 0.9649 - val_accuracy: 0.7148\n",
            "Epoch 20/20\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.2784 - accuracy: 0.9016 - val_loss: 0.9917 - val_accuracy: 0.7140\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.9913 - accuracy: 0.7140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9912737607955933, 0.714006245136261]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM2xBwVr41tG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "b1c61b76-6553-420a-bffb-6144aeb7f4d0"
      },
      "source": [
        "# from DataCamp example, using pre-trained gloVe embeddings\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len + 1, output_dim=100, trainable=True,                       \n",
        "                    embeddings_initializer=Constant(emb_mat),                       \n",
        "                    input_length=20, name=\"Embedding\"))  \n",
        "model.add(Dense(128, activation='relu', name=\"Dense1\")) \n",
        "model.add(Dropout(rate=0.25)) \n",
        "model.add(LSTM(128, return_sequences=True, dropout=0.15, name=\"LSTM\")) \n",
        "model.add(GRU(128, return_sequences=False, dropout=0.15, name=\"GRU\")) \n",
        "model.add(Dense(128, name=\"Dense2\")) \n",
        "model.add(Dropout(rate=0.25)) \n",
        "model.add(Dense(32, name=\"Dense3\")) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=20) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "160/160 [==============================] - 17s 107ms/step - loss: 1.2195 - accuracy: 0.5045 - val_loss: 0.9517 - val_accuracy: 0.6405\n",
            "Epoch 2/20\n",
            "160/160 [==============================] - 16s 99ms/step - loss: 0.9421 - accuracy: 0.6448 - val_loss: 0.8833 - val_accuracy: 0.6604\n",
            "Epoch 3/20\n",
            "160/160 [==============================] - 15s 96ms/step - loss: 0.8357 - accuracy: 0.6953 - val_loss: 0.7923 - val_accuracy: 0.7031\n",
            "Epoch 4/20\n",
            "160/160 [==============================] - 16s 97ms/step - loss: 0.7544 - accuracy: 0.7211 - val_loss: 0.7680 - val_accuracy: 0.7113\n",
            "Epoch 5/20\n",
            "160/160 [==============================] - 15s 96ms/step - loss: 0.6988 - accuracy: 0.7422 - val_loss: 0.7669 - val_accuracy: 0.7128\n",
            "Epoch 6/20\n",
            "160/160 [==============================] - 15s 96ms/step - loss: 0.6478 - accuracy: 0.7670 - val_loss: 0.7463 - val_accuracy: 0.7293\n",
            "Epoch 7/20\n",
            "160/160 [==============================] - 15s 96ms/step - loss: 0.6013 - accuracy: 0.7810 - val_loss: 0.8149 - val_accuracy: 0.7007\n",
            "Epoch 8/20\n",
            "160/160 [==============================] - 15s 94ms/step - loss: 0.5657 - accuracy: 0.7956 - val_loss: 0.7873 - val_accuracy: 0.7230\n",
            "Epoch 9/20\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 0.5320 - accuracy: 0.8108 - val_loss: 0.7638 - val_accuracy: 0.7265\n",
            "Epoch 10/20\n",
            "160/160 [==============================] - 15s 94ms/step - loss: 0.4943 - accuracy: 0.8231 - val_loss: 0.7639 - val_accuracy: 0.7293\n",
            "Epoch 11/20\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 0.4632 - accuracy: 0.8362 - val_loss: 0.7986 - val_accuracy: 0.7320\n",
            "Epoch 12/20\n",
            "160/160 [==============================] - 15s 93ms/step - loss: 0.4321 - accuracy: 0.8428 - val_loss: 0.8935 - val_accuracy: 0.7054\n",
            "Epoch 13/20\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 0.3983 - accuracy: 0.8585 - val_loss: 0.8716 - val_accuracy: 0.7164\n",
            "Epoch 14/20\n",
            "160/160 [==============================] - 15s 93ms/step - loss: 0.3791 - accuracy: 0.8647 - val_loss: 0.8692 - val_accuracy: 0.7254\n",
            "Epoch 15/20\n",
            "160/160 [==============================] - 15s 93ms/step - loss: 0.3486 - accuracy: 0.8793 - val_loss: 0.9290 - val_accuracy: 0.7199\n",
            "Epoch 16/20\n",
            "160/160 [==============================] - 16s 102ms/step - loss: 0.3273 - accuracy: 0.8859 - val_loss: 0.9422 - val_accuracy: 0.7148\n",
            "Epoch 17/20\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 0.3039 - accuracy: 0.8927 - val_loss: 0.9343 - val_accuracy: 0.7085\n",
            "Epoch 18/20\n",
            "160/160 [==============================] - 15s 94ms/step - loss: 0.2855 - accuracy: 0.8958 - val_loss: 0.9967 - val_accuracy: 0.7089\n",
            "Epoch 19/20\n",
            "160/160 [==============================] - 15s 91ms/step - loss: 0.2649 - accuracy: 0.9045 - val_loss: 1.0660 - val_accuracy: 0.7019\n",
            "Epoch 20/20\n",
            "160/160 [==============================] - 15s 94ms/step - loss: 0.2522 - accuracy: 0.9098 - val_loss: 1.0540 - val_accuracy: 0.7171\n",
            "80/80 [==============================] - 1s 11ms/step - loss: 1.0538 - accuracy: 0.7171\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0538235902786255, 0.7171361446380615]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6b9mzn2Rf8u",
        "colab_type": "text"
      },
      "source": [
        "#### Best simple LSTM (128 hu changed to 100)\n",
        "\n",
        "with GloVe, results are worse and the model converges longer.\n",
        "\n",
        "No GloVe, RMSprop = 0.7437, 4 epoch\n",
        "\n",
        "No GloVe, Adam = 0.7387, 2 epoch\n",
        "\n",
        "GloVe, RMSprop = 0.7371, 11 epoch\n",
        "\n",
        "GloVe, Adam = 0.7359, 8 epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usFo40fsNZ8D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "4349e3b2-feeb-40e5-ae13-b3b4670b3e6d"
      },
      "source": [
        "# best simple LSTM - RMSprop\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len + 1, output_dim=100, name=\"Embedding\"))  \n",
        "model.add(LSTM(128, dropout=0.2, name=\"LSTM\")) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=10) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "160/160 [==============================] - 10s 60ms/step - loss: 1.2520 - accuracy: 0.5018 - val_loss: 0.9268 - val_accuracy: 0.6628\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 9s 57ms/step - loss: 0.7785 - accuracy: 0.7230 - val_loss: 0.7708 - val_accuracy: 0.7140\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 9s 58ms/step - loss: 0.6255 - accuracy: 0.7802 - val_loss: 0.7451 - val_accuracy: 0.7383\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 9s 58ms/step - loss: 0.5406 - accuracy: 0.8105 - val_loss: 0.7363 - val_accuracy: 0.7437\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 9s 57ms/step - loss: 0.4800 - accuracy: 0.8313 - val_loss: 0.7340 - val_accuracy: 0.7430\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 9s 57ms/step - loss: 0.4314 - accuracy: 0.8508 - val_loss: 0.7621 - val_accuracy: 0.7336\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 9s 57ms/step - loss: 0.3910 - accuracy: 0.8641 - val_loss: 0.7969 - val_accuracy: 0.7312\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 9s 57ms/step - loss: 0.3556 - accuracy: 0.8751 - val_loss: 0.8115 - val_accuracy: 0.7324\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 9s 57ms/step - loss: 0.3226 - accuracy: 0.8868 - val_loss: 0.8127 - val_accuracy: 0.7203\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 9s 57ms/step - loss: 0.2974 - accuracy: 0.8969 - val_loss: 0.8795 - val_accuracy: 0.7140\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.8795 - accuracy: 0.7140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8794649839401245, 0.714006245136261]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaUNarjyR6Dl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "79ee0be0-34ea-4dd3-c90a-3e87a68d8c91"
      },
      "source": [
        "# best simple LSTM - Adam\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len + 1, output_dim=100, name=\"Embedding\"))  \n",
        "model.add(LSTM(128, dropout=0.2, name=\"LSTM\")) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=5) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "160/160 [==============================] - 10s 64ms/step - loss: 1.2181 - accuracy: 0.5151 - val_loss: 0.8261 - val_accuracy: 0.6854\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.6441 - accuracy: 0.7741 - val_loss: 0.7378 - val_accuracy: 0.7387\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.4398 - accuracy: 0.8483 - val_loss: 0.8115 - val_accuracy: 0.7152\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.3262 - accuracy: 0.8910 - val_loss: 0.8330 - val_accuracy: 0.7152\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 10s 61ms/step - loss: 0.2568 - accuracy: 0.9174 - val_loss: 0.9436 - val_accuracy: 0.7050\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.9435 - accuracy: 0.7050\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9435362815856934, 0.7050078511238098]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kusg_yciFIcE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "8dacfeba-974e-4866-8850-311b52c60ae7"
      },
      "source": [
        "# best simple LSTM, using pre-trained gloVe embeddings - RMSprop\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len + 1, output_dim=100, trainable=True,                       \n",
        "                    embeddings_initializer=Constant(emb_mat),                       \n",
        "                    input_length=20, name=\"Embedding\"))  \n",
        "model.add(LSTM(128, dropout=0.2, name=\"LSTM\")) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=20) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 1.1676 - accuracy: 0.5338 - val_loss: 0.9576 - val_accuracy: 0.6412\n",
            "Epoch 2/20\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.9285 - accuracy: 0.6498 - val_loss: 0.8785 - val_accuracy: 0.6729\n",
            "Epoch 3/20\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.8227 - accuracy: 0.6894 - val_loss: 0.8080 - val_accuracy: 0.6952\n",
            "Epoch 4/20\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.7499 - accuracy: 0.7180 - val_loss: 0.7703 - val_accuracy: 0.7121\n",
            "Epoch 5/20\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 0.6889 - accuracy: 0.7418 - val_loss: 0.7500 - val_accuracy: 0.7199\n",
            "Epoch 6/20\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 0.6421 - accuracy: 0.7611 - val_loss: 0.7392 - val_accuracy: 0.7218\n",
            "Epoch 7/20\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 0.5968 - accuracy: 0.7786 - val_loss: 0.7649 - val_accuracy: 0.7242\n",
            "Epoch 8/20\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.5550 - accuracy: 0.8016 - val_loss: 0.7528 - val_accuracy: 0.7324\n",
            "Epoch 9/20\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.5162 - accuracy: 0.8117 - val_loss: 0.7345 - val_accuracy: 0.7336\n",
            "Epoch 10/20\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 0.4820 - accuracy: 0.8250 - val_loss: 0.7535 - val_accuracy: 0.7336\n",
            "Epoch 11/20\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 0.4392 - accuracy: 0.8453 - val_loss: 0.7723 - val_accuracy: 0.7371\n",
            "Epoch 12/20\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 0.4072 - accuracy: 0.8519 - val_loss: 0.7881 - val_accuracy: 0.7359\n",
            "Epoch 13/20\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 0.3703 - accuracy: 0.8658 - val_loss: 0.8131 - val_accuracy: 0.7316\n",
            "Epoch 14/20\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.3491 - accuracy: 0.8740 - val_loss: 0.8229 - val_accuracy: 0.7293\n",
            "Epoch 15/20\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.3122 - accuracy: 0.8885 - val_loss: 0.8439 - val_accuracy: 0.7355\n",
            "Epoch 16/20\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 0.2895 - accuracy: 0.8968 - val_loss: 0.8677 - val_accuracy: 0.7312\n",
            "Epoch 17/20\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.2624 - accuracy: 0.9073 - val_loss: 0.8841 - val_accuracy: 0.7222\n",
            "Epoch 18/20\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 0.2433 - accuracy: 0.9142 - val_loss: 0.9354 - val_accuracy: 0.7203\n",
            "Epoch 19/20\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.2143 - accuracy: 0.9272 - val_loss: 0.9321 - val_accuracy: 0.7230\n",
            "Epoch 20/20\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.1938 - accuracy: 0.9332 - val_loss: 0.9933 - val_accuracy: 0.7230\n",
            "80/80 [==============================] - 1s 6ms/step - loss: 0.9929 - accuracy: 0.7230\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9929080009460449, 0.7230046987533569]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ds9Fg2zGDel",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "59501250-d0ec-4170-fb63-16cbdaa5f618"
      },
      "source": [
        "# best simple LSTM, using pre-trained gloVe embeddings - ADAM\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len + 1, output_dim=100, trainable=True,                       \n",
        "                    embeddings_initializer=Constant(emb_mat),                       \n",
        "                    input_length=20, name=\"Embedding\"))  \n",
        "model.add(LSTM(128, dropout=0.2, name=\"LSTM\")) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=10) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "160/160 [==============================] - 9s 55ms/step - loss: 1.1701 - accuracy: 0.5292 - val_loss: 0.9525 - val_accuracy: 0.6318\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.8713 - accuracy: 0.6739 - val_loss: 0.8217 - val_accuracy: 0.6964\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 9s 54ms/step - loss: 0.7327 - accuracy: 0.7273 - val_loss: 0.7685 - val_accuracy: 0.7140\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.6351 - accuracy: 0.7640 - val_loss: 0.7441 - val_accuracy: 0.7254\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.5502 - accuracy: 0.8001 - val_loss: 0.7506 - val_accuracy: 0.7179\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.4759 - accuracy: 0.8275 - val_loss: 0.7648 - val_accuracy: 0.7297\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.4202 - accuracy: 0.8494 - val_loss: 0.7824 - val_accuracy: 0.7289\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.3551 - accuracy: 0.8715 - val_loss: 0.8070 - val_accuracy: 0.7359\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.3093 - accuracy: 0.8926 - val_loss: 0.8301 - val_accuracy: 0.7226\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.2626 - accuracy: 0.9094 - val_loss: 0.8596 - val_accuracy: 0.7269\n",
            "80/80 [==============================] - 1s 6ms/step - loss: 0.8595 - accuracy: 0.7269\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.859515368938446, 0.726917028427124]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrrhQHUSNdrs",
        "colab_type": "text"
      },
      "source": [
        "#### Best simple GRU (128 emb changed to 100, GRU 256 + drop 0.3)\n",
        "\n",
        "No GloVe = 0.7394, 4 epoch\n",
        "\n",
        "No GloVe, with emb=128 (above) = 0.7449, 4 epoch\n",
        "\n",
        "GloVe = 0.7324, 9 epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-l_VpsyTnna",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "e8be5225-65db-476d-f8a3-2b567f94727a"
      },
      "source": [
        "# best simple GRU, no GloVe\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len + 1, output_dim=100, name=\"Embedding\"))  \n",
        "model.add(GRU(256, dropout=0.3, name=\"GRU\")) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=10) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "160/160 [==============================] - 16s 99ms/step - loss: 1.1915 - accuracy: 0.5300 - val_loss: 0.8594 - val_accuracy: 0.6858\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 15s 97ms/step - loss: 0.7509 - accuracy: 0.7357 - val_loss: 0.7548 - val_accuracy: 0.7238\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 16s 97ms/step - loss: 0.6149 - accuracy: 0.7855 - val_loss: 0.7388 - val_accuracy: 0.7371\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 15s 96ms/step - loss: 0.5363 - accuracy: 0.8123 - val_loss: 0.7342 - val_accuracy: 0.7394\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 16s 98ms/step - loss: 0.4830 - accuracy: 0.8277 - val_loss: 0.7527 - val_accuracy: 0.7344\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 16s 97ms/step - loss: 0.4335 - accuracy: 0.8462 - val_loss: 0.7761 - val_accuracy: 0.7312\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 16s 97ms/step - loss: 0.3904 - accuracy: 0.8654 - val_loss: 0.8043 - val_accuracy: 0.7367\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 16s 98ms/step - loss: 0.3519 - accuracy: 0.8750 - val_loss: 0.9046 - val_accuracy: 0.7191\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 15s 96ms/step - loss: 0.3175 - accuracy: 0.8880 - val_loss: 0.8650 - val_accuracy: 0.7281\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 16s 98ms/step - loss: 0.2864 - accuracy: 0.9012 - val_loss: 0.9318 - val_accuracy: 0.7191\n",
            "80/80 [==============================] - 1s 16ms/step - loss: 0.9317 - accuracy: 0.7191\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9317275285720825, 0.7190923094749451]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaV1nluyDPKp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "157dc9ca-775a-4f9d-f502-21b477659896"
      },
      "source": [
        "# best simple GRU using pre-trained gloVe embeddings\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len + 1, output_dim=100, trainable=True,                       \n",
        "                    embeddings_initializer=Constant(emb_mat),                       \n",
        "                    input_length=20, name=\"Embedding\"))  \n",
        "model.add(GRU(256, dropout=0.3, name=\"GRU\")) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=20) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "160/160 [==============================] - 15s 91ms/step - loss: 1.1713 - accuracy: 0.5296 - val_loss: 0.9622 - val_accuracy: 0.6381\n",
            "Epoch 2/20\n",
            "160/160 [==============================] - 14s 88ms/step - loss: 0.9504 - accuracy: 0.6393 - val_loss: 0.8777 - val_accuracy: 0.6694\n",
            "Epoch 3/20\n",
            "160/160 [==============================] - 14s 89ms/step - loss: 0.8484 - accuracy: 0.6835 - val_loss: 0.7997 - val_accuracy: 0.6972\n",
            "Epoch 4/20\n",
            "160/160 [==============================] - 14s 88ms/step - loss: 0.7782 - accuracy: 0.7095 - val_loss: 0.7715 - val_accuracy: 0.7124\n",
            "Epoch 5/20\n",
            "160/160 [==============================] - 14s 88ms/step - loss: 0.7236 - accuracy: 0.7327 - val_loss: 0.7525 - val_accuracy: 0.7167\n",
            "Epoch 6/20\n",
            "160/160 [==============================] - 14s 88ms/step - loss: 0.6719 - accuracy: 0.7536 - val_loss: 0.7382 - val_accuracy: 0.7199\n",
            "Epoch 7/20\n",
            "160/160 [==============================] - 14s 88ms/step - loss: 0.6301 - accuracy: 0.7680 - val_loss: 0.7714 - val_accuracy: 0.7128\n",
            "Epoch 8/20\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 0.5854 - accuracy: 0.7842 - val_loss: 0.7495 - val_accuracy: 0.7250\n",
            "Epoch 9/20\n",
            "160/160 [==============================] - 14s 88ms/step - loss: 0.5428 - accuracy: 0.7979 - val_loss: 0.7361 - val_accuracy: 0.7324\n",
            "Epoch 10/20\n",
            "160/160 [==============================] - 14s 89ms/step - loss: 0.5061 - accuracy: 0.8115 - val_loss: 0.7406 - val_accuracy: 0.7304\n",
            "Epoch 11/20\n",
            "160/160 [==============================] - 14s 89ms/step - loss: 0.4653 - accuracy: 0.8300 - val_loss: 0.7690 - val_accuracy: 0.7234\n",
            "Epoch 12/20\n",
            "160/160 [==============================] - 14s 90ms/step - loss: 0.4258 - accuracy: 0.8432 - val_loss: 0.7943 - val_accuracy: 0.7234\n",
            "Epoch 13/20\n",
            "160/160 [==============================] - 14s 90ms/step - loss: 0.3891 - accuracy: 0.8626 - val_loss: 0.8255 - val_accuracy: 0.7257\n",
            "Epoch 14/20\n",
            "160/160 [==============================] - 15s 91ms/step - loss: 0.3497 - accuracy: 0.8679 - val_loss: 0.8049 - val_accuracy: 0.7281\n",
            "Epoch 15/20\n",
            "160/160 [==============================] - 14s 90ms/step - loss: 0.3132 - accuracy: 0.8877 - val_loss: 0.8440 - val_accuracy: 0.7285\n",
            "Epoch 16/20\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 0.2782 - accuracy: 0.8999 - val_loss: 0.8828 - val_accuracy: 0.7250\n",
            "Epoch 17/20\n",
            "160/160 [==============================] - 15s 94ms/step - loss: 0.2522 - accuracy: 0.9107 - val_loss: 0.9007 - val_accuracy: 0.7203\n",
            "Epoch 18/20\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 0.2158 - accuracy: 0.9245 - val_loss: 0.9617 - val_accuracy: 0.7234\n",
            "Epoch 19/20\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 0.1925 - accuracy: 0.9305 - val_loss: 0.9958 - val_accuracy: 0.7230\n",
            "Epoch 20/20\n",
            "160/160 [==============================] - 15s 91ms/step - loss: 0.1663 - accuracy: 0.9396 - val_loss: 1.0771 - val_accuracy: 0.7214\n",
            "80/80 [==============================] - 1s 15ms/step - loss: 1.0766 - accuracy: 0.7214\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0766452550888062, 0.721439778804779]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA2BslOxPJpj",
        "colab_type": "text"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QnbA3JRVwAp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "ab292393-9f20-4b2c-8e61-034578face4b"
      },
      "source": [
        "# model from keras site, adapted, 250 hu, emb=128\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "kernel_size = 3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(dict_len + 1, output_dim=128,\n",
        "                    input_length=20))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(250,\n",
        "                 kernel_size,\n",
        "#  \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input.\n",
        "                 padding='valid', # 0.4 points worse with same \n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(250))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=5) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "160/160 [==============================] - 5s 30ms/step - loss: 1.1967 - accuracy: 0.5187 - val_loss: 0.8391 - val_accuracy: 0.6941\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 5s 29ms/step - loss: 0.7109 - accuracy: 0.7476 - val_loss: 0.7417 - val_accuracy: 0.7328\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 5s 29ms/step - loss: 0.5511 - accuracy: 0.8059 - val_loss: 0.7363 - val_accuracy: 0.7430\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 5s 29ms/step - loss: 0.4425 - accuracy: 0.8440 - val_loss: 0.7624 - val_accuracy: 0.7367\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 5s 29ms/step - loss: 0.3418 - accuracy: 0.8839 - val_loss: 0.7912 - val_accuracy: 0.7316\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.7911 - accuracy: 0.7316\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7911454439163208, 0.7316119074821472]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4gNUfodbip2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "78577f09-9d28-421a-ecaf-38f848c789fc"
      },
      "source": [
        "# model from keras site, adapted, 250 hu, emb=100\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "kernel_size = 3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(dict_len + 1, output_dim=100,\n",
        "                    input_length=20))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(250,\n",
        "                 kernel_size,\n",
        "#  \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input.\n",
        "                 padding='valid', # 0.3p lowers with \"same\"\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(250))\n",
        "model.add(Dropout(0.2)) # 0.27 lower w/o dropout here\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=5) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "160/160 [==============================] - 4s 25ms/step - loss: 1.2176 - accuracy: 0.5091 - val_loss: 0.8525 - val_accuracy: 0.6905\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 4s 24ms/step - loss: 0.7304 - accuracy: 0.7412 - val_loss: 0.7384 - val_accuracy: 0.7371\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 4s 24ms/step - loss: 0.5752 - accuracy: 0.7997 - val_loss: 0.7333 - val_accuracy: 0.7453\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 4s 24ms/step - loss: 0.4668 - accuracy: 0.8391 - val_loss: 0.7450 - val_accuracy: 0.7457\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 4s 24ms/step - loss: 0.3756 - accuracy: 0.8695 - val_loss: 0.7806 - val_accuracy: 0.7359\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.7805 - accuracy: 0.7359\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7805317640304565, 0.73591548204422]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF7jPzICcQpF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "3d84f95b-d723-41df-e8a8-df11a7a3a515"
      },
      "source": [
        "# model from keras site, adapted, 250 hu, emb=100\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "kernel_size = 3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(dict_len + 1, output_dim=100,\n",
        "                    input_length=20))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(250,\n",
        "                 kernel_size,\n",
        "#  \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input.\n",
        "                 padding='same', # changed padding here; 0.78p better with \"same\"\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(250))\n",
        "# model.add(Dropout(0.2)) # REMOVED DROPOUT HERE\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=5) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "160/160 [==============================] - 4s 26ms/step - loss: 1.1768 - accuracy: 0.5307 - val_loss: 0.8257 - val_accuracy: 0.6972\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 4s 25ms/step - loss: 0.7040 - accuracy: 0.7529 - val_loss: 0.7279 - val_accuracy: 0.7453\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 4s 25ms/step - loss: 0.5464 - accuracy: 0.8091 - val_loss: 0.7269 - val_accuracy: 0.7508\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 4s 25ms/step - loss: 0.4457 - accuracy: 0.8450 - val_loss: 0.7442 - val_accuracy: 0.7418\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 4s 25ms/step - loss: 0.3551 - accuracy: 0.8751 - val_loss: 0.7814 - val_accuracy: 0.7449\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.7814 - accuracy: 0.7449\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7813548445701599, 0.7449139356613159]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9prxt1FvFdo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "3d98c662-6514-458e-9675-7a20ba57efea"
      },
      "source": [
        "# model from keras site, adapted, 250 hu, emb=100\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "kernel_size = 3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(dict_len + 1, output_dim=100,\n",
        "                    input_length=20))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(250,\n",
        "                 kernel_size,\n",
        "#  \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input.\n",
        "                 padding='same', # changed padding here; 0.78p better with \"same\"\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(250))\n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=5) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "160/160 [==============================] - 5s 28ms/step - loss: 1.2028 - accuracy: 0.5157 - val_loss: 0.8483 - val_accuracy: 0.6851\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.7261 - accuracy: 0.7469 - val_loss: 0.7382 - val_accuracy: 0.7390\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.5726 - accuracy: 0.8004 - val_loss: 0.7364 - val_accuracy: 0.7426\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.4690 - accuracy: 0.8383 - val_loss: 0.7500 - val_accuracy: 0.7414\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 4s 28ms/step - loss: 0.3778 - accuracy: 0.8681 - val_loss: 0.7862 - val_accuracy: 0.7402\n",
            "80/80 [==============================] - 0s 4ms/step - loss: 0.7862 - accuracy: 0.7402\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7861568331718445, 0.7402191162109375]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6df8H6uEAB0H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "6ab277c9-43d1-4862-e88a-14dc4eefce7d"
      },
      "source": [
        "# with pretrained GloVe embeddings, worse.\n",
        "# with trainable = False, even worse: max valid.acc = 0.682   \n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "kernel_size = 3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(dict_len + 1, output_dim=100, trainable=True,                    \n",
        "                    embeddings_initializer=Constant(emb_mat),                       \n",
        "                    input_length=20, name=\"Embedding\"))  \n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(250,\n",
        "                 kernel_size,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(250))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=10) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 1.2436 - accuracy: 0.4873 - val_loss: 0.9376 - val_accuracy: 0.6534\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.9269 - accuracy: 0.6476 - val_loss: 0.8627 - val_accuracy: 0.6729\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.8033 - accuracy: 0.7015 - val_loss: 0.7889 - val_accuracy: 0.7015\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.7027 - accuracy: 0.7374 - val_loss: 0.7651 - val_accuracy: 0.7152\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.6251 - accuracy: 0.7672 - val_loss: 0.7628 - val_accuracy: 0.7203\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.5453 - accuracy: 0.8001 - val_loss: 0.7796 - val_accuracy: 0.7171\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.4765 - accuracy: 0.8244 - val_loss: 0.8984 - val_accuracy: 0.6843\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.4182 - accuracy: 0.8455 - val_loss: 0.8848 - val_accuracy: 0.6897\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 3s 19ms/step - loss: 0.3790 - accuracy: 0.8633 - val_loss: 0.8611 - val_accuracy: 0.7074\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 3s 18ms/step - loss: 0.3271 - accuracy: 0.8797 - val_loss: 0.8884 - val_accuracy: 0.7058\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.8881 - accuracy: 0.7058\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8881068229675293, 0.7057902812957764]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfdBXyWXDQmu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "e6d2d1e0-6543-48dd-b0f4-f5fa7b0d762b"
      },
      "source": [
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(dict_len + 1, output_dim=128,\n",
        "                    input_length=20))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(50, 3,\n",
        "#  \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input.\n",
        "                 padding='same', # 0.4 points better with same\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(Conv1D(100, 4,\n",
        "#  \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input.\n",
        "                 padding='same', # 0.4 points better with same\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(Conv1D(150, 5,\n",
        "#  \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input.\n",
        "                 padding='same', # 0.4 points better with same\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(MaxPooling1D(pool_size=5))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(250))\n",
        "# model.add(Dropout(0.2))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=10) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "160/160 [==============================] - 9s 59ms/step - loss: 1.3419 - accuracy: 0.3714 - val_loss: 1.1514 - val_accuracy: 0.4734\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 9s 57ms/step - loss: 0.9957 - accuracy: 0.6026 - val_loss: 0.9340 - val_accuracy: 0.6448\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 9s 57ms/step - loss: 0.7298 - accuracy: 0.7375 - val_loss: 0.8080 - val_accuracy: 0.7062\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.5823 - accuracy: 0.7983 - val_loss: 0.8014 - val_accuracy: 0.7250\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.4777 - accuracy: 0.8352 - val_loss: 0.7892 - val_accuracy: 0.7226\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.4000 - accuracy: 0.8618 - val_loss: 0.8077 - val_accuracy: 0.7261\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.3383 - accuracy: 0.8856 - val_loss: 0.8721 - val_accuracy: 0.7152\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.2819 - accuracy: 0.9050 - val_loss: 0.9466 - val_accuracy: 0.7222\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.2301 - accuracy: 0.9217 - val_loss: 0.9947 - val_accuracy: 0.7152\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.1858 - accuracy: 0.9378 - val_loss: 1.0959 - val_accuracy: 0.6937\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.0959 - accuracy: 0.6937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0959151983261108, 0.6936619877815247]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY975i3gAagP",
        "colab_type": "text"
      },
      "source": [
        "### Best CNN model so far"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCF2fjhunaoF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "outputId": "2b4ddeb8-029e-4ef7-ea35-3c31f1690df3"
      },
      "source": [
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "kernel_size = 3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(dict_len + 1, output_dim=100,\n",
        "                    input_length=20))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(500,\n",
        "                 kernel_size,\n",
        "#  \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input.\n",
        "                 padding='same', # changed padding here; 0.78p better with \"same\"\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(250))\n",
        "# model.add(Dropout(0.2)) # REMOVED DROPOUT HERE\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "history = model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=5) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_57\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_57 (Embedding)     (None, 20, 100)           932200    \n",
            "_________________________________________________________________\n",
            "dropout_56 (Dropout)         (None, 20, 100)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_56 (Conv1D)           (None, 20, 500)           150500    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_56 (Glo (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 250)               125250    \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 5)                 1255      \n",
            "=================================================================\n",
            "Total params: 1,209,205\n",
            "Trainable params: 1,209,205\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 1.1335 - accuracy: 0.5475 - val_loss: 0.7956 - val_accuracy: 0.7132\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.6920 - accuracy: 0.7550 - val_loss: 0.7236 - val_accuracy: 0.7484\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.5359 - accuracy: 0.8139 - val_loss: 0.7199 - val_accuracy: 0.7508\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.4377 - accuracy: 0.8472 - val_loss: 0.7378 - val_accuracy: 0.7551\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 9s 54ms/step - loss: 0.3446 - accuracy: 0.8817 - val_loss: 0.7765 - val_accuracy: 0.7445\n",
            "80/80 [==============================] - 0s 5ms/step - loss: 0.7764 - accuracy: 0.7445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7764409780502319, 0.7445226907730103]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2xOoKPegMn7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e9d421b7-13c1-49b4-f60f-70cd7a40eca5"
      },
      "source": [
        "max(history.history[\"val_accuracy\"]) # extract mav val_accuracy from the trained model."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7550860643386841"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaqndbsUAnLv",
        "colab_type": "text"
      },
      "source": [
        "#### Predict on test set for kaggle (3rd upload)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bhNjEPQgHx8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "842ed5d6-3c0a-4417-9e31-9369a16303a7"
      },
      "source": [
        "# the same, but trained for 4 epochs only to achieve max accuracy\n",
        "# model from keras site, adapted, 500 hu, emb=100\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "kernel_size = 3\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Embedding(dict_len + 1, output_dim=100,\n",
        "                    input_length=20))\n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(Conv1D(500,\n",
        "                 kernel_size,\n",
        "#  \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input.\n",
        "                 padding='same', # changed padding here; 0.78p better with \"same\"\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model3.add(GlobalMaxPooling1D())\n",
        "model3.add(Dense(250))\n",
        "model3.add(Activation('relu'))\n",
        "model3.add(Dense(5, activation=\"softmax\"))  \n",
        "model3.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "model3.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=4) \n",
        "model3.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "160/160 [==============================] - 10s 64ms/step - loss: 1.1335 - accuracy: 0.5475 - val_loss: 0.7956 - val_accuracy: 0.7132\n",
            "Epoch 2/4\n",
            "160/160 [==============================] - 10s 64ms/step - loss: 0.6920 - accuracy: 0.7550 - val_loss: 0.7236 - val_accuracy: 0.7484\n",
            "Epoch 3/4\n",
            "160/160 [==============================] - 10s 65ms/step - loss: 0.5359 - accuracy: 0.8139 - val_loss: 0.7199 - val_accuracy: 0.7508\n",
            "Epoch 4/4\n",
            "160/160 [==============================] - 10s 65ms/step - loss: 0.4377 - accuracy: 0.8472 - val_loss: 0.7378 - val_accuracy: 0.7551\n",
            "80/80 [==============================] - 0s 6ms/step - loss: 0.7377 - accuracy: 0.7551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7377182841300964, 0.7550860643386841]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hhjpySOu3E9J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "e46b06f3-568c-40d1-ff92-589fe681de8a"
      },
      "source": [
        "# Best CNN \n",
        "Y_test_pred = model3.predict_classes(X_test)\n",
        "Y_test_df = pd.DataFrame(Y_test)\n",
        "Y_test_categ = Y_test_df.idxmax(axis=1)\n",
        "confusion_matrix(Y_test_categ,Y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[413,  90,  40,  13,  32],\n",
              "       [ 90, 454,  18,  21,   5],\n",
              "       [ 65,  18, 398,  38,  41],\n",
              "       [ 12,  27,  31, 415,  17],\n",
              "       [ 30,   3,  24,  11, 250]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ktjjsV_D28JI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "2dbe48cb-f64f-4da9-a54a-4c338713e956"
      },
      "source": [
        "# GRU(256)\n",
        "Y_test_pred = model.predict_classes(X_test)\n",
        "Y_test_df = pd.DataFrame(Y_test)\n",
        "Y_test_categ = Y_test_df.idxmax(axis=1)\n",
        "confusion_matrix(Y_test_categ,Y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[403,  91,  58,  14,  22],\n",
              "       [ 77, 459,  25,  22,   5],\n",
              "       [ 56,  26, 400,  38,  40],\n",
              "       [ 13,  29,  44, 402,  14],\n",
              "       [ 33,   2,  32,  11, 240]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f5VKHFj24zCw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "c7ad16c3-a478-4fcf-f6f9-35444c7c3a39"
      },
      "source": [
        "# LSTM-128 RMSprop\n",
        "Y_test_pred = model2.predict_classes(X_test)\n",
        "Y_test_df = pd.DataFrame(Y_test)\n",
        "Y_test_categ = Y_test_df.idxmax(axis=1)\n",
        "confusion_matrix(Y_test_categ,Y_test_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[374, 104,  67,  18,  25],\n",
              "       [ 70, 466,  20,  27,   5],\n",
              "       [ 47,  25, 405,  42,  41],\n",
              "       [  9,  28,  40, 410,  15],\n",
              "       [ 25,   1,  34,  11, 247]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JVJQCSWgRFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "86373bc0-6619-4dcf-880b-d07f894c67af"
      },
      "source": [
        "Y_new3 = model3.predict_classes(X_new)\n",
        "# show the inputs and predicted outputs\n",
        "print(X_new[:5])\n",
        "for i in range(5):\n",
        "\tprint(\"X=%s, Predicted=%s\" % (X_new[i], Y_new3[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    3  482\n",
            "     8   32   15    1  117   66]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0 1591  130  758\n",
            "    20   66    1 1407  295  307]\n",
            " [   0    0    0    0    0    0   95    4  120    2   35   21  693 2005\n",
            "  6187    1   24    2  463  166]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0  378  229\n",
            "   793    1   47  278  399   14]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0   47  202  302  519]]\n",
            "X=[  0   0   0   0   0   0   0   0   0   0   0   0   3 482   8  32  15   1\n",
            " 117  66], Predicted=1\n",
            "X=[   0    0    0    0    0    0    0    0    0    0    0 1591  130  758\n",
            "   20   66    1 1407  295  307], Predicted=1\n",
            "X=[   0    0    0    0    0    0   95    4  120    2   35   21  693 2005\n",
            " 6187    1   24    2  463  166], Predicted=0\n",
            "X=[  0   0   0   0   0   0   0   0   0   0   0   0 378 229 793   1  47 278\n",
            " 399  14], Predicted=2\n",
            "X=[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  47 202\n",
            " 302 519], Predicted=2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTmNkFUlgwyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test3 = pd.DataFrame(list(zip(test['id'], Y_new3)), \n",
        "               columns = ['id', 'label'])\n",
        "test3\n",
        "test3.to_csv('test3.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4bhZHJsvXgp",
        "colab_type": "text"
      },
      "source": [
        "### Tune grid for the best CNN - did not make it work...\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx8G3BcawiAZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "798a0fd6-a7df-4d92-b193-7b030aecef4a"
      },
      "source": [
        "y = train[['label']]\n",
        "\n",
        "\n",
        "# https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model():\n",
        "  np.random.seed(42)\n",
        "  random.seed(12345)\n",
        "  session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                inter_op_parallelism_threads=1)\n",
        "  tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(dict_len + 1, output_dim=100,\n",
        "                      input_length=20))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv1D(500,\n",
        "                  kernel_size,\n",
        "                  padding='same', \n",
        "                  activation='relu',\n",
        "                  strides=1))\n",
        "  model.add(GlobalMaxPooling1D())\n",
        "  model.add(Dense(250))\n",
        "  # model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=7) \n",
        "  # model.evaluate(X_test, Y_test)\n",
        "  return model\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 10\n",
        "np.random.seed(seed)\n",
        "\n",
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=1)\n",
        "print(model.summary())\n",
        "\n",
        "# define the grid search parameters\n",
        "batch_size = [16, 32, 64, 128]\n",
        "epochs = [2,3,4,5]\n",
        "print(epochs)\n",
        "\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X=X, y=y)\n",
        "print(grid_result)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-8132270acf43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# create model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# define the grid search parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'summary'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMRmcA-1GD8h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "0f761ce6-4c59-43b4-c038-6a424de15abb"
      },
      "source": [
        "print(Y)\n",
        "print(Y.shape)\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]]\n",
            "(12779, 5)\n",
            "(12779, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EJaAMJUIzOL3"
      },
      "source": [
        "### Custom models with different filter sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ng_swncW77nL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "outputId": "8d4f67a1-e5d6-4997-a50c-e08b8062c193"
      },
      "source": [
        "# try the best simple model for a benchmark with a new seed\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5) \n",
        "\n",
        "kernel_size = 3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(dict_len + 1, output_dim=100,\n",
        "                    input_length=20))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(500,\n",
        "                 kernel_size,\n",
        "#  \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input.\n",
        "                 padding='same', # changed padding here; 0.78p better with \"same\"\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(250))\n",
        "# model.add(Dropout(0.2)) # REMOVED DROPOUT HERE\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "history = model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=5) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_131 (Embedding)    (None, 20, 100)           932200    \n",
            "_________________________________________________________________\n",
            "dropout_121 (Dropout)        (None, 20, 100)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_120 (Conv1D)          (None, 20, 500)           150500    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_114 (Gl (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_142 (Dense)            (None, 250)               125250    \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_143 (Dense)            (None, 5)                 1255      \n",
            "=================================================================\n",
            "Total params: 1,209,205\n",
            "Trainable params: 1,209,205\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 10s 65ms/step - loss: 1.1528 - accuracy: 0.5422 - val_loss: 0.8278 - val_accuracy: 0.7023\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 11s 67ms/step - loss: 0.6961 - accuracy: 0.7471 - val_loss: 0.7481 - val_accuracy: 0.7332\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 11s 66ms/step - loss: 0.5460 - accuracy: 0.8094 - val_loss: 0.7455 - val_accuracy: 0.7351\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 10s 65ms/step - loss: 0.4398 - accuracy: 0.8500 - val_loss: 0.7658 - val_accuracy: 0.7402\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 10s 65ms/step - loss: 0.3451 - accuracy: 0.8828 - val_loss: 0.8262 - val_accuracy: 0.7246\n",
            "80/80 [==============================] - 0s 6ms/step - loss: 0.8260 - accuracy: 0.7246\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8260191679000854, 0.7245696187019348]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d5xMc67GzOL5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ca67b7bb-5692-431a-9ea3-ec4ea885ea09"
      },
      "source": [
        "def custom_CNN(input_length=20,input_length2=12,vocab_size=dict_len+1,emb_dim = 100):\n",
        "  # define CNN layer\n",
        "  inputs1 = Input(shape=(input_length,))\n",
        "  emb1 = Embedding(vocab_size, emb_dim)(inputs1)\n",
        "  conv1 = Conv1D(filters=500, kernel_size=2, padding='same', activation='relu', strides=1)(emb1)\n",
        "  drop1 = Dropout(0.5)(conv1)\n",
        "  # pool1 = GlobalMaxPooling1D()(drop1)\n",
        "  pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
        "  flat1 = Flatten()(pool1)\n",
        "\n",
        "  inputs2 = Input(shape=(input_length,))\n",
        "  emb2 = Embedding(vocab_size, emb_dim)(inputs2)\n",
        "  conv2 = Conv1D(filters=500, kernel_size=3, padding='same', activation='relu', strides=1)(emb2)\n",
        "  drop2 = Dropout(0.5)(conv2)\n",
        "  # pool2 = GlobalMaxPooling1D()(drop2)\n",
        "  pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
        "  flat2 = Flatten()(pool2)\n",
        "\n",
        "  inputs3 = Input(shape=(input_length,))\n",
        "  emb3 = Embedding(vocab_size, emb_dim)(inputs3)\n",
        "  conv3 = Conv1D(filters=500, kernel_size=4, padding='same', activation='relu', strides=1)(emb3)\n",
        "  drop3 = Dropout(0.5)(conv3)\n",
        "  # pool3 = GlobalMaxPooling1D()(drop3)\n",
        "  pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
        "  flat3 = Flatten()(pool3)\n",
        "\n",
        "  # merge CNN output with reference stats\n",
        "  merged = concatenate([flat1, flat2, flat3])\n",
        "\n",
        "  dense1 = Dense(500, activation='relu')(merged)\n",
        "  outputs = Dense(5, activation=\"softmax\")(dense1)\n",
        "  model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "  return model\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "# define model\n",
        "model = custom_CNN(input_length=20, input_length2=12, vocab_size=dict_len+1,emb_dim = 100)\n",
        "model.fit(x=[X_train,X_train,X_train], y=Y_train, validation_data = ([X_test,X_test,X_test], Y_test), batch_size=64, epochs=5) \n",
        "# save the model\n",
        "# model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_36\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_97 (InputLayer)           [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_98 (InputLayer)           [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_99 (InputLayer)           [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_62 (Embedding)        (None, 20, 100)      932200      input_97[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_63 (Embedding)        (None, 20, 100)      932200      input_98[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_64 (Embedding)        (None, 20, 100)      932200      input_99[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_51 (Conv1D)              (None, 20, 500)      100500      embedding_62[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_52 (Conv1D)              (None, 20, 500)      150500      embedding_63[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_53 (Conv1D)              (None, 20, 500)      200500      embedding_64[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_52 (Dropout)            (None, 20, 500)      0           conv1d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_53 (Dropout)            (None, 20, 500)      0           conv1d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_54 (Dropout)            (None, 20, 500)      0           conv1d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D)    (None, 10, 500)      0           dropout_52[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 10, 500)      0           dropout_53[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 10, 500)      0           dropout_54[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_49 (Flatten)            (None, 5000)         0           max_pooling1d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_50 (Flatten)            (None, 5000)         0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_51 (Flatten)            (None, 5000)         0           max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_38 (TensorFl [(None, 15000)]      0           flatten_49[0][0]                 \n",
            "                                                                 flatten_50[0][0]                 \n",
            "                                                                 flatten_51[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_96 (Dense)                (None, 500)          7500500     tf_op_layer_concat_38[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_97 (Dense)                (None, 5)            2505        dense_96[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 10,751,105\n",
            "Trainable params: 10,751,105\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 43s 272ms/step - loss: 1.1038 - accuracy: 0.5597 - val_loss: 0.8078 - val_accuracy: 0.7105\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 44s 272ms/step - loss: 0.6131 - accuracy: 0.7849 - val_loss: 0.7723 - val_accuracy: 0.7152\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 43s 268ms/step - loss: 0.4092 - accuracy: 0.8606 - val_loss: 0.7858 - val_accuracy: 0.7179\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 43s 270ms/step - loss: 0.2416 - accuracy: 0.9200 - val_loss: 0.9304 - val_accuracy: 0.6995\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 43s 270ms/step - loss: 0.1284 - accuracy: 0.9590 - val_loss: 1.1386 - val_accuracy: 0.6819\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f818f256f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjTFWWcY162B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "63abb535-f4e4-4051-dd1a-f80ca47e933d"
      },
      "source": [
        "def custom_CNN(input_length=20,input_length2=12,vocab_size=dict_len+1,emb_dim = 100):\n",
        "  # define CNN layer\n",
        "  inputs1 = Input(shape=(input_length,))\n",
        "  emb1 = Embedding(vocab_size, emb_dim)(inputs1)\n",
        "  conv1 = Conv1D(filters=500, kernel_size=4, padding='same', activation='relu', strides=1)(emb1)\n",
        "  drop1 = Dropout(0.3)(conv1)\n",
        "  # pool1 = GlobalMaxPooling1D()(drop1)\n",
        "  pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
        "  flat1 = Flatten()(pool1)\n",
        "\n",
        "  inputs2 = Input(shape=(input_length,))\n",
        "  emb2 = Embedding(vocab_size, emb_dim)(inputs2)\n",
        "  conv2 = Conv1D(filters=500, kernel_size=6, padding='same', activation='relu', strides=1)(emb2)\n",
        "  drop2 = Dropout(0.3)(conv2)\n",
        "  # pool2 = GlobalMaxPooling1D()(drop2)\n",
        "  pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
        "  flat2 = Flatten()(pool2)\n",
        "\n",
        "  inputs3 = Input(shape=(input_length,))\n",
        "  emb3 = Embedding(vocab_size, emb_dim)(inputs3)\n",
        "  conv3 = Conv1D(filters=500, kernel_size=8, padding='same', activation='relu', strides=1)(emb3)\n",
        "  drop3 = Dropout(0.3)(conv3)\n",
        "  # pool3 = GlobalMaxPooling1D()(drop3)\n",
        "  pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
        "  flat3 = Flatten()(pool3)\n",
        "\n",
        "  # merge CNN output with reference stats\n",
        "  merged = concatenate([flat1, flat2, flat3])\n",
        "\n",
        "  dense1 = Dense(500, activation='relu')(merged)\n",
        "  outputs = Dense(5, activation=\"softmax\")(dense1)\n",
        "  model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "  return model\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "# define model\n",
        "model = custom_CNN(input_length=20, input_length2=12, vocab_size=dict_len+1,emb_dim = 100)\n",
        "model.fit(x=[X_train,X_train,X_train], y=Y_train, validation_data = ([X_test,X_test,X_test], Y_test), batch_size=64, epochs=5) \n",
        "# save the model\n",
        "# model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_37\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_100 (InputLayer)          [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_101 (InputLayer)          [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_102 (InputLayer)          [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_65 (Embedding)        (None, 20, 100)      932200      input_100[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_66 (Embedding)        (None, 20, 100)      932200      input_101[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_67 (Embedding)        (None, 20, 100)      932200      input_102[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_54 (Conv1D)              (None, 20, 500)      200500      embedding_65[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_55 (Conv1D)              (None, 20, 500)      300500      embedding_66[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_56 (Conv1D)              (None, 20, 500)      400500      embedding_67[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_55 (Dropout)            (None, 20, 500)      0           conv1d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_56 (Dropout)            (None, 20, 500)      0           conv1d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_57 (Dropout)            (None, 20, 500)      0           conv1d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, 10, 500)      0           dropout_55[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1D)  (None, 10, 500)      0           dropout_56[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1D)  (None, 10, 500)      0           dropout_57[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_52 (Flatten)            (None, 5000)         0           max_pooling1d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_53 (Flatten)            (None, 5000)         0           max_pooling1d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_54 (Flatten)            (None, 5000)         0           max_pooling1d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_39 (TensorFl [(None, 15000)]      0           flatten_52[0][0]                 \n",
            "                                                                 flatten_53[0][0]                 \n",
            "                                                                 flatten_54[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_98 (Dense)                (None, 500)          7500500     tf_op_layer_concat_39[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_99 (Dense)                (None, 5)            2505        dense_98[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 11,201,105\n",
            "Trainable params: 11,201,105\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 63s 392ms/step - loss: 1.0949 - accuracy: 0.5608 - val_loss: 0.8033 - val_accuracy: 0.7097\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 63s 394ms/step - loss: 0.5963 - accuracy: 0.7924 - val_loss: 0.7791 - val_accuracy: 0.7167\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 63s 397ms/step - loss: 0.3688 - accuracy: 0.8748 - val_loss: 0.8073 - val_accuracy: 0.7128\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 63s 394ms/step - loss: 0.1820 - accuracy: 0.9409 - val_loss: 1.0523 - val_accuracy: 0.6909\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 63s 394ms/step - loss: 0.0780 - accuracy: 0.9752 - val_loss: 1.4483 - val_accuracy: 0.6764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f818ef07668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SatApdMc3LYi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a23911ef-3ec4-4da6-fe4c-a66cefec1416"
      },
      "source": [
        "# Imitating article CNN for sentense classification:\n",
        "# filters: 100\n",
        "# kernel size: 3,4,5\n",
        "# dropout = 0.5\n",
        "# MaxOverTime pooling\n",
        "\n",
        "def custom_CNN(input_length=20,input_length2=12,vocab_size=dict_len+1,emb_dim = 100):\n",
        "  # define CNN layer\n",
        "  inputs1 = Input(shape=(input_length,))\n",
        "  emb1 = Embedding(vocab_size, emb_dim)(inputs1)\n",
        "  conv1 = Conv1D(filters=100, kernel_size=3, padding='same', activation='relu', strides=1)(emb1)\n",
        "  drop1 = Dropout(0.5)(conv1)\n",
        "  pool1 = GlobalMaxPooling1D()(drop1) # MaxOverTime\n",
        "  # pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
        "  flat1 = Flatten()(pool1)\n",
        "\n",
        "  inputs2 = Input(shape=(input_length,))\n",
        "  emb2 = Embedding(vocab_size, emb_dim)(inputs2)\n",
        "  conv2 = Conv1D(filters=100, kernel_size=4, padding='same', activation='relu', strides=1)(emb2)\n",
        "  drop2 = Dropout(0.5)(conv2)\n",
        "  pool2 = GlobalMaxPooling1D()(drop2)\n",
        "  # pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
        "  flat2 = Flatten()(pool2)\n",
        "\n",
        "  inputs3 = Input(shape=(input_length,))\n",
        "  emb3 = Embedding(vocab_size, emb_dim)(inputs3)\n",
        "  conv3 = Conv1D(filters=100, kernel_size=5, padding='same', activation='relu', strides=1)(emb3)\n",
        "  drop3 = Dropout(0.5)(conv3)\n",
        "  pool3 = GlobalMaxPooling1D()(drop3)\n",
        "  # pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
        "  flat3 = Flatten()(pool3)\n",
        "\n",
        "  # merge CNN output with reference stats\n",
        "  merged = concatenate([flat1, flat2, flat3])\n",
        "\n",
        "  dense1 = Dense(500, activation='relu')(merged)\n",
        "  outputs = Dense(5, activation=\"softmax\")(dense1)\n",
        "  model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "  return model\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "# define model\n",
        "model = custom_CNN(input_length=20, input_length2=12, vocab_size=dict_len+1,emb_dim = 100)\n",
        "model.fit(x=[X_train,X_train,X_train], y=Y_train, validation_data = ([X_test,X_test,X_test], Y_test), batch_size=64, epochs=5) \n",
        "# save the model\n",
        "# model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_39\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_106 (InputLayer)          [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_107 (InputLayer)          [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_108 (InputLayer)          [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_71 (Embedding)        (None, 20, 100)      932200      input_106[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_72 (Embedding)        (None, 20, 100)      932200      input_107[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_73 (Embedding)        (None, 20, 100)      932200      input_108[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_60 (Conv1D)              (None, 20, 100)      30100       embedding_71[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_61 (Conv1D)              (None, 20, 100)      40100       embedding_72[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_62 (Conv1D)              (None, 20, 100)      50100       embedding_73[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_61 (Dropout)            (None, 20, 100)      0           conv1d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_62 (Dropout)            (None, 20, 100)      0           conv1d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_63 (Dropout)            (None, 20, 100)      0           conv1d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_54 (Global (None, 100)          0           dropout_61[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_55 (Global (None, 100)          0           dropout_62[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_56 (Global (None, 100)          0           dropout_63[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_58 (Flatten)            (None, 100)          0           global_max_pooling1d_54[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_59 (Flatten)            (None, 100)          0           global_max_pooling1d_55[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_60 (Flatten)            (None, 100)          0           global_max_pooling1d_56[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_41 (TensorFl [(None, 300)]        0           flatten_58[0][0]                 \n",
            "                                                                 flatten_59[0][0]                 \n",
            "                                                                 flatten_60[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_102 (Dense)               (None, 500)          150500      tf_op_layer_concat_41[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_103 (Dense)               (None, 5)            2505        dense_102[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 3,069,905\n",
            "Trainable params: 3,069,905\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 1.1100 - accuracy: 0.5593 - val_loss: 0.8752 - val_accuracy: 0.7117\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.6282 - accuracy: 0.7778 - val_loss: 0.7798 - val_accuracy: 0.7183\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.4556 - accuracy: 0.8426 - val_loss: 0.7289 - val_accuracy: 0.7347\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.3320 - accuracy: 0.8862 - val_loss: 0.7311 - val_accuracy: 0.7390\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.2315 - accuracy: 0.9234 - val_loss: 0.7941 - val_accuracy: 0.7171\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8190bb9d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpcb35XU4x7w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "198c8584-5a84-4780-e225-266b3b5b84b5"
      },
      "source": [
        "# kernel size: 3,4,5\n",
        "dropout = [0, 0.25, 0.35, 0.5]\n",
        "filters = [50, 100, 200, 300]\n",
        "# MaxOverTime pooling\n",
        "\n",
        "for i in filters:\n",
        "  for j in dropout:\n",
        "    print(\"Number of hidden units: \", i, \"dropout: \",j)\n",
        "\n",
        "    def custom_CNN(input_length=20,input_length2=12,vocab_size=dict_len+1,emb_dim = 100):\n",
        "      # define CNN layer\n",
        "      inputs1 = Input(shape=(input_length,))\n",
        "      emb1 = Embedding(vocab_size, emb_dim)(inputs1)\n",
        "      conv1 = Conv1D(filters=i, kernel_size=3, padding='same', activation='relu', strides=1)(emb1)\n",
        "      drop1 = Dropout(j)(conv1)\n",
        "      pool1 = GlobalMaxPooling1D()(drop1) # MaxOverTime\n",
        "      # pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
        "      flat1 = Flatten()(pool1)\n",
        "\n",
        "      inputs2 = Input(shape=(input_length,))\n",
        "      emb2 = Embedding(vocab_size, emb_dim)(inputs2)\n",
        "      conv2 = Conv1D(filters=i, kernel_size=4, padding='same', activation='relu', strides=1)(emb2)\n",
        "      drop2 = Dropout(j)(conv2)\n",
        "      pool2 = GlobalMaxPooling1D()(drop2)\n",
        "      # pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
        "      flat2 = Flatten()(pool2)\n",
        "\n",
        "      inputs3 = Input(shape=(input_length,))\n",
        "      emb3 = Embedding(vocab_size, emb_dim)(inputs3)\n",
        "      conv3 = Conv1D(filters=i, kernel_size=5, padding='same', activation='relu', strides=1)(emb3)\n",
        "      drop3 = Dropout(j)(conv3)\n",
        "      pool3 = GlobalMaxPooling1D()(drop3)\n",
        "      # pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
        "      flat3 = Flatten()(pool3)\n",
        "\n",
        "      # merge CNN output with reference stats\n",
        "      merged = concatenate([flat1, flat2, flat3])\n",
        "\n",
        "      dense1 = Dense(500, activation='relu')(merged)\n",
        "      outputs = Dense(5, activation=\"softmax\")(dense1)\n",
        "      model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
        "      model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "      # print(model.summary())\n",
        "      # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "      return model\n",
        "\n",
        "    np.random.seed(5)\n",
        "    random.seed(5)\n",
        "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                  inter_op_parallelism_threads=1)\n",
        "    tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "    # define model\n",
        "    model = custom_CNN(input_length=20, input_length2=12, vocab_size=dict_len+1,emb_dim = 100)\n",
        "    model.fit(x=[X_train,X_train,X_train], y=Y_train, validation_data = ([X_test,X_test,X_test], Y_test), batch_size=64, epochs=5) \n",
        "    # save the model\n",
        "    # model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of hidden units:  50 dropout:  0\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 7s 42ms/step - loss: 1.1334 - accuracy: 0.5552 - val_loss: 0.8149 - val_accuracy: 0.7066\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 7s 41ms/step - loss: 0.5854 - accuracy: 0.7982 - val_loss: 0.7577 - val_accuracy: 0.7351\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 7s 41ms/step - loss: 0.3422 - accuracy: 0.8863 - val_loss: 0.7922 - val_accuracy: 0.7285\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 6s 41ms/step - loss: 0.1646 - accuracy: 0.9513 - val_loss: 0.8979 - val_accuracy: 0.7257\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 6s 41ms/step - loss: 0.0613 - accuracy: 0.9844 - val_loss: 1.0848 - val_accuracy: 0.7148\n",
            "Number of hidden units:  50 dropout:  0.25\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 7s 43ms/step - loss: 1.1381 - accuracy: 0.5543 - val_loss: 0.8370 - val_accuracy: 0.7105\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 7s 42ms/step - loss: 0.6105 - accuracy: 0.7856 - val_loss: 0.7442 - val_accuracy: 0.7300\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 7s 42ms/step - loss: 0.4042 - accuracy: 0.8608 - val_loss: 0.7333 - val_accuracy: 0.7312\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 7s 42ms/step - loss: 0.2524 - accuracy: 0.9148 - val_loss: 0.7853 - val_accuracy: 0.7324\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 7s 43ms/step - loss: 0.1464 - accuracy: 0.9562 - val_loss: 0.8781 - val_accuracy: 0.7187\n",
            "Number of hidden units:  50 dropout:  0.35\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 7s 41ms/step - loss: 1.1432 - accuracy: 0.5502 - val_loss: 0.8649 - val_accuracy: 0.7081\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 6s 40ms/step - loss: 0.6255 - accuracy: 0.7811 - val_loss: 0.7570 - val_accuracy: 0.7281\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 6s 39ms/step - loss: 0.4332 - accuracy: 0.8501 - val_loss: 0.7278 - val_accuracy: 0.7328\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 6s 40ms/step - loss: 0.2938 - accuracy: 0.8979 - val_loss: 0.7625 - val_accuracy: 0.7285\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 6s 40ms/step - loss: 0.1919 - accuracy: 0.9372 - val_loss: 0.8215 - val_accuracy: 0.7269\n",
            "Number of hidden units:  50 dropout:  0.5\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 7s 42ms/step - loss: 1.1484 - accuracy: 0.5468 - val_loss: 0.9051 - val_accuracy: 0.7074\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 7s 43ms/step - loss: 0.6489 - accuracy: 0.7732 - val_loss: 0.7801 - val_accuracy: 0.7316\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 7s 41ms/step - loss: 0.4726 - accuracy: 0.8348 - val_loss: 0.7321 - val_accuracy: 0.7387\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 7s 41ms/step - loss: 0.3549 - accuracy: 0.8750 - val_loss: 0.7300 - val_accuracy: 0.7332\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 6s 41ms/step - loss: 0.2580 - accuracy: 0.9124 - val_loss: 0.7630 - val_accuracy: 0.7250\n",
            "Number of hidden units:  100 dropout:  0\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 1.1069 - accuracy: 0.5673 - val_loss: 0.7912 - val_accuracy: 0.7179\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.5767 - accuracy: 0.7980 - val_loss: 0.7528 - val_accuracy: 0.7308\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.3454 - accuracy: 0.8837 - val_loss: 0.7925 - val_accuracy: 0.7242\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.1692 - accuracy: 0.9481 - val_loss: 0.8917 - val_accuracy: 0.7242\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.0605 - accuracy: 0.9831 - val_loss: 1.0775 - val_accuracy: 0.7210\n",
            "Number of hidden units:  100 dropout:  0.25\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 1.1034 - accuracy: 0.5666 - val_loss: 0.8186 - val_accuracy: 0.7152\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 9s 55ms/step - loss: 0.5979 - accuracy: 0.7898 - val_loss: 0.7514 - val_accuracy: 0.7261\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 9s 55ms/step - loss: 0.4003 - accuracy: 0.8632 - val_loss: 0.7378 - val_accuracy: 0.7320\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.2503 - accuracy: 0.9169 - val_loss: 0.8016 - val_accuracy: 0.7175\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.1397 - accuracy: 0.9572 - val_loss: 0.8906 - val_accuracy: 0.7207\n",
            "Number of hidden units:  100 dropout:  0.35\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 9s 57ms/step - loss: 1.1036 - accuracy: 0.5652 - val_loss: 0.8350 - val_accuracy: 0.7089\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 9s 55ms/step - loss: 0.6060 - accuracy: 0.7850 - val_loss: 0.7558 - val_accuracy: 0.7226\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.4197 - accuracy: 0.8560 - val_loss: 0.7306 - val_accuracy: 0.7332\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 9s 55ms/step - loss: 0.2840 - accuracy: 0.9034 - val_loss: 0.7658 - val_accuracy: 0.7297\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.1744 - accuracy: 0.9442 - val_loss: 0.8317 - val_accuracy: 0.7281\n",
            "Number of hidden units:  100 dropout:  0.5\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 1.1100 - accuracy: 0.5593 - val_loss: 0.8752 - val_accuracy: 0.7117\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 9s 55ms/step - loss: 0.6282 - accuracy: 0.7778 - val_loss: 0.7798 - val_accuracy: 0.7183\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.4556 - accuracy: 0.8426 - val_loss: 0.7289 - val_accuracy: 0.7347\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 9s 55ms/step - loss: 0.3320 - accuracy: 0.8862 - val_loss: 0.7311 - val_accuracy: 0.7390\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 9s 56ms/step - loss: 0.2315 - accuracy: 0.9234 - val_loss: 0.7941 - val_accuracy: 0.7171\n",
            "Number of hidden units:  200 dropout:  0\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 13s 79ms/step - loss: 1.0786 - accuracy: 0.5792 - val_loss: 0.7790 - val_accuracy: 0.7195\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 12s 78ms/step - loss: 0.5749 - accuracy: 0.8002 - val_loss: 0.7567 - val_accuracy: 0.7265\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 13s 78ms/step - loss: 0.3524 - accuracy: 0.8790 - val_loss: 0.7936 - val_accuracy: 0.7293\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 13s 79ms/step - loss: 0.1783 - accuracy: 0.9440 - val_loss: 0.9128 - val_accuracy: 0.7265\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 13s 79ms/step - loss: 0.0698 - accuracy: 0.9809 - val_loss: 1.0985 - val_accuracy: 0.7164\n",
            "Number of hidden units:  200 dropout:  0.25\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 13s 82ms/step - loss: 1.0769 - accuracy: 0.5723 - val_loss: 0.8037 - val_accuracy: 0.7179\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 13s 79ms/step - loss: 0.5903 - accuracy: 0.7937 - val_loss: 0.7547 - val_accuracy: 0.7195\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 13s 80ms/step - loss: 0.3976 - accuracy: 0.8616 - val_loss: 0.7364 - val_accuracy: 0.7410\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 13s 79ms/step - loss: 0.2490 - accuracy: 0.9184 - val_loss: 0.8028 - val_accuracy: 0.7281\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 13s 79ms/step - loss: 0.1352 - accuracy: 0.9582 - val_loss: 0.9031 - val_accuracy: 0.7203\n",
            "Number of hidden units:  200 dropout:  0.35\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 13s 79ms/step - loss: 1.0753 - accuracy: 0.5752 - val_loss: 0.8228 - val_accuracy: 0.7207\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 13s 79ms/step - loss: 0.5976 - accuracy: 0.7897 - val_loss: 0.7548 - val_accuracy: 0.7207\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 13s 80ms/step - loss: 0.4139 - accuracy: 0.8551 - val_loss: 0.7308 - val_accuracy: 0.7355\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 13s 79ms/step - loss: 0.2774 - accuracy: 0.9058 - val_loss: 0.7711 - val_accuracy: 0.7289\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 13s 79ms/step - loss: 0.1650 - accuracy: 0.9479 - val_loss: 0.8575 - val_accuracy: 0.7187\n",
            "Number of hidden units:  200 dropout:  0.5\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 13s 81ms/step - loss: 1.0796 - accuracy: 0.5733 - val_loss: 0.8628 - val_accuracy: 0.7117\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 13s 79ms/step - loss: 0.6110 - accuracy: 0.7861 - val_loss: 0.7741 - val_accuracy: 0.7238\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 13s 80ms/step - loss: 0.4396 - accuracy: 0.8472 - val_loss: 0.7225 - val_accuracy: 0.7293\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 13s 80ms/step - loss: 0.3122 - accuracy: 0.8919 - val_loss: 0.7475 - val_accuracy: 0.7265\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 13s 80ms/step - loss: 0.2080 - accuracy: 0.9318 - val_loss: 0.8217 - val_accuracy: 0.7167\n",
            "Number of hidden units:  300 dropout:  0\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 22s 136ms/step - loss: 1.0647 - accuracy: 0.5803 - val_loss: 0.7747 - val_accuracy: 0.7250\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 21s 134ms/step - loss: 0.5761 - accuracy: 0.8000 - val_loss: 0.7616 - val_accuracy: 0.7207\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 21s 134ms/step - loss: 0.3648 - accuracy: 0.8731 - val_loss: 0.7895 - val_accuracy: 0.7265\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 21s 134ms/step - loss: 0.1938 - accuracy: 0.9387 - val_loss: 0.9139 - val_accuracy: 0.7226\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 21s 134ms/step - loss: 0.0815 - accuracy: 0.9764 - val_loss: 1.0806 - val_accuracy: 0.7195\n",
            "Number of hidden units:  300 dropout:  0.25\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 22s 136ms/step - loss: 1.0575 - accuracy: 0.5801 - val_loss: 0.7983 - val_accuracy: 0.7226\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 22s 137ms/step - loss: 0.5913 - accuracy: 0.7934 - val_loss: 0.7559 - val_accuracy: 0.7195\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 22s 137ms/step - loss: 0.4052 - accuracy: 0.8601 - val_loss: 0.7346 - val_accuracy: 0.7363\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 22s 134ms/step - loss: 0.2562 - accuracy: 0.9119 - val_loss: 0.8173 - val_accuracy: 0.7191\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 22s 136ms/step - loss: 0.1387 - accuracy: 0.9570 - val_loss: 0.9201 - val_accuracy: 0.7160\n",
            "Number of hidden units:  300 dropout:  0.35\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 22s 136ms/step - loss: 1.0629 - accuracy: 0.5790 - val_loss: 0.8167 - val_accuracy: 0.7218\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 22s 135ms/step - loss: 0.6003 - accuracy: 0.7901 - val_loss: 0.7596 - val_accuracy: 0.7179\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 22s 136ms/step - loss: 0.4215 - accuracy: 0.8536 - val_loss: 0.7238 - val_accuracy: 0.7344\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 22s 138ms/step - loss: 0.2801 - accuracy: 0.9040 - val_loss: 0.7867 - val_accuracy: 0.7183\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 22s 136ms/step - loss: 0.1658 - accuracy: 0.9467 - val_loss: 0.8705 - val_accuracy: 0.7124\n",
            "Number of hidden units:  300 dropout:  0.5\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 22s 136ms/step - loss: 1.0690 - accuracy: 0.5772 - val_loss: 0.8609 - val_accuracy: 0.7187\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 22s 136ms/step - loss: 0.6082 - accuracy: 0.7833 - val_loss: 0.7716 - val_accuracy: 0.7152\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 22s 136ms/step - loss: 0.4411 - accuracy: 0.8448 - val_loss: 0.7229 - val_accuracy: 0.7340\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 22s 136ms/step - loss: 0.3141 - accuracy: 0.8905 - val_loss: 0.7541 - val_accuracy: 0.7254\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 22s 137ms/step - loss: 0.2094 - accuracy: 0.9336 - val_loss: 0.8225 - val_accuracy: 0.7183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCmub42Y7xXG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3da4cb42-45a5-4606-f7f7-ec972819c5c8"
      },
      "source": [
        "# kernel size: 3,4,5\n",
        "# removed padding = \"same\"\n",
        "dropout = [0, 0.25, 0.35, 0.5]\n",
        "filters = [50, 100, 200, 300]\n",
        "# MaxOverTime pooling\n",
        "\n",
        "for i in filters:\n",
        "  for j in dropout:\n",
        "    print(\"Number of hidden units: \", i, \"dropout: \",j)\n",
        "\n",
        "    def custom_CNN(input_length=20,input_length2=12,vocab_size=dict_len+1,emb_dim = 100):\n",
        "      # define CNN layer\n",
        "      inputs1 = Input(shape=(input_length,))\n",
        "      emb1 = Embedding(vocab_size, emb_dim)(inputs1)\n",
        "      conv1 = Conv1D(filters=i, kernel_size=3, activation='relu', strides=1)(emb1) # removed padding='same', \n",
        "      drop1 = Dropout(j)(conv1)\n",
        "      pool1 = GlobalMaxPooling1D()(drop1) # MaxOverTime\n",
        "      # pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
        "      flat1 = Flatten()(pool1)\n",
        "\n",
        "      inputs2 = Input(shape=(input_length,))\n",
        "      emb2 = Embedding(vocab_size, emb_dim)(inputs2)\n",
        "      conv2 = Conv1D(filters=i, kernel_size=4, activation='relu', strides=1)(emb2) # removed padding='same', \n",
        "      drop2 = Dropout(j)(conv2)\n",
        "      pool2 = GlobalMaxPooling1D()(drop2)\n",
        "      # pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
        "      flat2 = Flatten()(pool2)\n",
        "\n",
        "      inputs3 = Input(shape=(input_length,))\n",
        "      emb3 = Embedding(vocab_size, emb_dim)(inputs3)\n",
        "      conv3 = Conv1D(filters=i, kernel_size=5, activation='relu', strides=1)(emb3) # removed padding='same', \n",
        "      drop3 = Dropout(j)(conv3)\n",
        "      pool3 = GlobalMaxPooling1D()(drop3)\n",
        "      # pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
        "      flat3 = Flatten()(pool3)\n",
        "\n",
        "      # merge CNN output with reference stats\n",
        "      merged = concatenate([flat1, flat2, flat3])\n",
        "\n",
        "      dense1 = Dense(500, activation='relu')(merged)\n",
        "      outputs = Dense(5, activation=\"softmax\")(dense1)\n",
        "      model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
        "      model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "      # print(model.summary())\n",
        "      # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "      return model\n",
        "\n",
        "    np.random.seed(5)\n",
        "    random.seed(5)\n",
        "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                  inter_op_parallelism_threads=1)\n",
        "    tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "    # define model\n",
        "    model = custom_CNN(input_length=20, input_length2=12, vocab_size=dict_len+1,emb_dim = 100)\n",
        "    model.fit(x=[X_train,X_train,X_train], y=Y_train, validation_data = ([X_test,X_test,X_test], Y_test), batch_size=64, epochs=5) \n",
        "    # save the model\n",
        "    # model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of hidden units:  50 dropout:  0\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 6s 38ms/step - loss: 1.1480 - accuracy: 0.5474 - val_loss: 0.8246 - val_accuracy: 0.7023\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 6s 38ms/step - loss: 0.5914 - accuracy: 0.7934 - val_loss: 0.7591 - val_accuracy: 0.7261\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 6s 37ms/step - loss: 0.3412 - accuracy: 0.8858 - val_loss: 0.7892 - val_accuracy: 0.7222\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 6s 37ms/step - loss: 0.1599 - accuracy: 0.9521 - val_loss: 0.9036 - val_accuracy: 0.7257\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 6s 37ms/step - loss: 0.0597 - accuracy: 0.9848 - val_loss: 1.0869 - val_accuracy: 0.7105\n",
            "Number of hidden units:  50 dropout:  0.25\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 6s 38ms/step - loss: 1.1609 - accuracy: 0.5361 - val_loss: 0.8568 - val_accuracy: 0.7031\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 6s 38ms/step - loss: 0.6323 - accuracy: 0.7746 - val_loss: 0.7588 - val_accuracy: 0.7234\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 6s 38ms/step - loss: 0.4217 - accuracy: 0.8552 - val_loss: 0.7385 - val_accuracy: 0.7320\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 6s 38ms/step - loss: 0.2591 - accuracy: 0.9128 - val_loss: 0.7972 - val_accuracy: 0.7254\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 6s 38ms/step - loss: 0.1444 - accuracy: 0.9545 - val_loss: 0.8880 - val_accuracy: 0.7222\n",
            "Number of hidden units:  50 dropout:  0.35\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 6s 38ms/step - loss: 1.1649 - accuracy: 0.5343 - val_loss: 0.8739 - val_accuracy: 0.7027\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 6s 38ms/step - loss: 0.6449 - accuracy: 0.7695 - val_loss: 0.7713 - val_accuracy: 0.7175\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 6s 38ms/step - loss: 0.4508 - accuracy: 0.8446 - val_loss: 0.7276 - val_accuracy: 0.7402\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 6s 38ms/step - loss: 0.3035 - accuracy: 0.8967 - val_loss: 0.7670 - val_accuracy: 0.7312\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 6s 37ms/step - loss: 0.1918 - accuracy: 0.9380 - val_loss: 0.8388 - val_accuracy: 0.7203\n",
            "Number of hidden units:  50 dropout:  0.5\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 6s 38ms/step - loss: 1.1816 - accuracy: 0.5217 - val_loss: 0.9159 - val_accuracy: 0.7058\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 6s 38ms/step - loss: 0.6786 - accuracy: 0.7576 - val_loss: 0.7912 - val_accuracy: 0.7113\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 6s 38ms/step - loss: 0.4980 - accuracy: 0.8257 - val_loss: 0.7342 - val_accuracy: 0.7363\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 6s 37ms/step - loss: 0.3677 - accuracy: 0.8744 - val_loss: 0.7352 - val_accuracy: 0.7285\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 6s 37ms/step - loss: 0.2639 - accuracy: 0.9128 - val_loss: 0.7716 - val_accuracy: 0.7218\n",
            "Number of hidden units:  100 dropout:  0\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 1.1155 - accuracy: 0.5642 - val_loss: 0.7950 - val_accuracy: 0.7171\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 0.5784 - accuracy: 0.7973 - val_loss: 0.7589 - val_accuracy: 0.7234\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 0.3391 - accuracy: 0.8866 - val_loss: 0.8029 - val_accuracy: 0.7187\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 0.1577 - accuracy: 0.9523 - val_loss: 0.9003 - val_accuracy: 0.7242\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.0554 - accuracy: 0.9853 - val_loss: 1.1164 - val_accuracy: 0.7171\n",
            "Number of hidden units:  100 dropout:  0.25\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 1.1177 - accuracy: 0.5591 - val_loss: 0.8217 - val_accuracy: 0.7105\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 8s 47ms/step - loss: 0.6053 - accuracy: 0.7864 - val_loss: 0.7554 - val_accuracy: 0.7214\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 8s 47ms/step - loss: 0.3962 - accuracy: 0.8636 - val_loss: 0.7605 - val_accuracy: 0.7226\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.2331 - accuracy: 0.9248 - val_loss: 0.8057 - val_accuracy: 0.7164\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 8s 47ms/step - loss: 0.1210 - accuracy: 0.9628 - val_loss: 0.9346 - val_accuracy: 0.7105\n",
            "Number of hidden units:  100 dropout:  0.35\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 1.1224 - accuracy: 0.5571 - val_loss: 0.8381 - val_accuracy: 0.7074\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.6203 - accuracy: 0.7811 - val_loss: 0.7571 - val_accuracy: 0.7238\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 9s 54ms/step - loss: 0.4236 - accuracy: 0.8539 - val_loss: 0.7463 - val_accuracy: 0.7226\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.2719 - accuracy: 0.9083 - val_loss: 0.7721 - val_accuracy: 0.7210\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 0.1635 - accuracy: 0.9482 - val_loss: 0.8670 - val_accuracy: 0.7191\n",
            "Number of hidden units:  100 dropout:  0.5\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 8s 51ms/step - loss: 1.1410 - accuracy: 0.5472 - val_loss: 0.8768 - val_accuracy: 0.7066\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.6429 - accuracy: 0.7693 - val_loss: 0.7721 - val_accuracy: 0.7242\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 8s 53ms/step - loss: 0.4623 - accuracy: 0.8388 - val_loss: 0.7365 - val_accuracy: 0.7285\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.3265 - accuracy: 0.8878 - val_loss: 0.7500 - val_accuracy: 0.7297\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 8s 52ms/step - loss: 0.2263 - accuracy: 0.9244 - val_loss: 0.8619 - val_accuracy: 0.7066\n",
            "Number of hidden units:  200 dropout:  0\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 12s 74ms/step - loss: 1.0849 - accuracy: 0.5730 - val_loss: 0.7878 - val_accuracy: 0.7160\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 12s 73ms/step - loss: 0.5759 - accuracy: 0.7991 - val_loss: 0.7703 - val_accuracy: 0.7210\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 12s 72ms/step - loss: 0.3428 - accuracy: 0.8843 - val_loss: 0.8215 - val_accuracy: 0.7191\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 12s 72ms/step - loss: 0.1615 - accuracy: 0.9518 - val_loss: 0.9458 - val_accuracy: 0.7222\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 12s 73ms/step - loss: 0.0598 - accuracy: 0.9828 - val_loss: 1.2090 - val_accuracy: 0.7066\n",
            "Number of hidden units:  200 dropout:  0.25\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 12s 74ms/step - loss: 1.0917 - accuracy: 0.5643 - val_loss: 0.8079 - val_accuracy: 0.7203\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 12s 73ms/step - loss: 0.6012 - accuracy: 0.7869 - val_loss: 0.7555 - val_accuracy: 0.7230\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 12s 73ms/step - loss: 0.3968 - accuracy: 0.8603 - val_loss: 0.7514 - val_accuracy: 0.7304\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 12s 73ms/step - loss: 0.2346 - accuracy: 0.9228 - val_loss: 0.8350 - val_accuracy: 0.7175\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 12s 74ms/step - loss: 0.1198 - accuracy: 0.9639 - val_loss: 0.9863 - val_accuracy: 0.7132\n",
            "Number of hidden units:  200 dropout:  0.35\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 12s 74ms/step - loss: 1.0961 - accuracy: 0.5643 - val_loss: 0.8294 - val_accuracy: 0.7160\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 12s 73ms/step - loss: 0.6108 - accuracy: 0.7817 - val_loss: 0.7603 - val_accuracy: 0.7183\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 12s 73ms/step - loss: 0.4135 - accuracy: 0.8562 - val_loss: 0.7366 - val_accuracy: 0.7254\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 12s 72ms/step - loss: 0.2547 - accuracy: 0.9146 - val_loss: 0.8222 - val_accuracy: 0.7164\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 12s 73ms/step - loss: 0.1421 - accuracy: 0.9550 - val_loss: 0.9153 - val_accuracy: 0.7128\n",
            "Number of hidden units:  200 dropout:  0.5\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 12s 74ms/step - loss: 1.1111 - accuracy: 0.5536 - val_loss: 0.8674 - val_accuracy: 0.7124\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 12s 73ms/step - loss: 0.6295 - accuracy: 0.7782 - val_loss: 0.7813 - val_accuracy: 0.7183\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 12s 73ms/step - loss: 0.4457 - accuracy: 0.8452 - val_loss: 0.7317 - val_accuracy: 0.7312\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 12s 73ms/step - loss: 0.3020 - accuracy: 0.8964 - val_loss: 0.7713 - val_accuracy: 0.7187\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 12s 74ms/step - loss: 0.1918 - accuracy: 0.9363 - val_loss: 0.8746 - val_accuracy: 0.7117\n",
            "Number of hidden units:  300 dropout:  0\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 21s 129ms/step - loss: 1.0734 - accuracy: 0.5768 - val_loss: 0.7820 - val_accuracy: 0.7164\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 20s 127ms/step - loss: 0.5801 - accuracy: 0.7969 - val_loss: 0.7649 - val_accuracy: 0.7226\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 21s 129ms/step - loss: 0.3555 - accuracy: 0.8792 - val_loss: 0.7973 - val_accuracy: 0.7265\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 20s 128ms/step - loss: 0.1708 - accuracy: 0.9486 - val_loss: 0.9753 - val_accuracy: 0.7128\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 21s 131ms/step - loss: 0.0657 - accuracy: 0.9809 - val_loss: 1.2147 - val_accuracy: 0.7081\n",
            "Number of hidden units:  300 dropout:  0.25\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 21s 128ms/step - loss: 1.0811 - accuracy: 0.5687 - val_loss: 0.8081 - val_accuracy: 0.7199\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 20s 128ms/step - loss: 0.6004 - accuracy: 0.7888 - val_loss: 0.7516 - val_accuracy: 0.7214\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 21s 129ms/step - loss: 0.3979 - accuracy: 0.8661 - val_loss: 0.7412 - val_accuracy: 0.7297\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 21s 129ms/step - loss: 0.2300 - accuracy: 0.9246 - val_loss: 0.8348 - val_accuracy: 0.7167\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 20s 127ms/step - loss: 0.1126 - accuracy: 0.9663 - val_loss: 0.9997 - val_accuracy: 0.7089\n",
            "Number of hidden units:  300 dropout:  0.35\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 21s 129ms/step - loss: 1.0884 - accuracy: 0.5659 - val_loss: 0.8264 - val_accuracy: 0.7140\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 21s 128ms/step - loss: 0.6087 - accuracy: 0.7832 - val_loss: 0.7580 - val_accuracy: 0.7148\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 20s 128ms/step - loss: 0.4160 - accuracy: 0.8556 - val_loss: 0.7413 - val_accuracy: 0.7308\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 21s 129ms/step - loss: 0.2546 - accuracy: 0.9130 - val_loss: 0.8017 - val_accuracy: 0.7152\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 21s 129ms/step - loss: 0.1350 - accuracy: 0.9574 - val_loss: 0.9651 - val_accuracy: 0.7066\n",
            "Number of hidden units:  300 dropout:  0.5\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 21s 128ms/step - loss: 1.0993 - accuracy: 0.5616 - val_loss: 0.8608 - val_accuracy: 0.7160\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 20s 128ms/step - loss: 0.6233 - accuracy: 0.7788 - val_loss: 0.7780 - val_accuracy: 0.7140\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 21s 130ms/step - loss: 0.4458 - accuracy: 0.8439 - val_loss: 0.7282 - val_accuracy: 0.7340\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 20s 128ms/step - loss: 0.3025 - accuracy: 0.8980 - val_loss: 0.7617 - val_accuracy: 0.7285\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 20s 128ms/step - loss: 0.1847 - accuracy: 0.9416 - val_loss: 0.8423 - val_accuracy: 0.7214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0PsF4z24Vbg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "70d386be-1cfe-4b7b-a106-e47ea1a11744"
      },
      "source": [
        "# This one no good!\n",
        "# kernel size: 4,6,8 - CHANGED\n",
        "# Increased stride in layers with wider kernels to 1-2-3\n",
        "# MaxOverTime pooling\n",
        "\n",
        "dropout = [0, 0.25, 0.35, 0.5]\n",
        "filters = [50, 100, 200, 300]\n",
        "# MaxOverTime pooling\n",
        "\n",
        "for i in filters:\n",
        "  for j in dropout:\n",
        "    print(\"Number of hidden units: \", i, \"dropout: \",j)\n",
        "\n",
        "    def custom_CNN(input_length=20,input_length2=12,vocab_size=dict_len+1,emb_dim = 100):\n",
        "      # define CNN layer\n",
        "      inputs1 = Input(shape=(input_length,))\n",
        "      emb1 = Embedding(vocab_size, emb_dim)(inputs1)\n",
        "      conv1 = Conv1D(filters=i, kernel_size=4, padding='same', activation='relu', strides=1)(emb1)\n",
        "      drop1 = Dropout(j)(conv1)\n",
        "      pool1 = GlobalMaxPooling1D()(drop1) # MaxOverTime\n",
        "      # pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
        "      flat1 = Flatten()(pool1)\n",
        "\n",
        "      inputs2 = Input(shape=(input_length,))\n",
        "      emb2 = Embedding(vocab_size, emb_dim)(inputs2)\n",
        "      conv2 = Conv1D(filters=i, kernel_size=6, padding='same', activation='relu', strides=2)(emb2)\n",
        "      drop2 = Dropout(j)(conv2)\n",
        "      pool2 = GlobalMaxPooling1D()(drop2)\n",
        "      # pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
        "      flat2 = Flatten()(pool2)\n",
        "\n",
        "      inputs3 = Input(shape=(input_length,))\n",
        "      emb3 = Embedding(vocab_size, emb_dim)(inputs3)\n",
        "      conv3 = Conv1D(filters=i, kernel_size=8, padding='same', activation='relu', strides=3)(emb3)\n",
        "      drop3 = Dropout(j)(conv3)\n",
        "      pool3 = GlobalMaxPooling1D()(drop3)\n",
        "      # pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
        "      flat3 = Flatten()(pool3)\n",
        "\n",
        "      # merge CNN output with reference stats\n",
        "      merged = concatenate([flat1, flat2, flat3])\n",
        "\n",
        "      dense1 = Dense(500, activation='relu')(merged)\n",
        "      outputs = Dense(5, activation=\"softmax\")(dense1)\n",
        "      model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
        "      model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "      # print(model.summary())\n",
        "      # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "      return model\n",
        "\n",
        "    np.random.seed(5)\n",
        "    random.seed(5)\n",
        "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                  inter_op_parallelism_threads=1)\n",
        "    tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "    # define model\n",
        "    model = custom_CNN(input_length=20, input_length2=12, vocab_size=dict_len+1,emb_dim = 100)\n",
        "    model.fit(x=[X_train,X_train,X_train], y=Y_train, validation_data = ([X_test,X_test,X_test], Y_test), batch_size=64, epochs=5) \n",
        "    # save the model\n",
        "    # model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of hidden units:  50 dropout:  0\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 6s 37ms/step - loss: 1.1470 - accuracy: 0.5436 - val_loss: 0.8073 - val_accuracy: 0.7128\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 6s 37ms/step - loss: 0.5631 - accuracy: 0.8037 - val_loss: 0.7626 - val_accuracy: 0.7312\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.2927 - accuracy: 0.9044 - val_loss: 0.8308 - val_accuracy: 0.7167\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.1130 - accuracy: 0.9686 - val_loss: 1.0286 - val_accuracy: 0.6999\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.0328 - accuracy: 0.9922 - val_loss: 1.2906 - val_accuracy: 0.6929\n",
            "Number of hidden units:  50 dropout:  0.25\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 6s 37ms/step - loss: 1.1553 - accuracy: 0.5382 - val_loss: 0.8373 - val_accuracy: 0.7050\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.6013 - accuracy: 0.7861 - val_loss: 0.7554 - val_accuracy: 0.7273\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.3607 - accuracy: 0.8763 - val_loss: 0.7667 - val_accuracy: 0.7254\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 6s 37ms/step - loss: 0.1954 - accuracy: 0.9358 - val_loss: 0.9246 - val_accuracy: 0.6925\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 6s 37ms/step - loss: 0.0939 - accuracy: 0.9721 - val_loss: 1.0291 - val_accuracy: 0.6944\n",
            "Number of hidden units:  50 dropout:  0.35\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 6s 37ms/step - loss: 1.1626 - accuracy: 0.5362 - val_loss: 0.8514 - val_accuracy: 0.7070\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.6112 - accuracy: 0.7863 - val_loss: 0.7551 - val_accuracy: 0.7336\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.3847 - accuracy: 0.8680 - val_loss: 0.7438 - val_accuracy: 0.7308\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 6s 37ms/step - loss: 0.2238 - accuracy: 0.9266 - val_loss: 0.8512 - val_accuracy: 0.7081\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.1186 - accuracy: 0.9634 - val_loss: 0.9595 - val_accuracy: 0.6905\n",
            "Number of hidden units:  50 dropout:  0.5\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 6s 37ms/step - loss: 1.1836 - accuracy: 0.5233 - val_loss: 0.9041 - val_accuracy: 0.7027\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.6376 - accuracy: 0.7755 - val_loss: 0.7718 - val_accuracy: 0.7324\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.4251 - accuracy: 0.8506 - val_loss: 0.7431 - val_accuracy: 0.7332\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.2788 - accuracy: 0.9041 - val_loss: 0.7964 - val_accuracy: 0.7132\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 6s 36ms/step - loss: 0.1665 - accuracy: 0.9459 - val_loss: 0.8854 - val_accuracy: 0.7050\n",
            "Number of hidden units:  100 dropout:  0\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 1.1216 - accuracy: 0.5539 - val_loss: 0.7971 - val_accuracy: 0.7109\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 8s 47ms/step - loss: 0.5513 - accuracy: 0.8073 - val_loss: 0.7569 - val_accuracy: 0.7300\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 8s 47ms/step - loss: 0.2808 - accuracy: 0.9112 - val_loss: 0.8338 - val_accuracy: 0.7293\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 8s 47ms/step - loss: 0.1008 - accuracy: 0.9708 - val_loss: 1.0498 - val_accuracy: 0.7058\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 7s 46ms/step - loss: 0.0288 - accuracy: 0.9913 - val_loss: 1.3275 - val_accuracy: 0.6948\n",
            "Number of hidden units:  100 dropout:  0.25\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 1.1257 - accuracy: 0.5530 - val_loss: 0.8203 - val_accuracy: 0.7097\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.5756 - accuracy: 0.7976 - val_loss: 0.7575 - val_accuracy: 0.7246\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 7s 47ms/step - loss: 0.3330 - accuracy: 0.8893 - val_loss: 0.7871 - val_accuracy: 0.7207\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.1557 - accuracy: 0.9493 - val_loss: 0.9680 - val_accuracy: 0.6929\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 7s 47ms/step - loss: 0.0645 - accuracy: 0.9795 - val_loss: 1.1845 - val_accuracy: 0.6823\n",
            "Number of hidden units:  100 dropout:  0.35\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 1.1309 - accuracy: 0.5484 - val_loss: 0.8388 - val_accuracy: 0.7093\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 8s 47ms/step - loss: 0.5850 - accuracy: 0.7921 - val_loss: 0.7647 - val_accuracy: 0.7222\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 8s 47ms/step - loss: 0.3518 - accuracy: 0.8802 - val_loss: 0.7626 - val_accuracy: 0.7246\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 7s 47ms/step - loss: 0.1835 - accuracy: 0.9405 - val_loss: 0.9027 - val_accuracy: 0.6972\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 8s 47ms/step - loss: 0.0850 - accuracy: 0.9732 - val_loss: 1.0923 - val_accuracy: 0.6839\n",
            "Number of hidden units:  100 dropout:  0.5\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 1.1451 - accuracy: 0.5409 - val_loss: 0.8785 - val_accuracy: 0.7089\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 8s 50ms/step - loss: 0.6117 - accuracy: 0.7850 - val_loss: 0.7780 - val_accuracy: 0.7250\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 8s 49ms/step - loss: 0.3952 - accuracy: 0.8667 - val_loss: 0.7453 - val_accuracy: 0.7312\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 8s 48ms/step - loss: 0.2334 - accuracy: 0.9218 - val_loss: 0.8275 - val_accuracy: 0.6995\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 8s 47ms/step - loss: 0.1272 - accuracy: 0.9591 - val_loss: 1.0022 - val_accuracy: 0.6780\n",
            "Number of hidden units:  200 dropout:  0\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 14s 88ms/step - loss: 1.0851 - accuracy: 0.5707 - val_loss: 0.7811 - val_accuracy: 0.7195\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 0.5401 - accuracy: 0.8140 - val_loss: 0.7741 - val_accuracy: 0.7230\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 0.2707 - accuracy: 0.9118 - val_loss: 0.8808 - val_accuracy: 0.7132\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 0.0979 - accuracy: 0.9706 - val_loss: 1.0955 - val_accuracy: 0.6987\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 0.0288 - accuracy: 0.9911 - val_loss: 1.4306 - val_accuracy: 0.7007\n",
            "Number of hidden units:  200 dropout:  0.25\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 14s 88ms/step - loss: 1.0877 - accuracy: 0.5706 - val_loss: 0.8025 - val_accuracy: 0.7210\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 14s 88ms/step - loss: 0.5623 - accuracy: 0.8040 - val_loss: 0.7631 - val_accuracy: 0.7214\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 0.3148 - accuracy: 0.8936 - val_loss: 0.8020 - val_accuracy: 0.7265\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 0.1407 - accuracy: 0.9548 - val_loss: 1.0046 - val_accuracy: 0.6901\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 0.0565 - accuracy: 0.9824 - val_loss: 1.2693 - val_accuracy: 0.6776\n",
            "Number of hidden units:  200 dropout:  0.35\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 1.0943 - accuracy: 0.5647 - val_loss: 0.8239 - val_accuracy: 0.7226\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 0.5752 - accuracy: 0.8000 - val_loss: 0.7609 - val_accuracy: 0.7218\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 14s 86ms/step - loss: 0.3384 - accuracy: 0.8863 - val_loss: 0.7834 - val_accuracy: 0.7218\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 0.1631 - accuracy: 0.9483 - val_loss: 0.9894 - val_accuracy: 0.6858\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 0.0732 - accuracy: 0.9772 - val_loss: 1.1777 - val_accuracy: 0.6776\n",
            "Number of hidden units:  200 dropout:  0.5\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 1.1027 - accuracy: 0.5584 - val_loss: 0.8549 - val_accuracy: 0.7187\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 0.5981 - accuracy: 0.7900 - val_loss: 0.7778 - val_accuracy: 0.7144\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 0.3731 - accuracy: 0.8726 - val_loss: 0.7495 - val_accuracy: 0.7242\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 14s 86ms/step - loss: 0.2048 - accuracy: 0.9318 - val_loss: 0.8866 - val_accuracy: 0.6897\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 14s 89ms/step - loss: 0.1056 - accuracy: 0.9645 - val_loss: 1.0284 - val_accuracy: 0.6866\n",
            "Number of hidden units:  300 dropout:  0\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 24s 153ms/step - loss: 1.0701 - accuracy: 0.5761 - val_loss: 0.7815 - val_accuracy: 0.7261\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 24s 151ms/step - loss: 0.5390 - accuracy: 0.8136 - val_loss: 0.7789 - val_accuracy: 0.7261\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 24s 151ms/step - loss: 0.2682 - accuracy: 0.9137 - val_loss: 0.9152 - val_accuracy: 0.7144\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 0.0992 - accuracy: 0.9693 - val_loss: 1.1930 - val_accuracy: 0.6890\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 0.0325 - accuracy: 0.9897 - val_loss: 1.5550 - val_accuracy: 0.6788\n",
            "Number of hidden units:  300 dropout:  0.25\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 25s 154ms/step - loss: 1.0736 - accuracy: 0.5724 - val_loss: 0.8053 - val_accuracy: 0.7210\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 24s 151ms/step - loss: 0.5557 - accuracy: 0.8047 - val_loss: 0.7684 - val_accuracy: 0.7250\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 0.3096 - accuracy: 0.8961 - val_loss: 0.8445 - val_accuracy: 0.7156\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 0.1401 - accuracy: 0.9549 - val_loss: 1.0613 - val_accuracy: 0.6823\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 0.0547 - accuracy: 0.9827 - val_loss: 1.3280 - val_accuracy: 0.6772\n",
            "Number of hidden units:  300 dropout:  0.35\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 25s 155ms/step - loss: 1.0791 - accuracy: 0.5674 - val_loss: 0.8215 - val_accuracy: 0.7167\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 0.5698 - accuracy: 0.7989 - val_loss: 0.7631 - val_accuracy: 0.7226\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 25s 153ms/step - loss: 0.3265 - accuracy: 0.8895 - val_loss: 0.8188 - val_accuracy: 0.7175\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 0.1522 - accuracy: 0.9509 - val_loss: 0.9853 - val_accuracy: 0.6917\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 0.0669 - accuracy: 0.9796 - val_loss: 1.2643 - val_accuracy: 0.6678\n",
            "Number of hidden units:  300 dropout:  0.5\n",
            "Epoch 1/5\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 1.0873 - accuracy: 0.5662 - val_loss: 0.8581 - val_accuracy: 0.7128\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 24s 151ms/step - loss: 0.5869 - accuracy: 0.7936 - val_loss: 0.7814 - val_accuracy: 0.7136\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 24s 150ms/step - loss: 0.3583 - accuracy: 0.8773 - val_loss: 0.7914 - val_accuracy: 0.7136\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 24s 150ms/step - loss: 0.1872 - accuracy: 0.9373 - val_loss: 0.9175 - val_accuracy: 0.6913\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 24s 150ms/step - loss: 0.0911 - accuracy: 0.9694 - val_loss: 1.1210 - val_accuracy: 0.6729\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRFXm4NO7U5S",
        "colab_type": "text"
      },
      "source": [
        "## Using CV: results closer to Kaggle \n",
        "\n",
        "Summary:\n",
        "\n",
        "Best CNN, one layer (emb = 100, 500 hu in Conv1D, 250 in Dense) - **72.6% on Kaggle**\n",
        "\n",
        " * CV seed 10: 73.82% (+/- 1.49%)\n",
        " * CV seed 1234: 73.65% (+/- 1.13%)\n",
        "\n",
        " \n",
        " Best GRU: Emb=128, GRU=256 - **72.38% on Kaggle (with Word2Vec embeddings)**\n",
        " \n",
        " * dropout=0, CV seed 10: 73.14% (+/- 1.18%)\n",
        " * dropout=0.3, CV seed 10: 73.38% (+/- 1.26%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM4vVrYG91uP",
        "colab_type": "text"
      },
      "source": [
        "### CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L_v0I2SWxab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d7c3ec14-86f2-480a-89fe-ba396c64c979"
      },
      "source": [
        "y = train[['label']]\n",
        "\n",
        "# adapted from https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 10\n",
        "np.random.seed(seed)\n",
        "\n",
        "# define 10-fold cross validation split\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "\n",
        "cvscores = []\n",
        "for train_, test_ in kfold.split(X, y):\n",
        "  Y = to_categorical(y)\n",
        "  # create model\n",
        "  np.random.seed(42)\n",
        "  random.seed(12345)\n",
        "  session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                inter_op_parallelism_threads=1)\n",
        "  tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(dict_len + 1, output_dim=100,\n",
        "                      input_length=20))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv1D(500,3,\n",
        "                  padding='same', \n",
        "                  activation='relu',\n",
        "                  strides=1))\n",
        "  model.add(GlobalMaxPooling1D())\n",
        "  model.add(Dense(250))\n",
        "  # model.add(Dropout(0.2)) # REMOVED DROPOUT HERE\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(5, activation=\"softmax\"))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  # save the best model\n",
        "  # filepath=\"accuracy-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "  filepath=\"weights.best.hdf5\"\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1)\n",
        "  callbacks_list = [checkpoint] \n",
        "  # earlystop = EarlyStopping(monitor='val_accuracy', verbose=1, patience=0)  # , patience=2 - how many epochs w/o improvement we allow\n",
        "  # Fit the model\n",
        "  model.fit(X[train_], Y[train_], validation_data = (X[test_], Y[test_]), epochs=7, batch_size=64,callbacks=callbacks_list,verbose=0)\n",
        "  # load the best model before evaluation, otherwise a model from the last epoch will be used.\n",
        "  model = load_model(\"weights.best.hdf5\")\n",
        "  scores = model.evaluate(X[test_], Y[test_], verbose=0)\n",
        "  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  cvscores.append(scores[1] * 100)\t\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.70657, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.70657 to 0.71049, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.71049 to 0.72770, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.72770\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.72770 to 0.73161, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.73161\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.73161\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 73.16%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.68936, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.68936 to 0.73005, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.73005 to 0.73083, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.73083 to 0.73474, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.73474 to 0.73709, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.73709\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.73709\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 73.71%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.70892, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.70892 to 0.73161, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.73161 to 0.73787, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.73787\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.73787 to 0.73944, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.73944\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.73944\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 73.94%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.69484, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.69484 to 0.71987, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.71987 to 0.72926, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.72926 to 0.73474, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.73474\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.73474\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.73474\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 73.47%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.70501, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.70501 to 0.72613, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.72613\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.72613 to 0.73239, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.73239\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.73239\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.73239\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 73.24%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.71909, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.71909 to 0.75117, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.75117 to 0.76526, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.76526 to 0.77387, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.77387\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.77387\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.77387\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 77.39%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.70814, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.70814 to 0.71987, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.71987 to 0.73944, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.73944\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.73944\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.73944\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.73944\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 73.94%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.67684, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.67684 to 0.71753, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.71753 to 0.72222, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.72222\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.72222\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.72222\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.72222\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 72.22%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.70814, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.70814 to 0.73239, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.73239 to 0.75274, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.75274\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.75274\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.75274\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.75274\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 75.27%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.67502, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.67502 to 0.71026, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.71026 to 0.71339, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.71339 to 0.71887, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.71887\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.71887\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.71887\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 71.89%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YctHjyVcPIVP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "0395c8ff-c928-454a-a165-4d2a341cf185"
      },
      "source": [
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "plt.plot(cvscores)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73.82% (+/- 1.49%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMcCJiEyKAU5EZFL/Hzqw2NbG+jFRAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x81mXsNGjoeU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "df5ee612-b3c1-48c7-906c-a425a55a82be"
      },
      "source": [
        "y = train[['label']]\n",
        "\n",
        "# adapted from https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 1234\n",
        "np.random.seed(seed)\n",
        "\n",
        "# define 10-fold cross validation split\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "\n",
        "cvscores = []\n",
        "for train_, test_ in kfold.split(X, y):\n",
        "  Y = to_categorical(y)\n",
        "  # create model\n",
        "  np.random.seed(42)\n",
        "  random.seed(12345)\n",
        "  session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                inter_op_parallelism_threads=1)\n",
        "  tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(dict_len + 1, output_dim=100,\n",
        "                      input_length=20))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv1D(500,3,\n",
        "                  padding='same', \n",
        "                  activation='relu',\n",
        "                  strides=1))\n",
        "  model.add(GlobalMaxPooling1D())\n",
        "  model.add(Dense(250))\n",
        "  # model.add(Dropout(0.2)) # REMOVED DROPOUT HERE\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(5, activation=\"softmax\"))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  # save the best model\n",
        "  # filepath=\"accuracy-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "  filepath=\"weights.best.hdf5\"\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1)\n",
        "  callbacks_list = [checkpoint] \n",
        "  # earlystop = EarlyStopping(monitor='val_accuracy', verbose=1, patience=0)  # , patience=2 - how many epochs w/o improvement we allow\n",
        "  # Fit the model\n",
        "  model.fit(X[train_], Y[train_], validation_data = (X[test_], Y[test_]), epochs=7, batch_size=64,callbacks=callbacks_list,verbose=0)\n",
        "  # load the best model before evaluation, otherwise a model from the last epoch will be used.\n",
        "  model = load_model(\"weights.best.hdf5\")\n",
        "  scores = model.evaluate(X[test_], Y[test_], verbose=0)\n",
        "  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  cvscores.append(scores[1] * 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.69797, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.69797 to 0.72222, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.72222 to 0.73318, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.73318 to 0.74022, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.74022\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.74022\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.74022\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 74.02%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.69484, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.69484 to 0.72457, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.72457 to 0.73083, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.73083\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.73083\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.73083\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.73083\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 73.08%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.69249, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.69249 to 0.74726, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.74726\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.74726\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.74726\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.74726\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.74726\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 74.73%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.70501, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.70501 to 0.72144, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.72144 to 0.72926, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.72926\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.72926\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.72926\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.72926\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 72.93%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.68936, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.68936 to 0.69562, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.69562 to 0.72144, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.72144\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.72144\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.72144\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.72144\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 72.14%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.71127, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.71127 to 0.74335, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.74335\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.74335 to 0.75587, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.75587 to 0.75822, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.75822\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.75822\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 75.82%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.68153, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.68153 to 0.71205, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.71205 to 0.73552, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.73552\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.73552\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.73552\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.73552\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 73.55%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.69875, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.69875 to 0.71909, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.71909 to 0.73083, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.73083 to 0.73787, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.73787 to 0.74257, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.74257\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.74257\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 74.26%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.70266, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.70266 to 0.71909, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.71909\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.71909\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.71909\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.71909\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.71909\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 71.91%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.71104, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.71104 to 0.73923, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.73923\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.73923 to 0.74080, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.74080\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.74080\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.74080\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 74.08%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxMIPbYRnpJU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "af5b062e-b489-43ee-84ed-98df717dc969"
      },
      "source": [
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "plt.plot(cvscores)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73.65% (+/- 1.13%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD7CAYAAABkO19ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWaI3xpgYZ4neGGNi3P8PEcGiho31J34AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAW2lrLSG2Dy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e2c6ac82-9389-4644-e5fb-f386106a247f"
      },
      "source": [
        "y = train[['label']]\n",
        "\n",
        "# adapted from https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 10\n",
        "np.random.seed(seed)\n",
        "\n",
        "# define 10-fold cross validation split\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "\n",
        "cvscores = []\n",
        "for train_, test_ in kfold.split(X, y):\n",
        "  Y = to_categorical(y)\n",
        "  # create model\n",
        "  np.random.seed(42)\n",
        "  random.seed(12345)\n",
        "  session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                inter_op_parallelism_threads=1)\n",
        "  tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(dict_len + 1, output_dim=128,\n",
        "                      input_length=20))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv1D(50, 3,\n",
        "  #  \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input.\n",
        "                  padding='same', # 0.4 points better with same\n",
        "                  activation='relu',\n",
        "                  strides=1))\n",
        "  model.add(Conv1D(100, 4,\n",
        "                  padding='same',\n",
        "                  activation='relu',\n",
        "                  strides=1))\n",
        "  model.add(GlobalMaxPooling1D())\n",
        "  model.add(Dense(250))\n",
        "  # model.add(Dropout(0.2)) # REMOVED DROPOUT HERE\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(5, activation=\"softmax\"))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  # save the best model\n",
        "  # filepath=\"accuracy-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "  filepath=\"weights.best.hdf5\"\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1)\n",
        "  callbacks_list = [checkpoint] \n",
        "  # earlystop = EarlyStopping(monitor='val_accuracy', verbose=1, patience=0)  # , patience=2 - how many epochs w/o improvement we allow\n",
        "  # Fit the model\n",
        "  model.fit(X[train_], Y[train_], validation_data = (X[test_], Y[test_]), epochs=7, batch_size=64,callbacks=callbacks_list,verbose=0)\n",
        "  # load the best model before evaluation, otherwise a model from the last epoch will be used.\n",
        "  model = load_model(\"weights.best.hdf5\")\n",
        "  scores = model.evaluate(X[test_], Y[test_], verbose=0)\n",
        "  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  cvscores.append(scores[1] * 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.67136, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.67136 to 0.68388, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.68388 to 0.73005, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.73005 to 0.74648, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.74648\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.74648\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.74648\n",
            "accuracy: 74.65%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.59937, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.59937 to 0.70501, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.70501 to 0.72457, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.72457\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.72457\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.72457\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.72457\n",
            "accuracy: 72.46%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.70266, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.70266 to 0.70501, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.70501 to 0.72926, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.72926 to 0.73631, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.73631 to 0.75039, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.75039\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.75039\n",
            "accuracy: 75.04%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.64554, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.64554 to 0.71674, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.71674 to 0.73005, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.73005\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.73005\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.73005\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.73005\n",
            "accuracy: 73.00%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.68153, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.68153 to 0.70657, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.70657 to 0.71518, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.71518\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.71518\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.71518\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.71518\n",
            "accuracy: 71.52%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.65493, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.65493 to 0.72770, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.72770 to 0.72848, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.72848 to 0.75117, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.75117\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.75117\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.75117\n",
            "accuracy: 75.12%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.67293, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.67293 to 0.71049, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.71049 to 0.73239, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.73239\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.73239\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.73239\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.73239\n",
            "accuracy: 73.24%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.61659, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.61659 to 0.70579, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.70579 to 0.71362, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.71362\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.71362\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.71362\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.71362\n",
            "accuracy: 71.36%\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.66588 to 0.71283, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.71283 to 0.73787, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.73787 to 0.74570, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.74570\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.74570\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.74570\n",
            "accuracy: 74.57%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.61942, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.61942 to 0.69851, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.69851\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.69851 to 0.71026, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.71026\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.71026\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.71026\n",
            "accuracy: 71.03%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv7BKDjjHvl9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "3e1eb2ca-53ee-4595-9234-012c7cbe7c7a"
      },
      "source": [
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "plt.plot(cvscores)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73.20% (+/- 1.50%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvuLblQbVgG6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4902060b-0a99-4ae6-f807-c6db4526c223"
      },
      "source": [
        "y = train[['label']]\n",
        "\n",
        "# adapted from https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 10\n",
        "np.random.seed(seed)\n",
        "\n",
        "# define 10-fold cross validation split\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "\n",
        "cvscores = []\n",
        "for train_, test_ in kfold.split(X, y):\n",
        "  Y = to_categorical(y)\n",
        "  # create model\n",
        "  np.random.seed(42)\n",
        "  random.seed(12345)\n",
        "  session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                inter_op_parallelism_threads=1)\n",
        "  tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(dict_len + 1, output_dim=128,\n",
        "                      input_length=20))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv1D(50, 3,\n",
        "  #  \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input.\n",
        "                  padding='same', # 0.4 points better with same\n",
        "                  activation='relu',\n",
        "                  strides=1))\n",
        "  model.add(Conv1D(100, 4,\n",
        "                  padding='same',\n",
        "                  activation='relu',\n",
        "                  strides=1))\n",
        "  model.add(GlobalMaxPooling1D())\n",
        "  model.add(Dense(250))\n",
        "  # model.add(Dropout(0.2)) # REMOVED DROPOUT HERE\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(5, activation=\"softmax\"))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  # save the best model\n",
        "  # filepath=\"accuracy-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "  filepath=\"weights.best.hdf5\"\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1)\n",
        "  earlystop = EarlyStopping(monitor='val_accuracy', verbose=1, patience=0)  # , patience=2 - how many epochs w/o improvement we allow\n",
        "  # Fit the model\n",
        "  model.fit(X[train_], Y[train_], validation_data = (X[test_], Y[test_]), epochs=7, batch_size=64,callbacks=[earlystop, checkpoint],verbose=0)\n",
        "  # load the best model before evaluation, otherwise a model from the last epoch will be used.\n",
        "  model = load_model(\"weights.best.hdf5\")\n",
        "  scores = model.evaluate(X[test_], Y[test_], verbose=0)\n",
        "  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  cvscores.append(scores[1] * 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.67136, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.67136 to 0.68388, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.68388 to 0.73005, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.73005 to 0.74648, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.74648\n",
            "Epoch 00005: early stopping\n",
            "accuracy: 74.65%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.59937, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.59937 to 0.70501, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.70501 to 0.72457, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.72457\n",
            "Epoch 00004: early stopping\n",
            "accuracy: 72.46%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.70266, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.70266 to 0.70501, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.70501 to 0.72926, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.72926 to 0.73631, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.73631 to 0.75039, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.75039\n",
            "Epoch 00006: early stopping\n",
            "accuracy: 75.04%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.64554, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.64554 to 0.71674, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.71674 to 0.73005, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.73005\n",
            "Epoch 00004: early stopping\n",
            "accuracy: 73.00%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.68153, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.68153 to 0.70657, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.70657 to 0.71518, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.71518\n",
            "Epoch 00004: early stopping\n",
            "accuracy: 71.52%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.65493, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.65493 to 0.72770, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.72770 to 0.72848, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.72848 to 0.75117, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.75117\n",
            "Epoch 00005: early stopping\n",
            "accuracy: 75.12%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.67293, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.67293 to 0.71049, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.71049 to 0.73239, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.73239\n",
            "Epoch 00004: early stopping\n",
            "accuracy: 73.24%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.61659, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.61659 to 0.70579, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.70579 to 0.71362, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.71362\n",
            "Epoch 00004: early stopping\n",
            "accuracy: 71.36%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.66588, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.66588 to 0.71283, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.71283 to 0.73787, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.73787 to 0.74570, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.74570\n",
            "Epoch 00005: early stopping\n",
            "accuracy: 74.57%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.61942, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.61942 to 0.69851, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.69851\n",
            "Epoch 00003: early stopping\n",
            "accuracy: 69.85%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTVwFTBheA_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "43786e4a-9089-4fea-b934-60373e1514f3"
      },
      "source": [
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "plt.plot(cvscores)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73.08% (+/- 1.70%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o38oVODgmezu",
        "colab_type": "text"
      },
      "source": [
        "#### Best model from Bayesian Optimization (from a separate file)\n",
        "\n",
        "| iter | target | CNN_HU | DENSE_HU | EMB_SIZE | KERNEL | drop1 | drop2 | drop3 |\n",
        "|----------------|-------------|----------|----------------||----------------|-------------|----------|----------------|\n",
        "|  8        |  73.17    |  315.1    |  514.3    |  170.5    |  2.986    |  0.2751   |  0.3692   |  0.5      |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBFkdirrhfuC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "5fa5927b-0840-4953-ac68-b61bdf9111a4"
      },
      "source": [
        "y = train[['label']]\n",
        "\n",
        "CNN_HU = 315\n",
        "DENSE_HU = 514\n",
        "EMB_SIZE = 170\n",
        "KERNEL = 2\n",
        "drop1 = 0.2751\n",
        "drop2 = 0.3692\n",
        "drop3 = 0.5\n",
        "\n",
        "\n",
        "# adapted from https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 10\n",
        "np.random.seed(seed)\n",
        "\n",
        "# define 10-fold cross validation split\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "\n",
        "cvscores = []\n",
        "for train_, test_ in kfold.split(X, y):\n",
        "  Y = to_categorical(y)\n",
        "  # create model\n",
        "  np.random.seed(42)\n",
        "  random.seed(12345)\n",
        "  session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                inter_op_parallelism_threads=1)\n",
        "  tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(dict_len + 1, output_dim=int(EMB_SIZE),input_length=20))\n",
        "  model.add(Dropout(drop1))\n",
        "  model.add(Conv1D(filters=int(CNN_HU), kernel_size=int(KERNEL),\n",
        "                  padding='same', activation='relu', strides=1))\n",
        "  model.add(GlobalMaxPooling1D())\n",
        "  model.add(Dropout(drop2)) \n",
        "  model.add(Dense(int(DENSE_HU)))\n",
        "  model.add(Dropout(drop3)) \n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(5, activation=\"softmax\"))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  # here we save just model history and extract max val_cc from it.\n",
        "  earlystop = EarlyStopping(monitor='val_accuracy', verbose=1, patience=0)  # , patience=2 - how many epochs w/o improvement we allow\n",
        "  history = model.fit(X[train_], Y[train_], validation_data = (X[test_], Y[test_]), epochs=7, batch_size=64,callbacks=[earlystop],verbose=0) #, checkpoint\n",
        "  max(history.history[\"val_accuracy\"]) # extract mav val_accuracy from the trained model.\n",
        "  print(\"%s: %.2f%%\" % (\"validation accuracy: \", max(history.history[\"val_accuracy\"])*100))\n",
        "  cvscores.append(max(history.history[\"val_accuracy\"]) * 100)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 00004: early stopping\n",
            "validation accuracy: : 73.55%\n",
            "Epoch 00004: early stopping\n",
            "validation accuracy: : 73.55%\n",
            "Epoch 00005: early stopping\n",
            "validation accuracy: : 75.27%\n",
            "Epoch 00004: early stopping\n",
            "validation accuracy: : 73.08%\n",
            "Epoch 00003: early stopping\n",
            "validation accuracy: : 71.36%\n",
            "Epoch 00004: early stopping\n",
            "validation accuracy: : 75.27%\n",
            "Epoch 00005: early stopping\n",
            "validation accuracy: : 73.00%\n",
            "Epoch 00004: early stopping\n",
            "validation accuracy: : 72.38%\n",
            "Epoch 00004: early stopping\n",
            "validation accuracy: : 75.20%\n",
            "Epoch 00006: early stopping\n",
            "validation accuracy: : 72.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnNLWVInihQ6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "e2160016-f77b-42d9-8ac6-329646e2d7c2"
      },
      "source": [
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "plt.plot(cvscores)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73.53% (+/- 1.27%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r2in39sipmeF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "7fb98126-d84c-47bc-87d3-3e83bef5221f"
      },
      "source": [
        "y = train[['label']]\n",
        "\n",
        "CNN_HU = 315\n",
        "DENSE_HU = 514\n",
        "EMB_SIZE = 170\n",
        "KERNEL = 2\n",
        "drop1 = 0.2751\n",
        "drop2 = 0.3692\n",
        "drop3 = 0.5\n",
        "\n",
        "\n",
        "# adapted from https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 10\n",
        "np.random.seed(seed)\n",
        "\n",
        "# define 5-fold cross validation split\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "\n",
        "cvscores = []\n",
        "for train_, test_ in kfold.split(X, y):\n",
        "  Y = to_categorical(y)\n",
        "  # create model\n",
        "  np.random.seed(42)\n",
        "  random.seed(12345)\n",
        "  session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                inter_op_parallelism_threads=1)\n",
        "  tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(dict_len + 1, output_dim=int(EMB_SIZE),input_length=20))\n",
        "  model.add(Dropout(drop1))\n",
        "  model.add(Conv1D(filters=int(CNN_HU), kernel_size=int(KERNEL),\n",
        "                  padding='same', activation='relu', strides=1))\n",
        "  model.add(GlobalMaxPooling1D())\n",
        "  model.add(Dropout(drop2)) \n",
        "  model.add(Dense(int(DENSE_HU)))\n",
        "  model.add(Dropout(drop3)) \n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(5, activation=\"softmax\"))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  # here we save just model history and extract max val_cc from it.\n",
        "  earlystop = EarlyStopping(monitor='val_accuracy', verbose=1, patience=0)  # , patience=2 - how many epochs w/o improvement we allow\n",
        "  history = model.fit(X[train_], Y[train_], validation_data = (X[test_], Y[test_]), epochs=7, batch_size=64,callbacks=[earlystop],verbose=0) #, checkpoint\n",
        "  max(history.history[\"val_accuracy\"]) # extract mav val_accuracy from the trained model.\n",
        "  print(\"%s: %.2f%%\" % (\"validation accuracy: \", max(history.history[\"val_accuracy\"])*100))\n",
        "  cvscores.append(max(history.history[\"val_accuracy\"]) * 100)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 00004: early stopping\n",
            "validation accuracy: : 73.47%\n",
            "Epoch 00006: early stopping\n",
            "validation accuracy: : 73.04%\n",
            "Epoch 00006: early stopping\n",
            "validation accuracy: : 73.20%\n",
            "Epoch 00004: early stopping\n",
            "validation accuracy: : 72.18%\n",
            "Epoch 00004: early stopping\n",
            "validation accuracy: : 72.95%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C21aUdbuwkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "529f32a1-23a8-4b6b-da80-3beaeabe8fa2"
      },
      "source": [
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "plt.plot(cvscores)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "72.97% (+/- 0.43%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuUbhV2aq7KB",
        "colab_type": "text"
      },
      "source": [
        "### GRU\n",
        "\n",
        "Emb=128, GRU=256, drop=0 or drop=0.3\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2JzyV2LEkQ9A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ef769171-8e41-4991-9419-844f9d0c87c3"
      },
      "source": [
        "y = train[['label']]\n",
        "\n",
        "# adapted from https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 10\n",
        "np.random.seed(seed)\n",
        "\n",
        "# define 10-fold cross validation split\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "\n",
        "cvscores = []\n",
        "for train_, test_ in kfold.split(X, y):\n",
        "  Y = to_categorical(y)\n",
        "  # create model\n",
        "  np.random.seed(42)\n",
        "  random.seed(12345)\n",
        "  session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                inter_op_parallelism_threads=1)\n",
        "  tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(dict_len + 1, output_dim=128)) \n",
        "  model.add(GRU(256, dropout=0)) \n",
        "  model.add(Dense(5, activation=\"softmax\"))  \n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  # save the best model\n",
        "  # filepath=\"accuracy-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "  filepath=\"weights.best.hdf5\"\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1)\n",
        "  callbacks_list = [checkpoint] \n",
        "  # earlystop = EarlyStopping(monitor='val_accuracy', verbose=1, patience=0)  # , patience=2 - how many epochs w/o improvement we allow\n",
        "  # Fit the model\n",
        "  model.fit(X[train_], Y[train_], validation_data = (X[test_], Y[test_]), epochs=7, batch_size=64,callbacks=callbacks_list,verbose=0)\n",
        "  # load the best model before evaluation, otherwise a model from the last epoch will be used.\n",
        "  model = load_model(\"weights.best.hdf5\")\n",
        "  scores = model.evaluate(X[test_], Y[test_], verbose=0)\n",
        "  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  cvscores.append(scores[1] * 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 60\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.69014, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.69014 to 0.71831, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.71831 to 0.72144, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.72144 to 0.73239, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.73239 to 0.73474, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.73474\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.73474\n",
            "accuracy: 73.47%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.70736, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.70736 to 0.72222, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.72222\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.72222 to 0.73396, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.73396\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.73396\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.73396\n",
            "accuracy: 73.40%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.69797, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.69797 to 0.70266, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.70266 to 0.73161, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.73161 to 0.74491, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.74491 to 0.74883, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.74883\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.74883\n",
            "accuracy: 74.88%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.67762, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.67762 to 0.71831, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.71831 to 0.72613, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.72613\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.72613\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.72613\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.72613\n",
            "accuracy: 72.61%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.68779, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.68779 to 0.70423, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.70423 to 0.71049, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.71049 to 0.72066, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.72066\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.72066\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.72066\n",
            "accuracy: 72.07%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.68858, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.68858 to 0.73944, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.73944 to 0.74883, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.74883\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.74883\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.74883\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.74883\n",
            "accuracy: 74.88%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.70188, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.70188 to 0.72066, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.72066 to 0.72770, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.72770\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.72770\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.72770\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.72770\n",
            "accuracy: 72.77%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.68701, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.68701 to 0.71127, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.71127\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.71127\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.71127\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.71127\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.71127\n",
            "accuracy: 71.13%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.71909, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.71909 to 0.73239, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.73239 to 0.73318, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.73318 to 0.74100, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.74100\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.74100\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.74100\n",
            "accuracy: 74.10%\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.66719, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.66719 to 0.70164, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.70164 to 0.70399, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.70399 to 0.72044, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.72044\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.72044\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.72044\n",
            "accuracy: 72.04%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CWFAzyxpdrv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "28407d54-3736-4224-81ed-5306cae2997d"
      },
      "source": [
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "plt.plot(cvscores)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73.14% (+/- 1.18%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD5CAYAAAAp8/5SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbT4LuW7lByP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d33211a1-632e-4142-e83c-30a612373a8e"
      },
      "source": [
        "# DROPOUT increased from 0 to 0.3\n",
        "y = train[['label']]\n",
        "\n",
        "# adapted from https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 10\n",
        "np.random.seed(seed)\n",
        "\n",
        "# define 10-fold cross validation split\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "\n",
        "cvscores = []\n",
        "for train_, test_ in kfold.split(X, y):\n",
        "  Y = to_categorical(y)\n",
        "  # create model\n",
        "  np.random.seed(42)\n",
        "  random.seed(12345)\n",
        "  session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                inter_op_parallelism_threads=1)\n",
        "  tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(dict_len + 1, output_dim=128)) \n",
        "  model.add(GRU(256, dropout=0.3)) \n",
        "  model.add(Dense(5, activation=\"softmax\"))  \n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  # save the best model\n",
        "  # filepath=\"accuracy-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "  filepath=\"weights.best.hdf5\"\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1)\n",
        "  callbacks_list = [checkpoint] \n",
        "  # earlystop = EarlyStopping(monitor='val_accuracy', verbose=1, patience=0)  # , patience=2 - how many epochs w/o improvement we allow\n",
        "  # Fit the model\n",
        "  model.fit(X[train_], Y[train_], validation_data = (X[test_], Y[test_]), epochs=7, batch_size=64,callbacks=callbacks_list,verbose=0)\n",
        "  # load the best model before evaluation, otherwise a model from the last epoch will be used.\n",
        "  model = load_model(\"weights.best.hdf5\")\n",
        "  scores = model.evaluate(X[test_], Y[test_], verbose=0)\n",
        "  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  cvscores.append(scores[1] * 100)\t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.68701 to 0.70266, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.70266 to 0.72222, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.72222 to 0.74257, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.74257 to 0.74883, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.74883\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.74883\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 74.88%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.69405, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.69405 to 0.71283, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.71283 to 0.71596, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.71596 to 0.73083, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.73083\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.73083\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.73083\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 73.08%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.68388, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.68388 to 0.71283, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.71283 to 0.73552, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.73552\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.73552 to 0.73944, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.73944 to 0.74178, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.74178\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 74.18%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.68779, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.68779 to 0.71831, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.71831 to 0.72770, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.72770 to 0.73239, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.73239\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.73239\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.73239\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 73.24%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.68466, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.68466 to 0.70579, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.70579 to 0.71283, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.71283 to 0.72066, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.72066\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.72066\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.72066\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 72.07%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.67919, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.67919 to 0.73944, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.73944 to 0.74022, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.74022 to 0.74413, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.74413 to 0.75430, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.75430\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.75430\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 75.43%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.68779, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.68779 to 0.71753, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.71753 to 0.72379, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.72379\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.72379\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.72379\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.72379 to 0.72692, saving model to weights.best.hdf5\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 72.69%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.65962, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.65962 to 0.69953, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.69953 to 0.70736, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.70736 to 0.71596, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.71596\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.71596\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.71596\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 71.60%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.69797, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.69797 to 0.72770, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.72770 to 0.73787, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.73787 to 0.74570, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.74570\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.74570\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.74570\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 74.57%\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.67110, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.67110 to 0.68442, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.68442 to 0.69616, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.69616 to 0.71261, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.71261 to 0.71652, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.71652 to 0.72044, saving model to weights.best.hdf5\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.72044\n",
            "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "accuracy: 72.04%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPIj5LVjpjaw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "772d6c82-a545-450e-dc64-4175173f6636"
      },
      "source": [
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "plt.plot(cvscores)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73.38% (+/- 1.26%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naFzXI0Y6AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0d_RZCLwtvt",
        "colab_type": "text"
      },
      "source": [
        "## Using Word2Vec by Google\n",
        "\n",
        "Incrementally better with Word2Vec in LSTM and CNN\n",
        "\n",
        "LSTM emb=300, 128 hu, dropout = 0.2:\n",
        "\n",
        " * no pre-trained emb: 0.7410\n",
        " * with Word2Vec: 0.7423\n",
        "\n",
        "CNN emb = 300, 500 hum 250 in Dense\n",
        "\n",
        " * no pre-trained emb: 0.7426\n",
        " * with Word2Vec:0.7453\n",
        "\n",
        "GRU emb=300, 256 hu in GRU, dropout = 0.3: 0.7410/0.7406\n",
        "\n",
        "GRU emb=300, 128 hu in GRU, dropout = 0.3: 0.7422/0.7422\n",
        "\n",
        "GRU emb=300, 128 hu in GRU, dropout = 0.2: 0.7426/0.7430\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxKhsvEzJSbK",
        "colab_type": "text"
      },
      "source": [
        "#### Splitting data again: making dictionary only on the train set (minus validation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U-mkUw1Cm5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "title_train, title_test, Y_train, Y_test = train_test_split(\n",
        "    train.title, Y, test_size=0.2, random_state=1234, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdzYBwaTDrGv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "40741a57-9e4a-470f-f014-0dd960aedf96"
      },
      "source": [
        "title_train[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    interactive visual exploration of neighbor bas...\n",
              "1    relational division four algorithms and their ...\n",
              "2    simplifying xml schema effortless handling of ...\n",
              "3    funbase a function based information managemen...\n",
              "4    inverted matrix efficient discovery of frequen...\n",
              "5    computational aspects of covering in dominance...\n",
              "6    feaspar   a feature structure parser learning ...\n",
              "7    assessing the scenic route measuring the value...\n",
              "8    webanywhere enabling a screen reading interfac...\n",
              "9    non standard semantics for the method of tempo...\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol4tkV4GDWa6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "6061848d-7463-4f0d-9b2b-ce569d6b8b4c"
      },
      "source": [
        "# tokenize train data\n",
        "NUM_WORDS = 10000 # keep top 10000 words in a dictionary, can be changed later\n",
        "tokenizer = Tokenizer(num_words=NUM_WORDS)\n",
        "tokenizer.fit_on_texts(title_train)\n",
        "X_train = tokenizer.texts_to_sequences(title_train)\n",
        "X_train = pad_sequences(X_train, maxlen=20)\n",
        "X_train[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  157,\n",
              "         255,  406,    2,  847,    9,  123,    5,    8,  191],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,   46, 2062, 1460,   64,    4,  421,   56],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "        2434,   62,  225, 4073,  574,    2, 1796, 1629,  624],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0, 4074,    3,  279,    9,   17,   50,   16],\n",
              "       [   0,    0,    0,    0,  916,  515,   30,  210,    2,  407, 1119,\n",
              "           5,   44,  516,    5,    6,  116,    2,  157,   34],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,  265,  575,    2, 2063,    5, 1461,  182],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 4075,\n",
              "           3,  126,   66,  376,   14,    7, 1337,  394,   27],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,  802,    6, 4076, 1462,\n",
              "         517,    6,  214,    2,   24, 2985,    5,   15,  917],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0, 4077, 1630,    3,\n",
              "        4078, 1219,  296,    1,    6,   15,   11, 2064,   49],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "         124,  918,  103,    1,    6,   74,    2,   71, 1631]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y54GmwhQEPCA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "1d20080e-a579-476d-8f6e-e94b08d081a9"
      },
      "source": [
        "title_test[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10223    modeling chinese documents with topical word c...\n",
              "10224    software engineering for distributed applicati...\n",
              "10225    bin completion algorithms for multicontainer p...\n",
              "10226    using relational operators to structure long t...\n",
              "10227    partially synchronized dec mdps in dynamic mec...\n",
              "10228     disambiguating and interpreting verb definitions\n",
              "10229    user software engineering and the design of in...\n",
              "10230    a generation model to unify topic relevance an...\n",
              "10231                 contracting in the days of ebusiness\n",
              "10232                comparing hybrid peer to peer systems\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8QaU-yeEApT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "87cece60-e3e9-4932-cc88-c2b085db3061"
      },
      "source": [
        "# tokenize test data\n",
        "X_test = tokenizer.texts_to_sequences(title_test)\n",
        "X_test = pad_sequences(X_test, maxlen=20)\n",
        "X_test[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,   78,  268,  146,   10, 1346,  100, 1854,   32],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,   28,   65,    1,   40,   70,    6,   38,  261],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0, 2918, 1862,   64,    1, 2654,    4, 2063,  176],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,   12,   46, 1003,    7,   66,  948,  290,  127],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,  818, 1604, 7853,  996,    5,   54,  478,   38],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0, 5814,    4, 2431, 1118, 1194],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          79,   28,   65,    4,    6,   38,    2,  157,   19],\n",
              "       [   0,    0,    0,    0,    0,    0,    3,   72,   21,    7, 5721,\n",
              "         186,  151,    4,  520,    9,  789,    1,  929,   22],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    5,    6, 4334,    2],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,  757,  297,  197,    7,  197,   19]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiemsF3AFH_f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "bc317bc4-cc53-4c07-d439-285ddf21ab41"
      },
      "source": [
        "test.title[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    autodomainmine a graphical data mining system ...\n",
              "1    anipqo almost non intrusive parametric query o...\n",
              "2    selection and ranking of text from highly impe...\n",
              "3    conditional random fields for multi agent rein...\n",
              "4                 multi dimensional description logics\n",
              "5    fast on line index construction by geometric p...\n",
              "6                                reasoning about rings\n",
              "7    transductive regression piloted by inter manif...\n",
              "8    a fast and usually linear algorithm for global...\n",
              "9    conditional constraint satisfaction logical fo...\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agQ8C0pC2v6L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "43a92ae0-31a2-4f59-caf2-7be310419a72"
      },
      "source": [
        "# tokenize new data for Kaggle upload\n",
        "X_new = tokenizer.texts_to_sequences(test.title)\n",
        "X_new = pad_sequences(X_new, maxlen=20)\n",
        "X_new[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    3,  456,    8,   34,   16,    1,  136,   63],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "        1501,  124,  715,   20,   63,    1, 1304,  257,  298],\n",
              "       [   0,    0,    0,    0,    0,    0,   99,    4,  121,    2,   39,\n",
              "          23,  886, 1958, 5867,    1,   22,    2,  524,  175],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,  342,  234,  837,    1,   47,  247,  392,   14],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,   47,  195,  295,  559],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,  111,   11,  358,  285,  275,   33,  983,  539],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,   67,  291, 8228],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0, 2157,  318, 4643,   33, 1233, 2043,  189],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    3,\n",
              "         111,    4, 4086,  140,   57,    1,  305,  245,   25],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,  342,  149,  683,  360, 1259,    4,  193]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPdJONGm16mj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e5efd5d8-92cb-41a5-8d1d-3d49389f9bab"
      },
      "source": [
        "# find a number of unique tokens\n",
        "word2index = tokenizer.word_index # create a dictionary\n",
        "print('Found %s unique tokens.' % len(word2index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8357 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJI6rOP63oLh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "50dbf27f-ba70-40da-fc1f-6a1cc29b1d1f"
      },
      "source": [
        "word2index.items() # explore our dictionary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('for', 1), ('of', 2), ('a', 3), ('and', 4), ('in', 5), ('the', 6), ('to', 7), ('data', 8), ('based', 9), ('with', 10), ('on', 11), ('using', 12), ('an', 13), ('learning', 14), ('web', 15), ('system', 16), ('information', 17), ('database', 18), ('systems', 19), ('query', 20), ('model', 21), ('retrieval', 22), ('from', 23), ('search', 24), ('analysis', 25), ('approach', 26), ('language', 27), ('software', 28), ('databases', 29), ('efficient', 30), ('semantic', 31), ('models', 32), ('by', 33), ('mining', 34), ('knowledge', 35), ('programming', 36), ('time', 37), ('design', 38), ('text', 39), ('distributed', 40), ('processing', 41), ('queries', 42), ('object', 43), ('large', 44), ('evaluation', 45), ('relational', 46), ('multi', 47), ('oriented', 48), ('computer', 49), ('management', 50), ('automatic', 51), ('classification', 52), ('clustering', 53), ('dynamic', 54), ('logic', 55), ('performance', 56), ('algorithm', 57), ('translation', 58), ('machine', 59), ('networks', 60), ('document', 61), ('xml', 62), ('optimization', 63), ('algorithms', 64), ('engineering', 65), ('structure', 66), ('reasoning', 67), ('detection', 68), ('framework', 69), ('applications', 70), ('temporal', 71), ('generation', 72), ('study', 73), ('method', 74), ('programs', 75), ('parsing', 76), ('multiple', 77), ('modeling', 78), ('user', 79), ('high', 80), ('extraction', 81), ('parallel', 82), ('as', 83), ('case', 84), ('probabilistic', 85), ('program', 86), ('application', 87), ('network', 88), ('towards', 89), ('support', 90), ('planning', 91), ('control', 92), ('development', 93), ('new', 94), ('statistical', 95), ('course', 96), ('science', 97), ('via', 98), ('selection', 99), ('word', 100), ('tree', 101), ('through', 102), ('semantics', 103), ('rules', 104), ('natural', 105), ('environment', 106), ('teaching', 107), ('structured', 108), ('problem', 109), ('methods', 110), ('fast', 111), ('real', 112), ('indexing', 113), ('adaptive', 114), ('theory', 115), ('context', 116), ('online', 117), ('graph', 118), ('constraints', 119), ('tool', 120), ('ranking', 121), ('hierarchical', 122), ('patterns', 123), ('non', 124), ('techniques', 125), ('feature', 126), ('memory', 127), ('similarity', 128), ('order', 129), ('domain', 130), ('access', 131), ('into', 132), ('architecture', 133), ('computing', 134), ('languages', 135), ('process', 136), ('scale', 137), ('implementation', 138), ('inference', 139), ('linear', 140), ('estimation', 141), ('representation', 142), ('incremental', 143), ('structures', 144), ('integration', 145), ('documents', 146), ('first', 147), ('code', 148), ('constraint', 149), ('complex', 150), ('relevance', 151), ('over', 152), ('improving', 153), ('its', 154), ('level', 155), ('integrating', 156), ('interactive', 157), ('active', 158), ('recognition', 159), ('supervised', 160), ('base', 161), ('semi', 162), ('between', 163), ('optimal', 164), ('at', 165), ('type', 166), ('driven', 167), ('social', 168), ('objects', 169), ('answering', 170), ('local', 171), ('combining', 172), ('effective', 173), ('state', 174), ('content', 175), ('problems', 176), ('matching', 177), ('resolution', 178), ('rule', 179), ('trees', 180), ('join', 181), ('graphs', 182), ('is', 183), ('space', 184), ('decision', 185), ('topic', 186), ('feedback', 187), ('collaborative', 188), ('relations', 189), ('use', 190), ('streams', 191), ('automated', 192), ('complexity', 193), ('generalized', 194), ('dimensional', 195), ('bayesian', 196), ('peer', 197), ('comparison', 198), ('filtering', 199), ('exploiting', 200), ('grammar', 201), ('syntactic', 202), ('computation', 203), ('speech', 204), ('acquisition', 205), ('spatial', 206), ('prediction', 207), ('image', 208), ('services', 209), ('discovery', 210), ('pattern', 211), ('quality', 212), ('testing', 213), ('value', 214), ('mobile', 215), ('class', 216), ('querying', 217), ('two', 218), ('views', 219), ('dependency', 220), ('solving', 221), ('integrated', 222), ('supporting', 223), ('test', 224), ('schema', 225), ('understanding', 226), ('java', 227), ('finding', 228), ('scalable', 229), ('practical', 230), ('execution', 231), ('functional', 232), ('abstract', 233), ('random', 234), ('cross', 235), ('robust', 236), ('building', 237), ('heterogeneous', 238), ('strategies', 239), ('concurrent', 240), ('transaction', 241), ('research', 242), ('view', 243), ('report', 244), ('flow', 245), ('grammars', 246), ('agent', 247), ('self', 248), ('partial', 249), ('unsupervised', 250), ('japanese', 251), ('approximate', 252), ('formal', 253), ('results', 254), ('visual', 255), ('generating', 256), ('cost', 257), ('processes', 258), ('types', 259), ('domains', 260), ('project', 261), ('students', 262), ('verification', 263), ('features', 264), ('computational', 265), ('bases', 266), ('evaluating', 267), ('chinese', 268), ('question', 269), ('lexical', 270), ('engine', 271), ('general', 272), ('concept', 273), ('disambiguation', 274), ('construction', 275), ('kernel', 276), ('summarization', 277), ('event', 278), ('function', 279), ('experience', 280), ('service', 281), ('extracting', 282), ('how', 283), ('set', 284), ('index', 285), ('free', 286), ('markov', 287), ('concurrency', 288), ('association', 289), ('term', 290), ('about', 291), ('corpus', 292), ('simple', 293), ('requirements', 294), ('description', 295), ('interface', 296), ('hybrid', 297), ('functions', 298), ('machines', 299), ('path', 300), ('extended', 301), ('behavior', 302), ('games', 303), ('stream', 304), ('global', 305), ('technique', 306), ('file', 307), ('interaction', 308), ('segmentation', 309), ('sql', 310), ('english', 311), ('specification', 312), ('detecting', 313), ('interpretation', 314), ('training', 315), ('storage', 316), ('environments', 317), ('regression', 318), ('vector', 319), ('linguistic', 320), ('checking', 321), ('evolution', 322), ('stochastic', 323), ('concepts', 324), ('collection', 325), ('scheduling', 326), ('human', 327), ('scheme', 328), ('sets', 329), ('open', 330), ('sense', 331), ('multimedia', 332), ('categorization', 333), ('corpora', 334), ('consistency', 335), ('empirical', 336), ('without', 337), ('making', 338), ('introductory', 339), ('experiments', 340), ('conceptual', 341), ('conditional', 342), ('privacy', 343), ('security', 344), ('monitoring', 345), ('identification', 346), ('sources', 347), ('role', 348), ('curriculum', 349), ('source', 350), ('maintenance', 351), ('allocation', 352), ('optimizing', 353), ('intelligent', 354), ('server', 355), ('tracking', 356), ('entity', 357), ('line', 358), ('k', 359), ('logical', 360), ('independent', 361), ('visualization', 362), ('expert', 363), ('continuous', 364), ('sampling', 365), ('experimental', 366), ('improved', 367), ('task', 368), ('robot', 369), ('transfer', 370), ('projects', 371), ('dbms', 372), ('relationship', 373), ('sensitive', 374), ('undergraduate', 375), ('parser', 376), ('tools', 377), ('ontology', 378), ('sequential', 379), ('caching', 380), ('workshop', 381), ('recursive', 382), ('world', 383), ('representations', 384), ('predicting', 385), ('are', 386), ('improve', 387), ('latent', 388), ('form', 389), ('one', 390), ('dialogue', 391), ('reinforcement', 392), ('heuristic', 393), ('spoken', 394), ('unified', 395), ('compiler', 396), ('structural', 397), ('mapping', 398), ('searching', 399), ('abstraction', 400), ('aware', 401), ('aggregation', 402), ('dependencies', 403), ('measures', 404), ('discovering', 405), ('exploration', 406), ('frequent', 407), ('directed', 408), ('component', 409), ('pages', 410), ('link', 411), ('error', 412), ('what', 413), ('top', 414), ('some', 415), ('discourse', 416), ('preserving', 417), ('users', 418), ('unification', 419), ('alignment', 420), ('their', 421), ('classifiers', 422), ('strategy', 423), ('decomposition', 424), ('propagation', 425), ('it', 426), ('static', 427), ('intelligence', 428), ('agents', 429), ('series', 430), ('calculus', 431), ('that', 432), ('plans', 433), ('spaces', 434), ('community', 435), ('expansion', 436), ('rank', 437), ('sequence', 438), ('induction', 439), ('modelling', 440), ('perspective', 441), ('approximation', 442), ('cs', 443), ('game', 444), ('descriptions', 445), ('page', 446), ('more', 447), ('transactions', 448), ('or', 449), ('deductive', 450), ('weighted', 451), ('sensor', 452), ('recovery', 453), ('distance', 454), ('constrained', 455), ('graphical', 456), ('maximum', 457), ('flexible', 458), ('joins', 459), ('virtual', 460), ('incorporating', 461), ('experiences', 462), ('specific', 463), ('toward', 464), ('architectures', 465), ('under', 466), ('exploring', 467), ('organization', 468), ('approaches', 469), ('resource', 470), ('courses', 471), ('pruning', 472), ('effects', 473), ('belief', 474), ('co', 475), ('browsing', 476), ('operations', 477), ('mechanism', 478), ('tagging', 479), ('specifications', 480), ('up', 481), ('automatically', 482), ('annotation', 483), ('neural', 484), ('internet', 485), ('analyzing', 486), ('plan', 487), ('interfaces', 488), ('action', 489), ('relation', 490), ('education', 491), ('novel', 492), ('comparative', 493), ('transformation', 494), ('issues', 495), ('effectiveness', 496), ('classes', 497), ('implementing', 498), ('technology', 499), ('cache', 500), ('estimating', 501), ('communication', 502), ('texts', 503), ('update', 504), ('boosting', 505), ('auctions', 506), ('not', 507), ('beyond', 508), ('product', 509), ('group', 510), ('dictionary', 511), ('metric', 512), ('c', 513), ('extending', 514), ('matrix', 515), ('datasets', 516), ('measuring', 517), ('cooperative', 518), ('bilingual', 519), ('lexicon', 520), ('finite', 521), ('sharing', 522), ('efficiency', 523), ('video', 524), ('laboratory', 525), ('production', 526), ('incomplete', 527), ('vs', 528), ('advanced', 529), ('assessment', 530), ('labeling', 531), ('when', 532), ('example', 533), ('good', 534), ('methodology', 535), ('ir', 536), ('operating', 537), ('boolean', 538), ('partitioning', 539), ('digital', 540), ('phrase', 541), ('algebra', 542), ('artificial', 543), ('properties', 544), ('b', 545), ('very', 546), ('personalized', 547), ('named', 548), ('collections', 549), ('identifying', 550), ('business', 551), ('common', 552), ('discriminative', 553), ('low', 554), ('theoretic', 555), ('modular', 556), ('prolog', 557), ('practice', 558), ('logics', 559), ('morphological', 560), ('debugging', 561), ('impact', 562), ('dependence', 563), ('higher', 564), ('causal', 565), ('power', 566), ('coordination', 567), ('probability', 568), ('cluster', 569), ('engines', 570), ('iterative', 571), ('generic', 572), ('hashing', 573), ('handling', 574), ('aspects', 575), ('n', 576), ('reduction', 577), ('mixture', 578), ('hash', 579), ('shared', 580), ('words', 581), ('qualitative', 582), ('reuse', 583), ('policies', 584), ('integrity', 585), ('ordering', 586), ('cs1', 587), ('can', 588), ('olap', 589), ('preferences', 590), ('representing', 591), ('resources', 592), ('student', 593), ('ad', 594), ('sentence', 595), ('components', 596), ('do', 597), ('goal', 598), ('tasks', 599), ('examples', 600), ('updates', 601), ('schemes', 602), ('indexes', 603), ('typed', 604), ('nested', 605), ('entropy', 606), ('scientific', 607), ('sites', 608), ('prototype', 609), ('aggregate', 610), ('hierarchies', 611), ('attribute', 612), ('efficiently', 613), ('principles', 614), ('extensible', 615), ('best', 616), ('utility', 617), ('multidimensional', 618), ('range', 619), ('uncertainty', 620), ('small', 621), ('refinement', 622), ('complete', 623), ('expressions', 624), ('disk', 625), ('terms', 626), ('robots', 627), ('why', 628), ('protocol', 629), ('writing', 630), ('files', 631), ('challenges', 632), ('schemas', 633), ('compilation', 634), ('syntax', 635), ('noun', 636), ('changes', 637), ('propositional', 638), ('kernels', 639), ('events', 640), ('composition', 641), ('better', 642), ('assignment', 643), ('distribution', 644), ('processor', 645), ('keyword', 646), ('proving', 647), ('guided', 648), ('managing', 649), ('autonomous', 650), ('presence', 651), ('site', 652), ('actions', 653), ('binary', 654), ('applying', 655), ('news', 656), ('buffer', 657), ('relevant', 658), ('explanation', 659), ('personal', 660), ('evidence', 661), ('different', 662), ('hidden', 663), ('diagrams', 664), ('measure', 665), ('compression', 666), ('images', 667), ('string', 668), ('bounded', 669), ('reference', 670), ('preference', 671), ('meta', 672), ('physical', 673), ('usage', 674), ('e', 675), ('bridging', 676), ('log', 677), ('you', 678), ('adaptation', 679), ('multimodal', 680), ('answers', 681), ('locking', 682), ('satisfaction', 683), ('history', 684), ('sequences', 685), ('solution', 686), ('merging', 687), ('fuzzy', 688), ('sparse', 689), ('versus', 690), ('tag', 691), ('mt', 692), ('simulation', 693), ('designing', 694), ('modules', 695), ('field', 696), ('margin', 697), ('wide', 698), ('future', 699), ('streaming', 700), ('clusters', 701), ('modal', 702), ('direct', 703), ('key', 704), ('secure', 705), ('relationships', 706), ('size', 707), ('precision', 708), ('protocols', 709), ('classifier', 710), ('nearest', 711), ('theorem', 712), ('developing', 713), ('single', 714), ('parametric', 715), ('subspace', 716), ('multilingual', 717), ('transformations', 718), ('embedded', 719), ('instance', 720), ('garbage', 721), ('music', 722), ('media', 723), ('answer', 724), ('manipulation', 725), ('record', 726), ('introducing', 727), ('load', 728), ('extension', 729), ('algebraic', 730), ('criteria', 731), ('uncertain', 732), ('inductive', 733), ('combinatorial', 734), ('generalization', 735), ('fault', 736), ('instruction', 737), ('vision', 738), ('architectural', 739), ('solutions', 740), ('diagnosis', 741), ('fine', 742), ('predictive', 743), ('proof', 744), ('predicate', 745), ('scaling', 746), ('systematic', 747), ('basis', 748), ('dependent', 749), ('client', 750), ('full', 751), ('sat', 752), ('density', 753), ('accurate', 754), ('generative', 755), ('metrics', 756), ('comparing', 757), ('universal', 758), ('errors', 759), ('variable', 760), ('parallelism', 761), ('optimizations', 762), ('sentences', 763), ('proximity', 764), ('introduction', 765), ('cognitive', 766), ('interactions', 767), ('down', 768), ('spectral', 769), ('implicit', 770), ('alternative', 771), ('region', 772), ('policy', 773), ('xquery', 774), ('experiment', 775), ('main', 776), ('motion', 777), ('expression', 778), ('expressive', 779), ('redundancy', 780), ('correctness', 781), ('validation', 782), ('preliminary', 783), ('step', 784), ('equivalence', 785), ('way', 786), ('graphics', 787), ('specifying', 788), ('sentiment', 789), ('duplicate', 790), ('international', 791), ('loop', 792), ('default', 793), ('tutorial', 794), ('attributes', 795), ('weighting', 796), ('distributions', 797), ('recommendation', 798), ('tables', 799), ('entities', 800), ('constructing', 801), ('assessing', 802), ('dimensionality', 803), ('genetic', 804), ('electronic', 805), ('replication', 806), ('classifying', 807), ('limited', 808), ('inheritance', 809), ('we', 810), ('dynamically', 811), ('three', 812), ('materialized', 813), ('compressed', 814), ('overview', 815), ('quantitative', 816), ('composite', 817), ('partially', 818), ('parts', 819), ('correlation', 820), ('historical', 821), ('enhanced', 822), ('declarative', 823), ('grid', 824), ('library', 825), ('polynomial', 826), ('technologies', 827), ('reviews', 828), ('chart', 829), ('heuristics', 830), ('transitive', 831), ('near', 832), ('gap', 833), ('aspect', 834), ('score', 835), ('procedures', 836), ('fields', 837), ('factorization', 838), ('precise', 839), ('part', 840), ('joint', 841), ('demonstration', 842), ('medical', 843), ('optimizer', 844), ('accuracy', 845), ('summary', 846), ('neighbor', 847), ('inferring', 848), ('university', 849), ('consistent', 850), ('help', 851), ('max', 852), ('uml', 853), ('topics', 854), ('moving', 855), ('enterprise', 856), ('csp', 857), ('effect', 858), ('bound', 859), ('diverse', 860), ('interprocedural', 861), ('thinking', 862), ('investigation', 863), ('table', 864), ('bounds', 865), ('ai', 866), ('maintaining', 867), ('reliable', 868), ('algorithmic', 869), ('tractable', 870), ('reliability', 871), ('taxonomy', 872), ('selectivity', 873), ('hardware', 874), ('learned', 875), ('rewriting', 876), ('counting', 877), ('replicated', 878), ('automating', 879), ('than', 880), ('polymorphic', 881), ('re', 882), ('elimination', 883), ('pseudo', 884), ('categories', 885), ('highly', 886), ('extensions', 887), ('reverse', 888), ('intensive', 889), ('look', 890), ('visualizing', 891), ('discriminant', 892), ('lazy', 893), ('rdf', 894), ('like', 895), ('change', 896), ('contextual', 897), ('progress', 898), ('critical', 899), ('xpath', 900), ('activity', 901), ('phase', 902), ('negotiation', 903), ('optimized', 904), ('dual', 905), ('result', 906), ('statistics', 907), ('lessons', 908), ('values', 909), ('perception', 910), ('related', 911), ('dirichlet', 912), ('ontologies', 913), ('revisited', 914), ('minimization', 915), ('inverted', 916), ('logs', 917), ('standard', 918), ('attacks', 919), ('number', 920), ('theoretical', 921), ('recommendations', 922), ('length', 923), ('wireless', 924), ('warehouse', 925), ('informative', 926), ('means', 927), ('derivation', 928), ('opinion', 929), ('profiling', 930), ('review', 931), ('demand', 932), ('noise', 933), ('satisfiability', 934), ('automata', 935), ('call', 936), ('right', 937), ('oracle', 938), ('hypertext', 939), ('devices', 940), ('mixed', 941), ('redundant', 942), ('disjunctive', 943), ('importance', 944), ('teach', 945), ('revision', 946), ('survey', 947), ('long', 948), ('all', 949), ('1', 950), ('trust', 951), ('progressive', 952), ('minimal', 953), ('variables', 954), ('simultaneous', 955), ('phrases', 956), ('anaphora', 957), ('spatio', 958), ('output', 959), ('other', 960), ('definition', 961), ('combination', 962), ('gene', 963), ('paradigm', 964), ('hoc', 965), ('compiling', 966), ('map', 967), ('uniform', 968), ('difference', 969), ('studies', 970), ('across', 971), ('skills', 972), ('influence', 973), ('mechanisms', 974), ('version', 975), ('partitioned', 976), ('end', 977), ('programmers', 978), ('observations', 979), ('reducing', 980), ('levels', 981), ('evolutionary', 982), ('geometric', 983), ('gaussian', 984), ('navigation', 985), ('label', 986), ('workflow', 987), ('industrial', 988), ('array', 989), ('interval', 990), ('signature', 991), ('platform', 992), ('safe', 993), ('school', 994), ('ordered', 995), ('mdps', 996), ('measurement', 997), ('clause', 998), ('symbolic', 999), ('textual', 1000), ('configuration', 1001), ('coverage', 1002), ('operators', 1003), ('focused', 1004), ('pointer', 1005), ('embedding', 1006), ('predict', 1007), ('projection', 1008), ('adjoining', 1009), ('location', 1010), ('interoperability', 1011), ('experts', 1012), ('providing', 1013), ('compact', 1014), ('evolving', 1015), ('discrete', 1016), ('labeled', 1017), ('message', 1018), ('style', 1019), ('core', 1020), ('implications', 1021), ('shape', 1022), ('p2p', 1023), ('transition', 1024), ('team', 1025), ('termination', 1026), ('benchmark', 1027), ('robustness', 1028), ('operation', 1029), ('interesting', 1030), ('deep', 1031), ('commerce', 1032), ('explicit', 1033), ('points', 1034), ('frequency', 1035), ('normal', 1036), ('communities', 1037), ('nonmonotonic', 1038), ('synthesis', 1039), ('grained', 1040), ('capturing', 1041), ('valued', 1042), ('biomedical', 1043), ('federated', 1044), ('wikipedia', 1045), ('localization', 1046), ('noisy', 1047), ('voting', 1048), ('hard', 1049), ('summaries', 1050), ('market', 1051), ('reorganization', 1052), ('focus', 1053), ('register', 1054), ('frame', 1055), ('topological', 1056), ('arabic', 1057), ('tuning', 1058), ('multiprocessor', 1059), ('translating', 1060), ('bootstrapping', 1061), ('pomdps', 1062), ('back', 1063), ('adapting', 1064), ('reordering', 1065), ('servers', 1066), ('korean', 1067), ('learn', 1068), ('pre', 1069), ('organizing', 1070), ('be', 1071), ('recall', 1072), ('r', 1073), ('warehouses', 1074), ('convex', 1075), ('classroom', 1076), ('argumentation', 1077), ('biased', 1078), ('profiles', 1079), ('ml', 1080), ('transactional', 1081), ('routing', 1082), ('computers', 1083), ('list', 1084), ('point', 1085), ('formulas', 1086), ('lexicalized', 1087), ('enhancing', 1088), ('deterministic', 1089), ('nlp', 1090), ('procedure', 1091), ('dictionaries', 1092), ('center', 1093), ('massive', 1094), ('outliers', 1095), ('forms', 1096), ('your', 1097), ('soft', 1098), ('associative', 1099), ('reactive', 1100), ('characterization', 1101), ('db2', 1102), ('gradient', 1103), ('sound', 1104), ('deadlock', 1105), ('centered', 1106), ('only', 1107), ('multiagent', 1108), ('ii', 1109), ('parameter', 1110), ('questions', 1111), ('generalizing', 1112), ('side', 1113), ('commitment', 1114), ('closure', 1115), ('speed', 1116), ('among', 1117), ('verb', 1118), ('items', 1119), ('logistic', 1120), ('spam', 1121), ('libraries', 1122), ('weak', 1123), ('bottom', 1124), ('proactive', 1125), ('randomized', 1126), ('grammatical', 1127), ('during', 1128), ('head', 1129), ('morphology', 1130), ('recursion', 1131), ('quantified', 1132), ('paradigms', 1133), ('forward', 1134), ('correction', 1135), ('fully', 1136), ('negative', 1137), ('simulator', 1138), ('blog', 1139), ('zero', 1140), ('prototyping', 1141), ('abstractions', 1142), ('unlabeled', 1143), ('multidatabase', 1144), ('life', 1145), ('dialogues', 1146), ('less', 1147), ('run', 1148), ('minimum', 1149), ('logging', 1150), ('balancing', 1151), ('lisp', 1152), ('against', 1153), ('quasi', 1154), ('expected', 1155), ('beliefs', 1156), ('least', 1157), ('dimension', 1158), ('curricula', 1159), ('safety', 1160), ('no', 1161), ('energy', 1162), ('regularization', 1163), ('off', 1164), ('personalization', 1165), ('road', 1166), ('broad', 1167), ('customer', 1168), ('closed', 1169), ('generator', 1170), ('office', 1171), ('spontaneous', 1172), ('judgments', 1173), ('analyzer', 1174), ('conversion', 1175), ('formalism', 1176), ('occurrence', 1177), ('runtime', 1178), ('german', 1179), ('crawling', 1180), ('itemsets', 1181), ('email', 1182), ('just', 1183), ('operational', 1184), ('ethics', 1185), ('inconsistency', 1186), ('traffic', 1187), ('creation', 1188), ('does', 1189), ('analogy', 1190), ('geometry', 1191), ('synchronous', 1192), ('fusion', 1193), ('definitions', 1194), ('pagerank', 1195), ('goals', 1196), ('reranking', 1197), ('compositional', 1198), ('3d', 1199), ('match', 1200), ('generate', 1201), ('lightweight', 1202), ('external', 1203), ('bayes', 1204), ('legacy', 1205), ('annotations', 1206), ('cubes', 1207), ('constructive', 1208), ('sample', 1209), ('principle', 1210), ('anytime', 1211), ('practices', 1212), ('dynamics', 1213), ('ensembles', 1214), ('name', 1215), ('stable', 1216), ('ambiguity', 1217), ('structuring', 1218), ('reading', 1219), ('enhance', 1220), ('manipulating', 1221), ('educational', 1222), ('effort', 1223), ('deriving', 1224), ('majors', 1225), ('indices', 1226), ('tolerant', 1227), ('similar', 1228), ('provenance', 1229), ('undergraduates', 1230), ('unstructured', 1231), ('guide', 1232), ('inter', 1233), ('sort', 1234), ('facility', 1235), ('input', 1236), ('blind', 1237), ('paper', 1238), ('assistant', 1239), ('animation', 1240), ('lr', 1241), ('out', 1242), ('availability', 1243), ('strings', 1244), ('positive', 1245), ('agile', 1246), ('relative', 1247), ('implementations', 1248), ('advertising', 1249), ('comprehension', 1250), ('cad', 1251), ('archives', 1252), ('depth', 1253), ('trajectories', 1254), ('probabilities', 1255), ('early', 1256), ('transparent', 1257), ('quantifying', 1258), ('foundations', 1259), ('paths', 1260), ('account', 1261), ('middle', 1262), ('formation', 1263), ('projections', 1264), ('inspection', 1265), ('within', 1266), ('parameterized', 1267), ('browser', 1268), ('outlier', 1269), ('who', 1270), ('svm', 1271), ('isolation', 1272), ('emerging', 1273), ('solver', 1274), ('warehousing', 1275), ('orientation', 1276), ('strong', 1277), ('associations', 1278), ('poster', 1279), ('hierarchy', 1280), ('mathematics', 1281), ('presentation', 1282), ('challenge', 1283), ('behaviors', 1284), ('target', 1285), ('anomaly', 1286), ('need', 1287), ('metadata', 1288), ('monotonic', 1289), ('ranked', 1290), ('predicates', 1291), ('coalitional', 1292), ('expertise', 1293), ('pragmatic', 1294), ('prior', 1295), ('profile', 1296), ('confidence', 1297), ('conscious', 1298), ('ada', 1299), ('genre', 1300), ('selective', 1301), ('owl', 1302), ('meets', 1303), ('nonlinear', 1304), ('passing', 1305), ('normalization', 1306), ('groups', 1307), ('possibilistic', 1308), ('usability', 1309), ('classical', 1310), ('procedural', 1311), ('edge', 1312), ('designs', 1313), ('articles', 1314), ('independence', 1315), ('situation', 1316), ('binding', 1317), ('circumscription', 1318), ('instructions', 1319), ('interpreter', 1320), ('native', 1321), ('purpose', 1322), ('versions', 1323), ('planner', 1324), ('invariants', 1325), ('locality', 1326), ('bringing', 1327), ('conflict', 1328), ('links', 1329), ('pos', 1330), ('dataflow', 1331), ('i', 1332), ('neighborhood', 1333), ('filter', 1334), ('coreference', 1335), ('net', 1336), ('parse', 1337), ('vertical', 1338), ('intent', 1339), ('theories', 1340), ('aligning', 1341), ('transliteration', 1342), ('skyline', 1343), ('cardinality', 1344), ('serializability', 1345), ('topical', 1346), ('activities', 1347), ('layout', 1348), ('records', 1349), ('html', 1350), ('persistent', 1351), ('generated', 1352), ('thesaurus', 1353), ('category', 1354), ('approximations', 1355), ('www', 1356), ('clickthrough', 1357), ('vocabulary', 1358), ('restructuring', 1359), ('determination', 1360), ('inclusion', 1361), ('cs2', 1362), ('find', 1363), ('easy', 1364), ('infinite', 1365), ('maximal', 1366), ('categorial', 1367), ('loops', 1368), ('proofs', 1369), ('broadcast', 1370), ('gathering', 1371), ('completeness', 1372), ('categorical', 1373), ('histograms', 1374), ('toolkit', 1375), ('middleware', 1376), ('ensemble', 1377), ('missing', 1378), ('leveraging', 1379), ('networking', 1380), ('window', 1381), ('calls', 1382), ('metaphor', 1383), ('creating', 1384), ('describing', 1385), ('windows', 1386), ('anonymous', 1387), ('know', 1388), ('biological', 1389), ('lingual', 1390), ('lock', 1391), ('cube', 1392), ('states', 1393), ('go', 1394), ('rate', 1395), ('determining', 1396), ('argument', 1397), ('correct', 1398), ('pairs', 1399), ('women', 1400), ('unit', 1401), ('applied', 1402), ('unifying', 1403), ('smoothing', 1404), ('area', 1405), ('3', 1406), ('d', 1407), ('prover', 1408), ('face', 1409), ('de', 1410), ('names', 1411), ('contexts', 1412), ('numeric', 1413), ('subsequence', 1414), ('inducing', 1415), ('block', 1416), ('work', 1417), ('maps', 1418), ('exact', 1419), ('processors', 1420), ('defined', 1421), ('analytical', 1422), ('infrastructure', 1423), ('authority', 1424), ('session', 1425), ('well', 1426), ('aggregates', 1427), ('pair', 1428), ('bias', 1429), ('signatures', 1430), ('modularity', 1431), ('reusable', 1432), ('year', 1433), ('walks', 1434), ('pairwise', 1435), ('opportunities', 1436), ('instances', 1437), ('commit', 1438), ('competitive', 1439), ('branch', 1440), ('affective', 1441), ('secondary', 1442), ('failures', 1443), ('second', 1444), ('centric', 1445), ('gram', 1446), ('walk', 1447), ('bi', 1448), ('2', 1449), ('analyses', 1450), ('improvement', 1451), ('expectation', 1452), ('separation', 1453), ('concerns', 1454), ('contents', 1455), ('explanations', 1456), ('success', 1457), ('accessing', 1458), ('batch', 1459), ('four', 1460), ('dominance', 1461), ('route', 1462), ('useful', 1463), ('characterizing', 1464), ('refining', 1465), ('speculative', 1466), ('combined', 1467), ('compressing', 1468), ('formulation', 1469), ('attention', 1470), ('coarse', 1471), ('lists', 1472), ('sum', 1473), ('applicative', 1474), ('imprecise', 1475), ('mental', 1476), ('directional', 1477), ('organizational', 1478), ('existing', 1479), ('contract', 1480), ('current', 1481), ('sorting', 1482), ('suite', 1483), ('position', 1484), ('derived', 1485), ('teachers', 1486), ('iteration', 1487), ('relaxed', 1488), ('enough', 1489), ('there', 1490), ('unknown', 1491), ('boundaries', 1492), ('rates', 1493), ('cooperating', 1494), ('repositories', 1495), ('short', 1496), ('decisions', 1497), ('costs', 1498), ('controlling', 1499), ('ambiguous', 1500), ('almost', 1501), ('parallelization', 1502), ('integer', 1503), ('viewing', 1504), ('lecture', 1505), ('benefits', 1506), ('defaults', 1507), ('diagnostic', 1508), ('prosodic', 1509), ('template', 1510), ('asynchronous', 1511), ('optimistic', 1512), ('dont', 1513), ('subtyping', 1514), ('assignments', 1515), ('manager', 1516), ('rfid', 1517), ('considerations', 1518), ('parsers', 1519), ('multiclass', 1520), ('tradeoffs', 1521), ('read', 1522), ('nonparametric', 1523), ('poisson', 1524), ('svms', 1525), ('predictions', 1526), ('portable', 1527), ('french', 1528), ('desktop', 1529), ('likelihood', 1530), ('risk', 1531), ('augmented', 1532), ('informed', 1533), ('family', 1534), ('balanced', 1535), ('experimentation', 1536), ('roles', 1537), ('where', 1538), ('nets', 1539), ('dissemination', 1540), ('twig', 1541), ('investigating', 1542), ('interest', 1543), ('lattice', 1544), ('csps', 1545), ('mathematical', 1546), ('scope', 1547), ('extracted', 1548), ('subgraphs', 1549), ('annotated', 1550), ('arbitrary', 1551), ('bidding', 1552), ('io', 1553), ('subjectivity', 1554), ('realistic', 1555), ('conversational', 1556), ('remote', 1557), ('dealing', 1558), ('stage', 1559), ('alias', 1560), ('workflows', 1561), ('ground', 1562), ('mode', 1563), ('serial', 1564), ('coupling', 1565), ('needs', 1566), ('pc', 1567), ('lines', 1568), ('stories', 1569), ('frameworks', 1570), ('cs1cs2', 1571), ('laboratories', 1572), ('mappings', 1573), ('partition', 1574), ('reformulation', 1575), ('sensing', 1576), ('workload', 1577), ('semistructured', 1578), ('microarray', 1579), ('directions', 1580), ('coding', 1581), ('package', 1582), ('networked', 1583), ('decoding', 1584), ('scenarios', 1585), ('primitives', 1586), ('discussion', 1587), ('company', 1588), ('frames', 1589), ('synchronization', 1590), ('ubiquitous', 1591), ('specified', 1592), ('recognizing', 1593), ('performing', 1594), ('law', 1595), ('em', 1596), ('individual', 1597), ('choice', 1598), ('mechanical', 1599), ('channel', 1600), ('private', 1601), ('tags', 1602), ('focusing', 1603), ('synchronized', 1604), ('make', 1605), ('treatment', 1606), ('observation', 1607), ('controlled', 1608), ('templates', 1609), ('granularity', 1610), ('cases', 1611), ('optimality', 1612), ('optimizers', 1613), ('approximating', 1614), ('notes', 1615), ('inputs', 1616), ('hot', 1617), ('failure', 1618), ('formalization', 1619), ('paraphrasing', 1620), ('blogs', 1621), ('operator', 1622), ('physics', 1623), ('oodb', 1624), ('note', 1625), ('prioritized', 1626), ('differences', 1627), ('breadth', 1628), ('regular', 1629), ('enabling', 1630), ('arguments', 1631), ('threshold', 1632), ('quantifier', 1633), ('choices', 1634), ('bidirectional', 1635), ('charts', 1636), ('total', 1637), ('arc', 1638), ('sensors', 1639), ('light', 1640), ('eliminating', 1641), ('transducers', 1642), ('symmetry', 1643), ('reporting', 1644), ('thematic', 1645), ('alternatives', 1646), ('functionality', 1647), ('statements', 1648), ('financial', 1649), ('fair', 1650), ('collocations', 1651), ('communications', 1652), ('but', 1653), ('replacement', 1654), ('circuits', 1655), ('bag', 1656), ('analytic', 1657), ('adaptable', 1658), ('monolingual', 1659), ('assurance', 1660), ('filters', 1661), ('basic', 1662), ('both', 1663), ('write', 1664), ('computations', 1665), ('coupled', 1666), ('compound', 1667), ('intention', 1668), ('polymorphism', 1669), ('worlds', 1670), ('tier', 1671), ('factors', 1672), ('standards', 1673), ('scoring', 1674), ('arts', 1675), ('materialization', 1676), ('behavioral', 1677), ('dominant', 1678), ('updating', 1679), ('expressing', 1680), ('utilizing', 1681), ('factor', 1682), ('characters', 1683), ('parameters', 1684), ('modern', 1685), ('lambek', 1686), ('directory', 1687), ('collaboration', 1688), ('loosely', 1689), ('difficult', 1690), ('assisted', 1691), ('playing', 1692), ('adoption', 1693), ('formalisms', 1694), ('module', 1695), ('constituent', 1696), ('public', 1697), ('smart', 1698), ('globally', 1699), ('urls', 1700), ('advice', 1701), ('transport', 1702), ('visually', 1703), ('placement', 1704), ('reconstruction', 1705), ('strongly', 1706), ('tutoring', 1707), ('player', 1708), ('post', 1709), ('hypothesis', 1710), ('micro', 1711), ('delayed', 1712), ('few', 1713), ('pass', 1714), ('methodologies', 1715), ('collective', 1716), ('linking', 1717), ('geographic', 1718), ('timed', 1719), ('race', 1720), ('candidate', 1721), ('strategic', 1722), ('something', 1723), ('observable', 1724), ('fundamental', 1725), ('bit', 1726), ('most', 1727), ('restrictions', 1728), ('click', 1729), ('regions', 1730), ('mutual', 1731), ('searches', 1732), ('synopses', 1733), ('foundation', 1734), ('technical', 1735), ('meanings', 1736), ('robotic', 1737), ('modified', 1738), ('keyphrase', 1739), ('display', 1740), ('settings', 1741), ('axiomatic', 1742), ('verifying', 1743), ('p', 1744), ('recommender', 1745), ('cyclic', 1746), ('taking', 1747), ('ability', 1748), ('augmenting', 1749), ('behaviour', 1750), ('hand', 1751), ('robotics', 1752), ('entailment', 1753), ('multivariate', 1754), ('multithreaded', 1755), ('theorems', 1756), ('restricted', 1757), ('additive', 1758), ('breaking', 1759), ('trade', 1760), ('validating', 1761), ('assembly', 1762), ('labs', 1763), ('grouping', 1764), ('connected', 1765), ('teams', 1766), ('many', 1767), ('backtracking', 1768), ('sketch', 1769), ('recent', 1770), ('price', 1771), ('phrasal', 1772), ('conditions', 1773), ('nonnegative', 1774), ('panel', 1775), ('q', 1776), ('resolving', 1777), ('discrimination', 1778), ('dialog', 1779), ('snapshot', 1780), ('analogical', 1781), ('semantically', 1782), ('petri', 1783), ('consensus', 1784), ('histogram', 1785), ('weight', 1786), ('publishing', 1787), ('ahead', 1788), ('past', 1789), ('revealing', 1790), ('response', 1791), ('abductive', 1792), ('codes', 1793), ('clauses', 1794), ('repository', 1795), ('nondeterministic', 1796), ('generators', 1797), ('node', 1798), ('induced', 1799), ('healthcare', 1800), ('distributing', 1801), ('really', 1802), ('arrays', 1803), ('bug', 1804), ('collector', 1805), ('live', 1806), ('gpsg', 1807), ('explaining', 1808), ('eye', 1809), ('pointers', 1810), ('priors', 1811), ('containment', 1812), ('versioning', 1813), ('auction', 1814), ('false', 1815), ('whole', 1816), ('taxonomies', 1817), ('should', 1818), ('javascript', 1819), ('courseware', 1820), ('pedagogy', 1821), ('typing', 1822), ('messages', 1823), ('left', 1824), ('temporally', 1825), ('interoperable', 1826), ('alpha', 1827), ('conjunctive', 1828), ('rankings', 1829), ('terminology', 1830), ('publishsubscribe', 1831), ('factored', 1832), ('activation', 1833), ('documentation', 1834), ('slicing', 1835), ('winner', 1836), ('rdbms', 1837), ('diversity', 1838), ('forecasting', 1839), ('made', 1840), ('chemical', 1841), ('suggestion', 1842), ('multilevel', 1843), ('deduction', 1844), ('cues', 1845), ('api', 1846), ('pca', 1847), ('disks', 1848), ('equilibria', 1849), ('flash', 1850), ('preservation', 1851), ('accessibility', 1852), ('repairs', 1853), ('character', 1854), ('special', 1855), ('walking', 1856), ('strictness', 1857), ('liberal', 1858), ('rewrite', 1859), ('solve', 1860), ('wise', 1861), ('completion', 1862), ('if', 1863), ('equations', 1864), ('website', 1865), ('mapreduce', 1866), ('satisfying', 1867), ('greedy', 1868), ('biology', 1869), ('minimax', 1870), ('prefetching', 1871), ('achieving', 1872), ('anaphoric', 1873), ('editors', 1874), ('s', 1875), ('monte', 1876), ('carlo', 1877), ('x', 1878), ('anomalies', 1879), ('producing', 1880), ('party', 1881), ('definite', 1882), ('sponsored', 1883), ('manufacturing', 1884), ('ontological', 1885), ('elements', 1886), ('stability', 1887), ('comments', 1888), ('lda', 1889), ('smalltalk', 1890), ('column', 1891), ('count', 1892), ('defect', 1893), ('maximizing', 1894), ('metasearch', 1895), ('geo', 1896), ('automotive', 1897), ('diffusion', 1898), ('stored', 1899), ('reports', 1900), ('subject', 1901), ('predictors', 1902), ('contention', 1903), ('reduce', 1904), ('scene', 1905), ('rich', 1906), ('navigational', 1907), ('la', 1908), ('executing', 1909), ('requirement', 1910), ('rational', 1911), ('simulations', 1912), ('so', 1913), ('switching', 1914), ('seminar', 1915), ('threads', 1916), ('constructed', 1917), ('spelling', 1918), ('idea', 1919), ('seed', 1920), ('rare', 1921), ('college', 1922), ('vehicle', 1923), ('another', 1924), ('loading', 1925), ('organized', 1926), ('skew', 1927), ('correspondences', 1928), ('microsoft', 1929), ('wordnet', 1930), ('significant', 1931), ('visualisation', 1932), ('trends', 1933), ('trace', 1934), ('nominal', 1935), ('synthesizing', 1936), ('coherent', 1937), ('terminological', 1938), ('fact', 1939), ('improvements', 1940), ('migration', 1941), ('transformational', 1942), ('ellipsis', 1943), ('citation', 1944), ('quantification', 1945), ('instructional', 1946), ('government', 1947), ('adjectives', 1948), ('searchers', 1949), ('retrieving', 1950), ('capstone', 1951), ('exchange', 1952), ('crawler', 1953), ('wrapper', 1954), ('specialization', 1955), ('possible', 1956), ('containing', 1957), ('imperfect', 1958), ('concrete', 1959), ('delivery', 1960), ('protecting', 1961), ('horizontal', 1962), ('fragments', 1963), ('iterated', 1964), ('learners', 1965), ('directories', 1966), ('industry', 1967), ('distances', 1968), ('instant', 1969), ('linkage', 1970), ('surface', 1971), ('numerical', 1972), ('indexed', 1973), ('facts', 1974), ('shift', 1975), ('facilitate', 1976), ('denotational', 1977), ('inverse', 1978), ('descent', 1979), ('lasso', 1980), ('guarantees', 1981), ('2001', 1982), ('chain', 1983), ('status', 1984), ('studying', 1985), ('transform', 1986), ('edit', 1987), ('perspectives', 1988), ('oltp', 1989), ('individuals', 1990), ('comparable', 1991), ('aided', 1992), ('bad', 1993), ('20', 1994), ('everyone', 1995), ('friendly', 1996), ('trec', 1997), ('signal', 1998), ('correlated', 1999), ('literature', 2000), ('regularized', 2001), ('holistic', 2002), ('multidatabases', 2003), ('regret', 2004), ('background', 2005), ('cleaning', 2006), ('skill', 2007), ('intensional', 2008), ('simplified', 2009), ('command', 2010), ('years', 2011), ('piecewise', 2012), ('build', 2013), ('advances', 2014), ('encodings', 2015), ('layered', 2016), ('dimensions', 2017), ('proper', 2018), ('portals', 2019), ('cooperation', 2020), ('decentralized', 2021), ('auxiliary', 2022), ('edges', 2023), ('flat', 2024), ('perceptron', 2025), ('prevention', 2026), ('seeking', 2027), ('capability', 2028), ('extreme', 2029), ('poker', 2030), ('novice', 2031), ('hmm', 2032), ('pronoun', 2033), ('unix', 2034), ('next', 2035), ('audio', 2036), ('mind', 2037), ('decompositions', 2038), ('extensibility', 2039), ('assistance', 2040), ('intermediate', 2041), ('correlations', 2042), ('manifold', 2043), ('estimate', 2044), ('anchor', 2045), ('atomic', 2046), ('maximization', 2047), ('treebank', 2048), ('merge', 2049), ('smt', 2050), ('google', 2051), ('suffix', 2052), ('combinatory', 2053), ('inconsistent', 2054), ('retention', 2055), ('weakly', 2056), ('convergence', 2057), ('symmetric', 2058), ('objective', 2059), ('keys', 2060), ('differential', 2061), ('division', 2062), ('covering', 2063), ('any', 2064), ('they', 2065), ('coloring', 2066), ('opinions', 2067), ('grams', 2068), ('sms', 2069), ('declustering', 2070), ('macro', 2071), ('shortest', 2072), ('utilization', 2073), ('knn', 2074), ('interdisciplinary', 2075), ('tape', 2076), ('ssa', 2077), ('phi', 2078), ('harmful', 2079), ('double', 2080), ('parsed', 2081), ('hypergraph', 2082), ('corner', 2083), ('segments', 2084), ('inferencing', 2085), ('chains', 2086), ('lfg', 2087), ('expensive', 2088), ('intended', 2089), ('informational', 2090), ('clinical', 2091), ('tagged', 2092), ('examination', 2093), ('2003', 2094), ('neutral', 2095), ('degree', 2096), ('expressiveness', 2097), ('weights', 2098), ('argumentative', 2099), ('massively', 2100), ('referring', 2101), ('beta', 2102), ('faceted', 2103), ('detect', 2104), ('overlay', 2105), ('selecting', 2106), ('locating', 2107), ('rapid', 2108), ('copy', 2109), ('readers', 2110), ('paraphrases', 2111), ('transforms', 2112), ('optimize', 2113), ('integrate', 2114), ('loss', 2115), ('ciphers', 2116), ('stack', 2117), ('last', 2118), ('blackboard', 2119), ('nash', 2120), ('mediation', 2121), ('cut', 2122), ('pure', 2123), ('mean', 2124), ('flickr', 2125), ('faults', 2126), ('gaps', 2127), ('issue', 2128), ('patent', 2129), ('exploratory', 2130), ('abduction', 2131), ('recurrent', 2132), ('major', 2133), ('traditional', 2134), ('show', 2135), ('accesses', 2136), ('constituency', 2137), ('ode', 2138), ('facilitating', 2139), ('us', 2140), ('ecommerce', 2141), ('hiding', 2142), ('sales', 2143), ('popular', 2144), ('bioinformatics', 2145), ('automation', 2146), ('snippet', 2147), ('drift', 2148), ('multiversion', 2149), ('device', 2150), ('extract', 2151), ('editing', 2152), ('fifteen', 2153), ('compilers', 2154), ('productivity', 2155), ('rating', 2156), ('transductive', 2157), ('notion', 2158), ('bulk', 2159), ('population', 2160), ('interests', 2161), ('resident', 2162), ('orthogonal', 2163), ('curse', 2164), ('gui', 2165), ('conformant', 2166), ('bibliography', 2167), ('spatiotemporal', 2168), ('art', 2169), ('autonomic', 2170), ('trading', 2171), ('cs0', 2172), ('disjunctions', 2173), ('testbed', 2174), ('neighbour', 2175), ('meaningful', 2176), ('numbers', 2177), ('messaging', 2178), ('relating', 2179), ('linguistically', 2180), ('connecting', 2181), ('too', 2182), ('lexicons', 2183), ('geographical', 2184), ('subexpressions', 2185), ('reusability', 2186), ('replica', 2187), ('defining', 2188), ('intranet', 2189), ('root', 2190), ('m', 2191), ('exponential', 2192), ('while', 2193), ('helping', 2194), ('see', 2195), ('lexicalization', 2196), ('injection', 2197), ('stationary', 2198), ('horn', 2199), ('multiparty', 2200), ('conversation', 2201), ('matrices', 2202), ('provide', 2203), ('atms', 2204), ('pronunciation', 2205), ('indefinite', 2206), ('brief', 2207), ('exercise', 2208), ('grain', 2209), ('triggers', 2210), ('traversal', 2211), ('interpretations', 2212), ('hypergraphs', 2213), ('hpsg', 2214), ('webpage', 2215), ('discovered', 2216), ('mu', 2217), ('anatomy', 2218), ('vague', 2219), ('mutation', 2220), ('commodity', 2221), ('flows', 2222), ('morpheme', 2223), ('board', 2224), ('must', 2225), ('mobility', 2226), ('measurements', 2227), ('going', 2228), ('negation', 2229), ('supported', 2230), ('pipelined', 2231), ('earth', 2232), ('algebras', 2233), ('addressing', 2234), ('optical', 2235), ('prototypes', 2236), ('star', 2237), ('permutation', 2238), ('proxy', 2239), ('criterion', 2240), ('encryption', 2241), ('sensitivity', 2242), ('cycles', 2243), ('fixpoint', 2244), ('freshness', 2245), ('hypermedia', 2246), ('presentations', 2247), ('filling', 2248), ('changing', 2249), ('products', 2250), ('pascal', 2251), ('ill', 2252), ('gain', 2253), ('wavelet', 2254), ('exceptions', 2255), ('reengineering', 2256), ('gender', 2257), ('acyclic', 2258), ('nl', 2259), ('marketing', 2260), ('pipeline', 2261), ('wavelets', 2262), ('decidable', 2263), ('analyze', 2264), ('author', 2265), ('essential', 2266), ('blocking', 2267), ('guarantee', 2268), ('f', 2269), ('screening', 2270), ('evaluate', 2271), ('evaluations', 2272), ('naive', 2273), ('shell', 2274), ('transduction', 2275), ('ansi', 2276), ('vectors', 2277), ('persistence', 2278), ('tokenization', 2279), ('blogosphere', 2280), ('compromise', 2281), ('sketching', 2282), ('turkish', 2283), ('attack', 2284), ('situations', 2285), ('tailoring', 2286), ('bootstrap', 2287), ('curve', 2288), ('grounded', 2289), ('clones', 2290), ('videos', 2291), ('traceability', 2292), ('humans', 2293), ('engineers', 2294), ('examining', 2295), ('agenda', 2296), ('summarizing', 2297), ('clusterings', 2298), ('verbal', 2299), ('entry', 2300), ('meaning', 2301), ('compatibility', 2302), ('concise', 2303), ('living', 2304), ('decoupling', 2305), ('big', 2306), ('wrapping', 2307), ('closing', 2308), ('invariant', 2309), ('picture', 2310), ('ie', 2311), ('analytics', 2312), ('10', 2313), ('bounding', 2314), ('3rd', 2315), ('me', 2316), ('powerful', 2317), ('quorum', 2318), ('neighbors', 2319), ('adding', 2320), ('collocation', 2321), ('viewpoint', 2322), ('classify', 2323), ('snippets', 2324), ('acm', 2325), ('initiative', 2326), ('promoting', 2327), ('which', 2328), ('diagnosing', 2329), ('splitting', 2330), ('tertiary', 2331), ('corporate', 2332), ('attitudes', 2333), ('skewed', 2334), ('intrusion', 2335), ('learner', 2336), ('reversible', 2337), ('relaxation', 2338), ('avoiding', 2339), ('aids', 2340), ('underlying', 2341), ('stores', 2342), ('distinguishing', 2343), ('authorship', 2344), ('boundary', 2345), ('codasyl', 2346), ('significance', 2347), ('acts', 2348), ('running', 2349), ('buffering', 2350), ('emotions', 2351), ('correcting', 2352), ('communicating', 2353), ('magic', 2354), ('surfaces', 2355), ('linguistics', 2356), ('protein', 2357), ('bid', 2358), ('refactoring', 2359), ('acquiring', 2360), ('clone', 2361), ('comprehensive', 2362), ('particle', 2363), ('people', 2364), ('attachment', 2365), ('periodic', 2366), ('subcategorization', 2367), ('transitions', 2368), ('constant', 2369), ('steps', 2370), ('forests', 2371), ('hypotheses', 2372), ('translations', 2373), ('enforcing', 2374), ('several', 2375), ('spectrum', 2376), ('invited', 2377), ('divide', 2378), ('yahoo', 2379), ('lower', 2380), ('store', 2381), ('tv', 2382), ('hands', 2383), ('have', 2384), ('scenes', 2385), ('mdl', 2386), ('aggressive', 2387), ('reason', 2388), ('departments', 2389), ('lambda', 2390), ('diagram', 2391), ('catalogs', 2392), ('grounding', 2393), ('passage', 2394), ('qa', 2395), ('nmf', 2396), ('represent', 2397), ('assumptions', 2398), ('phenomena', 2399), ('dl', 2400), ('phonological', 2401), ('workloads', 2402), ('lectures', 2403), ('speeding', 2404), ('assistants', 2405), ('grids', 2406), ('retrospective', 2407), ('composing', 2408), ('linked', 2409), ('sizes', 2410), ('overlapping', 2411), ('article', 2412), ('handle', 2413), ('aid', 2414), ('handwriting', 2415), ('randomization', 2416), ('variance', 2417), ('cultural', 2418), ('miner', 2419), ('likely', 2420), ('whats', 2421), ('equality', 2422), ('tensor', 2423), ('descriptive', 2424), ('force', 2425), ('preconditions', 2426), ('vote', 2427), ('situated', 2428), ('item', 2429), ('assigning', 2430), ('interpreting', 2431), ('capture', 2432), ('outputs', 2433), ('simplifying', 2434), ('passive', 2435), ('discussions', 2436), ('movements', 2437), ('scoping', 2438), ('computable', 2439), ('statistic', 2440), ('establishing', 2441), ('anonymizing', 2442), ('push', 2443), ('bitmap', 2444), ('proposed', 2445), ('scalar', 2446), ('outerjoins', 2447), ('troubleshooting', 2448), ('mass', 2449), ('stemming', 2450), ('principal', 2451), ('sky', 2452), ('accessible', 2453), ('hindsight', 2454), ('consequence', 2455), ('drt', 2456), ('simd', 2457), ('patient', 2458), ('lego', 2459), ('polarity', 2460), ('graded', 2461), ('fluents', 2462), ('sciences', 2463), ('day', 2464), ('currency', 2465), ('divergence', 2466), ('variant', 2467), ('controls', 2468), ('taxonomic', 2469), ('pictures', 2470), ('bio', 2471), ('spreading', 2472), ('abandonment', 2473), ('inferences', 2474), ('jump', 2475), ('story', 2476), ('emotion', 2477), ('elections', 2478), ('novices', 2479), ('reusing', 2480), ('mixtures', 2481), ('spammers', 2482), ('taught', 2483), ('coherency', 2484), ('setting', 2485), ('duplication', 2486), ('weaving', 2487), ('concert', 2488), ('reconstructing', 2489), ('incrementality', 2490), ('ideal', 2491), ('present', 2492), ('release', 2493), ('same', 2494), ('deviation', 2495), ('tsimmis', 2496), ('skylines', 2497), ('continual', 2498), ('unrestricted', 2499), ('boltzmann', 2500), ('ebl', 2501), ('forgetting', 2502), ('adversarial', 2503), ('referential', 2504), ('squares', 2505), ('editor', 2506), ('thread', 2507), ('starburst', 2508), ('discontinuous', 2509), ('elaboration', 2510), ('bytecode', 2511), ('notions', 2512), ('tcp', 2513), ('postgres', 2514), ('pi', 2515), ('providers', 2516), ('clouds', 2517), ('identity', 2518), ('detailed', 2519), ('important', 2520), ('imperative', 2521), ('ocr', 2522), ('nodes', 2523), ('associated', 2524), ('encyclopedia', 2525), ('fragment', 2526), ('contest', 2527), ('summer', 2528), ('substitution', 2529), ('centering', 2530), ('focal', 2531), ('works', 2532), ('principled', 2533), ('subqueries', 2534), ('element', 2535), ('nn', 2536), ('samples', 2537), ('connectionist', 2538), ('topology', 2539), ('visibility', 2540), ('cumulative', 2541), ('transducer', 2542), ('exclusive', 2543), ('manage', 2544), ('fly', 2545), ('intrusions', 2546), ('viewpoints', 2547), ('phonology', 2548), ('andor', 2549), ('refined', 2550), ('lite', 2551), ('factory', 2552), ('pronominal', 2553), ('soccer', 2554), ('edits', 2555), ('far', 2556), ('mandarin', 2557), ('clues', 2558), ('stemmer', 2559), ('provably', 2560), ('chunks', 2561), ('tough', 2562), ('tuples', 2563), ('tagger', 2564), ('10g', 2565), ('interpreters', 2566), ('potential', 2567), ('attribution', 2568), ('treewidth', 2569), ('customizable', 2570), ('onto', 2571), ('choosing', 2572), ('syntactically', 2573), ('substring', 2574), ('mediators', 2575), ('characterizations', 2576), ('getting', 2577), ('schools', 2578), ('overcoming', 2579), ('deployment', 2580), ('much', 2581), ('reduced', 2582), ('cp', 2583), ('localized', 2584), ('movie', 2585), ('prepositional', 2586), ('hp', 2587), ('opportunity', 2588), ('sorted', 2589), ('nonmyopic', 2590), ('demo', 2591), ('heterogenous', 2592), ('manual', 2593), ('simpler', 2594), ('elementary', 2595), ('barrier', 2596), ('insurance', 2597), ('variation', 2598), ('pitch', 2599), ('contrast', 2600), ('des', 2601), ('sub', 2602), ('counts', 2603), ('envy', 2604), ('goods', 2605), ('customization', 2606), ('emergent', 2607), ('executable', 2608), ('conservative', 2609), ('tunable', 2610), ('gis', 2611), ('recurrence', 2612), ('humor', 2613), ('agnostic', 2614), ('molecular', 2615), ('including', 2616), ('tracing', 2617), ('mls', 2618), ('certifying', 2619), ('inversion', 2620), ('century', 2621), ('identify', 2622), ('causes', 2623), ('12', 2624), ('this', 2625), ('orders', 2626), ('variety', 2627), ('verbose', 2628), ('job', 2629), ('intersection', 2630), ('segmenting', 2631), ('goes', 2632), ('locally', 2633), ('nothing', 2634), ('quickly', 2635), ('hierarchically', 2636), ('durations', 2637), ('lab', 2638), ('compliance', 2639), ('together', 2640), ('intractable', 2641), ('cloning', 2642), ('envelope', 2643), ('2000', 2644), ('senses', 2645), ('developers', 2646), ('exploitation', 2647), ('act', 2648), ('robocup', 2649), ('color', 2650), ('axioms', 2651), ('imitation', 2652), ('play', 2653), ('packing', 2654), ('formed', 2655), ('tabular', 2656), ('scores', 2657), ('lookahead', 2658), ('suites', 2659), ('exactly', 2660), ('layer', 2661), ('stopping', 2662), ('exhaustive', 2663), ('icse', 2664), ('cognition', 2665), ('ordinal', 2666), ('feasibility', 2667), ('units', 2668), ('equivalent', 2669), ('bandit', 2670), ('designed', 2671), ('distributional', 2672), ('coordinating', 2673), ('request', 2674), ('indirect', 2675), ('legal', 2676), ('enhancements', 2677), ('staged', 2678), ('traces', 2679), ('shopping', 2680), ('purchase', 2681), ('bugs', 2682), ('adjusting', 2683), ('property', 2684), ('monitor', 2685), ('vlsi', 2686), ('restarts', 2687), ('defeasible', 2688), ('subspaces', 2689), ('proposal', 2690), ('average', 2691), ('will', 2692), ('versatile', 2693), ('characteristics', 2694), ('preprocessing', 2695), ('transmission', 2696), ('continuation', 2697), ('propagating', 2698), ('combinations', 2699), ('db', 2700), ('projective', 2701), ('epsilon', 2702), ('derive', 2703), ('notation', 2704), ('defense', 2705), ('permission', 2706), ('combine', 2707), ('sliding', 2708), ('exodus', 2709), ('super', 2710), ('compressor', 2711), ('distinct', 2712), ('multiset', 2713), ('exploits', 2714), ('crash', 2715), ('checkpointing', 2716), ('continuations', 2717), ('alignments', 2718), ('promises', 2719), ('admissible', 2720), ('dependability', 2721), ('portal', 2722), ('terminologies', 2723), ('memories', 2724), ('priorities', 2725), ('null', 2726), ('o2', 2727), ('labels', 2728), ('scheduler', 2729), ('blogging', 2730), ('ads', 2731), ('aerial', 2732), ('tune', 2733), ('deictic', 2734), ('gestures', 2735), ('optimum', 2736), ('incrementally', 2737), ('factoring', 2738), ('salience', 2739), ('accreditation', 2740), ('scenario', 2741), ('stop', 2742), ('estimators', 2743), ('used', 2744), ('pilot', 2745), ('fourier', 2746), ('aligned', 2747), ('webdav', 2748), ('contracts', 2749), ('compare', 2750), ('branching', 2751), ('conflicts', 2752), ('quadratic', 2753), ('cheap', 2754), ('creative', 2755), ('pool', 2756), ('equivalents', 2757), ('haystack', 2758), ('sharable', 2759), ('keywords', 2760), ('checker', 2761), ('ugly', 2762), ('interactivity', 2763), ('nsf', 2764), ('funding', 2765), ('posterior', 2766), ('nasa', 2767), ('environmental', 2768), ('consumer', 2769), ('correspondence', 2770), ('math', 2771), ('rigorous', 2772), ('pipelining', 2773), ('typical', 2774), ('accelerated', 2775), ('backup', 2776), ('philosophy', 2777), ('sequencing', 2778), ('participation', 2779), ('interlingual', 2780), ('square', 2781), ('hyper', 2782), ('growth', 2783), ('morpho', 2784), ('analyser', 2785), ('succinct', 2786), ('hit', 2787), ('recognize', 2788), ('given', 2789), ('ajax', 2790), ('cryptographically', 2791), ('era', 2792), ('risc', 2793), ('mail', 2794), ('built', 2795), ('optimally', 2796), ('implicatures', 2797), ('identifiers', 2798), ('clustered', 2799), ('bipartite', 2800), ('haplotype', 2801), ('thought', 2802), ('quantile', 2803), ('annotating', 2804), ('million', 2805), ('bank', 2806), ('discontinuities', 2807), ('narratives', 2808), ('developer', 2809), ('mashup', 2810), ('hypertree', 2811), ('third', 2812), ('fundamentals', 2813), ('valid', 2814), ('assertion', 2815), ('delivering', 2816), ('overload', 2817), ('estimates', 2818), ('broadening', 2819), ('categorisation', 2820), ('difficulty', 2821), ('tests', 2822), ('verbs', 2823), ('script', 2824), ('title', 2825), ('effectively', 2826), ('hits', 2827), ('minimizing', 2828), ('camera', 2829), ('pushing', 2830), ('chunking', 2831), ('dense', 2832), ('subsumption', 2833), ('telecommunication', 2834), ('insight', 2835), ('configuring', 2836), ('versioned', 2837), ('date', 2838), ('conjunctions', 2839), ('conference', 2840), ('translate', 2841), ('utterances', 2842), ('atomicity', 2843), ('exception', 2844), ('talk', 2845), ('normalizing', 2846), ('compiled', 2847), ('fractal', 2848), ('vehicles', 2849), ('puzzle', 2850), ('benefit', 2851), ('reachability', 2852), ('episodes', 2853), ('aliasing', 2854), ('give', 2855), ('child', 2856), ('ambiguities', 2857), ('enabled', 2858), ('rue', 2859), ('2008', 2860), ('recovering', 2861), ('spacecraft', 2862), ('syllable', 2863), ('achieve', 2864), ('closures', 2865), ('culture', 2866), ('encapsulation', 2867), ('readability', 2868), ('available', 2869), ('generalised', 2870), ('ccg', 2871), ('parallelizing', 2872), ('constructions', 2873), ('substructure', 2874), ('distillation', 2875), ('statically', 2876), ('resistant', 2877), ('schedules', 2878), ('spin', 2879), ('philosophers', 2880), ('heap', 2881), ('pervasive', 2882), ('securing', 2883), ('enumeration', 2884), ('turning', 2885), ('bed', 2886), ('encoding', 2887), ('recommending', 2888), ('travel', 2889), ('packages', 2890), ('various', 2891), ('place', 2892), ('mediator', 2893), ('certification', 2894), ('irrelevance', 2895), ('popularity', 2896), ('auto', 2897), ('bdds', 2898), ('learnability', 2899), ('odmg', 2900), ('naming', 2901), ('every', 2902), ('ease', 2903), ('multiplication', 2904), ('anomalous', 2905), ('russian', 2906), ('guessing', 2907), ('segment', 2908), ('covariance', 2909), ('ownership', 2910), ('bottleneck', 2911), ('markers', 2912), ('advantages', 2913), ('graduate', 2914), ('hci', 2915), ('motivated', 2916), ('angle', 2917), ('bin', 2918), ('cipher', 2919), ('get', 2920), ('populated', 2921), ('o', 2922), ('lifecycle', 2923), ('heterogeneity', 2924), ('basket', 2925), ('trip', 2926), ('revisiting', 2927), ('treating', 2928), ('propositions', 2929), ('brokering', 2930), ('decade', 2931), ('connection', 2932), ('wild', 2933), ('internal', 2934), ('pdas', 2935), ('construct', 2936), ('coalition', 2937), ('turing', 2938), ('closest', 2939), ('priority', 2940), ('acquired', 2941), ('authoring', 2942), ('lifetime', 2943), ('infer', 2944), ('puzzles', 2945), ('hindi', 2946), ('illinois', 2947), ('sessions', 2948), ('volume', 2949), ('99', 2950), ('haskell', 2951), ('keyframe', 2952), ('constructs', 2953), ('iii', 2954), ('folksonomy', 2955), ('comparisons', 2956), ('bagging', 2957), ('accurately', 2958), ('reclamation', 2959), ('displays', 2960), ('novelty', 2961), ('national', 2962), ('trend', 2963), ('autoepistemic', 2964), ('overlap', 2965), ('multifaceted', 2966), ('meeting', 2967), ('coefficient', 2968), ('transforming', 2969), ('perfect', 2970), ('reputation', 2971), ('intervals', 2972), ('locations', 2973), ('equational', 2974), ('fixed', 2975), ('cryptography', 2976), ('interrelated', 2977), ('expectations', 2978), ('literacy', 2979), ('t', 2980), ('fitting', 2981), ('du', 2982), ('primary', 2983), ('convolution', 2984), ('trails', 2985), ('exist', 2986), ('threaded', 2987), ('dag', 2988), ('erp', 2989), ('baseline', 2990), ('datr', 2991), ('adapted', 2992), ('island', 2993), ('commonsense', 2994), ('motivation', 2995), ('overhead', 2996), ('positions', 2997), ('freshman', 2998), ('singular', 2999), ('follow', 3000), ('rationale', 3001), ('promotion', 3002), ('freely', 3003), ('aqua', 3004), ('redescription', 3005), ('projected', 3006), ('reconfigurable', 3007), ('economics', 3008), ('parsimonious', 3009), ('positives', 3010), ('salsa', 3011), ('scientists', 3012), ('superoptimizer', 3013), ('lsh', 3014), ('grace', 3015), ('strength', 3016), ('classic', 3017), ('mindstorms', 3018), ('disaster', 3019), ('american', 3020), ('him', 3021), ('broadcasts', 3022), ('aqualogic', 3023), ('backjumping', 3024), ('varying', 3025), ('ria', 3026), ('ap', 3027), ('ndcg', 3028), ('calendar', 3029), ('pushdown', 3030), ('clique', 3031), ('letting', 3032), ('cat', 3033), ('say', 3034), ('defects', 3035), ('eufid', 3036), ('again', 3037), ('after', 3038), ('kernelized', 3039), ('w3qs', 3040), ('survivability', 3041), ('accounting', 3042), ('dataspaces', 3043), ('inspired', 3044), ('tutors', 3045), ('health', 3046), ('abnormal', 3047), ('interestingness', 3048), ('emotional', 3049), ('pronouns', 3050), ('echo', 3051), ('anticipating', 3052), ('harmonic', 3053), ('variational', 3054), ('ibm', 3055), ('asymmetric', 3056), ('decomposing', 3057), ('outsourcing', 3058), ('fixpoints', 3059), ('firing', 3060), ('coalitions', 3061), ('pragmatics', 3062), ('macros', 3063), ('dataspace', 3064), ('exponentially', 3065), ('animations', 3066), ('sift', 3067), ('similarities', 3068), ('oo', 3069), ('enhancement', 3070), ('hilbert', 3071), ('fractals', 3072), ('mosaic', 3073), ('mark', 3074), ('provision', 3075), ('mid', 3076), ('queueing', 3077), ('subtypes', 3078), ('optimisation', 3079), ('respond', 3080), ('performances', 3081), ('telegraph', 3082), ('smooth', 3083), ('payment', 3084), ('repairing', 3085), ('dls', 3086), ('analysing', 3087), ('summarisation', 3088), ('schemasql', 3089), ('guest', 3090), ('skip', 3091), ('cosine', 3092), ('judgements', 3093), ('worst', 3094), ('care', 3095), ('cpu', 3096), ('orchestra', 3097), ('unusual', 3098), ('terabyte', 3099), ('sized', 3100), ('feed', 3101), ('formally', 3102), ('interpreted', 3103), ('epistemic', 3104), ('infrastructures', 3105), ('agree', 3106), ('identifiability', 3107), ('geographically', 3108), ('statistically', 3109), ('delta', 3110), ('duration', 3111), ('lookup', 3112), ('simplification', 3113), ('apply', 3114), ('catching', 3115), ('stride', 3116), ('department', 3117), ('thai', 3118), ('responses', 3119), ('before', 3120), ('ultra', 3121), ('dyadic', 3122), ('catalog', 3123), ('existential', 3124), ('intentional', 3125), ('satisfiable', 3126), ('connections', 3127), ('hyperlinked', 3128), ('handwritten', 3129), ('empty', 3130), ('anonymity', 3131), ('isomorphism', 3132), ('zoo', 3133), ('centrality', 3134), ('sketched', 3135), ('inspections', 3136), ('acceleration', 3137), ('snapshots', 3138), ('scaled', 3139), ('revised', 3140), ('cyc', 3141), ('implement', 3142), ('scalability', 3143), ('infosleuth', 3144), ('realising', 3145), ('syntactified', 3146), ('backwards', 3147), ('controllers', 3148), ('fairness', 3149), ('uniqueness', 3150), ('perceived', 3151), ('stock', 3152), ('misuse', 3153), ('combinator', 3154), ('duality', 3155), ('variability', 3156), ('budget', 3157), ('enforcement', 3158), ('plots', 3159), ('speculation', 3160), ('cover', 3161), ('violation', 3162), ('formulations', 3163), ('crawlers', 3164), ('diam', 3165), ('texture', 3166), ('gist', 3167), ('knowledgeable', 3168), ('per', 3169), ('fraud', 3170), ('affinity', 3171), ('acronym', 3172), ('credit', 3173), ('subgraph', 3174), ('95', 3175), ('nuggets', 3176), ('sentential', 3177), ('trained', 3178), ('pearl', 3179), ('prefix', 3180), ('suspicious', 3181), ('observed', 3182), ('atoms', 3183), ('reconciling', 3184), ('requests', 3185), ('impaired', 3186), ('thumbs', 3187), ('compacting', 3188), ('diagnosability', 3189), ('6', 3190), ('subsystem', 3191), ('scripting', 3192), ('leakage', 3193), ('quantiles', 3194), ('subjective', 3195), ('idiom', 3196), ('xprs', 3197), ('limits', 3198), ('semijoin', 3199), ('selections', 3200), ('gossiping', 3201), ('unnesting', 3202), ('member', 3203), ('devise', 3204), ('htn', 3205), ('dialect', 3206), ('maybe', 3207), ('section', 3208), ('actively', 3209), ('steroids', 3210), ('mention', 3211), ('maxent', 3212), ('reciprocal', 3213), ('connectivity', 3214), ('accents', 3215), ('suppressed', 3216), ('par', 3217), ('le', 3218), ('taken', 3219), ('dom', 3220), ('freeness', 3221), ('indivisible', 3222), ('mailing', 3223), ('mine', 3224), ('alc', 3225), ('ratio', 3226), ('degrees', 3227), ('freedom', 3228), ('sgml', 3229), ('immune', 3230), ('rasdaman', 3231), ('disambiguate', 3232), ('exemplar', 3233), ('collectors', 3234), ('disequilibrium', 3235), ('sloan', 3236), ('tighter', 3237), ('recency', 3238), ('oop', 3239), ('wave', 3240), ('discount', 3241), ('shapelets', 3242), ('interrupts', 3243), ('ddb', 3244), ('necessity', 3245), ('nature', 3246), ('logically', 3247), ('home', 3248), ('wallet', 3249), ('seemed', 3250), ('tumor', 3251), ('reaching', 3252), ('unsatisfiability', 3253), ('asymptotic', 3254), ('shallow', 3255), ('fix', 3256), ('delimited', 3257), ('heads', 3258), ('graduates', 3259), ('yet', 3260), ('auc', 3261), ('shapes', 3262), ('gradual', 3263), ('dilemma', 3264), ('add', 3265), ('competence', 3266), ('addition', 3267), ('studio', 3268), ('tying', 3269), ('subquery', 3270), ('avoidance', 3271), ('encyclopedic', 3272), ('disc', 3273), ('subtopic', 3274), ('fresh', 3275), ('interacting', 3276), ('marginal', 3277), ('coordinates', 3278), ('channels', 3279), ('drug', 3280), ('sequoia', 3281), ('prefer', 3282), ('observer', 3283), ('costly', 3284), ('explainable', 3285), ('tactical', 3286), ('skewing', 3287), ('storing', 3288), ('frontier', 3289), ('administration', 3290), ('compete', 3291), ('compile', 3292), ('subsumers', 3293), ('eportal', 3294), ('empirically', 3295), ('janus', 3296), ('archiving', 3297), ('hosting', 3298), ('centers', 3299), ('offering', 3300), ('verbmobil', 3301), ('coach', 3302), ('antlima', 3303), ('spreadsheets', 3304), ('autonomy', 3305), ('even', 3306), ('managers', 3307), ('paragraph', 3308), ('kronecker', 3309), ('burst', 3310), ('coping', 3311), ('those', 3312), ('cant', 3313), ('behavioural', 3314), ('justification', 3315), ('dominators', 3316), ('medicine', 3317), ('augmentation', 3318), ('banking', 3319), ('biologically', 3320), ('genes', 3321), ('markets', 3322), ('height', 3323), ('cougar', 3324), ('metonymy', 3325), ('developed', 3326), ('tutor', 3327), ('vp', 3328), ('adjustment', 3329), ('signals', 3330), ('pac', 3331), ('personality', 3332), ('cue', 3333), ('planners', 3334), ('swing', 3335), ('xtra', 3336), ('deletion', 3337), ('semidefinite', 3338), ('corba', 3339), ('wisdom', 3340), ('yield', 3341), ('differing', 3342), ('polyhedral', 3343), ('address', 3344), ('animate', 3345), ('yes', 3346), ('makes', 3347), ('advance', 3348), ('organizer', 3349), ('ltag', 3350), ('ephemeral', 3351), ('bisimulation', 3352), ('ambients', 3353), ('predicted', 3354), ('proportional', 3355), ('chance', 3356), ('advisor', 3357), ('2005', 3358), ('wrap', 3359), ('externalities', 3360), ('psychology', 3361), ('portfolio', 3362), ('intellectual', 3363), ('basics', 3364), ('instructors', 3365), ('iceberg', 3366), ('delay', 3367), ('scripts', 3368), ('bridge', 3369), ('philosophical', 3370), ('reducible', 3371), ('modest', 3372), ('oss', 3373), ('encouraging', 3374), ('gmap', 3375), ('huge', 3376), ('select', 3377), ('blogscope', 3378), ('railroad', 3379), ('styles', 3380), ('vdm', 3381), ('strudel', 3382), ('eos', 3383), ('targeted', 3384), ('paradigmatic', 3385), ('mediated', 3386), ('timing', 3387), ('counterfactuals', 3388), ('bibliographic', 3389), ('roc', 3390), ('fragmentation', 3391), ('checkpoints', 3392), ('longevity', 3393), ('dbmss', 3394), ('limiting', 3395), ('preferred', 3396), ('dialectical', 3397), ('trajectory', 3398), ('unexpected', 3399), ('generality', 3400), ('chip', 3401), ('inflectional', 3402), ('platforms', 3403), ('multinomial', 3404), ('normalized', 3405), ('learnable', 3406), ('organize', 3407), ('associating', 3408), ('perceptions', 3409), ('paging', 3410), ('fetches', 3411), ('essence', 3412), ('investment', 3413), ('extensive', 3414), ('populations', 3415), ('inapplicable', 3416), ('introspection', 3417), ('disjunction', 3418), ('known', 3419), ('convergent', 3420), ('plsa', 3421), ('deepening', 3422), ('inexpensive', 3423), ('accelerating', 3424), ('factoid', 3425), ('observational', 3426), ('reasoners', 3427), ('magnetic', 3428), ('strictly', 3429), ('inlining', 3430), ('mcdb', 3431), ('modifying', 3432), ('intermittently', 3433), ('putting', 3434), ('scans', 3435), ('bandwidth', 3436), ('hints', 3437), ('informatics', 3438), ('written', 3439), ('conversations', 3440), ('backbones', 3441), ('backdoors', 3442), ('coordinate', 3443), ('jflap', 3444), ('tac', 3445), ('direction', 3446), ('atlas', 3447), ('authors', 3448), ('maze', 3449), ('targets', 3450), ('unfamiliar', 3451), ('clip', 3452), ('participants', 3453), ('lattices', 3454), ('determine', 3455), ('architecting', 3456), ('gesture', 3457), ('truncated', 3458), ('circular', 3459), ('sublanguage', 3460), ('incentive', 3461), ('synchronisation', 3462), ('damping', 3463), ('exclusion', 3464), ('phonemes', 3465), ('z', 3466), ('idlp', 3467), ('dnnf', 3468), ('relatively', 3469), ('notification', 3470), ('revelation', 3471), ('return', 3472), ('densification', 3473), ('crowds', 3474), ('decomposability', 3475), ('disseminating', 3476), ('amazons', 3477), ('subscription', 3478), ('standardization', 3479), ('debate', 3480), ('malware', 3481), ('offs', 3482), ('money', 3483), ('forum', 3484), ('gradients', 3485), ('brain', 3486), ('fun', 3487), ('rotation', 3488), ('convenient', 3489), ('motor', 3490), ('typechecking', 3491), ('ended', 3492), ('linker', 3493), ('astral', 3494), ('awareness', 3495), ('connectors', 3496), ('guidelines', 3497), ('motifs', 3498), ('resiliency', 3499), ('thresholding', 3500), ('oil', 3501), ('equipment', 3502), ('accelerator', 3503), ('multiprocessors', 3504), ('previews', 3505), ('banks', 3506), ('spider', 3507), ('debugger', 3508), ('prioritizing', 3509), ('quadratically', 3510), ('commitments', 3511), ('perform', 3512), ('jawaa', 3513), ('formations', 3514), ('oid', 3515), ('may', 3516), ('experiencing', 3517), ('literal', 3518), ('cryptographic', 3519), ('percentile', 3520), ('runs', 3521), ('subsets', 3522), ('branches', 3523), ('led', 3524), ('deduplication', 3525), ('overlapped', 3526), ('quantifiers', 3527), ('translational', 3528), ('velocity', 3529), ('derivatives', 3530), ('miss', 3531), ('assertions', 3532), ('eth', 3533), ('zurich', 3534), ('synopsis', 3535), ('mars', 3536), ('customers', 3537), ('required', 3538), ('boat', 3539), ('el', 3540), ('dependable', 3541), ('bcnf', 3542), ('institutions', 3543), ('quizzes', 3544), ('reaction', 3545), ('circuit', 3546), ('burstiness', 3547), ('enriching', 3548), ('negotiating', 3549), ('five', 3550), ('decide', 3551), ('whether', 3552), ('schedule', 3553), ('continuously', 3554), ('therapy', 3555), ('pedagogical', 3556), ('has', 3557), ('reserve', 3558), ('prices', 3559), ('bids', 3560), ('cellular', 3561), ('acoustic', 3562), ('spotting', 3563), ('indian', 3564), ('formatting', 3565), ('teamwork', 3566), ('intra', 3567), ('metatheory', 3568), ('curves', 3569), ('garden', 3570), ('female', 3571), ('critique', 3572), ('rendering', 3573), ('espresso', 3574), ('conjunction', 3575), ('vldb', 3576), ('vectorization', 3577), ('tail', 3578), ('shilling', 3579), ('profit', 3580), ('prima', 3581), ('descriptors', 3582), ('wheel', 3583), ('radar', 3584), ('microcomputer', 3585), ('distributive', 3586), ('stereotype', 3587), ('cinematic', 3588), ('modes', 3589), ('mixing', 3590), ('weather', 3591), ('forecasts', 3592), ('fp', 3593), ('wall', 3594), ('abnormality', 3595), ('recording', 3596), ('reasons', 3597), ('roll', 3598), ('requires', 3599), ('rime', 3600), ('extensional', 3601), ('imbalanced', 3602), ('lifting', 3603), ('srl', 3604), ('pathfinder', 3605), ('holmes', 3606), ('enity', 3607), ('competition', 3608), ('multiway', 3609), ('certain', 3610), ('topss', 3611), ('tournament', 3612), ('equilibrium', 3613), ('abstracts', 3614), ('nonstop', 3615), ('cots', 3616), ('soar', 3617), ('players', 3618), ('disruptions', 3619), ('eliciting', 3620), ('hierarchic', 3621), ('truthful', 3622), ('climbing', 3623), ('laplacian', 3624), ('nf2', 3625), ('perceptual', 3626), ('prospects', 3627), ('token', 3628), ('partitions', 3629), ('metaphors', 3630), ('securely', 3631), ('warping', 3632), ('invention', 3633), ('markup', 3634), ('xxl', 3635), ('implicitly', 3636), ('pcfg', 3637), ('rethinking', 3638), ('eca', 3639), ('oodbms', 3640), ('ida', 3641), ('mereological', 3642), ('insertion', 3643), ('arithmetic', 3644), ('semitic', 3645), ('whose', 3646), ('odometry', 3647), ('id', 3648), ('exogenous', 3649), ('markovian', 3650), ('specify', 3651), ('black', 3652), ('universities', 3653), ('ride', 3654), ('throughout', 3655), ('papers', 3656), ('folding', 3657), ('achievements', 3658), ('photographs', 3659), ('leak', 3660), ('container', 3661), ('reviewers', 3662), ('isomorphisms', 3663), ('formulating', 3664), ('prove', 3665), ('cliques', 3666), ('polysemy', 3667), ('repeat', 3668), ('yahoos', 3669), ('rough', 3670), ('great', 3671), ('insights', 3672), ('cells', 3673), ('close', 3674), ('also', 3675), ('necessary', 3676), ('weakest', 3677), ('sufficient', 3678), ('comic', 3679), ('surrogate', 3680), ('synergistic', 3681), ('recompilation', 3682), ('water', 3683), ('repetition', 3684), ('crawl', 3685), ('marked', 3686), ('problematic', 3687), ('deferred', 3688), ('inferential', 3689), ('multiview', 3690), ('hyperlinks', 3691), ('plus', 3692), ('enforce', 3693), ('se', 3694), ('ramifications', 3695), ('qualifications', 3696), ('smash', 3697), ('interruptions', 3698), ('nomadic', 3699), ('economic', 3700), ('j2ee', 3701), ('normality', 3702), ('hypothetical', 3703), ('literate', 3704), ('tiered', 3705), ('marking', 3706), ('th', 3707), ('prize', 3708), ('unifies', 3709), ('audit', 3710), ('parent', 3711), ('unaware', 3712), ('gsp', 3713), ('aspectual', 3714), ('layers', 3715), ('asking', 3716), ('windowed', 3717), ('ancient', 3718), ('mrfs', 3719), ('triple', 3720), ('beginners', 3721), ('harder', 3722), ('having', 3723), ('protection', 3724), ('restful', 3725), ('contrasting', 3726), ('earley', 3727), ('unbounded', 3728), ('widening', 3729), ('specialized', 3730), ('scattergather', 3731), ('conquer', 3732), ('successes', 3733), ('oov', 3734), ('adequacy', 3735), ('locks', 3736), ('compute', 3737), ('generics', 3738), ('oracle8i', 3739), ('apache', 3740), ('phylogenetic', 3741), ('humming', 3742), ('verified', 3743), ('epic', 3744), ('homogeneous', 3745), ('coordinated', 3746), ('backdoor', 3747), ('upon', 3748), ('assist', 3749), ('retaining', 3750), ('configurations', 3751), ('apparent', 3752), ('book', 3753), ('gestalt', 3754), ('salient', 3755), ('predictability', 3756), ('preserves', 3757), ('being', 3758), ('probing', 3759), ('away', 3760), ('academic', 3761), ('homepage', 3762), ('begin', 3763), ('causality', 3764), ('morph', 3765), ('kinds', 3766), ('compilability', 3767), ('sections', 3768), ('hide', 3769), ('seek', 3770), ('choose', 3771), ('integrative', 3772), ('condition', 3773), ('selected', 3774), ('cohesive', 3775), ('bracketed', 3776), ('observing', 3777), ('adtrees', 3778), ('winwin', 3779), ('hopfield', 3780), ('existence', 3781), ('stm', 3782), ('internationalization', 3783), ('interleaved', 3784), ('allens', 3785), ('multilabel', 3786), ('extent', 3787), ('manifesto', 3788), ('covers', 3789), ('nulls', 3790), ('discriminating', 3791), ('powered', 3792), ('segmented', 3793), ('commercial', 3794), ('signs', 3795), ('geotagging', 3796), ('serf', 3797), ('box', 3798), ('titles', 3799), ('advancement', 3800), ('taggers', 3801), ('reversing', 3802), ('increasing', 3803), ('meet', 3804), ('fail', 3805), ('personalize', 3806), ('onboard', 3807), ('penn', 3808), ('multigram', 3809), ('sigma', 3810), ('cc', 3811), ('contradiction', 3812), ('exam', 3813), ('coming', 3814), ('age', 3815), ('xtract', 3816), ('2002', 3817), ('translators', 3818), ('japan', 3819), ('whom', 3820), ('occurrences', 3821), ('icon', 3822), ('timeline', 3823), ('urban', 3824), ('looking', 3825), ('glass', 3826), ('options', 3827), ('reconciliation', 3828), ('scales', 3829), ('preventing', 3830), ('preparation', 3831), ('isolated', 3832), ('0', 3833), ('constructivist', 3834), ('compress', 3835), ('interleaving', 3836), ('dissimilarity', 3837), ('moment', 3838), ('delegation', 3839), ('desires', 3840), ('crisis', 3841), ('currying', 3842), ('reservoir', 3843), ('tale', 3844), ('winning', 3845), ('asymmetry', 3846), ('wrappers', 3847), ('transferring', 3848), ('vocabularies', 3849), ('crowdsourcing', 3850), ('ratings', 3851), ('controllability', 3852), ('longest', 3853), ('canadian', 3854), ('traveller', 3855), ('move', 3856), ('mcmc', 3857), ('removing', 3858), ('iconic', 3859), ('created', 3860), ('borealis', 3861), ('frequencies', 3862), ('respect', 3863), ('untrusted', 3864), ('iid', 3865), ('stratified', 3866), ('seeing', 3867), ('dbo', 3868), ('photos', 3869), ('opportunistic', 3870), ('isnt', 3871), ('slot', 3872), ('fielded', 3873), ('orthographic', 3874), ('kanji', 3875), ('faculty', 3876), ('discipline', 3877), ('determinism', 3878), ('iterator', 3879), ('datalog', 3880), ('pictorial', 3881), ('thing', 3882), ('remarks', 3883), ('mined', 3884), ('apples', 3885), ('agility', 3886), ('confusion', 3887), ('educators', 3888), ('working', 3889), ('marketplace', 3890), ('affine', 3891), ('contour', 3892), ('calculations', 3893), ('risky', 3894), ('modulo', 3895), ('ner', 3896), ('multiattribute', 3897), ('preferential', 3898), ('golog', 3899), ('surveillance', 3900), ('keep', 3901), ('systemic', 3902), ('adaboost', 3903), ('calibration', 3904), ('adapt', 3905), ('start', 3906), ('expansions', 3907), ('monotone', 3908), ('primitive', 3909), ('influences', 3910), ('agglutinative', 3911), ('urbana', 3912), ('champaign', 3913), ('needed', 3914), ('throughput', 3915), ('scrolling', 3916), ('improves', 3917), ('plausible', 3918), ('reformulations', 3919), ('fluent', 3920), ('marker', 3921), ('artifacts', 3922), ('intonation', 3923), ('car', 3924), ('holdem', 3925), ('contours', 3926), ('artists', 3927), ('contact', 3928), ('kdd', 3929), ('obligations', 3930), ('sealed', 3931), ('initialization', 3932), ('lead', 3933), ('developments', 3934), ('hyperparameter', 3935), ('copying', 3936), ('raid', 3937), ('elastic', 3938), ('employing', 3939), ('genome', 3940), ('backward', 3941), ('recursively', 3942), ('narrative', 3943), ('allowing', 3944), ('h', 3945), ('spots', 3946), ('banner', 3947), ('matter', 3948), ('monotonicity', 3949), ('pools', 3950), ('innovative', 3951), ('mashups', 3952), ('refresh', 3953), ('retrieve', 3954), ('mesh', 3955), ('supply', 3956), ('decomposable', 3957), ('lesson', 3958), ('successful', 3959), ('microprocessor', 3960), ('tablet', 3961), ('folksonomies', 3962), ('informal', 3963), ('minority', 3964), ('material', 3965), ('oblivious', 3966), ('c45', 3967), ('oar', 3968), ('sap', 3969), ('check', 3970), ('dutch', 3971), ('cis', 3972), ('described', 3973), ('gr8', 3974), ('initial', 3975), ('executive', 3976), ('upper', 3977), ('nonlocal', 3978), ('facial', 3979), ('multiuser', 3980), ('collusion', 3981), ('trenches', 3982), ('connectives', 3983), ('v', 3984), ('czech', 3985), ('grammatically', 3986), ('pro', 3987), ('lifted', 3988), ('person', 3989), ('shading', 3990), ('engaging', 3991), ('structurally', 3992), ('lineage', 3993), ('manifolds', 3994), ('substitutions', 3995), ('personalised', 3996), ('damia', 3997), ('isometric', 3998), ('probe', 3999), ('fit', 4000), ('talking', 4001), ('toolbox', 4002), ('separating', 4003), ('roots', 4004), ('aggregated', 4005), ('combinational', 4006), ('forest', 4007), ('addressable', 4008), ('revolution', 4009), ('gps', 4010), ('terminal', 4011), ('votes', 4012), ('prefetch', 4013), ('floating', 4014), ('intuition', 4015), ('final', 4016), ('neuroevolution', 4017), ('psi', 4018), ('behind', 4019), ('calculation', 4020), ('shelf', 4021), ('qualifiers', 4022), ('professional', 4023), ('agglomerative', 4024), ('contingent', 4025), ('flight', 4026), ('insensitive', 4027), ('usable', 4028), ('additional', 4029), ('actor', 4030), ('15', 4031), ('union', 4032), ('usefulness', 4033), ('precedence', 4034), ('conformance', 4035), ('reflective', 4036), ('textes', 4037), ('lexique', 4038), ('80', 4039), ('dining', 4040), ('uses', 4041), ('backed', 4042), ('round', 4043), ('repair', 4044), ('coalescing', 4045), ('beam', 4046), ('consequences', 4047), ('opponent', 4048), ('outreach', 4049), ('representative', 4050), ('intonational', 4051), ('spreadsheet', 4052), ('mac', 4053), ('asymmetrical', 4054), ('ds', 4055), ('rigid', 4056), ('scan', 4057), ('pl', 4058), ('categorizing', 4059), ('synonyms', 4060), ('mongolian', 4061), ('lp', 4062), ('norms', 4063), ('multirelational', 4064), ('theme', 4065), ('positioning', 4066), ('deployed', 4067), ('histories', 4068), ('evidential', 4069), ('theres', 4070), ('denial', 4071), ('assessments', 4072), ('effortless', 4073), ('funbase', 4074), ('feaspar', 4075), ('scenic', 4076), ('webanywhere', 4077), ('screen', 4078), ('exsearch', 4079), ('barter', 4080), ('progression', 4081), ('aol', 4082), ('cryptanalytic', 4083), ('pseudorandom', 4084), ('nonexistence', 4085), ('usually', 4086), ('manipulate', 4087), ('contradictory', 4088), ('revival', 4089), ('mouse', 4090), ('rim', 4091), ('bsr', 4092), ('teg', 4093), ('localisation', 4094), ('blood', 4095), ('transfusion', 4096), ('porting', 4097), ('roadmap', 4098), ('members', 4099), ('survive', 4100), ('jungle', 4101), ('customizing', 4102), ('outlines', 4103), ('archived', 4104), ('span', 4105), ('envisioning', 4106), ('clients', 4107), ('itineraries', 4108), ('wellmade', 4109), ('t4sql', 4110), ('performamatics', 4111), ('taj', 4112), ('taint', 4113), ('aging', 4114), ('reorderable', 4115), ('freespan', 4116), ('jukebox', 4117), ('benign', 4118), ('racesallusing', 4119), ('replay', 4120), ('dantes', 4121), ('decreased', 4122), ('rdbv1', 4123), ('inline', 4124), ('trains', 4125), ('marketed', 4126), ('scanning', 4127), ('denali', 4128), ('lexeme', 4129), ('computationaily', 4130), ('everything', 4131), ('s81', 4132), ('zoomuserviews', 4133), ('latency', 4134), ('gess', 4135), ('interactively', 4136), ('wordnets', 4137), ('freshmen', 4138), ('unbundling', 4139), ('psst', 4140), ('political', 4141), ('outcomes', 4142), ('hospital', 4143), ('disjoint', 4144), ('poor', 4145), ('cognates', 4146), ('added', 4147), ('abuse', 4148), ('signing', 4149), ('rsa', 4150), ('monkeys', 4151), ('african', 4152), ('millennial', 4153), ('classificatory', 4154), ('hyperbf', 4155), ('ipse', 4156), ('anyone', 4157), ('precluding', 4158), ('saiu', 4159), ('nrrc', 4160), ('bfnumdocs', 4161), ('thor', 4162), ('cmradar', 4163), ('pronunciations', 4164), ('wysiwyg', 4165), ('forwarding', 4166), ('shake', 4167), ('bake', 4168), ('paraccel', 4169), ('medusa', 4170), ('xsds', 4171), ('morphographemic', 4172), ('nonconcatenative', 4173), ('redefinitions', 4174), ('encountered', 4175), ('supercompilation', 4176), ('contrastive', 4177), ('encapsualtion', 4178), ('viewed', 4179), ('computerised', 4180), ('express', 4181), ('transposed', 4182), ('jasmin', 4183), ('ethical', 4184), ('societal', 4185), ('memoryless', 4186), ('polyphony', 4187), ('divergences', 4188), ('outsourced', 4189), ('bypass', 4190), ('aerospace', 4191), ('von', 4192), ('neumann', 4193), ('quantminer', 4194), ('micmac', 4195), ('microprogram', 4196), ('adon', 4197), ('certified', 4198), ('track', 4199), ('experiencer', 4200), ('proquel', 4201), ('php', 4202), ('maintain', 4203), ('sqlxnf', 4204), ('reinforcing', 4205), ('cutting', 4206), ('8th', 4207), ('manuals', 4208), ('junction', 4209), ('neptune', 4210), ('netserf', 4211), ('medialife', 4212), ('chronicle', 4213), ('sin', 4214), ('algovista', 4215), ('doubly', 4216), ('biin', 4217), ('evaluability', 4218), ('serfing', 4219), ('cabob', 4220), ('fpgas', 4221), ('subtasks', 4222), ('fcl', 4223), ('tribute', 4224), ('memorial', 4225), ('fractionation', 4226), ('refractionation', 4227), ('swarm', 4228), ('adnoun', 4229), ('supernode', 4230), ('hypertalk', 4231), ('overture', 4232), ('flocks', 4233), ('set®', 4234), ('deformable', 4235), ('lrpd', 4236), ('privatization', 4237), ('organizations', 4238), ('pinwheel', 4239), ('sides', 4240), ('coin', 4241), ('anorexic', 4242), ('paranoids', 4243), ('semiautomatic', 4244), ('bb1', 4245), ('orkut', 4246), ('transductions', 4247), ('hyperqueries', 4248), ('immix', 4249), ('mutator', 4250), ('equi', 4251), ('personalisation', 4252), ('telecommunications', 4253), ('invalidation', 4254), ('cam', 4255), ('jazz', 4256), ('impure', 4257), ('reformatting', 4258), ('header', 4259), ('interferring', 4260), ('emulator', 4261), ('helpful', 4262), ('biclustering', 4263), ('pcfgs', 4264), ('indicators', 4265), ('newton', 4266), ('machinima', 4267), ('impressionrank', 4268), ('sectioning', 4269), ('regex', 4270), ('card', 4271), ('swarms', 4272), ('defensive', 4273), ('climate', 4274), ('carefully', 4275), ('swizzling', 4276), ('cohesion', 4277), ('webware', 4278), ('letter', 4279), ('especial', 4280), ('1991', 4281), ('incentives', 4282), ('foreign', 4283), ('granularities', 4284), ('analogic', 4285), ('locker', 4286), ('extensiblerule', 4287), ('prune', 4288), ('reconsideration', 4289), ('passenger', 4290), ('airline', 4291), ('apportioning', 4292), ('subtype', 4293), ('baffling', 4294), ('factual', 4295), ('situationactivation', 4296), ('bimodal', 4297), ('fingerprinting', 4298), ('gregress', 4299), ('ohsumed', 4300), ('hol', 4301), ('metapher', 4302), ('sniafl', 4303), ('period', 4304), ('compensations', 4305), ('overseas', 4306), ('discord', 4307), ('ablation', 4308), ('shaping', 4309), ('shadowed', 4310), ('predilection', 4311), ('topigraphy', 4312), ('vita', 4313), ('cmm', 4314), ('dlfm', 4315), ('boxing', 4316), ('symbology', 4317), ('arrangement', 4318), ('ensembling', 4319), ('affiliated', 4320), ('supervision', 4321), ('biwtl', 4322), ('useless', 4323), ('statistice', 4324), ('aspiration', 4325), ('cnn', 4326), ('idiolectic', 4327), ('doctor', 4328), ('matches', 4329), ('ao', 4330), ('myths', 4331), ('sei', 4332), ('repartitioning', 4333), ('days', 4334), ('inspecting', 4335), ('placing', 4336), ('intensities', 4337), ('lars', 4338), ('recommenders', 4339), ('lexicalising', 4340), ('ccgbank', 4341), ('hat', 4342), ('extendible', 4343), ('little', 4344), ('diagrama', 4345), ('turbo', 4346), ('charging', 4347), ('spontaneously', 4348), ('dxq', 4349), ('dust', 4350), ('microeconomic', 4351), ('captions', 4352), ('warp', 4353), ('routine', 4354), ('gio', 4355), ('metu', 4356), ('cubetree', 4357), ('sesame', 4358), ('deceptively', 4359), ('ures', 4360), ('methodological', 4361), ('trey', 4362), ('tempus', 4363), ('fugit', 4364), ('workbench', 4365), ('winrdbi', 4366), ('refitting', 4367), ('slides', 4368), ('tabletpc', 4369), ('uncertainties', 4370), ('circumscribing', 4371), ('demonizing', 4372), ('publication', 4373), ('symbol', 4374), ('sri', 4375), ('carpenter', 4376), ('representativeness', 4377), ('walkthroughs', 4378), ('icicles', 4379), ('ratios', 4380), ('abbreviations', 4381), ('dataplorer', 4382), ('edict', 4383), ('bumps', 4384), ('curvature', 4385), ('zodiac', 4386), ('federation', 4387), ('cim', 4388), ('migrating', 4389), ('electronics', 4390), ('quark', 4391), ('resampling', 4392), ('financially', 4393), ('prioritization', 4394), ('encina', 4395), ('db2xml', 4396), ('representationalist', 4397), ('increase', 4398), ('adlads', 4399), ('upperbounds', 4400), ('streamglobe', 4401), ('youre', 4402), ('turnstile', 4403), ('linda', 4404), ('spmt', 4405), ('rpj', 4406), ('admit', 4407), ('conspiracy', 4408), ('pid', 4409), ('plow', 4410), ('instrumentation', 4411), ('hyperfairness', 4412), ('monadic', 4413), ('eql', 4414), ('bounce', 4415), ('advertisements', 4416), ('slim', 4417), ('adequate', 4418), ('polylingual', 4419), ('bigrams', 4420), ('spotsigs', 4421), ('melbourne', 4422), ('individualism', 4423), ('parameterizable', 4424), ('balance', 4425), ('vickrey', 4426), ('exchanges', 4427), ('prism', 4428), ('chase', 4429), ('framenet', 4430), ('loadstore', 4431), ('solves', 4432), ('semiconductor', 4433), ('assign', 4434), ('crosslingual', 4435), ('inside', 4436), ('giuku', 4437), ('utilities', 4438), ('camouflaged', 4439), ('horting', 4440), ('hatches', 4441), ('egg', 4442), ('exclaim', 4443), ('regeneration', 4444), ('eden', 4445), ('cohersion', 4446), ('rated', 4447), ('master', 4448), ('clp', 4449), ('substrate', 4450), ('davis', 4451), ('putnam', 4452), ('outerplanar', 4453), ('central', 4454), ('tip', 4455), ('informix', 4456), ('artdb', 4457), ('taxation', 4458), ('sustainable', 4459), ('chillers', 4460), ('definitional', 4461), ('functionally', 4462), ('rstar', 4463), ('concentration', 4464), ('ming', 4465), ('statix', 4466), ('automatized', 4467), ('dances', 4468), ('cause', 4469), ('checklist', 4470), ('nah', 4471), ('syndrome', 4472), ('sinuhe', 4473), ('ado', 4474), ('mediating', 4475), ('orientated', 4476), ('scarce', 4477), ('dialogic', 4478), ('walrus', 4479), ('redo', 4480), ('tolerating', 4481), ('disagreement', 4482), ('relief', 4483), ('rapidity', 4484), ('started', 4485), ('clarification', 4486), ('p2cast', 4487), ('patching', 4488), ('vod', 4489), ('symrnetric', 4490), ('guiding', 4491), ('rlsc', 4492), ('agony', 4493), ('interform', 4494), ('cf', 4495), ('gas', 4496), ('turbine', 4497), ('proliant', 4498), ('multimode', 4499), ('summarize', 4500), ('universe', 4501), ('affect', 4502), ('vista', 4503), ('mapgraph', 4504), ('labelled', 4505), ('cpcv', 4506), ('generations', 4507), ('overcome', 4508), ('developmentevolution', 4509), ('deeper', 4510), ('qrelx', 4511), ('geospatially', 4512), ('photograph', 4513), ('perf', 4514), ('bloomjoin', 4515), ('teapot', 4516), ('beaten', 4517), ('tracks', 4518), ('pay', 4519), ('subword', 4520), ('critics', 4521), ('substantional', 4522), ('enclosing', 4523), ('balls', 4524), ('emoticons', 4525), ('eyed', 4526), ('stereo', 4527), ('archjava', 4528), ('crossing', 4529), ('controller', 4530), ('assembler', 4531), ('mrdsm', 4532), ('timer', 4533), ('alerters', 4534), ('rooted', 4535), ('lob', 4536), ('talisman', 4537), ('un', 4538), ('système', 4539), ('gouverné', 4540), ('lois', 4541), ('linguistiques', 4542), ('pour', 4543), ('traitement', 4544), ('langue', 4545), ('naturelle', 4546), ('mcs', 4547), ('reconstruct', 4548), ('regulatory', 4549), ('ascription', 4550), ('dynamo', 4551), ('moded', 4552), ('prime', 4553), ('implicate', 4554), ('quantifiable', 4555), ('qos', 4556), ('incompleteness', 4557), ('chatty', 4558), ('renderman', 4559), ('kernelizing', 4560), ('pls', 4561), ('memoization', 4562), ('fax', 4563), ('proda', 4564), ('ink', 4565), ('exercises', 4566), ('taco', 4567), ('statisticalscientific', 4568), ('bnchmark', 4569), ('ulixes', 4570), ('gpx', 4571), ('paradise', 4572), ('chatting', 4573), ('occasions', 4574), ('factorial', 4575), ('cgcexplorer', 4576), ('treedt', 4577), ('sdss', 4578), ('skyserver', 4579), ('exercising', 4580), ('handy', 4581), ('trac', 4582), ('selforganizing', 4583), ('reuters', 4584), ('poison', 4585), ('pills', 4586), ('topically', 4587), ('miqis', 4588), ('chained', 4589), ('subdialogues', 4590), ('virtualized', 4591), ('seismic', 4592), ('treisman', 4593), ('workshops', 4594), ('rewards', 4595), ('critiquing', 4596), ('hypothesized', 4597), ('occlusion', 4598), ('asserting', 4599), ('preemptive', 4600), ('deoptimization', 4601), ('adms±', 4602), ('workstation', 4603), ('mainframe', 4604), ('gorder', 4605), ('17th', 4606), ('inex', 4607), ('ferry', 4608), ('optics', 4609), ('spill', 4610), ('infeasible', 4611), ('stanislavskian', 4612), ('dualminer', 4613), ('lung', 4614), ('markerless', 4615), ('gating', 4616), ('radiotherapy', 4617), ('cybercivics', 4618), ('motivational', 4619), ('gunsat', 4620), ('aktionsarten', 4621), ('gsat', 4622), ('drawings', 4623), ('urgent', 4624), ('subseries', 4625), ('movers', 4626), ('topp', 4627), ('magnitude', 4628), ('comfort', 4629), ('korea', 4630), ('coa', 4631), ('patents', 4632), ('artemis', 4633), ('lagrangian', 4634), ('tails', 4635), ('struggles', 4636), ('compatible', 4637), ('tight', 4638), ('recompression', 4639), ('carousel', 4640), ('morpiiemes', 4641), ('bellman', 4642), ('piloted', 4643), ('rmses', 4644), ('pareto', 4645), ('maturity', 4646), ('presenters', 4647), ('remembering', 4648), ('jule', 4649), ('neuro', 4650), ('muse', 4651), ('tricks', 4652), ('traps', 4653), ('initiating', 4654), ('opsm', 4655), ('epdl', 4656), ('dirty', 4657), ('contained', 4658), ('animated', 4659), ('winmagic', 4660), ('compilable', 4661), ('delicious', 4662), ('xquisite', 4663), ('multitext', 4664), ('pomdp', 4665), ('aviation', 4666), ('rolex', 4667), ('navigable', 4668), ('simplifications', 4669), ('isotonic', 4670), ('programing', 4671), ('worm', 4672), ('discs', 4673), ('glue', 4674), ('carbohydrate', 4675), ('multirobot', 4676), ('eggyolk', 4677), ('sorts', 4678), ('fm91', 4679), ('ocam', 4680), ('spinning', 4681), ('italian', 4682), ('dbcache', 4683), ('splice', 4684), ('doing', 4685), ('satellite', 4686), ('whiteboard', 4687), ('acting', 4688), ('cd', 4689), ('rom', 4690), ('superscalar', 4691), ('superimposed', 4692), ('rainforest', 4693), ('requiring', 4694), ('privatizing', 4695), ('thine', 4696), ('enemy', 4697), ('champion', 4698), ('ut', 4699), ('arlington', 4700), ('whisper', 4701), ('retina', 4702), ('anchorwoman', 4703), ('masses', 4704), ('verifier', 4705), ('modularizing', 4706), ('codescriptive', 4707), ('feedforward', 4708), ('timesten', 4709), ('optional', 4710), ('koref', 4711), ('gossip', 4712), ('slow', 4713), ('illumination', 4714), ('odd', 4715), ('coordinators', 4716), ('responders', 4717), ('shakespeare', 4718), ('rectangle', 4719), ('explication', 4720), ('articulatory', 4721), ('opening', 4722), ('eyes', 4723), ('armor', 4724), ('los', 4725), ('angeles', 4726), ('airport', 4727), ('cone', 4728), ('sqlb', 4729), ('consumers', 4730), ('hydra', 4731), ('auv', 4732), ('wildcards', 4733), ('desktops', 4734), ('motif', 4735), ('surf', 4736), ('gr2', 4737), ('lrtak', 4738), ('trigger', 4739), ('shopsmart', 4740), ('crfs', 4741), ('cascaded', 4742), ('lk', 4743), ('pier', 4744), ('luby', 4745), ('rackoff', 4746), ('negotiators', 4747), ('win', 4748), ('arbus', 4749), ('dbs', 4750), ('iphones', 4751), ('phones', 4752), ('oh', 4753), ('my', 4754), ('advertise', 4755), ('inexact', 4756), ('publications', 4757), ('speechlanguage', 4758), ('spellchecking', 4759), ('autocorrection', 4760), ('inspector', 4761), ('fringe', 4762), ('saving', 4763), ('warning', 4764), ('vulnerability', 4765), ('orderings', 4766), ('connect', 4767), ('radically', 4768), ('statechart', 4769), ('valuable', 4770), ('compared', 4771), ('own', 4772), ('armed', 4773), ('presuppositional', 4774), ('lexicalised', 4775), ('pdms', 4776), ('shard', 4777), ('laura', 4778), ('her', 4779), ('algorithmics', 4780), ('cui', 4781), ('capabilities', 4782), ('spark', 4783), ('beacond', 4784), ('counterexample', 4785), ('xseq', 4786), ('campaign', 4787), ('informatively', 4788), ('meinongian', 4789), ('pintos', 4790), ('prescription', 4791), ('admission', 4792), ('underspecification', 4793), ('transitivity', 4794), ('foregrounding', 4795), ('summarising', 4796), ('martingale', 4797), ('noa', 4798), ('normative', 4799), ('congruences', 4800), ('topologically', 4801), ('fpga', 4802), ('tower', 4803), ('straw', 4804), ('hypotheticals', 4805), ('holder', 4806), ('calling', 4807), ('conventions', 4808), ('filing', 4809), ('stripes', 4810), ('cape', 4811), ('tuned', 4812), ('complementarities', 4813), ('tdlambda', 4814), ('eligibility', 4815), ('further', 4816), ('topaz', 4817), ('parallelizer', 4818), ('sanitization', 4819), ('terminator', 4820), ('unrestrictd', 4821), ('gapping', 4822), ('rely', 4823), ('bigsur', 4824), ('koda', 4825), ('enumerating', 4826), ('popel', 4827), ('counters', 4828), ('sale', 4829), ('scrap', 4830), ('triggering', 4831), ('florid', 4832), ('fluid', 4833), ('centred', 4834), ('incompletely', 4835), ('boltzrank', 4836), ('maximize', 4837), ('translator', 4838), ('matesek', 4839), ('ring', 4840), ('sarms', 4841), ('gait', 4842), ('cocomo', 4843), ('uflip', 4844), ('staggered', 4845), ('striping', 4846), ('statestep', 4847), ('cm', 4848), ('eves', 4849), ('thresholds', 4850), ('tp', 4851), ('counterfactual', 4852), ('conditioning', 4853), ('inferred', 4854), ('decompose', 4855), ('vault', 4856), ('ibe', 4857), ('confidential', 4858), ('drafting', 4859), ('pods', 4860), ('nominals', 4861), ('pylonic', 4862), ('eeg', 4863), ('epileptic', 4864), ('seizures', 4865), ('cacheportal', 4866), ('hosted', 4867), ('dsdt', 4868), ('durable', 4869), ('xvm', 4870), ('credibility', 4871), ('brier', 4872), ('potentialities', 4873), ('reducers', 4874), ('redus', 4875), ('swifft', 4876), ('fft', 4877), ('influencing', 4878), ('constraining', 4879), ('unicorn', 4880), ('seasonality', 4881), ('facile', 4882), ('simulators', 4883), ('parlog', 4884), ('superoperators', 4885), ('screamer', 4886), ('deserialization', 4887), ('fl', 4888), ('cayuga', 4889), ('achievement', 4890), ('dstributed', 4891), ('genealogy', 4892), ('uncovering', 4893), ('ideas', 4894), ('vietnamese', 4895), ('isalog', 4896), ('amongst', 4897), ('outer', 4898), ('california', 4899), ('vital', 4900), ('scopes', 4901), ('randomizing', 4902), ('lilog', 4903), ('virtualization', 4904), ('ims', 4905), ('impedance', 4906), ('syntagmatic', 4907), ('powerdb', 4908), ('involving', 4909), ('abstaining', 4910), ('lingo', 4911), ('totally', 4912), ('recrawl', 4913), ('dark', 4914), ('sgs', 4915), ('uncontrollable', 4916), ('cockpit', 4917), ('senior', 4918), ('concatenative', 4919), ('morphotactics', 4920), ('affects', 4921), ('giving', 4922), ('omt', 4923), ('scaffolding', 4924), ('flexibility', 4925), ('pane', 4926), ('residues', 4927), ('orchestrating', 4928), ('multicore', 4929), ('muvis', 4930), ('motivations', 4931), ('inspiring', 4932), ('pursue', 4933), ('chatbots', 4934), ('imt', 4935), ('pathologies', 4936), ('cooperate', 4937), ('repeated', 4938), ('sparq2l', 4939), ('rendezvous', 4940), ('penalized', 4941), ('determinant', 4942), ('amalgamating', 4943), ('viper', 4944), ('entropic', 4945), ('jmocha', 4946), ('bc', 4947), ('opponents', 4948), ('origins', 4949), ('suppressing', 4950), ('trainable', 4951), ('finders', 4952), ('authentication', 4953), ('adams', 4954), ('alliances', 4955), ('multilayered', 4956), ('aer', 4957), ('warnings', 4958), ('threats', 4959), ('storm', 4960), ('idm', 4961), ('reap', 4962), ('corroborate', 4963), ('mutually', 4964), ('establishment', 4965), ('hybridized', 4966), ('locksmith', 4967), ('challenged', 4968), ('qcsp', 4969), ('workplace', 4970), ('nonprofits', 4971), ('backbone', 4972), ('shoqd', 4973), ('forcing', 4974), ('testability', 4975), ('maximally', 4976), ('pinpointing', 4977), ('dedicated', 4978), ('qursed', 4979), ('restructured', 4980), ('agreements', 4981), ('essentials', 4982), ('bucketing', 4983), ('wheat', 4984), ('voxelwise', 4985), ('resonance', 4986), ('canlogs', 4987), ('gate', 4988), ('seasons', 4989), ('farm', 4990), ('looks', 4991), ('taxis', 4992), ('lime', 4993), ('ups', 4994), ('downs', 4995), ('preposition', 4996), ('esl', 4997), ('trobe', 4998), ('poliqarp', 4999), ('indexer', 5000), ('palka', 5001), ('sifting', 5002), ('sda', 5003), ('cai', 5004), ('superlatives', 5005), ('meetings', 5006), ('csrs', 5007), ('excon', 5008), ('advocating', 5009), ('webview', 5010), ('hyperbolic', 5011), ('plane', 5012), ('adheat', 5013), ('ecosystem', 5014), ('sustainability', 5015), ('blockwise', 5016), ('landscan', 5017), ('alerter', 5018), ('referent', 5019), ('datarace', 5020), ('deadlocks', 5021), ('realizations', 5022), ('interact', 5023), ('scm', 5024), ('passages', 5025), ('scored', 5026), ('expanded', 5027), ('charalign', 5028), ('byte', 5029), ('screens', 5030), ('recasting', 5031), ('sigcse', 5032), ('knack', 5033), ('11g', 5034), ('cvdb', 5035), ('2004', 5036), ('attracting', 5037), ('keeping', 5038), ('brightest', 5039), ('experienced', 5040), ('hddbs', 5041), ('countability', 5042), ('withouta', 5043), ('priori', 5044), ('personalizing', 5045), ('subgoal', 5046), ('wip', 5047), ('intellimedia', 5048), ('wsqdsq', 5049), ('systemt', 5050), ('accent', 5051), ('interfacile', 5052), ('rasp', 5053), ('asam', 5054), ('odx', 5055), ('oodbs', 5056), ('vyrd', 5057), ('ccal', 5058), ('questionnaire', 5059), ('trailfinding', 5060), ('modularization', 5061), ('logistics', 5062), ('debug', 5063), ('associational', 5064), ('flowcharts', 5065), ('blending', 5066), ('tcoz', 5067), ('algol', 5068), ('ecr', 5069), ('tasktracker', 5070), ('majsat', 5071), ('mierucompiler', 5072), ('ironing', 5073), ('redundancies', 5074), ('propbank', 5075), ('clotho', 5076), ('mentions', 5077), ('awaredav', 5078), ('rollups', 5079), ('parametricity', 5080), ('leveled', 5081), ('pundit', 5082), ('gcx', 5083), ('defacto', 5084), ('incident', 5085), ('commanders', 5086), ('overconstrained', 5087), ('resilient', 5088), ('propagator', 5089), ('sequel', 5090), ('might', 5091), ('thinker', 5092), ('linearizing', 5093), ('agency', 5094), ('closegraph', 5095), ('turk', 5096), ('junit', 5097), ('itemset', 5098), ('gauss', 5099), ('unbalanced', 5100), ('saying', 5101), ('already', 5102), ('capitalized', 5103), ('fintime', 5104), ('exits', 5105), ('reopening', 5106), ('song', 5107), ('tapping', 5108), ('gray', 5109), ('nearly', 5110), ('geominer', 5111), ('coevolving', 5112), ('mice', 5113), ('rewritings', 5114), ('laundering', 5115), ('crimes', 5116), ('fabrication', 5117), ('tangible', 5118), ('creativity', 5119), ('dnf', 5120), ('needle', 5121), ('invasive', 5122), ('actuated', 5123), ('gibbs', 5124), ('detectioncorrection', 5125), ('casee', 5126), ('rediscovering', 5127), ('passion', 5128), ('beauty', 5129), ('joy', 5130), ('awe', 5131), ('continued', 5132), ('webdiplomat', 5133), ('multilist', 5134), ('affiliation', 5135), ('ford', 5136), ('xpathxslt', 5137), ('poogle', 5138), ('lrt', 5139), ('ip', 5140), ('jibiki', 5141), ('lexalp', 5142), ('benchmarking', 5143), ('interbase', 5144), ('ergonomics', 5145), ('siebel', 5146), ('mechanizing', 5147), ('sage', 5148), ('sqout', 5149), ('workblench', 5150), ('dbis', 5151), ('variations', 5152), ('forensic', 5153), ('tampering', 5154), ('dereference', 5155), ('mppm', 5156), ('consolution', 5157), ('www2004', 5158), ('lowell', 5159), ('misclassification', 5160), ('pcb', 5161), ('drilling', 5162), ('redefining', 5163), ('paraphrase', 5164), ('ungreedy', 5165), ('probalistic', 5166), ('evil', 5167), ('flexibly', 5168), ('mergepurge', 5169), ('captioned', 5170), ('figures', 5171), ('mathfind', 5172), ('rights', 5173), ('duties', 5174), ('accessed', 5175), ('scr', 5176), ('uqlips', 5177), ('centralization', 5178), ('whither', 5179), ('21', 5180), ('dart', 5181), ('wiki', 5182), ('adaptivity', 5183), ('svg', 5184), ('european', 5185), ('continous', 5186), ('visiprog', 5187), ('abstracting', 5188), ('inherently', 5189), ('want', 5190), ('brooks', 5191), ('coopware', 5192), ('masters', 5193), ('families', 5194), ('timegraphs', 5195), ('suboptimal', 5196), ('singleton', 5197), ('idioms', 5198), ('microprogramming', 5199), ('watch', 5200), ('reminding', 5201), ('drawing', 5202), ('idiomatic', 5203), ('rel', 5204), ('laterally', 5205), ('spiking', 5206), ('neurons', 5207), ('revenue', 5208), ('relying', 5209), ('lof', 5210), ('gnu', 5211), ('mobide', 5212), ('cybertech', 5213), ('sensible', 5214), ('biosurveillance', 5215), ('indexicals', 5216), ('demonstratives', 5217), ('egalitarist', 5218), ('incommensurable', 5219), ('concolic', 5220), ('missed', 5221), ('actual', 5222), ('gamps', 5223), ('amplitude', 5224), ('compaction', 5225), ('overlays', 5226), ('papyrus', 5227), ('6th', 5228), ('setl', 5229), ('renaissance', 5230), ('unitran', 5231), ('intents', 5232), ('superior', 5233), ('hgdm', 5234), ('ac', 5235), ('apis', 5236), ('siren', 5237), ('hyperrectangle', 5238), ('declustered', 5239), ('deafault', 5240), ('angular', 5241), ('reputable', 5242), ('servents', 5243), ('subtask', 5244), ('extrapolation', 5245), ('jeroo', 5246), ('majority', 5247), ('aliases', 5248), ('pengi', 5249), ('rivaling', 5250), ('professionals', 5251), ('perplexity', 5252), ('fusing', 5253), ('communicative', 5254), ('subset', 5255), ('mips', 5256), ('snitch', 5257), ('paste', 5258), ('plagiarism', 5259), ('tickets', 5260), ('terminals', 5261), ('occam', 5262), ('gamma', 5263), ('schems', 5264), ('scratch', 5265), ('alphasort', 5266), ('interfacing', 5267), ('colorblind', 5268), ('coallocation', 5269), ('collaborations', 5270), ('punctuated', 5271), ('trips', 5272), ('valuation', 5273), ('sqlem', 5274), ('emergency', 5275), ('triage', 5276), ('wrong', 5277), ('waves', 5278), ('redesigning', 5279), ('plackett', 5280), ('luce', 5281), ('multimediaminer', 5282), ('emperical', 5283), ('redux', 5284), ('qsf', 5285), ('attacking', 5286), ('decipherment', 5287), ('entrans', 5288), ('edsc', 5289), ('vectorial', 5290), ('exprim', 5291), ('rivage', 5292), ('orthotics', 5293), ('custom', 5294), ('reassignment', 5295), ('realization', 5296), ('weaknesses', 5297), ('incoherency', 5298), ('aggregators', 5299), ('obsolescent', 5300), ('warlock', 5301), ('batmobile', 5302), ('taxi', 5303), ('synergy', 5304), ('publish', 5305), ('subscribe', 5306), ('cpoe', 5307), ('eel', 5308), ('stimuli', 5309), ('syntemic', 5310), ('fg', 5311), ('minute', 5312), ('ten', 5313), ('later', 5314), ('thumb', 5315), ('socp', 5316), ('interpreternative', 5317), ('sensitivities', 5318), ('thermodynamics', 5319), ('eddies', 5320), ('xl', 5321), ('expose', 5322), ('cs2cs7', 5323), ('following', 5324), ('validated', 5325), ('tab', 5326), ('emphasis', 5327), ('carrier', 5328), ('hiv', 5329), ('promising', 5330), ('valency', 5331), ('wring', 5332), ('dry', 5333), ('sellers', 5334), ('competing', 5335), ('buyers', 5336), ('shill', 5337), ('fees', 5338), ('200', 5339), ('cmerun', 5340), ('tapestry', 5341), ('maneuvering', 5342), ('obstacles', 5343), ('quadtree', 5344), ('positional', 5345), ('vc', 5346), ('exceptional', 5347), ('deliberation', 5348), ('thousands', 5349), ('bubble', 5350), ('archaeological', 5351), ('selc', 5352), ('enactment', 5353), ('playback', 5354), ('continuity', 5355), ('pooled', 5356), ('sampled', 5357), ('slavic', 5358), ('condensed', 5359), ('dtps', 5360), ('tcsps', 5361), ('truecasing', 5362), ('78', 5363), ('preceding', 5364), ('ethernet', 5365), ('multigraphs', 5366), ('phonetic', 5367), ('constituents', 5368), ('omes', 5369), ('webkhoj', 5370), ('lsl', 5371), ('selector', 5372), ('componentware', 5373), ('requirementsassurances', 5374), ('explorer', 5375), ('hadoop', 5376), ('netnews', 5377), ('rationality', 5378), ('mdm', 5379), ('mbdp', 5380), ('subsetting', 5381), ('superposition', 5382), ('discotect', 5383), ('traveled', 5384), ('baccalaureate', 5385), ('sustain', 5386), ('ghost', 5387), ('introspective', 5388), ('bitwidth', 5389), ('multipurpose', 5390), ('indeterminancy', 5391), ('memeta', 5392), ('mutable', 5393), ('ss', 5394), ('translingual', 5395), ('sos', 5396), ('evolve', 5397), ('irregularity', 5398), ('hamming', 5399), ('skoll', 5400), ('scaffolded', 5401), ('rbe', 5402), ('harvesting', 5403), ('productions', 5404), ('reductions', 5405), ('phantom', 5406), ('predicative', 5407), ('measured', 5408), ('demands', 5409), ('explosion', 5410), ('bunsetsu', 5411), ('hough', 5412), ('enable', 5413), ('petroglyphs', 5414), ('swiss', 5415), ('listener', 5416), ('reader', 5417), ('exterminator', 5418), ('biographical', 5419), ('independently', 5420), ('safeguard', 5421), ('uc', 5422), ('simlist', 5423), ('lexikon', 5424), ('helps', 5425), ('airphys', 5426), ('indic', 5427), ('train', 5428), ('encompass', 5429), ('interchange', 5430), ('imaged', 5431), ('pdf', 5432), ('biotech', 5433), ('translated', 5434), ('micronet', 5435), ('hypercubes', 5436), ('instantiations', 5437), ('kcat', 5438), ('intervention', 5439), ('darshak', 5440), ('degrading', 5441), ('animator', 5442), ('cl', 5443), ('researchs', 5444), ('fastest', 5445), ('odyssey', 5446), ('codd', 5447), ('s5', 5448), ('microfeature', 5449), ('rices', 5450), ('quicklink', 5451), ('residual', 5452), ('heart', 5453), ('decaying', 5454), ('vanity', 5455), ('querylog', 5456), ('bundles', 5457), ('delexical', 5458), ('usenet', 5459), ('gral', 5460), ('c2c', 5461), ('cool', 5462), ('machiavelli', 5463), ('border', 5464), ('redistribution', 5465), ('broaden', 5466), ('resistance', 5467), ('relocation', 5468), ('accelerate', 5469), ('wirelessmobile', 5470), ('metadatabase', 5471), ('rensselaer', 5472), ('engineer', 5473), ('pepx', 5474), ('burden', 5475), ('collinearity', 5476), ('nonnumeric', 5477), ('correctly', 5478), ('picnics', 5479), ('kittens', 5480), ('wigs', 5481), ('satisfy', 5482), ('g', 5483), ('goat', 5484), ('sqlmx', 5485), ('jerpa', 5486), ('cloze', 5487), ('temperature', 5488), ('3w', 5489), ('stereotypes', 5490), ('sddm', 5491), ('cypress', 5492), ('taker', 5493), ('verbalizes', 5494), ('discoveries', 5495), ('practicum', 5496), ('trie', 5497), ('perusing', 5498), ('videodisk', 5499), ('tokens', 5500), ('sematically', 5501), ('bell', 5502), ('hebrew', 5503), ('secureblox', 5504), ('shoulders', 5505), ('giants', 5506), ('slices', 5507), ('ansisparc', 5508), ('successive', 5509), ('eigenmaps', 5510), ('honors', 5511), ('adapter', 5512), ('sigmoids', 5513), ('frequently', 5514), ('updated', 5515), ('simplicity', 5516), ('iloc', 5517), ('mtr', 5518), ('corporation', 5519), ('hong', 5520), ('kong', 5521), ('tiled', 5522), ('minimising', 5523), ('automobile', 5524), ('sealing', 5525), ('evolvable', 5526), ('eve', 5527), ('radixzip', 5528), ('menus', 5529), ('rock', 5530), ('contributed', 5531), ('rankcut', 5532), ('rewriter', 5533), ('neuroimagery', 5534), ('embracing', 5535), ('pop', 5536), ('maritime', 5537), ('cracked', 5538), ('amelioration', 5539), ('arieskvl', 5540), ('multiaction', 5541), ('webviews', 5542), ('ocfs', 5543), ('centroid', 5544), ('glr', 5545), ('hundreds', 5546), ('interlisp', 5547), ('paving', 5548), ('diligent', 5549), ('eight', 5550), ('euclidean', 5551), ('scc', 5552), ('dcc', 5553), ('implicature', 5554), ('rbf', 5555), ('weesa', 5556), ('dblearn', 5557), ('xinuwu', 5558), ('xinu', 5559), ('csis', 5560), ('deconstructing', 5561), ('restoration', 5562), ('diacritics', 5563), ('clue', 5564), ('returned', 5565), ('portability', 5566), ('semint', 5567), ('rao', 5568), ('blackwellised', 5569), ('writable', 5570), ('disclosure', 5571), ('hippocratic', 5572), ('abridged', 5573), ('navigator', 5574), ('historically', 5575), ('colleges', 5576), ('objectbase', 5577), ('ucair', 5578), ('toolbar', 5579), ('remora', 5580), ('xslt', 5581), ('triangulated', 5582), ('4th', 5583), ('metaphoric', 5584), ('coercion', 5585), ('reminiscences', 5586), ('influential', 5587), ('21st', 5588), ('mindset', 5589), ('cyberporn', 5590), ('xrpc', 5591), ('chicago', 5592), ('lognormal', 5593), ('erasure', 5594), ('nusmv', 5595), ('slm', 5596), ('arboreal', 5597), ('prow', 5598), ('shipping', 5599), ('astronomy', 5600), ('serving', 5601), ('submitted', 5602), ('manuscripts', 5603), ('questionanswering', 5604), ('misconceptions', 5605), ('todays', 5606), ('hypercard', 5607), ('accommodating', 5608), ('follower', 5609), ('offset', 5610), ('multiaccess', 5611), ('url', 5612), ('assets', 5613), ('toys', 5614), ('aboutness', 5615), ('gaze', 5616), ('extractive', 5617), ('systolic', 5618), ('udfs', 5619), ('efficacy', 5620), ('invalidity', 5621), ('allocating', 5622), ('eliminate', 5623), ('trnon', 5624), ('ansductive', 5625), ('reexamining', 5626), ('complementary', 5627), ('fourth', 5628), ('airweb', 5629), ('decorrelation', 5630), ('man', 5631), ('lookups', 5632), ('founded', 5633), ('reasoner', 5634), ('repeats', 5635), ('itself', 5636), ('enthusiasm', 5637), ('cook', 5638), ('pet', 5639), ('erroneous', 5640), ('coko', 5641), ('allocator', 5642), ('shifting', 5643), ('agatha', 5644), ('christie', 5645), ('leads', 5646), ('geodesic', 5647), ('boosted', 5648), ('diathesis', 5649), ('alternations', 5650), ('combinators', 5651), ('ariescsa', 5652), ('tribes', 5653), ('knit', 5654), ('employment', 5655), ('montagues', 5656), ('dragon', 5657), ('hunters', 5658), ('splines', 5659), ('nnow', 5660), ('nurbs', 5661), ('minijava', 5662), ('samos', 5663), ('growing', 5664), ('cord', 5665), ('appraoch', 5666), ('ntcir', 5667), ('strongest', 5668), ('disorder', 5669), ('suitable', 5670), ('tridirectional', 5671), ('monothetic', 5672), ('practive', 5673), ('reactions', 5674), ('commentary', 5675), ('applicable', 5676), ('pens', 5677), ('shuffling', 5678), ('stacked', 5679), ('deck', 5680), ('vlkdbs', 5681), ('intermodule', 5682), ('supervaluation', 5683), ('inland', 5684), ('monic', 5685), ('multicluster', 5686), ('grafting', 5687), ('comex', 5688), ('commodities', 5689), ('finance', 5690), ('suspects', 5691), ('laws', 5692), ('shrinking', 5693), ('diameters', 5694), ('comprehensibility', 5695), ('academically', 5696), ('vrifa', 5697), ('nomogram', 5698), ('radial', 5699), ('lrbf', 5700), ('pathfinding', 5701), ('sitemaps', 5702), ('above', 5703), ('duty', 5704), ('lhrs', 5705), ('overtly', 5706), ('uddi', 5707), ('registries', 5708), ('regrets', 5709), ('observability', 5710), ('mood', 5711), ('til', 5712), ('sofis', 5713), ('replace', 5714), ('wsj', 5715), ('mainteinability', 5716), ('transportable', 5717), ('cpus', 5718), ('iterators', 5719), ('readable', 5720), ('unify', 5721), ('filename', 5722), ('nul', 5723), ('maxsat', 5724), ('modification', 5725), ('hahacronym', 5726), ('invocation', 5727), ('ptime', 5728), ('coercive', 5729), ('descriptiveness', 5730), ('caseframe', 5731), ('late', 5732), ('ce2', 5733), ('commandtalk', 5734), ('harry', 5735), ('met', 5736), ('harri', 5737), ('hunter', 5738), ('gatherer', 5739), ('socqet', 5740), ('yap3', 5741), ('seurat', 5742), ('earlier', 5743), ('disciplined', 5744), ('icse99', 5745), ('bifocal', 5746), ('microsurgery', 5747), ('nugget', 5748), ('consolidation', 5749), ('naturalistic', 5750), ('nonstationary', 5751), ('stamps', 5752), ('esa', 5753), ('rays', 5754), ('neurorule', 5755), ('configurable', 5756), ('skeptical', 5757), ('lifelog', 5758), ('bgp', 5759), ('lens', 5760), ('joysticks', 5761), ('mippets', 5762), ('dbir', 5763), ('sigmod', 5764), ('standalone', 5765), ('uncooperative', 5766), ('suspend', 5767), ('resume', 5768), ('rotating', 5769), ('odeview', 5770), ('updatability', 5771), ('malm', 5772), ('old', 5773), ('pharse', 5774), ('progres', 5775), ('scaleable', 5776), ('pessimistic', 5777), ('bt', 5778), ('branched', 5779), ('did', 5780), ('trax', 5781), ('ifo', 5782), ('designer', 5783), ('definites', 5784), ('toy', 5785), ('arm', 5786), ('dags', 5787), ('emperiment', 5788), ('authorizations', 5789), ('lexicalist', 5790), ('icelandic', 5791), ('ruralcafe', 5792), ('rural', 5793), ('w', 5794), ('pan', 5795), ('cb', 5796), ('ranksql', 5797), ('potts', 5798), ('mft', 5799), ('caramel', 5800), ('curry', 5801), ('howard', 5802), ('differentially', 5803), ('netflix', 5804), ('contenders', 5805), ('deobfuscation', 5806), ('preconditioned', 5807), ('algres', 5808), ('chimera', 5809), ('onion', 5810), ('kidney', 5811), ('magead', 5812), ('dialects', 5813), ('disambiguating', 5814), ('transmutation', 5815), ('mccs', 5816), ('didactic', 5817), ('dialectic', 5818), ('headline', 5819), ('intertask', 5820), ('exr', 5821), ('mixin', 5822), ('pivotunpivot', 5823), ('lapses', 5824), ('resumption', 5825), ('interrupted', 5826), ('loads', 5827), ('tempoexpress', 5828), ('expressivity', 5829), ('musical', 5830), ('tempo', 5831), ('impacts', 5832), ('reproduction', 5833), ('ica', 5834), ('wizards', 5835), ('wikispeedia', 5836), ('starving', 5837), ('hitting', 5838), ('kriegspiel', 5839), ('metapositions', 5840), ('harm', 5841), ('mismatch', 5842), ('lama', 5843), ('absolute', 5844), ('pennies', 5845), ('touch', 5846), ('cancer', 5847), ('restricting', 5848), ('aquery', 5849), ('pqc', 5850), ('matchsim', 5851), ('surprising', 5852), ('superdatabases', 5853), ('protel', 5854), ('umlanalyzer', 5855), ('satcsp', 5856), ('expander', 5857), ('nesc', 5858), ('pact', 5859), ('delinearization', 5860), ('break', 5861), ('multiloop', 5862), ('specificity', 5863), ('amnesic', 5864), ('cryptanalysis', 5865), ('snefru', 5866), ('transcripts', 5867), ('polyhedra', 5868), ('consciousness', 5869), ('underapproximation', 5870), ('hyrex', 5871), ('rehist', 5872), ('bundle', 5873), ('fire', 5874), ('bm25', 5875), ('csql', 5876), ('dynamicity', 5877), ('bilvideo', 5878), ('contraction', 5879), ('contemplate', 5880), ('columnsort', 5881), ('subgroups', 5882), ('golden', 5883), ('clickstreams', 5884), ('controversies', 5885), ('syncro', 5886), ('lilithmodula', 5887), ('knows', 5888), ('sovereign', 5889), ('lossy', 5890), ('stamped', 5891), ('smartback', 5892), ('recallprecision', 5893), ('quickmig', 5894), ('diagnosers', 5895), ('controlflow', 5896), ('lack', 5897), ('linux', 5898), ('tapes', 5899), ('hold', 5900), ('investing', 5901), ('thin', 5902), ('featherweight', 5903), ('exposing', 5904), ('internals', 5905), ('leo', 5906), ('db2s', 5907), ('tic', 5908), ('toe', 5909), ('tba', 5910), ('gloss', 5911), ('pointless', 5912), ('pda', 5913), ('tucking', 5914), ('rcc', 5915), ('cycs', 5916), ('xsb', 5917), ('operability', 5918), ('interruptible', 5919), ('insure', 5920), ('granting', 5921), ('binarization', 5922), ('cky', 5923), ('instantaneous', 5924), ('anything', 5925), ('worth', 5926), ('crimson', 5927), ('flexrecs', 5928), ('contacts', 5929), ('belong', 5930), ('theft', 5931), ('ellipsoid', 5932), ('rankboost', 5933), ('facet', 5934), ('landscapes', 5935), ('functor', 5936), ('interpolation', 5937), ('perm', 5938), ('cpr', 5939), ('molecules', 5940), ('flaws', 5941), ('clare', 5942), ('briefings', 5943), ('protdb', 5944), ('cyclone', 5945), ('interventional', 5946), ('pull', 5947), ('rogue', 5948), ('segmental', 5949), ('jitter', 5950), ('eccles', 5951), ('achievent', 5952), ('israeli', 5953), ('neighborhoods', 5954), ('unlocking', 5955), ('awarding', 5956), ('verifiable', 5957), ('allocated', 5958), ('develop', 5959), ('tutorials', 5960), ('mariko', 5961), ('talks', 5962), ('siegfried', 5963), ('japanesegerman', 5964), ('warriors', 5965), ('phobes', 5966), ('attitude', 5967), ('easiest', 5968), ('ridl', 5969), ('bearing', 5970), ('imputing', 5971), ('spatiotemporalspatiotemporal', 5972), ('reversal', 5973), ('utile', 5974), ('distinctions', 5975), ('outside', 5976), ('chiron', 5977), ('simfusion', 5978), ('warfare', 5979), ('expanding', 5980), ('indonesian', 5981), ('pivot', 5982), ('inaccessible', 5983), ('foci', 5984), ('deadline', 5985), ('intersystem', 5986), ('gated', 5987), ('multipipeline', 5988), ('monads', 5989), ('triangle', 5990), ('utaclir', 5991), ('toponym', 5992), ('birch', 5993), ('iepad', 5994), ('collative', 5995), ('straightforward', 5996), ('xmldb', 5997), ('breakout', 5998), ('remember', 5999), ('think', 6000), ('executions', 6001), ('paintingclass', 6002), ('sometimes', 6003), ('aggregating', 6004), ('jpredictor', 6005), ('ecrins86', 6006), ('lets', 6007), ('permanent', 6008), ('transient', 6009), ('compensating', 6010), ('picodmbs', 6011), ('smartcard', 6012), ('adapters', 6013), ('tailored', 6014), ('ggraphlog', 6015), ('transpose', 6016), ('demystified', 6017), ('florida', 6018), ('vambam', 6019), ('omnidirectional', 6020), ('kc3', 6021), ('mash', 6022), ('opinionated', 6023), ('kinematic', 6024), ('articulated', 6025), ('slca', 6026), ('aptitude', 6027), ('attains', 6028), ('death', 6029), ('blast', 6030), ('guarded', 6031), ('redirection', 6032), ('gmine', 6033), ('fixing', 6034), ('inconsistencies', 6035), ('polynominal', 6036), ('packet', 6037), ('tpm', 6038), ('informality', 6039), ('boredom', 6040), ('consolidating', 6041), ('realisation', 6042), ('pachinko', 6043), ('slam', 6044), ('testtube', 6045), ('parses', 6046), ('satellites', 6047), ('knownet', 6048), ('champagne', 6049), ('tulips', 6050), ('teachable', 6051), ('axis', 6052), ('concomitant', 6053), ('medethex', 6054), ('dyc', 6055), ('javanet', 6056), ('opinionminer', 6057), ('luckiness', 6058), ('prefectching', 6059), ('aroma', 6060), ('hepatitis', 6061), ('quantities', 6062), ('visualizations', 6063), ('amateurs', 6064), ('premodifiers', 6065), ('revel8or', 6066), ('capacity', 6067), ('professionalism', 6068), ('rss', 6069), ('transtrl', 6070), ('locator', 6071), ('rethink', 6072), ('inventories', 6073), ('segmentations', 6074), ('democratic', 6075), ('lexicographic', 6076), ('consultation', 6077), ('abbreviation', 6078), ('cla', 6079), ('perturbation', 6080), ('lemma', 6081), ('subclass', 6082), ('plsi', 6083), ('bilexical', 6084), ('adaptability', 6085), ('quarks', 6086), ('combating', 6087), ('trustrank', 6088), ('air', 6089), ('goldilocks', 6090), ('opaque', 6091), ('shangri', 6092), ('recommend', 6093), ('reve', 6094), ('participatory', 6095), ('assumption', 6096), ('hierachy', 6097), ('crocopat', 6098), ('integers', 6099), ('matcher', 6100), ('vipas', 6101), ('galileo', 6102), ('unsegmented', 6103), ('our', 6104), ('stanford', 6105), ('emphasizing', 6106), ('extents', 6107), ('exposed', 6108), ('attibute', 6109), ('diversifying', 6110), ('secret', 6111), ('omissions', 6112), ('format', 6113), ('blas', 6114), ('mammography', 6115), ('isolate', 6116), ('ossd', 6117), ('ldiff', 6118), ('differencing', 6119), ('accelerometer', 6120), ('smdp', 6121), ('homomorphisms', 6122), ('residency', 6123), ('asknet', 6124), ('sytems', 6125), ('species', 6126), ('biosystematics', 6127), ('ofs', 6128), ('odp', 6129), ('sciencecraft', 6130), ('eo', 6131), ('componential', 6132), ('ergodic', 6133), ('bloom', 6134), ('tension', 6135), ('reals', 6136), ('merrier', 6137), ('mini', 6138), ('disease', 6139), ('reflexive', 6140), ('cham', 6141), ('eclipse', 6142), ('demaq', 6143), ('orion', 6144), ('postscript', 6145), ('videoreach', 6146), ('enrichment', 6147), ('misses', 6148), ('paraconsistency', 6149), ('chronologies', 6150), ('raster', 6151), ('tractability', 6152), ('fictitious', 6153), ('continuum', 6154), ('ficsr', 6155), ('eedback', 6156), ('nonistency', 6157), ('esolution', 6158), ('misaligned', 6159), ('ofcourse', 6160), ('materials', 6161), ('soat', 6162), ('peanut', 6163), ('gallery', 6164), ('assessor', 6165), ('lyapunov', 6166), ('clonetracker', 6167), ('pp', 6168), ('treebanking', 6169), ('blazing', 6170), ('lies', 6171), ('synonymy', 6172), ('eager', 6173), ('books', 6174), ('meronyms', 6175), ('unique', 6176), ('passed', 6177), ('restructure', 6178), ('entries', 6179), ('linkages', 6180), ('sql3', 6181), ('uncorrelated', 6182), ('indiana', 6183), ('purdue', 6184), ('convoy', 6185), ('movement', 6186), ('city', 6187), ('alice', 6188), ('front', 6189), ('cardinalities', 6190), ('walkthrough', 6191), ('trail', 6192), ('cutex', 6193), ('lemonade', 6194), ('bright', 6195), ('dr', 6196), ('eventtrigger', 6197), ('unibase', 6198), ('newspaper', 6199), ('xmem', 6200), ('hyperstorm', 6201), ('administering', 6202), ('convolutional', 6203), ('linkclus', 6204), ('identically', 6205), ('progxe', 6206), ('telcordias', 6207), ('unanchored', 6208), ('ignorant', 6209), ('xqbe', 6210), ('blocks', 6211), ('correlational', 6212), ('itinerary', 6213), ('beg', 6214), ('ends', 6215), ('cardio', 6216), ('vascular', 6217), ('app', 6218), ('olympic', 6219), ('equestrian', 6220), ('experiential', 6221), ('roadrunner', 6222), ('suitability', 6223), ('kinesthetic', 6224), ('documented', 6225), ('refinements', 6226), ('converter', 6227), ('semirings', 6228), ('definability', 6229), ('learns', 6230), ('piece', 6231), ('addressed', 6232), ('5', 6233), ('iwpse', 6234), ('soon', 6235), ('abbreviated', 6236), ('marie', 6237), ('decoder', 6238), ('resolutions', 6239), ('membership', 6240), ('1000', 6241), ('commute', 6242), ('potters', 6243), ('dsl', 6244), ('ssc2', 6245), ('skeletons', 6246), ('reproducing', 6247), ('myerson', 6248), ('satterthwaite', 6249), ('impossibility', 6250), ('unweighted', 6251), ('labelers', 6252), ('relaxations', 6253), ('selectors', 6254), ('behaviosites', 6255), ('parasitic', 6256), ('infection', 6257), ('intentions', 6258), ('invariance', 6259), ('reviewing', 6260), ('relocating', 6261), ('rerankeverything', 6262), ('mindreader', 6263), ('ultimate', 6264), ('cautious', 6265), ('surfer', 6266), ('joulesort', 6267), ('nero', 6268), ('importing', 6269), ('casting', 6270), ('accumulative', 6271), ('multicomputer', 6272), ('rework', 6273), ('yago', 6274), ('billiards', 6275), ('senseclusters', 6276), ('guesstimate', 6277), ('curing', 6278), ('1tn', 6279), ('autocompletion', 6280), ('tolerate', 6281), ('linearizable', 6282), ('snowball', 6283), ('elu', 6284), ('cal', 6285), ('aggie', 6286), ('matic', 6287), ('cybersecurity', 6288), ('glory', 6289), ('contestants', 6290), ('contests', 6291), ('topcodercom', 6292), ('always', 6293), ('appc', 6294), ('enrich', 6295), ('attributio', 6296), ('hypercode', 6297), ('serv', 6298), ('seen', 6299), ('crosslinguistic', 6300), ('motivate', 6301), ('bargaining', 6302), ('become', 6303), ('disaggregation', 6304), ('webcq', 6305), ('psycho', 6306), ('engineered', 6307), ('arizona', 6308), ('tdts', 6309), ('joining', 6310), ('blackboards', 6311), ('hedged', 6312), ('purpors', 6313), ('igrid', 6314), ('gateway', 6315), ('deducing', 6316), ('truncations', 6317), ('thresher', 6318), ('unwrapping', 6319), ('wavefront', 6320), ('granular', 6321), ('braid', 6322), ('lag', 6323), ('reasonably', 6324), ('consul', 6325), ('aptness', 6326), ('cast', 6327), ('minimally', 6328), ('cleanly', 6329), ('messy', 6330), ('mv3r', 6331), ('timestamp', 6332), ('ondux', 6333), ('supersense', 6334), ('lisfs', 6335), ('mock', 6336), ('trials', 6337), ('times', 6338), ('asymptotically', 6339), ('qbf', 6340), ('anisotropic', 6341), ('xor', 6342), ('aktionsart', 6343), ('fighting', 6344), ('solvers', 6345), ('mixins', 6346), ('inclination', 6347), ('geared', 6348), ('manifest', 6349), ('separate', 6350), ('pwa', 6351), ('sssalpha', 6352), ('accounts', 6353), ('debit', 6354), ('found', 6355), ('lexnet', 6356), ('dynamical', 6357), ('basedatabase', 6358), ('appropriateness', 6359), ('handheld', 6360), ('accomodation', 6361), ('multiterm', 6362), ('mca', 6363), ('explorations', 6364), ('probabilitstic', 6365), ('vivid', 6366), ('clarity', 6367), ('delaying', 6368), ('unteachable', 6369), ('verifiers', 6370), ('ilog', 6371), ('awa', 6372), ('cassm', 6373), ('whips', 6374), ('cease', 6375), ('because', 6376), ('ignored', 6377), ('relativised', 6378), ('nba', 6379), ('multigranularity', 6380), ('fittest', 6381), ('survives', 6382), ('xcfs', 6383), ('flavers', 6384), ('negations', 6385), ('contradictions', 6386), ('vispedia', 6387), ('deficiencies', 6388), ('borders', 6389), ('neighboring', 6390), ('spot', 6391), ('compostion', 6392), ('tell', 6393), ('turnover', 6394), ('transliterations', 6395), ('schemr', 6396), ('payoff', 6397), ('xrules', 6398), ('deals', 6399), ('contingency', 6400), ('unsuspecting', 6401), ('audience', 6402), ('groupware', 6403), ('explain', 6404), ('discover', 6405), ('strips', 6406), ('realizational', 6407), ('dirt', 6408), ('sbtdiscovery', 6409), ('asynchronously', 6410), ('leaf', 6411), ('pangloss', 6412), ('hadoopdb', 6413), ('optimising', 6414), ('governed', 6415), ('calendars', 6416), ('layering', 6417), ('april', 6418), ('madbot', 6419), ('ihmms', 6420), ('cabinet', 6421), ('sprint', 6422), ('eiffel', 6423), ('conserved', 6424), ('thetenthstrand', 6425), ('ethicaldebates', 6426), ('tiling', 6427), ('checkers', 6428), ('diva', 6429), ('liptus', 6430), ('treat', 6431), ('eclectic', 6432), ('invisible', 6433), ('capital', 6434), ('relates', 6435), ('lurking', 6436), ('sake', 6437), ('themselves', 6438), ('sinhala', 6439), ('grapheme', 6440), ('phoneme', 6441), ('schwa', 6442), ('epenthesis', 6443), ('hisbase', 6444), ('priming', 6445), ('alarms', 6446), ('actionable', 6447), ('genomes', 6448), ('volatile', 6449), ('checkpoint', 6450), ('unparsing', 6451), ('rdfxml', 6452), ('homonymy', 6453), ('authorities', 6454), ('hubs', 6455), ('runways', 6456), ('extremal', 6457), ('baskets', 6458), ('singer', 6459), ('mp3', 6460), ('subregularities', 6461), ('prosody', 6462), ('friends', 6463), ('determinization', 6464), ('formulae', 6465), ('phased', 6466), ('delocalisation', 6467), ('replanning', 6468), ('attractiveness', 6469), ('multiprocessing', 6470), ('pspace', 6471), ('proximus', 6472), ('attributed', 6473), ('perceptrons', 6474), ('wam', 6475), ('contemporary', 6476), ('journals', 6477), ('immc', 6478), ('brittleness', 6479), ('blackout', 6480), ('anywhere', 6481), ('remove', 6482), ('bottlenecks', 6483), ('derbys', 6484), ('bbm', 6485), ('petabyte', 6486), ('handlinh', 6487), ('immediate', 6488), ('phishing', 6489), ('emails', 6490), ('illiterate', 6491), ('lh', 6492), ('reed', 6493), ('solomon', 6494), ('street', 6495), ('journal', 6496), ('linearizability', 6497), ('lsa', 6498), ('soundness', 6499), ('masked', 6500), ('dip', 6501), ('punctuation', 6502), ('obtaining', 6503), ('equalities', 6504), ('ask', 6505), ('groupwise', 6506), ('extremum', 6507), ('sonar', 6508), ('associationrules', 6509), ('electrical', 6510), ('ct', 6511), ('personnel', 6512), ('acceptability', 6513), ('option', 6514), ('drill', 6515), ('degrade', 6516), ('dtds', 6517), ('sie', 6518), ('obi', 6519), ('serpent', 6520), ('hungarian', 6521), ('viewsystem', 6522), ('exhibit', 6523), ('critter', 6524), ('agricultural', 6525), ('fmri', 6526), ('volcano', 6527), ('contribution', 6528), ('contra', 6529), ('xvcl', 6530), ('dot', 6531), ('watson', 6532), ('tele', 6533), ('professor', 6534), ('recorded', 6535), ('pesto', 6536), ('querybrowser', 6537), ('principals', 6538), ('oz', 6539), ('mglair', 6540), ('scaleless', 6541), ('sphere', 6542), ('semmo', 6543), ('multiplayer', 6544), ('row', 6545), ('laplace', 6546), ('albep', 6547), ('caption', 6548), ('loose', 6549), ('stand', 6550), ('synchronizable', 6551), ('preach', 6552), ('predefined', 6553), ('polarized', 6554), ('kiss', 6555), ('powers', 6556), ('aadds', 6557), ('cmu', 6558), ('rover', 6559), ('schematically', 6560), ('centralized', 6561), ('crowdreranking', 6562), ('mmtk', 6563), ('individualized', 6564), ('intensity', 6565), ('forgiving', 6566), ('cream', 6567), ('valuepetri', 6568), ('china', 6569), ('practicioners', 6570), ('managed', 6571), ('ecu', 6572), ('vindicated', 6573), ('cot', 6574), ('detecton', 6575), ('clicks', 6576), ('overfitting', 6577), ('emerge', 6578), ('verbosity', 6579), ('25', 6580), ('rise', 6581), ('fall', 6582), ('salton', 6583), ('award', 6584), ('simulating', 6585), ('tactic', 6586), ('gpsm', 6587), ('dissolution', 6588), ('shiq', 6589), ('extremely', 6590), ('fibring', 6591), ('gputerasort', 6592), ('unpartitioned', 6593), ('holonic', 6594), ('pedestrian', 6595), ('rqafqi', 6596), ('indeterminate', 6597), ('constructor', 6598), ('carpediem', 6599), ('ssl', 6600), ('coarticulation', 6601), ('separable', 6602), ('ceteris', 6603), ('paribus', 6604), ('mocha', 6605), ('mirroring', 6606), ('alternating', 6607), ('jeroboam', 6608), ('epilepsy', 6609), ('s3', 6610), ('xpress', 6611), ('queriable', 6612), ('textured', 6613), ('bits', 6614), ('termsets', 6615), ('dataset', 6616), ('bacteria', 6617), ('cultures', 6618), ('scattering', 6619), ('vr', 6620), ('shifts', 6621), ('samuel', 6622), ('amarel', 6623), ('cbse', 6624), ('datacycle', 6625), ('1978', 6626), ('cst', 6627), ('citizens', 6628), ('psycholinguistically', 6629), ('hardness', 6630), ('ingres', 6631), ('parafac2', 6632), ('mpf', 6633), ('stars', 6634), ('coocurrences', 6635), ('import', 6636), ('limitations', 6637), ('denoising', 6638), ('autoencoders', 6639), ('tabling', 6640), ('quadrupedal', 6641), ('locomotion', 6642), ('diversification', 6643), ('multitheme', 6644), ('markovsemi', 6645), ('destinations', 6646), ('nondirectional', 6647), ('labor', 6648), ('characteristic', 6649), ('ddos', 6650), ('identified', 6651), ('reused', 6652), ('neighbourhood', 6653), ('broadband', 6654), ('v3', 6655), ('analog', 6656), ('clips', 6657), ('keypoints', 6658), ('sister', 6659), ('reclustering', 6660), ('3se', 6661), ('widely', 6662), ('proclamation', 6663), ('elaborate', 6664), ('anf', 6665), ('sammie', 6666), ('rufus', 6667), ('television', 6668), ('radio', 6669), ('texas', 6670), ('aems', 6671), ('codds', 6672), ('reformulated', 6673), ('appear', 6674), ('posting', 6675), ('degradation', 6676), ('determined', 6677), ('elision', 6678), ('curio', 6679), ('reviving', 6680), ('removal', 6681), ('fertility', 6682), ('anti', 6683), ('compositions', 6684), ('voted', 6685), ('hdp', 6686), ('concentric', 6687), ('hyperspaces', 6688), ('converting', 6689), ('modula', 6690), ('labellings', 6691), ('cse', 6692), ('volunteers', 6693), ('hillsborough', 6694), ('county', 6695), ('district', 6696), ('labelling', 6697), ('transsformation', 6698), ('dolce', 6699), ('unsound', 6700), ('automateddistributed', 6701), ('multiresolution', 6702), ('mrf', 6703), ('theta', 6704), ('socially', 6705), ('here', 6706), ('pskip', 6707), ('scribble', 6708), ('alikes', 6709), ('chorochronos', 6710), ('folklore', 6711), ('confirmed', 6712), ('larger', 6713), ('widl', 6714), ('inconcert', 6715), ('archive', 6716), ('sqlmed', 6717), ('tenant', 6718), ('telephone', 6719), ('journey', 6720), ('simplifier', 6721), ('gotolessness', 6722), ('infomix', 6723), ('prague', 6724), ('mima', 6725), ('innovation', 6726), ('interim', 6727), ('acmieee', 6728), ('despite', 6729), ('imbalance', 6730), ('stress', 6731), ('realizing', 6732), ('directors', 6733), ('implication', 6734), ('factorizations', 6735), ('datajoiner', 6736), ('collecting', 6737), ('ocean', 6738), ('conservant', 6739), ('multitale', 6740), ('bookmark', 6741), ('designated', 6742), ('sash', 6743), ('sportscast', 6744), ('ancestors', 6745), ('weblab', 6746), ('hyperthesis', 6747), ('grna', 6748), ('spell', 6749), ('crops', 6750), ('soil', 6751), ('multiobjective', 6752), ('situational', 6753), ('presupposition', 6754), ('socratic', 6755), ('exegesis', 6756), ('wake', 6757), ('wlan', 6758), ('repeating', 6759), ('aries', 6760), ('intractability', 6761), ('faces', 6762), ('kap', 6763), ('greediness', 6764), ('memm', 6765), ('segregation', 6766), ('dat', 6767), ('dd', 6768), ('chameleon', 6769), ('spiteful', 6770), ('explanatory', 6771), ('xmill', 6772), ('majorization', 6773), ('instantiation', 6774), ('ailp', 6775), ('p3vi', 6776), ('mtw06', 6777), ('inequality', 6778), ('listening', 6779), ('provisions', 6780), ('operationally', 6781), ('multibuffer', 6782), ('transposition', 6783), ('compliant', 6784), ('statsnowball', 6785), ('dumber', 6786), ('speeddating', 6787), ('systematically', 6788), ('triangulation', 6789), ('plop', 6790), ('ghostdb', 6791), ('visible', 6792), ('leaks', 6793), ('continually', 6794), ('sensory', 6795), ('nico', 6796), ('habermanns', 6797), ('saps', 6798), ('nonmonotonicity', 6799), ('batching', 6800), ('rearrangement', 6801), ('bags', 6802), ('inexperienced', 6803), ('spiral', 6804), ('beat', 6805), ('queens', 6806), ('machined', 6807), ('rrxf', 6808), ('punjabi', 6809), ('speaking', 6810), ('food', 6811), ('complaints', 6812), ('ticket', 6813), ('lore', 6814), ('soquet', 6815), ('crosscutting', 6816), ('rp', 6817), ('liveclassifier', 6818), ('atis', 6819), ('leave', 6820), ('said', 6821), ('debates', 6822), ('snif', 6823), ('sniffing', 6824), ('autocorrelation', 6825), ('topographic', 6826), ('dpop', 6827), ('dcop', 6828), ('datametadata', 6829), ('append', 6830), ('emergence', 6831), ('pres', 6832), ('upside', 6833), ('drosophila', 6834), ('capping', 6835), ('judges', 6836), ('exchangeable', 6837), ('drawn', 6838), ('praire', 6839), ('databasenetwork', 6840), ('phoneticsphonology', 6841), ('u', 6842), ('bird', 6843), ('hisa', 6844), ('committees', 6845), ('understandable', 6846), ('dalí', 6847), ('quantum', 6848), ('fa', 6849), ('metamodeling', 6850), ('noticing', 6851), ('costing', 6852), ('expressed', 6853), ('crosslanguage', 6854), ('obtain', 6855), ('ciphertext', 6856), ('allophonic', 6857), ('phonotactic', 6858), ('deployers', 6859), ('vertically', 6860), ('prompt', 6861), ('coma', 6862), ('unmodified', 6863), ('browsers', 6864), ('backoff', 6865), ('administrators', 6866), ('believable', 6867), ('tourism', 6868), ('prose', 6869), ('generalizaiton', 6870), ('cafeobj', 6871), ('regularised', 6872), ('wishful', 6873), ('viable', 6874), ('handprinted', 6875), ('practicing', 6876), ('judo', 6877), ('boards', 6878), ('essays', 6879), ('jisdos', 6880), ('icp', 6881), ('nonrigid', 6882), ('equal', 6883), ('guis', 6884), ('shrex', 6885), ('appliances', 6886), ('dhts', 6887), ('j2me', 6888), ('heat', 6889), ('candidates', 6890), ('atom', 6891), ('customized', 6892), ('bundling', 6893), ('bregman', 6894), ('dpls', 6895), ('pol', 6896), ('around', 6897), ('incorporation', 6898), ('seller', 6899), ('brazilian', 6900), ('dependences', 6901), ('omega', 6902), ('galax', 6903), ('partitionings', 6904), ('hop', 6905), ('amcr', 6906), ('dispatching', 6907), ('epos', 6908), ('cope', 6909), ('byzantine', 6910), ('generals', 6911), ('magma', 6912), ('fill', 6913), ('dominating', 6914), ('profitably', 6915), ('sed', 6916), ('prf', 6917), ('lends', 6918), ('intersections', 6919), ('mis', 6920), ('dumping', 6921), ('simrank', 6922), ('clickgraph', 6923), ('unlevel', 6924), ('chronology', 6925), ('newswires', 6926), ('bleu', 6927), ('fluxplayer', 6928), ('vowels', 6929), ('quest', 6930), ('viewers', 6931), ('analogue', 6932), ('declaration', 6933), ('closer', 6934), ('wordmeanings', 6935), ('sleeved', 6936), ('coclustering', 6937), ('blacklists', 6938), ('malicious', 6939), ('escape', 6940), ('polyglot', 6941), ('interrelationship', 6942), ('avionics', 6943), ('churn', 6944), ('finalization', 6945), ('spanning', 6946), ('readings', 6947), ('writes', 6948), ('viztree', 6949), ('wakashi', 6950), ('perceptually', 6951), ('efis', 6952), ('paramodulation', 6953), ('controllable', 6954), ('osamt', 6955), ('oqlt', 6956), ('conditioned', 6957), ('ballot', 6958), ('sincerity', 6959), ('proofness', 6960), ('diophantine', 6961), ('adverbials', 6962), ('refreshment', 6963), ('diverging', 6964), ('dissimilarities', 6965), ('bea', 6966), ('chi', 6967), ('validity', 6968), ('create', 6969), ('subgroup', 6970), ('nestream', 6971), ('intuitive', 6972), ('jarap', 6973), ('semcog', 6974), ('huberized', 6975), ('visitor', 6976), ('boomerang', 6977), ('resourceful', 6978), ('lenses', 6979), ('surviving', 6980), ('2nd', 6981), ('spread', 6982), ('multiparadigm', 6983), ('idefix', 6984), ('browserank', 6985), ('consideration', 6986), ('eroc', 6987), ('neato', 6988), ('hosts', 6989), ('tolerance', 6990), ('usind', 6991), ('r3', 6992), ('installations', 6993), ('anycast', 6994), ('cdns', 6995), ('ferret', 6996), ('filestore', 6997), ('stdl', 6998), ('clide', 6999), ('defection', 7000), ('calculi', 7001), ('dancing', 7002), ('dynalab', 7003), ('endearing', 7004), ('caede', 7005), ('multitasking', 7006), ('embdedded', 7007), ('traits', 7008), ('guaranteed', 7009), ('errorperformance', 7010), ('rippling', 7011), ('hub', 7012), ('groves', 7013), ('disproportionate', 7014), ('interventions', 7015), ('narrowing', 7016), ('ginga', 7017), ('multiplicative', 7018), ('tangent', 7019), ('sourcing', 7020), ('reloaded', 7021), ('encapsulated', 7022), ('smil', 7023), ('experimenting', 7024), ('revisits', 7025), ('seeding', 7026), ('underpinnings', 7027), ('taggerlemmatiser', 7028), ('collision', 7029), ('calibrated', 7030), ('maxq', 7031), ('mudular', 7032), ('workstyle', 7033), ('hotspots', 7034), ('fgp', 7035), ('kohonen', 7036), ('possibility', 7037), ('girls', 7038), ('cascades', 7039), ('forgettings', 7040), ('ariel', 7041), ('ppcp', 7042), ('clear', 7043), ('supertagging', 7044), ('claim', 7045), ('mathematicians', 7046), ('pymk', 7047), ('friend', 7048), ('myspace', 7049), ('midas', 7050), ('periods', 7051), ('distinction', 7052), ('twittermonitor', 7053), ('twitter', 7054), ('faster', 7055), ('reformulating', 7056), ('primes', 7057), ('drivers', 7058), ('assessors', 7059), ('mistakes', 7060), ('dipra', 7061), ('idef1', 7062), ('pearsons', 7063), ('considering', 7064), ('agglutinativity', 7065), ('spacing', 7066), ('correlativity', 7067), ('obliviousness', 7068), ('photo', 7069), ('hallucination', 7070), ('tioga', 7071), ('drjava', 7072), ('pedagogic', 7073), ('educating', 7074), ('superarchitects', 7075), ('min', 7076), ('disabled', 7077), ('children', 7078), ('commercially', 7079), ('prenominal', 7080), ('bet', 7081), ('humancomputer', 7082), ('things', 7083), ('pubmed', 7084), ('hopper', 7085), ('visits', 7086), ('collocated', 7087), ('ugv', 7088), ('blurring', 7089), ('produces', 7090), ('artistic', 7091), ('calligraphy', 7092), ('fred', 7093), ('csurf', 7094), ('institutional', 7095), ('multipaging', 7096), ('momis', 7097), ('ssd', 7098), ('deeds', 7099), ('thetis', 7100), ('timeout', 7101), ('judgmental', 7102), ('dewild', 7103), ('cards', 7104), ('formalizations', 7105), ('marcus', 7106), ('cxhist', 7107), ('scavenger', 7108), ('hunt', 7109), ('unranked', 7110), ('automaton', 7111), ('semrank', 7112), ('destructors', 7113), ('finalizers', 7114), ('imecho', 7115), ('writers', 7116), ('memex', 7117), ('potentiality', 7118), ('fulltext', 7119), ('retaliate', 7120), ('shooter', 7121), ('consisting', 7122), ('cfg', 7123), ('jive', 7124), ('jove', 7125), ('happens', 7126), ('retrievability', 7127), ('genesis', 7128), ('sliced', 7129), ('whirl', 7130), ('araneus', 7131), ('amount', 7132), ('disparity', 7133), ('anticipatory', 7134), ('multistage', 7135), ('weve', 7136), ('been', 7137), ('requirementsdesign', 7138), ('ucms', 7139), ('vsams', 7140), ('doritos', 7141), ('cylindrical', 7142), ('smoothed', 7143), ('rainbow', 7144), ('actiview', 7145), ('supersql', 7146), ('augmentative', 7147), ('aggregations', 7148), ('hownet', 7149), ('pardes', 7150), ('proto', 7151), ('bistratal', 7152), ('subsentential', 7153), ('regularly', 7154), ('citri', 7155), ('modifier', 7156), ('disima', 7157), ('oddessy', 7158), ('programme', 7159), ('guides', 7160), ('patchwork', 7161), ('profiled', 7162), ('datablitz', 7163), ('offline', 7164), ('maximizationminimization', 7165), ('gulf', 7166), ('deryaft', 7167), ('landmarks', 7168), ('wt10g', 7169), ('proteins', 7170), ('thou', 7171), ('shalt', 7172), ('covet', 7173), ('thy', 7174), ('cake', 7175), ('wordform', 7176), ('compounds', 7177), ('aac', 7178), ('montage', 7179), ('queryable', 7180), ('kbse', 7181), ('checkmate', 7182), ('cornering', 7183), ('checked', 7184), ('adjuncts', 7185), ('cooccurrence', 7186), ('serpentine', 7187), ('drives', 7188), ('sentinel', 7189), ('tone', 7190), ('jazzmatch', 7191), ('introducng', 7192), ('medium', 7193), ('kb', 7194), ('dj', 7195), ('fabric', 7196), ('augeas', 7197), ('authoritativeness', 7198), ('grading', 7199), ('creepy', 7200), ('desired', 7201), ('foral', 7202), ('tweeted', 7203), ('gf', 7204), ('weaker', 7205), ('universality', 7206), ('diag', 7207), ('1n', 7208), ('adventures', 7209), ('thesauri', 7210), ('prompter', 7211), ('intelligibility', 7212), ('rcx', 7213), ('understand', 7214), ('qualification', 7215), ('toolset', 7216), ('tedi', 7217), ('marshaling', 7218), ('carrying', 7219), ('commitlsn', 7220), ('latching', 7221), ('synchronizer', 7222), ('ppm', 7223), ('caterogization', 7224), ('sm3', 7225), ('itaca', 7226), ('kbs', 7227), ('diluting', 7228), ('acid', 7229), ('projecting', 7230), ('weekday', 7231), ('thumbnail', 7232), ('mariposa', 7233), ('orchestral', 7234), ('accompaniment', 7235), ('lexica', 7236), ('morphologically', 7237), ('coexistence', 7238), ('reman', 7239), ('saliency', 7240), ('unconcerned', 7241), ('heritage', 7242), ('microcomputers', 7243), ('traveling', 7244), ('salesman', 7245), ('mint', 7246), ('separability', 7247), ('retieval', 7248), ('linearly', 7249), ('pagesim', 7250), ('aimilarity', 7251), ('canonical', 7252), ('permutations', 7253), ('objectives', 7254), ('governors', 7255), ('ubidata', 7256), ('expertconsultation', 7257), ('kl', 7258), ('butterfly\\x99', 7259), ('pulse', 7260), ('testo', 7261), ('ag', 7262), ('proteome', 7263), ('analyst', 7264), ('seeded', 7265), ('codebooks', 7266), ('habitats', 7267), ('adam', 7268), ('fad', 7269), ('untyped', 7270), ('degraded', 7271), ('adaptively', 7272), ('arbitrarily', 7273), ('gaining', 7274), ('tour', 7275), ('retroactive', 7276), ('namur', 7277), ('retrievals', 7278), ('hifi', 7279), ('fan', 7280), ('introduce', 7281), ('coral', 7282), ('unite', 7283), ('mhp', 7284), ('idtv', 7285), ('presentable', 7286), ('underspecified', 7287), ('cascade', 7288), ('detectors', 7289), ('ranks', 7290), ('generalising', 7291), ('recapture', 7292), ('equijoins', 7293), ('apt', 7294), ('ois', 7295), ('numeral', 7296), ('episodic', 7297), ('iv', 7298), ('shuttle', 7299), ('tscan', 7300), ('fluency', 7301), ('tasking', 7302), ('emt', 7303), ('imperfectly', 7304), ('xtag', 7305), ('metarules', 7306), ('nexusscout', 7307), ('symmetries', 7308), ('neat', 7309), ('storytelling', 7310), ('margins', 7311), ('incoherent', 7312), ('degress', 7313), ('liquid', 7314), ('schedulable', 7315), ('daml', 7316), ('received', 7317), ('amazoncom', 7318), ('helpfulness', 7319), ('gpgpu', 7320), ('subtransitive', 7321), ('agreement', 7322), ('mearf', 7323), ('stencils', 7324), ('bengali', 7325), ('greek', 7326), ('deciding', 7327), ('stateless', 7328), ('pigeons', 7329), ('abducing', 7330), ('conclusions', 7331), ('split', 7332), ('clocks', 7333), ('thoughts', 7334), ('octopus', 7335), ('modality', 7336), ('planck', 7337), ('institute', 7338), ('iconism', 7339), ('gains', 7340), ('scheduled', 7341), ('revi', 7342), ('warranty', 7343), ('goodwill', 7344), ('rdfpeers', 7345), ('ur', 7346), ('metaprogramming', 7347), ('deixis', 7348), ('aspectj', 7349), ('formats', 7350), ('chatbot', 7351), ('forums', 7352), ('fruit', 7353), ('embryo', 7354), ('webcrow', 7355), ('crossword', 7356), ('everyday', 7357), ('sketches', 7358), ('neuroscience', 7359), ('semiparametric', 7360), ('concatenation', 7361), ('precursor', 7362), ('traveler', 7363), ('multiversioned', 7364), ('shedding', 7365), ('generalisation', 7366), ('distortion', 7367), ('pape', 7368), ('printing', 7369), ('congestion', 7370), ('existentially', 7371), ('shine', 7372), ('id3', 7373), ('authentic', 7374), ('chat', 7375), ('room', 7376), ('recovered', 7377), ('proximal', 7378), ('rounding', 7379), ('geoplot', 7380), ('knowing', 7381), ('topicrank', 7382), ('bluetooth', 7383), ('nesting', 7384), ('football', 7385), ('moses', 7386), ('arisenisr', 7387), ('sharc', 7388), ('completing', 7389), ('dvss', 7390), ('ionterfaces', 7391), ('visibly', 7392), ('cell', 7393), ('sounding', 7394), ('unpacking', 7395), ('bioscience', 7396), ('opac', 7397), ('permit', 7398), ('disciplines', 7399), ('catalogue', 7400), ('icons', 7401), ('objecttask', 7402), ('imds', 7403), ('swoogle', 7404), ('naos', 7405), ('datascope', 7406), ('spices', 7407), ('murax', 7408), ('mix', 7409), ('domino', 7410), ('undertow', 7411), ('tms', 7412), ('ebay', 7413), ('docqs', 7414), ('aqax', 7415), ('randomised', 7416), ('interpretable', 7417), ('cops', 7418), ('gila', 7419), ('aggregaterank', 7420), ('men', 7421), ('richer', 7422), ('psychological', 7423), ('patches', 7424), ('isis', 7425), ('customizability', 7426), ('c2', 7427), ('matchbox', 7428), ('patr', 7429), ('commutativity', 7430), ('cmic', 7431), ('anchors', 7432), ('shot', 7433), ('tense', 7434), ('crf', 7435), ('opt', 7436), ('extend', 7437), ('conventional', 7438), ('sided', 7439), ('outerjoin', 7440), ('computationally', 7441), ('bdi', 7442), ('smoqe', 7443), ('fist', 7444), ('korat', 7445), ('winners', 7446), ('listwise', 7447), ('unfolding', 7448), ('submodular', 7449), ('gold', 7450), ('classifications', 7451), ('snugglebug', 7452), ('simulate', 7453), ('tangram', 7454), ('recom', 7455), ('vgm', 7456), ('khufu', 7457), ('generativediscriminative', 7458), ('javaxxxl', 7459), ('semdiff', 7460), ('att', 7461), ('netweaver', 7462), ('graphplans', 7463), ('maybms', 7464), ('clustra', 7465), ('telecom', 7466), ('hodfa', 7467), ('homogenizing', 7468), ('kdms', 7469), ('krisys', 7470), ('csv', 7471), ('datacubes', 7472), ('planetary', 7473), ('webml', 7474), ('vip', 7475), ('vml', 7476), ('underrepresented', 7477), ('multicriteria', 7478), ('blosom', 7479), ('reconsidered', 7480), ('bordaconsensus', 7481), ('calin', 7482), ('logarithmic', 7483), ('assertional', 7484), ('munin', 7485), ('electromyographic', 7486), ('findings', 7487), ('nooksack', 7488), ('falls', 7489), ('hydroelectric', 7490), ('station', 7491), ('xanadue', 7492), ('arity', 7493), ('kalman', 7494), ('iliad', 7495), ('oklahoma', 7496), ('fetching', 7497), ('nondeterminism', 7498), ('shadowing', 7499), ('ware', 7500), ('vibe', 7501), ('geotagged', 7502), ('inexpressivity', 7503), ('monad', 7504), ('transformers', 7505), ('myportal', 7506), ('kaleidoscope', 7507), ('menu', 7508), ('vimsys', 7509), ('aptly', 7510), ('summarizatiion', 7511), ('gai', 7512), ('tomita', 7513), ('exquex', 7514), ('geoenvironmental', 7515), ('mismatched', 7516), ('turn', 7517), ('demonstrations', 7518), ('citations', 7519), ('oracles', 7520), ('triples', 7521), ('subscribed', 7522), ('proportion', 7523), ('transportation', 7524), ('raw', 7525), ('forgotten', 7526), ('connective', 7527), ('loaded', 7528), ('xel', 7529), ('hollands', 7530), ('congruence', 7531), ('considered', 7532), ('graduated', 7533), ('exposure', 7534), ('zoning', 7535), ('chemistry', 7536), ('matchmaking', 7537), ('posts', 7538), ('synchronizing', 7539), ('illustrated', 7540), ('er', 7541), ('twicpen', 7542), ('held', 7543), ('scanner', 7544), ('rete', 7545), ('inclusions', 7546), ('textmole', 7547), ('reconstructive', 7548), ('hyperlink', 7549), ('eventually', 7550), ('kit', 7551), ('hyspirit', 7552), ('picky', 7553), ('dsps', 7554), ('cssv', 7555), ('overflows', 7556), ('recsplorer', 7557), ('demeter', 7558), ('keyphrases', 7559), ('fashion', 7560), ('wearable', 7561), ('ddc', 7562), ('genres', 7563), ('lisp7o', 7564), ('40', 7565), ('i4e', 7566), ('genie', 7567), ('raising', 7568), ('directionality', 7569), ('clash', 7570), ('intuitions', 7571), ('basenp', 7572), ('vulnerabilities', 7573), ('besoins', 7574), ('lexicaux', 7575), ('lumiere', 7576), ('lanalyse', 7577), ('statistique', 7578), ('projet', 7579), ('bref', 7580), ('bdlex', 7581), ('francais', 7582), ('ecrit', 7583), ('et', 7584), ('oral', 7585), ('crafted', 7586), ('cocqa', 7587), ('eurotra', 7588), ('factorizing', 7589), ('ipodlinux', 7590), ('os', 7591), ('penalties', 7592), ('hyperparamodulation', 7593), ('cleansing', 7594), ('crowded', 7595), ('cooccurance', 7596), ('majic', 7597), ('matlab', 7598), ('responsiveness', 7599), ('rebuild', 7600), ('inquiry', 7601), ('broader', 7602), ('recycling', 7603), ('axiom', 7604), ('failsafe', 7605), ('floor', 7606), ('ebg', 7607), ('limeds', 7608), ('lincks', 7609), ('delayre', 7610), ('eracer', 7611), ('miniconference', 7612), ('paraphraser', 7613), ('entityrank', 7614), ('directly', 7615), ('holistically', 7616), ('cgi', 7617), ('modperl', 7618), ('plangoal', 7619), ('postprocessing', 7620), ('laminar', 7621), ('lifestyle', 7622), ('ilsa', 7623), ('idbd', 7624), ('dbtg', 7625), ('monitors', 7626), ('clir', 7627), ('unsuccessful', 7628), ('expedite', 7629), ('encoded', 7630), ('acquire', 7631), ('investigaton', 7632), ('competitions', 7633), ('sell', 7634), ('conditionally', 7635), ('advertisement', 7636), ('popfed', 7637), ('instace', 7638), ('amn', 7639), ('2d', 7640), ('laser', 7641), ('memoizer', 7642), ('supports', 7643), ('ict', 7644), ('enriched', 7645), ('limit', 7646), ('spirit', 7647), ('diagnoses', 7648), ('terraserver', 7649), ('barriers', 7650), ('widespread', 7651), ('pbfilter', 7652), ('tirs', 7653), ('waller', 7654), ('kraft', 7655), ('wish', 7656), ('triplet', 7657), ('targeting', 7658), ('regional', 7659), ('promise', 7660), ('perils', 7661), ('likelihoods', 7662), ('dictations', 7663), ('bind', 7664), ('them', 7665), ('topx', 7666), ('dare', 7667), ('weathra', 7668), ('interrupt', 7669), ('teacher', 7670), ('honorifics', 7671), ('recur', 7672), ('equation', 7673), ('dm', 7674), ('pict', 7675), ('overloading', 7676), ('ccgs', 7677), ('raised', 7678), ('stereotrust', 7679), ('taxonomical', 7680), ('featureide', 7681), ('apprentice', 7682), ('scsl', 7683), ('sox', 7684), ('insite', 7685), ('demon', 7686), ('authorization', 7687), ('lotos', 7688), ('doc', 7689), ('prob', 7690), ('maxn', 7691), ('brained', 7692), ('morphing', 7693), ('rhode', 7694), ('audiovideo', 7695), ('boosts', 7696), ('sac', 7697), ('cleanliness', 7698), ('cdn', 7699), ('zones', 7700), ('comes', 7701), ('94', 7702), ('tpr', 7703), ('altricial', 7704), ('precocial', 7705), ('intro', 7706), ('compatibilities', 7707), ('synonym', 7708), ('diabetic', 7709), ('cuber', 7710), ('nodose', 7711), ('subsystems', 7712), ('spectroscopy', 7713), ('eigenspaces', 7714), ('morpheus', 7715), ('mugi', 7716), ('wap', 7717), ('restore', 7718), ('detective', 7719), ('defeating', 7720), ('enforced', 7721), ('xtream', 7722), ('hdsampler', 7723), ('teleputing', 7724), ('corev', 7725), ('averaged', 7726), ('mlcs', 7727), ('urdu', 7728), ('tinycasper', 7729), ('routes', 7730), ('perpetual', 7731), ('cc2001', 7732), ('cited', 7733), ('inection', 7734), ('quantized', 7735), ('parsercompiler', 7736), ('v8', 7737), ('4', 7738), ('sintesi', 7739), ('honesty', 7740), ('marketplaces', 7741), ('nonemptiness', 7742), ('scannerless', 7743), ('nslr1', 7744), ('recognizers', 7745), ('lmrp', 7746), ('quickstart', 7747), ('ltrules', 7748), ('rose', 7749), ('retail', 7750), ('outlet', 7751), ('precomputed', 7752), ('mss', 7753), ('mus', 7754), ('thanks', 7755), ('cyberwar', 7756), ('harmless', 7757), ('arsa', 7758), ('impediments', 7759), ('ops5', 7760), ('undesired', 7761), ('anonymization', 7762), ('grammer', 7763), ('newsgroups', 7764), ('arising', 7765), ('invert', 7766), ('guidance', 7767), ('realism', 7768), ('hrdm', 7769), ('lifespans', 7770), ('polyphonic', 7771), ('surrogates', 7772), ('comprehensions', 7773), ('tradeoff', 7774), ('unpredictable', 7775), ('loanwords', 7776), ('leaming', 7777), ('yoopick', 7778), ('sports', 7779), ('arcs', 7780), ('rapidly', 7781), ('2pxminer', 7782), ('openrulebench', 7783), ('presenter', 7784), ('lecturing', 7785), ('hugin', 7786), ('universes', 7787), ('phrasetable', 7788), ('medians', 7789), ('insanity', 7790), ('himotoki', 7791), ('diagonal', 7792), ('nightmare', 7793), ('mlisp2', 7794), ('multifractals', 7795), ('nonmontonic', 7796), ('exploit', 7797), ('traitor', 7798), ('comprehensible', 7799), ('fzi', 7800), ('karlsruhe', 7801), ('dfr', 7802), ('setups', 7803), ('satisficing', 7804), ('prisoner', 7805), ('webquilt', 7806), ('offics', 7807), ('telling', 7808), ('toggle', 7809), ('pebm', 7810), ('homomorphism', 7811), ('downward', 7812), ('upward', 7813), ('cfls', 7814), ('stencil', 7815), ('distinctness', 7816), ('dqp', 7817), ('sybase', 7818), ('ase', 7819), ('congolog', 7820), ('investigations', 7821), ('marriage', 7822), ('indexation', 7823), ('lapprentissage', 7824), ('pronomial', 7825), ('mud', 7826), ('damage', 7827), ('quarantine', 7828), ('mission', 7829), ('minesweeper', 7830), ('cocoviz', 7831), ('ambient', 7832), ('vizql', 7833), ('simdb', 7834), ('replies', 7835), ('truth', 7836), ('contextualization', 7837), ('unorganized', 7838), ('empower', 7839), ('privileged', 7840), ('bantu', 7841), ('untagged', 7842), ('psychsim', 7843), ('threat', 7844), ('dcube', 7845), ('penalty', 7846), ('wa', 7847), ('disguised', 7848), ('encounter', 7849), ('symbols', 7850), ('spilling', 7851), ('cws', 7852), ('dec', 7853), ('colorful', 7854), ('factorisation', 7855), ('diffuse', 7856), ('failing', 7857), ('hearsay', 7858), ('reallocation', 7859), ('cpm', 7860), ('wlans', 7861), ('deadliner', 7862), ('niche', 7863), ('velodrome', 7864), ('avoid', 7865), ('drastic', 7866), ('sequentially', 7867), ('numericalvectors', 7868), ('published', 7869), ('confluence', 7870), ('guaranteeing', 7871), ('mangers', 7872), ('weblog', 7873), ('synthesized', 7874), ('dispositions', 7875), ('converses', 7876), ('pumping', 7877), ('lemmas', 7878), ('forth', 7879), ('tuple', 7880), ('homogeneity', 7881), ('7', 7882), ('wdas', 7883), ('2006', 7884), ('frontal', 7885), ('print', 7886), ('feistel', 7887), ('six', 7888), ('rounds', 7889), ('equip', 7890), ('tourists', 7891), ('travelogues', 7892), ('prepare', 7893), ('martlet', 7894), ('abstracted', 7895), ('parallelisation', 7896), ('inc', 7897), ('rubric', 7898), ('longitudinal', 7899), ('tagmark', 7900), ('estimations', 7901), ('chianti', 7902), ('essay', 7903), ('printed', 7904), ('twigs', 7905), ('undecidable', 7906), ('rdbvms', 7907), ('skeleton', 7908), ('forensics', 7909), ('permanents', 7910), ('polytopes', 7911), ('multidisciplinary', 7912), ('youtube', 7913), ('spc', 7914), ('cwb', 7915), ('interchangeabilities', 7916), ('resolve', 7917), ('venture', 7918), ('threesomes', 7919), ('blame', 7920), ('methodical', 7921), ('fasttrack', 7922), ('tenth', 7923), ('dolap07', 7924), ('fcvw', 7925), ('plug', 7926), ('csd', 7927), ('uoc', 7928), ('inconsisent', 7929), ('revising', 7930), ('seth', 7931), ('gc', 7932), ('themed', 7933), ('ilp', 7934), ('compressive', 7935), ('solo', 7936), ('orthosis', 7937), ('trio', 7938), ('perturb', 7939), ('interruptable', 7940), ('career', 7941), ('disentangling', 7942), ('called', 7943), ('punctuality', 7944), ('hierarchyscan', 7945), ('flexpath', 7946), ('surveys', 7947), ('autotagging', 7948), ('closurize', 7949), ('concentrate', 7950), ('magical', 7951), ('coil', 7952), ('cognate', 7953), ('orthography', 7954), ('workfile', 7955), ('mergesorts', 7956), ('dignosis', 7957), ('alibi', 7958), ('timestamping', 7959), ('wiser', 7960), ('deliberative', 7961), ('apprenticeship', 7962), ('meme', 7963), ('cycle', 7964), ('advantage', 7965), ('nf', 7966), ('bucket', 7967), ('voronoi', 7968), ('ditributed', 7969), ('raddle', 7970), ('consultant', 7971), ('lid', 7972), ('never', 7973), ('spotfire', 7974), ('ale', 7975), ('assume', 7976), ('svd', 7977), ('houston', 7978), ('oxygen', 7979), ('tank', 7980), ('ariesim', 7981), ('broken', 7982), ('plural', 7983), ('billion', 7984), ('synthetic', 7985), ('embeddings', 7986), ('extenders', 7987), ('restart', 7988), ('flattening', 7989), ('grocery', 7990), ('merits', 7991), ('smallest', 7992), ('lcas', 7993), ('humanoid', 7994), ('taming', 7995), ('gemini', 7996), ('funnel', 7997), ('advertisers', 7998), ('marion', 7999), ('retargetable', 8000), ('networkweb', 8001), ('others', 8002), ('esp', 8003), ('nombank', 8004), ('quota', 8005), ('statement', 8006), ('dlv', 8007), ('agora', 8008), ('atm', 8009), ('queuing', 8010), ('dely', 8011), ('collected', 8012), ('pmi', 8013), ('noncorrecting', 8014), ('cubeexplorer', 8015), ('partitional', 8016), ('simplify', 8017), ('deckard', 8018), ('transcription', 8019), ('opium', 8020), ('installuninstall', 8021), ('generational', 8022), ('validator', 8023), ('grassmann', 8024), ('preferable', 8025), ('zooming', 8026), ('gameboy', 8027), ('homebrew', 8028), ('metho', 8029), ('metaclasses', 8030), ('provisioning', 8031), ('unreliable', 8032), ('proposing', 8033), ('substitutability', 8034), ('csiec', 8035), ('bootstrapped', 8036), ('codecrawler', 8037), ('pepsys', 8038), ('ntjfsatnot', 8039), ('downdate', 8040), ('paid', 8041), ('commands', 8042), ('diet', 8043), ('foks', 8044), ('scavenging', 8045), ('concerning', 8046), ('purposeful', 8047), ('dossier', 8048), ('contraints', 8049), ('alen', 8050), ('imperatives', 8051), ('calculating', 8052), ('quirky', 8053), ('sor', 8054), ('sagas', 8055), ('navigations', 8056), ('hinting', 8057), ('indexable', 8058), ('pla', 8059), ('alphanumeric', 8060), ('nlhe', 8061), ('village', 8062), ('conways', 8063), ('datasplash', 8064), ('bagger', 8065), ('extends', 8066), ('generalizes', 8067), ('pasta', 8068), ('3s', 8069), ('watermarking', 8070), ('brooklyn', 8071), ('teenage', 8072), ('persons', 8073), ('dementia', 8074), ('cognitively', 8075), ('describe', 8076), ('rigel', 8077), ('prospective', 8078), ('assumeguarantee', 8079), ('verisoft', 8080), ('isomorphic', 8081), ('montague', 8082), ('restarting', 8083), ('codesign', 8084), ('replicator', 8085), ('odesew', 8086), ('pddl', 8087), ('naturally', 8088), ('provable', 8089), ('ituned', 8090), ('lost', 8091), ('gpu', 8092), ('socializing', 8093), ('uksearch', 8094), ('storylines', 8095), ('reality', 8096), ('leadership', 8097), ('metareasoning', 8098), ('orden', 8099), ('volatility', 8100), ('empowering', 8101), ('millenium', 8102), ('mad', 8103), ('abe', 8104), ('selectional', 8105), ('hps', 8106), ('xas', 8107), ('componentized', 8108), ('lexemes', 8109), ('idarex', 8110), ('discernment', 8111), ('reconnaissance', 8112), ('worldwide', 8113), ('telescope', 8114), ('scramble', 8115), ('encrypt', 8116), ('falcon', 8117), ('psr', 8118), ('jkarelrobot', 8119), ('monologue', 8120), ('accadian', 8121), ('mul', 8122), ('green', 8123), ('illustration', 8124), ('corel', 8125), ('pipe', 8126), ('fork', 8127), ('resoution', 8128), ('danaphore', 8129), ('partir', 8130), ('dun', 8131), ('grammaire', 8132), ('verbes', 8133), ('anaphoriques', 8134), ('sparsely', 8135), ('btrees', 8136), ('x86', 8137), ('mrd', 8138), ('mistake', 8139), ('sending', 8140), ('capable', 8141), ('federations', 8142), ('immigration', 8143), ('bolasso', 8144), ('maintainers', 8145), ('utilize', 8146), ('tpc', 8147), ('knapsack', 8148), ('sg', 8149), ('ternary', 8150), ('kda', 8151), ('chaotic', 8152), ('expense', 8153), ('reimbursement', 8154), ('subroutines', 8155), ('goethe', 8156), ('hypersurfaces', 8157), ('quantity', 8158), ('hyperspread', 8159), ('cbir', 8160), ('elicitation', 8161), ('sampler', 8162), ('dp', 8163), ('multikey', 8164), ('quad', 8165), ('password', 8166), ('stretching', 8167), ('salts', 8168), ('3dstring', 8169), ('voxelized', 8170), ('recognizer', 8171), ('garlic', 8172), ('flavor', 8173), ('duping', 8174), ('quasigroup', 8175), ('fostering', 8176), ('niagaracq', 8177), ('rendered', 8178), ('doodle', 8179), ('persuasive', 8180), ('aod', 8181), ('tiie', 8182), ('hal', 8183), ('sprinkling', 8184), ('yields', 8185), ('restoring', 8186), ('interpretive', 8187), ('weiner', 8188), ('presenting', 8189), ('microkernels', 8190), ('submodule', 8191), ('nitpick', 8192), ('clearing', 8193), ('quotations', 8194), ('inserted', 8195), ('arena', 8196), ('bodies', 8197), ('infusion', 8198), ('fidelity', 8199), ('imposition', 8200), ('trick', 8201), ('rpref', 8202), ('bpref', 8203), ('chaining', 8204), ('due', 8205), ('ccured', 8206), ('retrofitting', 8207), ('asilomar', 8208), ('isolating', 8209), ('claremont', 8210), ('passwords', 8211), ('absence', 8212), ('cursive', 8213), ('charting', 8214), ('depths', 8215), ('bdd', 8216), ('polytime', 8217), ('schedulers', 8218), ('planarisation', 8219), ('stl', 8220), ('sardsrn', 8221), ('winnowing', 8222), ('subexpression', 8223), ('unknowns', 8224), ('prevent', 8225), ('stages', 8226), ('horizontally', 8227), ('rings', 8228), ('misconfigured', 8229), ('quantative', 8230), ('trackers', 8231), ('mercy', 8232), ('sector', 8233), ('turings', 8234), ('dream', 8235), ('sndocrank', 8236), ('parsetalk', 8237), ('nonrecursive', 8238), ('heavy', 8239), ('tailed', 8240), ('dewey', 8241), ('gp', 8242), ('lvm', 8243), ('dempster', 8244), ('shafers', 8245), ('mirror', 8246), ('moby', 8247), ('disco', 8248), ('novo', 8249), ('gogo', 8250), ('mallows', 8251), ('tge', 8252), ('tlinks', 8253), ('legged', 8254), ('spicy', 8255), ('chomsky', 8256), ('diderichsen', 8257), ('progressing', 8258), ('sim', 8259), ('biases', 8260), ('keyhole', 8261), ('robotstxt', 8262), ('mpsocs', 8263), ('comment', 8264), ('undirected', 8265), ('sgl', 8266), ('asymmetrically', 8267), ('collocational', 8268), ('unconditional', 8269), ('jumps', 8270), ('stick', 8271), ('i11', 8272), ('replicability', 8273), ('peg', 8274), ('towers', 8275), ('hanoi', 8276), ('grabber', 8277), ('quickstore', 8278), ('curb', 8279), ('circumspective', 8280), ('inclusive', 8281), ('myopia', 8282), ('hill', 8283), ('sessionlock', 8284), ('eavesdropping', 8285), ('engagement', 8286), ('egs', 8287), ('kana', 8288), ('expressional', 8289), ('uninteresting', 8290), ('pdl', 8291), ('datapath', 8292), ('revisted', 8293), ('projectron', 8294), ('portlet', 8295), ('tbt', 8296), ('interating', 8297), ('normalisation', 8298), ('sums', 8299), ('customes', 8300), ('port', 8301), ('singapore', 8302), ('psa', 8303), ('dualising', 8304), ('chess', 8305), ('quiescene', 8306), ('sacrifices', 8307), ('ransac', 8308), ('cylinders', 8309), ('ball', 8310), ('lham', 8311), ('8', 8312), ('flowgraphs', 8313), ('tensorial', 8314), ('flick', 8315), ('idl', 8316), ('graphscope', 8317), ('lean', 8318), ('alep', 8319), ('approximators', 8320), ('redesign', 8321), ('routines', 8322), ('concernlines', 8323), ('occurring', 8324), ('erknn', 8325), ('behaved', 8326), ('schemata', 8327), ('psiphi', 8328), ('norm', 8329), ('locus', 8330), ('ray', 8331), ('forces', 8332), ('mbrs', 8333), ('rhythms', 8334), ('megaprogramming', 8335), ('once', 8336), ('kemeny', 8337), ('eigentransfer', 8338), ('combinatorical', 8339), ('queues', 8340), ('asp', 8341), ('initiator', 8342), ('gateways', 8343), ('mr', 8344), ('substrings', 8345), ('lrk', 8346), ('graduating', 8347), ('beamforming', 8348), ('destructive', 8349), ('bot', 8350), ('instantiating', 8351), ('coefficients', 8352), ('senselearner', 8353), ('bushy', 8354), ('mereology', 8355), ('modularized', 8356), ('feasible', 8357)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esNjZbrJ4lay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "227cddf1-464e-4c17-df3a-5463e0aeec84"
      },
      "source": [
        "print(word2index) # just the same"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'for': 1, 'of': 2, 'a': 3, 'and': 4, 'in': 5, 'the': 6, 'to': 7, 'data': 8, 'based': 9, 'with': 10, 'on': 11, 'using': 12, 'an': 13, 'learning': 14, 'web': 15, 'system': 16, 'information': 17, 'database': 18, 'systems': 19, 'query': 20, 'model': 21, 'retrieval': 22, 'from': 23, 'search': 24, 'analysis': 25, 'approach': 26, 'language': 27, 'software': 28, 'databases': 29, 'efficient': 30, 'semantic': 31, 'models': 32, 'by': 33, 'mining': 34, 'knowledge': 35, 'programming': 36, 'time': 37, 'design': 38, 'text': 39, 'distributed': 40, 'processing': 41, 'queries': 42, 'object': 43, 'large': 44, 'evaluation': 45, 'relational': 46, 'multi': 47, 'oriented': 48, 'computer': 49, 'management': 50, 'automatic': 51, 'classification': 52, 'clustering': 53, 'dynamic': 54, 'logic': 55, 'performance': 56, 'algorithm': 57, 'translation': 58, 'machine': 59, 'networks': 60, 'document': 61, 'xml': 62, 'optimization': 63, 'algorithms': 64, 'engineering': 65, 'structure': 66, 'reasoning': 67, 'detection': 68, 'framework': 69, 'applications': 70, 'temporal': 71, 'generation': 72, 'study': 73, 'method': 74, 'programs': 75, 'parsing': 76, 'multiple': 77, 'modeling': 78, 'user': 79, 'high': 80, 'extraction': 81, 'parallel': 82, 'as': 83, 'case': 84, 'probabilistic': 85, 'program': 86, 'application': 87, 'network': 88, 'towards': 89, 'support': 90, 'planning': 91, 'control': 92, 'development': 93, 'new': 94, 'statistical': 95, 'course': 96, 'science': 97, 'via': 98, 'selection': 99, 'word': 100, 'tree': 101, 'through': 102, 'semantics': 103, 'rules': 104, 'natural': 105, 'environment': 106, 'teaching': 107, 'structured': 108, 'problem': 109, 'methods': 110, 'fast': 111, 'real': 112, 'indexing': 113, 'adaptive': 114, 'theory': 115, 'context': 116, 'online': 117, 'graph': 118, 'constraints': 119, 'tool': 120, 'ranking': 121, 'hierarchical': 122, 'patterns': 123, 'non': 124, 'techniques': 125, 'feature': 126, 'memory': 127, 'similarity': 128, 'order': 129, 'domain': 130, 'access': 131, 'into': 132, 'architecture': 133, 'computing': 134, 'languages': 135, 'process': 136, 'scale': 137, 'implementation': 138, 'inference': 139, 'linear': 140, 'estimation': 141, 'representation': 142, 'incremental': 143, 'structures': 144, 'integration': 145, 'documents': 146, 'first': 147, 'code': 148, 'constraint': 149, 'complex': 150, 'relevance': 151, 'over': 152, 'improving': 153, 'its': 154, 'level': 155, 'integrating': 156, 'interactive': 157, 'active': 158, 'recognition': 159, 'supervised': 160, 'base': 161, 'semi': 162, 'between': 163, 'optimal': 164, 'at': 165, 'type': 166, 'driven': 167, 'social': 168, 'objects': 169, 'answering': 170, 'local': 171, 'combining': 172, 'effective': 173, 'state': 174, 'content': 175, 'problems': 176, 'matching': 177, 'resolution': 178, 'rule': 179, 'trees': 180, 'join': 181, 'graphs': 182, 'is': 183, 'space': 184, 'decision': 185, 'topic': 186, 'feedback': 187, 'collaborative': 188, 'relations': 189, 'use': 190, 'streams': 191, 'automated': 192, 'complexity': 193, 'generalized': 194, 'dimensional': 195, 'bayesian': 196, 'peer': 197, 'comparison': 198, 'filtering': 199, 'exploiting': 200, 'grammar': 201, 'syntactic': 202, 'computation': 203, 'speech': 204, 'acquisition': 205, 'spatial': 206, 'prediction': 207, 'image': 208, 'services': 209, 'discovery': 210, 'pattern': 211, 'quality': 212, 'testing': 213, 'value': 214, 'mobile': 215, 'class': 216, 'querying': 217, 'two': 218, 'views': 219, 'dependency': 220, 'solving': 221, 'integrated': 222, 'supporting': 223, 'test': 224, 'schema': 225, 'understanding': 226, 'java': 227, 'finding': 228, 'scalable': 229, 'practical': 230, 'execution': 231, 'functional': 232, 'abstract': 233, 'random': 234, 'cross': 235, 'robust': 236, 'building': 237, 'heterogeneous': 238, 'strategies': 239, 'concurrent': 240, 'transaction': 241, 'research': 242, 'view': 243, 'report': 244, 'flow': 245, 'grammars': 246, 'agent': 247, 'self': 248, 'partial': 249, 'unsupervised': 250, 'japanese': 251, 'approximate': 252, 'formal': 253, 'results': 254, 'visual': 255, 'generating': 256, 'cost': 257, 'processes': 258, 'types': 259, 'domains': 260, 'project': 261, 'students': 262, 'verification': 263, 'features': 264, 'computational': 265, 'bases': 266, 'evaluating': 267, 'chinese': 268, 'question': 269, 'lexical': 270, 'engine': 271, 'general': 272, 'concept': 273, 'disambiguation': 274, 'construction': 275, 'kernel': 276, 'summarization': 277, 'event': 278, 'function': 279, 'experience': 280, 'service': 281, 'extracting': 282, 'how': 283, 'set': 284, 'index': 285, 'free': 286, 'markov': 287, 'concurrency': 288, 'association': 289, 'term': 290, 'about': 291, 'corpus': 292, 'simple': 293, 'requirements': 294, 'description': 295, 'interface': 296, 'hybrid': 297, 'functions': 298, 'machines': 299, 'path': 300, 'extended': 301, 'behavior': 302, 'games': 303, 'stream': 304, 'global': 305, 'technique': 306, 'file': 307, 'interaction': 308, 'segmentation': 309, 'sql': 310, 'english': 311, 'specification': 312, 'detecting': 313, 'interpretation': 314, 'training': 315, 'storage': 316, 'environments': 317, 'regression': 318, 'vector': 319, 'linguistic': 320, 'checking': 321, 'evolution': 322, 'stochastic': 323, 'concepts': 324, 'collection': 325, 'scheduling': 326, 'human': 327, 'scheme': 328, 'sets': 329, 'open': 330, 'sense': 331, 'multimedia': 332, 'categorization': 333, 'corpora': 334, 'consistency': 335, 'empirical': 336, 'without': 337, 'making': 338, 'introductory': 339, 'experiments': 340, 'conceptual': 341, 'conditional': 342, 'privacy': 343, 'security': 344, 'monitoring': 345, 'identification': 346, 'sources': 347, 'role': 348, 'curriculum': 349, 'source': 350, 'maintenance': 351, 'allocation': 352, 'optimizing': 353, 'intelligent': 354, 'server': 355, 'tracking': 356, 'entity': 357, 'line': 358, 'k': 359, 'logical': 360, 'independent': 361, 'visualization': 362, 'expert': 363, 'continuous': 364, 'sampling': 365, 'experimental': 366, 'improved': 367, 'task': 368, 'robot': 369, 'transfer': 370, 'projects': 371, 'dbms': 372, 'relationship': 373, 'sensitive': 374, 'undergraduate': 375, 'parser': 376, 'tools': 377, 'ontology': 378, 'sequential': 379, 'caching': 380, 'workshop': 381, 'recursive': 382, 'world': 383, 'representations': 384, 'predicting': 385, 'are': 386, 'improve': 387, 'latent': 388, 'form': 389, 'one': 390, 'dialogue': 391, 'reinforcement': 392, 'heuristic': 393, 'spoken': 394, 'unified': 395, 'compiler': 396, 'structural': 397, 'mapping': 398, 'searching': 399, 'abstraction': 400, 'aware': 401, 'aggregation': 402, 'dependencies': 403, 'measures': 404, 'discovering': 405, 'exploration': 406, 'frequent': 407, 'directed': 408, 'component': 409, 'pages': 410, 'link': 411, 'error': 412, 'what': 413, 'top': 414, 'some': 415, 'discourse': 416, 'preserving': 417, 'users': 418, 'unification': 419, 'alignment': 420, 'their': 421, 'classifiers': 422, 'strategy': 423, 'decomposition': 424, 'propagation': 425, 'it': 426, 'static': 427, 'intelligence': 428, 'agents': 429, 'series': 430, 'calculus': 431, 'that': 432, 'plans': 433, 'spaces': 434, 'community': 435, 'expansion': 436, 'rank': 437, 'sequence': 438, 'induction': 439, 'modelling': 440, 'perspective': 441, 'approximation': 442, 'cs': 443, 'game': 444, 'descriptions': 445, 'page': 446, 'more': 447, 'transactions': 448, 'or': 449, 'deductive': 450, 'weighted': 451, 'sensor': 452, 'recovery': 453, 'distance': 454, 'constrained': 455, 'graphical': 456, 'maximum': 457, 'flexible': 458, 'joins': 459, 'virtual': 460, 'incorporating': 461, 'experiences': 462, 'specific': 463, 'toward': 464, 'architectures': 465, 'under': 466, 'exploring': 467, 'organization': 468, 'approaches': 469, 'resource': 470, 'courses': 471, 'pruning': 472, 'effects': 473, 'belief': 474, 'co': 475, 'browsing': 476, 'operations': 477, 'mechanism': 478, 'tagging': 479, 'specifications': 480, 'up': 481, 'automatically': 482, 'annotation': 483, 'neural': 484, 'internet': 485, 'analyzing': 486, 'plan': 487, 'interfaces': 488, 'action': 489, 'relation': 490, 'education': 491, 'novel': 492, 'comparative': 493, 'transformation': 494, 'issues': 495, 'effectiveness': 496, 'classes': 497, 'implementing': 498, 'technology': 499, 'cache': 500, 'estimating': 501, 'communication': 502, 'texts': 503, 'update': 504, 'boosting': 505, 'auctions': 506, 'not': 507, 'beyond': 508, 'product': 509, 'group': 510, 'dictionary': 511, 'metric': 512, 'c': 513, 'extending': 514, 'matrix': 515, 'datasets': 516, 'measuring': 517, 'cooperative': 518, 'bilingual': 519, 'lexicon': 520, 'finite': 521, 'sharing': 522, 'efficiency': 523, 'video': 524, 'laboratory': 525, 'production': 526, 'incomplete': 527, 'vs': 528, 'advanced': 529, 'assessment': 530, 'labeling': 531, 'when': 532, 'example': 533, 'good': 534, 'methodology': 535, 'ir': 536, 'operating': 537, 'boolean': 538, 'partitioning': 539, 'digital': 540, 'phrase': 541, 'algebra': 542, 'artificial': 543, 'properties': 544, 'b': 545, 'very': 546, 'personalized': 547, 'named': 548, 'collections': 549, 'identifying': 550, 'business': 551, 'common': 552, 'discriminative': 553, 'low': 554, 'theoretic': 555, 'modular': 556, 'prolog': 557, 'practice': 558, 'logics': 559, 'morphological': 560, 'debugging': 561, 'impact': 562, 'dependence': 563, 'higher': 564, 'causal': 565, 'power': 566, 'coordination': 567, 'probability': 568, 'cluster': 569, 'engines': 570, 'iterative': 571, 'generic': 572, 'hashing': 573, 'handling': 574, 'aspects': 575, 'n': 576, 'reduction': 577, 'mixture': 578, 'hash': 579, 'shared': 580, 'words': 581, 'qualitative': 582, 'reuse': 583, 'policies': 584, 'integrity': 585, 'ordering': 586, 'cs1': 587, 'can': 588, 'olap': 589, 'preferences': 590, 'representing': 591, 'resources': 592, 'student': 593, 'ad': 594, 'sentence': 595, 'components': 596, 'do': 597, 'goal': 598, 'tasks': 599, 'examples': 600, 'updates': 601, 'schemes': 602, 'indexes': 603, 'typed': 604, 'nested': 605, 'entropy': 606, 'scientific': 607, 'sites': 608, 'prototype': 609, 'aggregate': 610, 'hierarchies': 611, 'attribute': 612, 'efficiently': 613, 'principles': 614, 'extensible': 615, 'best': 616, 'utility': 617, 'multidimensional': 618, 'range': 619, 'uncertainty': 620, 'small': 621, 'refinement': 622, 'complete': 623, 'expressions': 624, 'disk': 625, 'terms': 626, 'robots': 627, 'why': 628, 'protocol': 629, 'writing': 630, 'files': 631, 'challenges': 632, 'schemas': 633, 'compilation': 634, 'syntax': 635, 'noun': 636, 'changes': 637, 'propositional': 638, 'kernels': 639, 'events': 640, 'composition': 641, 'better': 642, 'assignment': 643, 'distribution': 644, 'processor': 645, 'keyword': 646, 'proving': 647, 'guided': 648, 'managing': 649, 'autonomous': 650, 'presence': 651, 'site': 652, 'actions': 653, 'binary': 654, 'applying': 655, 'news': 656, 'buffer': 657, 'relevant': 658, 'explanation': 659, 'personal': 660, 'evidence': 661, 'different': 662, 'hidden': 663, 'diagrams': 664, 'measure': 665, 'compression': 666, 'images': 667, 'string': 668, 'bounded': 669, 'reference': 670, 'preference': 671, 'meta': 672, 'physical': 673, 'usage': 674, 'e': 675, 'bridging': 676, 'log': 677, 'you': 678, 'adaptation': 679, 'multimodal': 680, 'answers': 681, 'locking': 682, 'satisfaction': 683, 'history': 684, 'sequences': 685, 'solution': 686, 'merging': 687, 'fuzzy': 688, 'sparse': 689, 'versus': 690, 'tag': 691, 'mt': 692, 'simulation': 693, 'designing': 694, 'modules': 695, 'field': 696, 'margin': 697, 'wide': 698, 'future': 699, 'streaming': 700, 'clusters': 701, 'modal': 702, 'direct': 703, 'key': 704, 'secure': 705, 'relationships': 706, 'size': 707, 'precision': 708, 'protocols': 709, 'classifier': 710, 'nearest': 711, 'theorem': 712, 'developing': 713, 'single': 714, 'parametric': 715, 'subspace': 716, 'multilingual': 717, 'transformations': 718, 'embedded': 719, 'instance': 720, 'garbage': 721, 'music': 722, 'media': 723, 'answer': 724, 'manipulation': 725, 'record': 726, 'introducing': 727, 'load': 728, 'extension': 729, 'algebraic': 730, 'criteria': 731, 'uncertain': 732, 'inductive': 733, 'combinatorial': 734, 'generalization': 735, 'fault': 736, 'instruction': 737, 'vision': 738, 'architectural': 739, 'solutions': 740, 'diagnosis': 741, 'fine': 742, 'predictive': 743, 'proof': 744, 'predicate': 745, 'scaling': 746, 'systematic': 747, 'basis': 748, 'dependent': 749, 'client': 750, 'full': 751, 'sat': 752, 'density': 753, 'accurate': 754, 'generative': 755, 'metrics': 756, 'comparing': 757, 'universal': 758, 'errors': 759, 'variable': 760, 'parallelism': 761, 'optimizations': 762, 'sentences': 763, 'proximity': 764, 'introduction': 765, 'cognitive': 766, 'interactions': 767, 'down': 768, 'spectral': 769, 'implicit': 770, 'alternative': 771, 'region': 772, 'policy': 773, 'xquery': 774, 'experiment': 775, 'main': 776, 'motion': 777, 'expression': 778, 'expressive': 779, 'redundancy': 780, 'correctness': 781, 'validation': 782, 'preliminary': 783, 'step': 784, 'equivalence': 785, 'way': 786, 'graphics': 787, 'specifying': 788, 'sentiment': 789, 'duplicate': 790, 'international': 791, 'loop': 792, 'default': 793, 'tutorial': 794, 'attributes': 795, 'weighting': 796, 'distributions': 797, 'recommendation': 798, 'tables': 799, 'entities': 800, 'constructing': 801, 'assessing': 802, 'dimensionality': 803, 'genetic': 804, 'electronic': 805, 'replication': 806, 'classifying': 807, 'limited': 808, 'inheritance': 809, 'we': 810, 'dynamically': 811, 'three': 812, 'materialized': 813, 'compressed': 814, 'overview': 815, 'quantitative': 816, 'composite': 817, 'partially': 818, 'parts': 819, 'correlation': 820, 'historical': 821, 'enhanced': 822, 'declarative': 823, 'grid': 824, 'library': 825, 'polynomial': 826, 'technologies': 827, 'reviews': 828, 'chart': 829, 'heuristics': 830, 'transitive': 831, 'near': 832, 'gap': 833, 'aspect': 834, 'score': 835, 'procedures': 836, 'fields': 837, 'factorization': 838, 'precise': 839, 'part': 840, 'joint': 841, 'demonstration': 842, 'medical': 843, 'optimizer': 844, 'accuracy': 845, 'summary': 846, 'neighbor': 847, 'inferring': 848, 'university': 849, 'consistent': 850, 'help': 851, 'max': 852, 'uml': 853, 'topics': 854, 'moving': 855, 'enterprise': 856, 'csp': 857, 'effect': 858, 'bound': 859, 'diverse': 860, 'interprocedural': 861, 'thinking': 862, 'investigation': 863, 'table': 864, 'bounds': 865, 'ai': 866, 'maintaining': 867, 'reliable': 868, 'algorithmic': 869, 'tractable': 870, 'reliability': 871, 'taxonomy': 872, 'selectivity': 873, 'hardware': 874, 'learned': 875, 'rewriting': 876, 'counting': 877, 'replicated': 878, 'automating': 879, 'than': 880, 'polymorphic': 881, 're': 882, 'elimination': 883, 'pseudo': 884, 'categories': 885, 'highly': 886, 'extensions': 887, 'reverse': 888, 'intensive': 889, 'look': 890, 'visualizing': 891, 'discriminant': 892, 'lazy': 893, 'rdf': 894, 'like': 895, 'change': 896, 'contextual': 897, 'progress': 898, 'critical': 899, 'xpath': 900, 'activity': 901, 'phase': 902, 'negotiation': 903, 'optimized': 904, 'dual': 905, 'result': 906, 'statistics': 907, 'lessons': 908, 'values': 909, 'perception': 910, 'related': 911, 'dirichlet': 912, 'ontologies': 913, 'revisited': 914, 'minimization': 915, 'inverted': 916, 'logs': 917, 'standard': 918, 'attacks': 919, 'number': 920, 'theoretical': 921, 'recommendations': 922, 'length': 923, 'wireless': 924, 'warehouse': 925, 'informative': 926, 'means': 927, 'derivation': 928, 'opinion': 929, 'profiling': 930, 'review': 931, 'demand': 932, 'noise': 933, 'satisfiability': 934, 'automata': 935, 'call': 936, 'right': 937, 'oracle': 938, 'hypertext': 939, 'devices': 940, 'mixed': 941, 'redundant': 942, 'disjunctive': 943, 'importance': 944, 'teach': 945, 'revision': 946, 'survey': 947, 'long': 948, 'all': 949, '1': 950, 'trust': 951, 'progressive': 952, 'minimal': 953, 'variables': 954, 'simultaneous': 955, 'phrases': 956, 'anaphora': 957, 'spatio': 958, 'output': 959, 'other': 960, 'definition': 961, 'combination': 962, 'gene': 963, 'paradigm': 964, 'hoc': 965, 'compiling': 966, 'map': 967, 'uniform': 968, 'difference': 969, 'studies': 970, 'across': 971, 'skills': 972, 'influence': 973, 'mechanisms': 974, 'version': 975, 'partitioned': 976, 'end': 977, 'programmers': 978, 'observations': 979, 'reducing': 980, 'levels': 981, 'evolutionary': 982, 'geometric': 983, 'gaussian': 984, 'navigation': 985, 'label': 986, 'workflow': 987, 'industrial': 988, 'array': 989, 'interval': 990, 'signature': 991, 'platform': 992, 'safe': 993, 'school': 994, 'ordered': 995, 'mdps': 996, 'measurement': 997, 'clause': 998, 'symbolic': 999, 'textual': 1000, 'configuration': 1001, 'coverage': 1002, 'operators': 1003, 'focused': 1004, 'pointer': 1005, 'embedding': 1006, 'predict': 1007, 'projection': 1008, 'adjoining': 1009, 'location': 1010, 'interoperability': 1011, 'experts': 1012, 'providing': 1013, 'compact': 1014, 'evolving': 1015, 'discrete': 1016, 'labeled': 1017, 'message': 1018, 'style': 1019, 'core': 1020, 'implications': 1021, 'shape': 1022, 'p2p': 1023, 'transition': 1024, 'team': 1025, 'termination': 1026, 'benchmark': 1027, 'robustness': 1028, 'operation': 1029, 'interesting': 1030, 'deep': 1031, 'commerce': 1032, 'explicit': 1033, 'points': 1034, 'frequency': 1035, 'normal': 1036, 'communities': 1037, 'nonmonotonic': 1038, 'synthesis': 1039, 'grained': 1040, 'capturing': 1041, 'valued': 1042, 'biomedical': 1043, 'federated': 1044, 'wikipedia': 1045, 'localization': 1046, 'noisy': 1047, 'voting': 1048, 'hard': 1049, 'summaries': 1050, 'market': 1051, 'reorganization': 1052, 'focus': 1053, 'register': 1054, 'frame': 1055, 'topological': 1056, 'arabic': 1057, 'tuning': 1058, 'multiprocessor': 1059, 'translating': 1060, 'bootstrapping': 1061, 'pomdps': 1062, 'back': 1063, 'adapting': 1064, 'reordering': 1065, 'servers': 1066, 'korean': 1067, 'learn': 1068, 'pre': 1069, 'organizing': 1070, 'be': 1071, 'recall': 1072, 'r': 1073, 'warehouses': 1074, 'convex': 1075, 'classroom': 1076, 'argumentation': 1077, 'biased': 1078, 'profiles': 1079, 'ml': 1080, 'transactional': 1081, 'routing': 1082, 'computers': 1083, 'list': 1084, 'point': 1085, 'formulas': 1086, 'lexicalized': 1087, 'enhancing': 1088, 'deterministic': 1089, 'nlp': 1090, 'procedure': 1091, 'dictionaries': 1092, 'center': 1093, 'massive': 1094, 'outliers': 1095, 'forms': 1096, 'your': 1097, 'soft': 1098, 'associative': 1099, 'reactive': 1100, 'characterization': 1101, 'db2': 1102, 'gradient': 1103, 'sound': 1104, 'deadlock': 1105, 'centered': 1106, 'only': 1107, 'multiagent': 1108, 'ii': 1109, 'parameter': 1110, 'questions': 1111, 'generalizing': 1112, 'side': 1113, 'commitment': 1114, 'closure': 1115, 'speed': 1116, 'among': 1117, 'verb': 1118, 'items': 1119, 'logistic': 1120, 'spam': 1121, 'libraries': 1122, 'weak': 1123, 'bottom': 1124, 'proactive': 1125, 'randomized': 1126, 'grammatical': 1127, 'during': 1128, 'head': 1129, 'morphology': 1130, 'recursion': 1131, 'quantified': 1132, 'paradigms': 1133, 'forward': 1134, 'correction': 1135, 'fully': 1136, 'negative': 1137, 'simulator': 1138, 'blog': 1139, 'zero': 1140, 'prototyping': 1141, 'abstractions': 1142, 'unlabeled': 1143, 'multidatabase': 1144, 'life': 1145, 'dialogues': 1146, 'less': 1147, 'run': 1148, 'minimum': 1149, 'logging': 1150, 'balancing': 1151, 'lisp': 1152, 'against': 1153, 'quasi': 1154, 'expected': 1155, 'beliefs': 1156, 'least': 1157, 'dimension': 1158, 'curricula': 1159, 'safety': 1160, 'no': 1161, 'energy': 1162, 'regularization': 1163, 'off': 1164, 'personalization': 1165, 'road': 1166, 'broad': 1167, 'customer': 1168, 'closed': 1169, 'generator': 1170, 'office': 1171, 'spontaneous': 1172, 'judgments': 1173, 'analyzer': 1174, 'conversion': 1175, 'formalism': 1176, 'occurrence': 1177, 'runtime': 1178, 'german': 1179, 'crawling': 1180, 'itemsets': 1181, 'email': 1182, 'just': 1183, 'operational': 1184, 'ethics': 1185, 'inconsistency': 1186, 'traffic': 1187, 'creation': 1188, 'does': 1189, 'analogy': 1190, 'geometry': 1191, 'synchronous': 1192, 'fusion': 1193, 'definitions': 1194, 'pagerank': 1195, 'goals': 1196, 'reranking': 1197, 'compositional': 1198, '3d': 1199, 'match': 1200, 'generate': 1201, 'lightweight': 1202, 'external': 1203, 'bayes': 1204, 'legacy': 1205, 'annotations': 1206, 'cubes': 1207, 'constructive': 1208, 'sample': 1209, 'principle': 1210, 'anytime': 1211, 'practices': 1212, 'dynamics': 1213, 'ensembles': 1214, 'name': 1215, 'stable': 1216, 'ambiguity': 1217, 'structuring': 1218, 'reading': 1219, 'enhance': 1220, 'manipulating': 1221, 'educational': 1222, 'effort': 1223, 'deriving': 1224, 'majors': 1225, 'indices': 1226, 'tolerant': 1227, 'similar': 1228, 'provenance': 1229, 'undergraduates': 1230, 'unstructured': 1231, 'guide': 1232, 'inter': 1233, 'sort': 1234, 'facility': 1235, 'input': 1236, 'blind': 1237, 'paper': 1238, 'assistant': 1239, 'animation': 1240, 'lr': 1241, 'out': 1242, 'availability': 1243, 'strings': 1244, 'positive': 1245, 'agile': 1246, 'relative': 1247, 'implementations': 1248, 'advertising': 1249, 'comprehension': 1250, 'cad': 1251, 'archives': 1252, 'depth': 1253, 'trajectories': 1254, 'probabilities': 1255, 'early': 1256, 'transparent': 1257, 'quantifying': 1258, 'foundations': 1259, 'paths': 1260, 'account': 1261, 'middle': 1262, 'formation': 1263, 'projections': 1264, 'inspection': 1265, 'within': 1266, 'parameterized': 1267, 'browser': 1268, 'outlier': 1269, 'who': 1270, 'svm': 1271, 'isolation': 1272, 'emerging': 1273, 'solver': 1274, 'warehousing': 1275, 'orientation': 1276, 'strong': 1277, 'associations': 1278, 'poster': 1279, 'hierarchy': 1280, 'mathematics': 1281, 'presentation': 1282, 'challenge': 1283, 'behaviors': 1284, 'target': 1285, 'anomaly': 1286, 'need': 1287, 'metadata': 1288, 'monotonic': 1289, 'ranked': 1290, 'predicates': 1291, 'coalitional': 1292, 'expertise': 1293, 'pragmatic': 1294, 'prior': 1295, 'profile': 1296, 'confidence': 1297, 'conscious': 1298, 'ada': 1299, 'genre': 1300, 'selective': 1301, 'owl': 1302, 'meets': 1303, 'nonlinear': 1304, 'passing': 1305, 'normalization': 1306, 'groups': 1307, 'possibilistic': 1308, 'usability': 1309, 'classical': 1310, 'procedural': 1311, 'edge': 1312, 'designs': 1313, 'articles': 1314, 'independence': 1315, 'situation': 1316, 'binding': 1317, 'circumscription': 1318, 'instructions': 1319, 'interpreter': 1320, 'native': 1321, 'purpose': 1322, 'versions': 1323, 'planner': 1324, 'invariants': 1325, 'locality': 1326, 'bringing': 1327, 'conflict': 1328, 'links': 1329, 'pos': 1330, 'dataflow': 1331, 'i': 1332, 'neighborhood': 1333, 'filter': 1334, 'coreference': 1335, 'net': 1336, 'parse': 1337, 'vertical': 1338, 'intent': 1339, 'theories': 1340, 'aligning': 1341, 'transliteration': 1342, 'skyline': 1343, 'cardinality': 1344, 'serializability': 1345, 'topical': 1346, 'activities': 1347, 'layout': 1348, 'records': 1349, 'html': 1350, 'persistent': 1351, 'generated': 1352, 'thesaurus': 1353, 'category': 1354, 'approximations': 1355, 'www': 1356, 'clickthrough': 1357, 'vocabulary': 1358, 'restructuring': 1359, 'determination': 1360, 'inclusion': 1361, 'cs2': 1362, 'find': 1363, 'easy': 1364, 'infinite': 1365, 'maximal': 1366, 'categorial': 1367, 'loops': 1368, 'proofs': 1369, 'broadcast': 1370, 'gathering': 1371, 'completeness': 1372, 'categorical': 1373, 'histograms': 1374, 'toolkit': 1375, 'middleware': 1376, 'ensemble': 1377, 'missing': 1378, 'leveraging': 1379, 'networking': 1380, 'window': 1381, 'calls': 1382, 'metaphor': 1383, 'creating': 1384, 'describing': 1385, 'windows': 1386, 'anonymous': 1387, 'know': 1388, 'biological': 1389, 'lingual': 1390, 'lock': 1391, 'cube': 1392, 'states': 1393, 'go': 1394, 'rate': 1395, 'determining': 1396, 'argument': 1397, 'correct': 1398, 'pairs': 1399, 'women': 1400, 'unit': 1401, 'applied': 1402, 'unifying': 1403, 'smoothing': 1404, 'area': 1405, '3': 1406, 'd': 1407, 'prover': 1408, 'face': 1409, 'de': 1410, 'names': 1411, 'contexts': 1412, 'numeric': 1413, 'subsequence': 1414, 'inducing': 1415, 'block': 1416, 'work': 1417, 'maps': 1418, 'exact': 1419, 'processors': 1420, 'defined': 1421, 'analytical': 1422, 'infrastructure': 1423, 'authority': 1424, 'session': 1425, 'well': 1426, 'aggregates': 1427, 'pair': 1428, 'bias': 1429, 'signatures': 1430, 'modularity': 1431, 'reusable': 1432, 'year': 1433, 'walks': 1434, 'pairwise': 1435, 'opportunities': 1436, 'instances': 1437, 'commit': 1438, 'competitive': 1439, 'branch': 1440, 'affective': 1441, 'secondary': 1442, 'failures': 1443, 'second': 1444, 'centric': 1445, 'gram': 1446, 'walk': 1447, 'bi': 1448, '2': 1449, 'analyses': 1450, 'improvement': 1451, 'expectation': 1452, 'separation': 1453, 'concerns': 1454, 'contents': 1455, 'explanations': 1456, 'success': 1457, 'accessing': 1458, 'batch': 1459, 'four': 1460, 'dominance': 1461, 'route': 1462, 'useful': 1463, 'characterizing': 1464, 'refining': 1465, 'speculative': 1466, 'combined': 1467, 'compressing': 1468, 'formulation': 1469, 'attention': 1470, 'coarse': 1471, 'lists': 1472, 'sum': 1473, 'applicative': 1474, 'imprecise': 1475, 'mental': 1476, 'directional': 1477, 'organizational': 1478, 'existing': 1479, 'contract': 1480, 'current': 1481, 'sorting': 1482, 'suite': 1483, 'position': 1484, 'derived': 1485, 'teachers': 1486, 'iteration': 1487, 'relaxed': 1488, 'enough': 1489, 'there': 1490, 'unknown': 1491, 'boundaries': 1492, 'rates': 1493, 'cooperating': 1494, 'repositories': 1495, 'short': 1496, 'decisions': 1497, 'costs': 1498, 'controlling': 1499, 'ambiguous': 1500, 'almost': 1501, 'parallelization': 1502, 'integer': 1503, 'viewing': 1504, 'lecture': 1505, 'benefits': 1506, 'defaults': 1507, 'diagnostic': 1508, 'prosodic': 1509, 'template': 1510, 'asynchronous': 1511, 'optimistic': 1512, 'dont': 1513, 'subtyping': 1514, 'assignments': 1515, 'manager': 1516, 'rfid': 1517, 'considerations': 1518, 'parsers': 1519, 'multiclass': 1520, 'tradeoffs': 1521, 'read': 1522, 'nonparametric': 1523, 'poisson': 1524, 'svms': 1525, 'predictions': 1526, 'portable': 1527, 'french': 1528, 'desktop': 1529, 'likelihood': 1530, 'risk': 1531, 'augmented': 1532, 'informed': 1533, 'family': 1534, 'balanced': 1535, 'experimentation': 1536, 'roles': 1537, 'where': 1538, 'nets': 1539, 'dissemination': 1540, 'twig': 1541, 'investigating': 1542, 'interest': 1543, 'lattice': 1544, 'csps': 1545, 'mathematical': 1546, 'scope': 1547, 'extracted': 1548, 'subgraphs': 1549, 'annotated': 1550, 'arbitrary': 1551, 'bidding': 1552, 'io': 1553, 'subjectivity': 1554, 'realistic': 1555, 'conversational': 1556, 'remote': 1557, 'dealing': 1558, 'stage': 1559, 'alias': 1560, 'workflows': 1561, 'ground': 1562, 'mode': 1563, 'serial': 1564, 'coupling': 1565, 'needs': 1566, 'pc': 1567, 'lines': 1568, 'stories': 1569, 'frameworks': 1570, 'cs1cs2': 1571, 'laboratories': 1572, 'mappings': 1573, 'partition': 1574, 'reformulation': 1575, 'sensing': 1576, 'workload': 1577, 'semistructured': 1578, 'microarray': 1579, 'directions': 1580, 'coding': 1581, 'package': 1582, 'networked': 1583, 'decoding': 1584, 'scenarios': 1585, 'primitives': 1586, 'discussion': 1587, 'company': 1588, 'frames': 1589, 'synchronization': 1590, 'ubiquitous': 1591, 'specified': 1592, 'recognizing': 1593, 'performing': 1594, 'law': 1595, 'em': 1596, 'individual': 1597, 'choice': 1598, 'mechanical': 1599, 'channel': 1600, 'private': 1601, 'tags': 1602, 'focusing': 1603, 'synchronized': 1604, 'make': 1605, 'treatment': 1606, 'observation': 1607, 'controlled': 1608, 'templates': 1609, 'granularity': 1610, 'cases': 1611, 'optimality': 1612, 'optimizers': 1613, 'approximating': 1614, 'notes': 1615, 'inputs': 1616, 'hot': 1617, 'failure': 1618, 'formalization': 1619, 'paraphrasing': 1620, 'blogs': 1621, 'operator': 1622, 'physics': 1623, 'oodb': 1624, 'note': 1625, 'prioritized': 1626, 'differences': 1627, 'breadth': 1628, 'regular': 1629, 'enabling': 1630, 'arguments': 1631, 'threshold': 1632, 'quantifier': 1633, 'choices': 1634, 'bidirectional': 1635, 'charts': 1636, 'total': 1637, 'arc': 1638, 'sensors': 1639, 'light': 1640, 'eliminating': 1641, 'transducers': 1642, 'symmetry': 1643, 'reporting': 1644, 'thematic': 1645, 'alternatives': 1646, 'functionality': 1647, 'statements': 1648, 'financial': 1649, 'fair': 1650, 'collocations': 1651, 'communications': 1652, 'but': 1653, 'replacement': 1654, 'circuits': 1655, 'bag': 1656, 'analytic': 1657, 'adaptable': 1658, 'monolingual': 1659, 'assurance': 1660, 'filters': 1661, 'basic': 1662, 'both': 1663, 'write': 1664, 'computations': 1665, 'coupled': 1666, 'compound': 1667, 'intention': 1668, 'polymorphism': 1669, 'worlds': 1670, 'tier': 1671, 'factors': 1672, 'standards': 1673, 'scoring': 1674, 'arts': 1675, 'materialization': 1676, 'behavioral': 1677, 'dominant': 1678, 'updating': 1679, 'expressing': 1680, 'utilizing': 1681, 'factor': 1682, 'characters': 1683, 'parameters': 1684, 'modern': 1685, 'lambek': 1686, 'directory': 1687, 'collaboration': 1688, 'loosely': 1689, 'difficult': 1690, 'assisted': 1691, 'playing': 1692, 'adoption': 1693, 'formalisms': 1694, 'module': 1695, 'constituent': 1696, 'public': 1697, 'smart': 1698, 'globally': 1699, 'urls': 1700, 'advice': 1701, 'transport': 1702, 'visually': 1703, 'placement': 1704, 'reconstruction': 1705, 'strongly': 1706, 'tutoring': 1707, 'player': 1708, 'post': 1709, 'hypothesis': 1710, 'micro': 1711, 'delayed': 1712, 'few': 1713, 'pass': 1714, 'methodologies': 1715, 'collective': 1716, 'linking': 1717, 'geographic': 1718, 'timed': 1719, 'race': 1720, 'candidate': 1721, 'strategic': 1722, 'something': 1723, 'observable': 1724, 'fundamental': 1725, 'bit': 1726, 'most': 1727, 'restrictions': 1728, 'click': 1729, 'regions': 1730, 'mutual': 1731, 'searches': 1732, 'synopses': 1733, 'foundation': 1734, 'technical': 1735, 'meanings': 1736, 'robotic': 1737, 'modified': 1738, 'keyphrase': 1739, 'display': 1740, 'settings': 1741, 'axiomatic': 1742, 'verifying': 1743, 'p': 1744, 'recommender': 1745, 'cyclic': 1746, 'taking': 1747, 'ability': 1748, 'augmenting': 1749, 'behaviour': 1750, 'hand': 1751, 'robotics': 1752, 'entailment': 1753, 'multivariate': 1754, 'multithreaded': 1755, 'theorems': 1756, 'restricted': 1757, 'additive': 1758, 'breaking': 1759, 'trade': 1760, 'validating': 1761, 'assembly': 1762, 'labs': 1763, 'grouping': 1764, 'connected': 1765, 'teams': 1766, 'many': 1767, 'backtracking': 1768, 'sketch': 1769, 'recent': 1770, 'price': 1771, 'phrasal': 1772, 'conditions': 1773, 'nonnegative': 1774, 'panel': 1775, 'q': 1776, 'resolving': 1777, 'discrimination': 1778, 'dialog': 1779, 'snapshot': 1780, 'analogical': 1781, 'semantically': 1782, 'petri': 1783, 'consensus': 1784, 'histogram': 1785, 'weight': 1786, 'publishing': 1787, 'ahead': 1788, 'past': 1789, 'revealing': 1790, 'response': 1791, 'abductive': 1792, 'codes': 1793, 'clauses': 1794, 'repository': 1795, 'nondeterministic': 1796, 'generators': 1797, 'node': 1798, 'induced': 1799, 'healthcare': 1800, 'distributing': 1801, 'really': 1802, 'arrays': 1803, 'bug': 1804, 'collector': 1805, 'live': 1806, 'gpsg': 1807, 'explaining': 1808, 'eye': 1809, 'pointers': 1810, 'priors': 1811, 'containment': 1812, 'versioning': 1813, 'auction': 1814, 'false': 1815, 'whole': 1816, 'taxonomies': 1817, 'should': 1818, 'javascript': 1819, 'courseware': 1820, 'pedagogy': 1821, 'typing': 1822, 'messages': 1823, 'left': 1824, 'temporally': 1825, 'interoperable': 1826, 'alpha': 1827, 'conjunctive': 1828, 'rankings': 1829, 'terminology': 1830, 'publishsubscribe': 1831, 'factored': 1832, 'activation': 1833, 'documentation': 1834, 'slicing': 1835, 'winner': 1836, 'rdbms': 1837, 'diversity': 1838, 'forecasting': 1839, 'made': 1840, 'chemical': 1841, 'suggestion': 1842, 'multilevel': 1843, 'deduction': 1844, 'cues': 1845, 'api': 1846, 'pca': 1847, 'disks': 1848, 'equilibria': 1849, 'flash': 1850, 'preservation': 1851, 'accessibility': 1852, 'repairs': 1853, 'character': 1854, 'special': 1855, 'walking': 1856, 'strictness': 1857, 'liberal': 1858, 'rewrite': 1859, 'solve': 1860, 'wise': 1861, 'completion': 1862, 'if': 1863, 'equations': 1864, 'website': 1865, 'mapreduce': 1866, 'satisfying': 1867, 'greedy': 1868, 'biology': 1869, 'minimax': 1870, 'prefetching': 1871, 'achieving': 1872, 'anaphoric': 1873, 'editors': 1874, 's': 1875, 'monte': 1876, 'carlo': 1877, 'x': 1878, 'anomalies': 1879, 'producing': 1880, 'party': 1881, 'definite': 1882, 'sponsored': 1883, 'manufacturing': 1884, 'ontological': 1885, 'elements': 1886, 'stability': 1887, 'comments': 1888, 'lda': 1889, 'smalltalk': 1890, 'column': 1891, 'count': 1892, 'defect': 1893, 'maximizing': 1894, 'metasearch': 1895, 'geo': 1896, 'automotive': 1897, 'diffusion': 1898, 'stored': 1899, 'reports': 1900, 'subject': 1901, 'predictors': 1902, 'contention': 1903, 'reduce': 1904, 'scene': 1905, 'rich': 1906, 'navigational': 1907, 'la': 1908, 'executing': 1909, 'requirement': 1910, 'rational': 1911, 'simulations': 1912, 'so': 1913, 'switching': 1914, 'seminar': 1915, 'threads': 1916, 'constructed': 1917, 'spelling': 1918, 'idea': 1919, 'seed': 1920, 'rare': 1921, 'college': 1922, 'vehicle': 1923, 'another': 1924, 'loading': 1925, 'organized': 1926, 'skew': 1927, 'correspondences': 1928, 'microsoft': 1929, 'wordnet': 1930, 'significant': 1931, 'visualisation': 1932, 'trends': 1933, 'trace': 1934, 'nominal': 1935, 'synthesizing': 1936, 'coherent': 1937, 'terminological': 1938, 'fact': 1939, 'improvements': 1940, 'migration': 1941, 'transformational': 1942, 'ellipsis': 1943, 'citation': 1944, 'quantification': 1945, 'instructional': 1946, 'government': 1947, 'adjectives': 1948, 'searchers': 1949, 'retrieving': 1950, 'capstone': 1951, 'exchange': 1952, 'crawler': 1953, 'wrapper': 1954, 'specialization': 1955, 'possible': 1956, 'containing': 1957, 'imperfect': 1958, 'concrete': 1959, 'delivery': 1960, 'protecting': 1961, 'horizontal': 1962, 'fragments': 1963, 'iterated': 1964, 'learners': 1965, 'directories': 1966, 'industry': 1967, 'distances': 1968, 'instant': 1969, 'linkage': 1970, 'surface': 1971, 'numerical': 1972, 'indexed': 1973, 'facts': 1974, 'shift': 1975, 'facilitate': 1976, 'denotational': 1977, 'inverse': 1978, 'descent': 1979, 'lasso': 1980, 'guarantees': 1981, '2001': 1982, 'chain': 1983, 'status': 1984, 'studying': 1985, 'transform': 1986, 'edit': 1987, 'perspectives': 1988, 'oltp': 1989, 'individuals': 1990, 'comparable': 1991, 'aided': 1992, 'bad': 1993, '20': 1994, 'everyone': 1995, 'friendly': 1996, 'trec': 1997, 'signal': 1998, 'correlated': 1999, 'literature': 2000, 'regularized': 2001, 'holistic': 2002, 'multidatabases': 2003, 'regret': 2004, 'background': 2005, 'cleaning': 2006, 'skill': 2007, 'intensional': 2008, 'simplified': 2009, 'command': 2010, 'years': 2011, 'piecewise': 2012, 'build': 2013, 'advances': 2014, 'encodings': 2015, 'layered': 2016, 'dimensions': 2017, 'proper': 2018, 'portals': 2019, 'cooperation': 2020, 'decentralized': 2021, 'auxiliary': 2022, 'edges': 2023, 'flat': 2024, 'perceptron': 2025, 'prevention': 2026, 'seeking': 2027, 'capability': 2028, 'extreme': 2029, 'poker': 2030, 'novice': 2031, 'hmm': 2032, 'pronoun': 2033, 'unix': 2034, 'next': 2035, 'audio': 2036, 'mind': 2037, 'decompositions': 2038, 'extensibility': 2039, 'assistance': 2040, 'intermediate': 2041, 'correlations': 2042, 'manifold': 2043, 'estimate': 2044, 'anchor': 2045, 'atomic': 2046, 'maximization': 2047, 'treebank': 2048, 'merge': 2049, 'smt': 2050, 'google': 2051, 'suffix': 2052, 'combinatory': 2053, 'inconsistent': 2054, 'retention': 2055, 'weakly': 2056, 'convergence': 2057, 'symmetric': 2058, 'objective': 2059, 'keys': 2060, 'differential': 2061, 'division': 2062, 'covering': 2063, 'any': 2064, 'they': 2065, 'coloring': 2066, 'opinions': 2067, 'grams': 2068, 'sms': 2069, 'declustering': 2070, 'macro': 2071, 'shortest': 2072, 'utilization': 2073, 'knn': 2074, 'interdisciplinary': 2075, 'tape': 2076, 'ssa': 2077, 'phi': 2078, 'harmful': 2079, 'double': 2080, 'parsed': 2081, 'hypergraph': 2082, 'corner': 2083, 'segments': 2084, 'inferencing': 2085, 'chains': 2086, 'lfg': 2087, 'expensive': 2088, 'intended': 2089, 'informational': 2090, 'clinical': 2091, 'tagged': 2092, 'examination': 2093, '2003': 2094, 'neutral': 2095, 'degree': 2096, 'expressiveness': 2097, 'weights': 2098, 'argumentative': 2099, 'massively': 2100, 'referring': 2101, 'beta': 2102, 'faceted': 2103, 'detect': 2104, 'overlay': 2105, 'selecting': 2106, 'locating': 2107, 'rapid': 2108, 'copy': 2109, 'readers': 2110, 'paraphrases': 2111, 'transforms': 2112, 'optimize': 2113, 'integrate': 2114, 'loss': 2115, 'ciphers': 2116, 'stack': 2117, 'last': 2118, 'blackboard': 2119, 'nash': 2120, 'mediation': 2121, 'cut': 2122, 'pure': 2123, 'mean': 2124, 'flickr': 2125, 'faults': 2126, 'gaps': 2127, 'issue': 2128, 'patent': 2129, 'exploratory': 2130, 'abduction': 2131, 'recurrent': 2132, 'major': 2133, 'traditional': 2134, 'show': 2135, 'accesses': 2136, 'constituency': 2137, 'ode': 2138, 'facilitating': 2139, 'us': 2140, 'ecommerce': 2141, 'hiding': 2142, 'sales': 2143, 'popular': 2144, 'bioinformatics': 2145, 'automation': 2146, 'snippet': 2147, 'drift': 2148, 'multiversion': 2149, 'device': 2150, 'extract': 2151, 'editing': 2152, 'fifteen': 2153, 'compilers': 2154, 'productivity': 2155, 'rating': 2156, 'transductive': 2157, 'notion': 2158, 'bulk': 2159, 'population': 2160, 'interests': 2161, 'resident': 2162, 'orthogonal': 2163, 'curse': 2164, 'gui': 2165, 'conformant': 2166, 'bibliography': 2167, 'spatiotemporal': 2168, 'art': 2169, 'autonomic': 2170, 'trading': 2171, 'cs0': 2172, 'disjunctions': 2173, 'testbed': 2174, 'neighbour': 2175, 'meaningful': 2176, 'numbers': 2177, 'messaging': 2178, 'relating': 2179, 'linguistically': 2180, 'connecting': 2181, 'too': 2182, 'lexicons': 2183, 'geographical': 2184, 'subexpressions': 2185, 'reusability': 2186, 'replica': 2187, 'defining': 2188, 'intranet': 2189, 'root': 2190, 'm': 2191, 'exponential': 2192, 'while': 2193, 'helping': 2194, 'see': 2195, 'lexicalization': 2196, 'injection': 2197, 'stationary': 2198, 'horn': 2199, 'multiparty': 2200, 'conversation': 2201, 'matrices': 2202, 'provide': 2203, 'atms': 2204, 'pronunciation': 2205, 'indefinite': 2206, 'brief': 2207, 'exercise': 2208, 'grain': 2209, 'triggers': 2210, 'traversal': 2211, 'interpretations': 2212, 'hypergraphs': 2213, 'hpsg': 2214, 'webpage': 2215, 'discovered': 2216, 'mu': 2217, 'anatomy': 2218, 'vague': 2219, 'mutation': 2220, 'commodity': 2221, 'flows': 2222, 'morpheme': 2223, 'board': 2224, 'must': 2225, 'mobility': 2226, 'measurements': 2227, 'going': 2228, 'negation': 2229, 'supported': 2230, 'pipelined': 2231, 'earth': 2232, 'algebras': 2233, 'addressing': 2234, 'optical': 2235, 'prototypes': 2236, 'star': 2237, 'permutation': 2238, 'proxy': 2239, 'criterion': 2240, 'encryption': 2241, 'sensitivity': 2242, 'cycles': 2243, 'fixpoint': 2244, 'freshness': 2245, 'hypermedia': 2246, 'presentations': 2247, 'filling': 2248, 'changing': 2249, 'products': 2250, 'pascal': 2251, 'ill': 2252, 'gain': 2253, 'wavelet': 2254, 'exceptions': 2255, 'reengineering': 2256, 'gender': 2257, 'acyclic': 2258, 'nl': 2259, 'marketing': 2260, 'pipeline': 2261, 'wavelets': 2262, 'decidable': 2263, 'analyze': 2264, 'author': 2265, 'essential': 2266, 'blocking': 2267, 'guarantee': 2268, 'f': 2269, 'screening': 2270, 'evaluate': 2271, 'evaluations': 2272, 'naive': 2273, 'shell': 2274, 'transduction': 2275, 'ansi': 2276, 'vectors': 2277, 'persistence': 2278, 'tokenization': 2279, 'blogosphere': 2280, 'compromise': 2281, 'sketching': 2282, 'turkish': 2283, 'attack': 2284, 'situations': 2285, 'tailoring': 2286, 'bootstrap': 2287, 'curve': 2288, 'grounded': 2289, 'clones': 2290, 'videos': 2291, 'traceability': 2292, 'humans': 2293, 'engineers': 2294, 'examining': 2295, 'agenda': 2296, 'summarizing': 2297, 'clusterings': 2298, 'verbal': 2299, 'entry': 2300, 'meaning': 2301, 'compatibility': 2302, 'concise': 2303, 'living': 2304, 'decoupling': 2305, 'big': 2306, 'wrapping': 2307, 'closing': 2308, 'invariant': 2309, 'picture': 2310, 'ie': 2311, 'analytics': 2312, '10': 2313, 'bounding': 2314, '3rd': 2315, 'me': 2316, 'powerful': 2317, 'quorum': 2318, 'neighbors': 2319, 'adding': 2320, 'collocation': 2321, 'viewpoint': 2322, 'classify': 2323, 'snippets': 2324, 'acm': 2325, 'initiative': 2326, 'promoting': 2327, 'which': 2328, 'diagnosing': 2329, 'splitting': 2330, 'tertiary': 2331, 'corporate': 2332, 'attitudes': 2333, 'skewed': 2334, 'intrusion': 2335, 'learner': 2336, 'reversible': 2337, 'relaxation': 2338, 'avoiding': 2339, 'aids': 2340, 'underlying': 2341, 'stores': 2342, 'distinguishing': 2343, 'authorship': 2344, 'boundary': 2345, 'codasyl': 2346, 'significance': 2347, 'acts': 2348, 'running': 2349, 'buffering': 2350, 'emotions': 2351, 'correcting': 2352, 'communicating': 2353, 'magic': 2354, 'surfaces': 2355, 'linguistics': 2356, 'protein': 2357, 'bid': 2358, 'refactoring': 2359, 'acquiring': 2360, 'clone': 2361, 'comprehensive': 2362, 'particle': 2363, 'people': 2364, 'attachment': 2365, 'periodic': 2366, 'subcategorization': 2367, 'transitions': 2368, 'constant': 2369, 'steps': 2370, 'forests': 2371, 'hypotheses': 2372, 'translations': 2373, 'enforcing': 2374, 'several': 2375, 'spectrum': 2376, 'invited': 2377, 'divide': 2378, 'yahoo': 2379, 'lower': 2380, 'store': 2381, 'tv': 2382, 'hands': 2383, 'have': 2384, 'scenes': 2385, 'mdl': 2386, 'aggressive': 2387, 'reason': 2388, 'departments': 2389, 'lambda': 2390, 'diagram': 2391, 'catalogs': 2392, 'grounding': 2393, 'passage': 2394, 'qa': 2395, 'nmf': 2396, 'represent': 2397, 'assumptions': 2398, 'phenomena': 2399, 'dl': 2400, 'phonological': 2401, 'workloads': 2402, 'lectures': 2403, 'speeding': 2404, 'assistants': 2405, 'grids': 2406, 'retrospective': 2407, 'composing': 2408, 'linked': 2409, 'sizes': 2410, 'overlapping': 2411, 'article': 2412, 'handle': 2413, 'aid': 2414, 'handwriting': 2415, 'randomization': 2416, 'variance': 2417, 'cultural': 2418, 'miner': 2419, 'likely': 2420, 'whats': 2421, 'equality': 2422, 'tensor': 2423, 'descriptive': 2424, 'force': 2425, 'preconditions': 2426, 'vote': 2427, 'situated': 2428, 'item': 2429, 'assigning': 2430, 'interpreting': 2431, 'capture': 2432, 'outputs': 2433, 'simplifying': 2434, 'passive': 2435, 'discussions': 2436, 'movements': 2437, 'scoping': 2438, 'computable': 2439, 'statistic': 2440, 'establishing': 2441, 'anonymizing': 2442, 'push': 2443, 'bitmap': 2444, 'proposed': 2445, 'scalar': 2446, 'outerjoins': 2447, 'troubleshooting': 2448, 'mass': 2449, 'stemming': 2450, 'principal': 2451, 'sky': 2452, 'accessible': 2453, 'hindsight': 2454, 'consequence': 2455, 'drt': 2456, 'simd': 2457, 'patient': 2458, 'lego': 2459, 'polarity': 2460, 'graded': 2461, 'fluents': 2462, 'sciences': 2463, 'day': 2464, 'currency': 2465, 'divergence': 2466, 'variant': 2467, 'controls': 2468, 'taxonomic': 2469, 'pictures': 2470, 'bio': 2471, 'spreading': 2472, 'abandonment': 2473, 'inferences': 2474, 'jump': 2475, 'story': 2476, 'emotion': 2477, 'elections': 2478, 'novices': 2479, 'reusing': 2480, 'mixtures': 2481, 'spammers': 2482, 'taught': 2483, 'coherency': 2484, 'setting': 2485, 'duplication': 2486, 'weaving': 2487, 'concert': 2488, 'reconstructing': 2489, 'incrementality': 2490, 'ideal': 2491, 'present': 2492, 'release': 2493, 'same': 2494, 'deviation': 2495, 'tsimmis': 2496, 'skylines': 2497, 'continual': 2498, 'unrestricted': 2499, 'boltzmann': 2500, 'ebl': 2501, 'forgetting': 2502, 'adversarial': 2503, 'referential': 2504, 'squares': 2505, 'editor': 2506, 'thread': 2507, 'starburst': 2508, 'discontinuous': 2509, 'elaboration': 2510, 'bytecode': 2511, 'notions': 2512, 'tcp': 2513, 'postgres': 2514, 'pi': 2515, 'providers': 2516, 'clouds': 2517, 'identity': 2518, 'detailed': 2519, 'important': 2520, 'imperative': 2521, 'ocr': 2522, 'nodes': 2523, 'associated': 2524, 'encyclopedia': 2525, 'fragment': 2526, 'contest': 2527, 'summer': 2528, 'substitution': 2529, 'centering': 2530, 'focal': 2531, 'works': 2532, 'principled': 2533, 'subqueries': 2534, 'element': 2535, 'nn': 2536, 'samples': 2537, 'connectionist': 2538, 'topology': 2539, 'visibility': 2540, 'cumulative': 2541, 'transducer': 2542, 'exclusive': 2543, 'manage': 2544, 'fly': 2545, 'intrusions': 2546, 'viewpoints': 2547, 'phonology': 2548, 'andor': 2549, 'refined': 2550, 'lite': 2551, 'factory': 2552, 'pronominal': 2553, 'soccer': 2554, 'edits': 2555, 'far': 2556, 'mandarin': 2557, 'clues': 2558, 'stemmer': 2559, 'provably': 2560, 'chunks': 2561, 'tough': 2562, 'tuples': 2563, 'tagger': 2564, '10g': 2565, 'interpreters': 2566, 'potential': 2567, 'attribution': 2568, 'treewidth': 2569, 'customizable': 2570, 'onto': 2571, 'choosing': 2572, 'syntactically': 2573, 'substring': 2574, 'mediators': 2575, 'characterizations': 2576, 'getting': 2577, 'schools': 2578, 'overcoming': 2579, 'deployment': 2580, 'much': 2581, 'reduced': 2582, 'cp': 2583, 'localized': 2584, 'movie': 2585, 'prepositional': 2586, 'hp': 2587, 'opportunity': 2588, 'sorted': 2589, 'nonmyopic': 2590, 'demo': 2591, 'heterogenous': 2592, 'manual': 2593, 'simpler': 2594, 'elementary': 2595, 'barrier': 2596, 'insurance': 2597, 'variation': 2598, 'pitch': 2599, 'contrast': 2600, 'des': 2601, 'sub': 2602, 'counts': 2603, 'envy': 2604, 'goods': 2605, 'customization': 2606, 'emergent': 2607, 'executable': 2608, 'conservative': 2609, 'tunable': 2610, 'gis': 2611, 'recurrence': 2612, 'humor': 2613, 'agnostic': 2614, 'molecular': 2615, 'including': 2616, 'tracing': 2617, 'mls': 2618, 'certifying': 2619, 'inversion': 2620, 'century': 2621, 'identify': 2622, 'causes': 2623, '12': 2624, 'this': 2625, 'orders': 2626, 'variety': 2627, 'verbose': 2628, 'job': 2629, 'intersection': 2630, 'segmenting': 2631, 'goes': 2632, 'locally': 2633, 'nothing': 2634, 'quickly': 2635, 'hierarchically': 2636, 'durations': 2637, 'lab': 2638, 'compliance': 2639, 'together': 2640, 'intractable': 2641, 'cloning': 2642, 'envelope': 2643, '2000': 2644, 'senses': 2645, 'developers': 2646, 'exploitation': 2647, 'act': 2648, 'robocup': 2649, 'color': 2650, 'axioms': 2651, 'imitation': 2652, 'play': 2653, 'packing': 2654, 'formed': 2655, 'tabular': 2656, 'scores': 2657, 'lookahead': 2658, 'suites': 2659, 'exactly': 2660, 'layer': 2661, 'stopping': 2662, 'exhaustive': 2663, 'icse': 2664, 'cognition': 2665, 'ordinal': 2666, 'feasibility': 2667, 'units': 2668, 'equivalent': 2669, 'bandit': 2670, 'designed': 2671, 'distributional': 2672, 'coordinating': 2673, 'request': 2674, 'indirect': 2675, 'legal': 2676, 'enhancements': 2677, 'staged': 2678, 'traces': 2679, 'shopping': 2680, 'purchase': 2681, 'bugs': 2682, 'adjusting': 2683, 'property': 2684, 'monitor': 2685, 'vlsi': 2686, 'restarts': 2687, 'defeasible': 2688, 'subspaces': 2689, 'proposal': 2690, 'average': 2691, 'will': 2692, 'versatile': 2693, 'characteristics': 2694, 'preprocessing': 2695, 'transmission': 2696, 'continuation': 2697, 'propagating': 2698, 'combinations': 2699, 'db': 2700, 'projective': 2701, 'epsilon': 2702, 'derive': 2703, 'notation': 2704, 'defense': 2705, 'permission': 2706, 'combine': 2707, 'sliding': 2708, 'exodus': 2709, 'super': 2710, 'compressor': 2711, 'distinct': 2712, 'multiset': 2713, 'exploits': 2714, 'crash': 2715, 'checkpointing': 2716, 'continuations': 2717, 'alignments': 2718, 'promises': 2719, 'admissible': 2720, 'dependability': 2721, 'portal': 2722, 'terminologies': 2723, 'memories': 2724, 'priorities': 2725, 'null': 2726, 'o2': 2727, 'labels': 2728, 'scheduler': 2729, 'blogging': 2730, 'ads': 2731, 'aerial': 2732, 'tune': 2733, 'deictic': 2734, 'gestures': 2735, 'optimum': 2736, 'incrementally': 2737, 'factoring': 2738, 'salience': 2739, 'accreditation': 2740, 'scenario': 2741, 'stop': 2742, 'estimators': 2743, 'used': 2744, 'pilot': 2745, 'fourier': 2746, 'aligned': 2747, 'webdav': 2748, 'contracts': 2749, 'compare': 2750, 'branching': 2751, 'conflicts': 2752, 'quadratic': 2753, 'cheap': 2754, 'creative': 2755, 'pool': 2756, 'equivalents': 2757, 'haystack': 2758, 'sharable': 2759, 'keywords': 2760, 'checker': 2761, 'ugly': 2762, 'interactivity': 2763, 'nsf': 2764, 'funding': 2765, 'posterior': 2766, 'nasa': 2767, 'environmental': 2768, 'consumer': 2769, 'correspondence': 2770, 'math': 2771, 'rigorous': 2772, 'pipelining': 2773, 'typical': 2774, 'accelerated': 2775, 'backup': 2776, 'philosophy': 2777, 'sequencing': 2778, 'participation': 2779, 'interlingual': 2780, 'square': 2781, 'hyper': 2782, 'growth': 2783, 'morpho': 2784, 'analyser': 2785, 'succinct': 2786, 'hit': 2787, 'recognize': 2788, 'given': 2789, 'ajax': 2790, 'cryptographically': 2791, 'era': 2792, 'risc': 2793, 'mail': 2794, 'built': 2795, 'optimally': 2796, 'implicatures': 2797, 'identifiers': 2798, 'clustered': 2799, 'bipartite': 2800, 'haplotype': 2801, 'thought': 2802, 'quantile': 2803, 'annotating': 2804, 'million': 2805, 'bank': 2806, 'discontinuities': 2807, 'narratives': 2808, 'developer': 2809, 'mashup': 2810, 'hypertree': 2811, 'third': 2812, 'fundamentals': 2813, 'valid': 2814, 'assertion': 2815, 'delivering': 2816, 'overload': 2817, 'estimates': 2818, 'broadening': 2819, 'categorisation': 2820, 'difficulty': 2821, 'tests': 2822, 'verbs': 2823, 'script': 2824, 'title': 2825, 'effectively': 2826, 'hits': 2827, 'minimizing': 2828, 'camera': 2829, 'pushing': 2830, 'chunking': 2831, 'dense': 2832, 'subsumption': 2833, 'telecommunication': 2834, 'insight': 2835, 'configuring': 2836, 'versioned': 2837, 'date': 2838, 'conjunctions': 2839, 'conference': 2840, 'translate': 2841, 'utterances': 2842, 'atomicity': 2843, 'exception': 2844, 'talk': 2845, 'normalizing': 2846, 'compiled': 2847, 'fractal': 2848, 'vehicles': 2849, 'puzzle': 2850, 'benefit': 2851, 'reachability': 2852, 'episodes': 2853, 'aliasing': 2854, 'give': 2855, 'child': 2856, 'ambiguities': 2857, 'enabled': 2858, 'rue': 2859, '2008': 2860, 'recovering': 2861, 'spacecraft': 2862, 'syllable': 2863, 'achieve': 2864, 'closures': 2865, 'culture': 2866, 'encapsulation': 2867, 'readability': 2868, 'available': 2869, 'generalised': 2870, 'ccg': 2871, 'parallelizing': 2872, 'constructions': 2873, 'substructure': 2874, 'distillation': 2875, 'statically': 2876, 'resistant': 2877, 'schedules': 2878, 'spin': 2879, 'philosophers': 2880, 'heap': 2881, 'pervasive': 2882, 'securing': 2883, 'enumeration': 2884, 'turning': 2885, 'bed': 2886, 'encoding': 2887, 'recommending': 2888, 'travel': 2889, 'packages': 2890, 'various': 2891, 'place': 2892, 'mediator': 2893, 'certification': 2894, 'irrelevance': 2895, 'popularity': 2896, 'auto': 2897, 'bdds': 2898, 'learnability': 2899, 'odmg': 2900, 'naming': 2901, 'every': 2902, 'ease': 2903, 'multiplication': 2904, 'anomalous': 2905, 'russian': 2906, 'guessing': 2907, 'segment': 2908, 'covariance': 2909, 'ownership': 2910, 'bottleneck': 2911, 'markers': 2912, 'advantages': 2913, 'graduate': 2914, 'hci': 2915, 'motivated': 2916, 'angle': 2917, 'bin': 2918, 'cipher': 2919, 'get': 2920, 'populated': 2921, 'o': 2922, 'lifecycle': 2923, 'heterogeneity': 2924, 'basket': 2925, 'trip': 2926, 'revisiting': 2927, 'treating': 2928, 'propositions': 2929, 'brokering': 2930, 'decade': 2931, 'connection': 2932, 'wild': 2933, 'internal': 2934, 'pdas': 2935, 'construct': 2936, 'coalition': 2937, 'turing': 2938, 'closest': 2939, 'priority': 2940, 'acquired': 2941, 'authoring': 2942, 'lifetime': 2943, 'infer': 2944, 'puzzles': 2945, 'hindi': 2946, 'illinois': 2947, 'sessions': 2948, 'volume': 2949, '99': 2950, 'haskell': 2951, 'keyframe': 2952, 'constructs': 2953, 'iii': 2954, 'folksonomy': 2955, 'comparisons': 2956, 'bagging': 2957, 'accurately': 2958, 'reclamation': 2959, 'displays': 2960, 'novelty': 2961, 'national': 2962, 'trend': 2963, 'autoepistemic': 2964, 'overlap': 2965, 'multifaceted': 2966, 'meeting': 2967, 'coefficient': 2968, 'transforming': 2969, 'perfect': 2970, 'reputation': 2971, 'intervals': 2972, 'locations': 2973, 'equational': 2974, 'fixed': 2975, 'cryptography': 2976, 'interrelated': 2977, 'expectations': 2978, 'literacy': 2979, 't': 2980, 'fitting': 2981, 'du': 2982, 'primary': 2983, 'convolution': 2984, 'trails': 2985, 'exist': 2986, 'threaded': 2987, 'dag': 2988, 'erp': 2989, 'baseline': 2990, 'datr': 2991, 'adapted': 2992, 'island': 2993, 'commonsense': 2994, 'motivation': 2995, 'overhead': 2996, 'positions': 2997, 'freshman': 2998, 'singular': 2999, 'follow': 3000, 'rationale': 3001, 'promotion': 3002, 'freely': 3003, 'aqua': 3004, 'redescription': 3005, 'projected': 3006, 'reconfigurable': 3007, 'economics': 3008, 'parsimonious': 3009, 'positives': 3010, 'salsa': 3011, 'scientists': 3012, 'superoptimizer': 3013, 'lsh': 3014, 'grace': 3015, 'strength': 3016, 'classic': 3017, 'mindstorms': 3018, 'disaster': 3019, 'american': 3020, 'him': 3021, 'broadcasts': 3022, 'aqualogic': 3023, 'backjumping': 3024, 'varying': 3025, 'ria': 3026, 'ap': 3027, 'ndcg': 3028, 'calendar': 3029, 'pushdown': 3030, 'clique': 3031, 'letting': 3032, 'cat': 3033, 'say': 3034, 'defects': 3035, 'eufid': 3036, 'again': 3037, 'after': 3038, 'kernelized': 3039, 'w3qs': 3040, 'survivability': 3041, 'accounting': 3042, 'dataspaces': 3043, 'inspired': 3044, 'tutors': 3045, 'health': 3046, 'abnormal': 3047, 'interestingness': 3048, 'emotional': 3049, 'pronouns': 3050, 'echo': 3051, 'anticipating': 3052, 'harmonic': 3053, 'variational': 3054, 'ibm': 3055, 'asymmetric': 3056, 'decomposing': 3057, 'outsourcing': 3058, 'fixpoints': 3059, 'firing': 3060, 'coalitions': 3061, 'pragmatics': 3062, 'macros': 3063, 'dataspace': 3064, 'exponentially': 3065, 'animations': 3066, 'sift': 3067, 'similarities': 3068, 'oo': 3069, 'enhancement': 3070, 'hilbert': 3071, 'fractals': 3072, 'mosaic': 3073, 'mark': 3074, 'provision': 3075, 'mid': 3076, 'queueing': 3077, 'subtypes': 3078, 'optimisation': 3079, 'respond': 3080, 'performances': 3081, 'telegraph': 3082, 'smooth': 3083, 'payment': 3084, 'repairing': 3085, 'dls': 3086, 'analysing': 3087, 'summarisation': 3088, 'schemasql': 3089, 'guest': 3090, 'skip': 3091, 'cosine': 3092, 'judgements': 3093, 'worst': 3094, 'care': 3095, 'cpu': 3096, 'orchestra': 3097, 'unusual': 3098, 'terabyte': 3099, 'sized': 3100, 'feed': 3101, 'formally': 3102, 'interpreted': 3103, 'epistemic': 3104, 'infrastructures': 3105, 'agree': 3106, 'identifiability': 3107, 'geographically': 3108, 'statistically': 3109, 'delta': 3110, 'duration': 3111, 'lookup': 3112, 'simplification': 3113, 'apply': 3114, 'catching': 3115, 'stride': 3116, 'department': 3117, 'thai': 3118, 'responses': 3119, 'before': 3120, 'ultra': 3121, 'dyadic': 3122, 'catalog': 3123, 'existential': 3124, 'intentional': 3125, 'satisfiable': 3126, 'connections': 3127, 'hyperlinked': 3128, 'handwritten': 3129, 'empty': 3130, 'anonymity': 3131, 'isomorphism': 3132, 'zoo': 3133, 'centrality': 3134, 'sketched': 3135, 'inspections': 3136, 'acceleration': 3137, 'snapshots': 3138, 'scaled': 3139, 'revised': 3140, 'cyc': 3141, 'implement': 3142, 'scalability': 3143, 'infosleuth': 3144, 'realising': 3145, 'syntactified': 3146, 'backwards': 3147, 'controllers': 3148, 'fairness': 3149, 'uniqueness': 3150, 'perceived': 3151, 'stock': 3152, 'misuse': 3153, 'combinator': 3154, 'duality': 3155, 'variability': 3156, 'budget': 3157, 'enforcement': 3158, 'plots': 3159, 'speculation': 3160, 'cover': 3161, 'violation': 3162, 'formulations': 3163, 'crawlers': 3164, 'diam': 3165, 'texture': 3166, 'gist': 3167, 'knowledgeable': 3168, 'per': 3169, 'fraud': 3170, 'affinity': 3171, 'acronym': 3172, 'credit': 3173, 'subgraph': 3174, '95': 3175, 'nuggets': 3176, 'sentential': 3177, 'trained': 3178, 'pearl': 3179, 'prefix': 3180, 'suspicious': 3181, 'observed': 3182, 'atoms': 3183, 'reconciling': 3184, 'requests': 3185, 'impaired': 3186, 'thumbs': 3187, 'compacting': 3188, 'diagnosability': 3189, '6': 3190, 'subsystem': 3191, 'scripting': 3192, 'leakage': 3193, 'quantiles': 3194, 'subjective': 3195, 'idiom': 3196, 'xprs': 3197, 'limits': 3198, 'semijoin': 3199, 'selections': 3200, 'gossiping': 3201, 'unnesting': 3202, 'member': 3203, 'devise': 3204, 'htn': 3205, 'dialect': 3206, 'maybe': 3207, 'section': 3208, 'actively': 3209, 'steroids': 3210, 'mention': 3211, 'maxent': 3212, 'reciprocal': 3213, 'connectivity': 3214, 'accents': 3215, 'suppressed': 3216, 'par': 3217, 'le': 3218, 'taken': 3219, 'dom': 3220, 'freeness': 3221, 'indivisible': 3222, 'mailing': 3223, 'mine': 3224, 'alc': 3225, 'ratio': 3226, 'degrees': 3227, 'freedom': 3228, 'sgml': 3229, 'immune': 3230, 'rasdaman': 3231, 'disambiguate': 3232, 'exemplar': 3233, 'collectors': 3234, 'disequilibrium': 3235, 'sloan': 3236, 'tighter': 3237, 'recency': 3238, 'oop': 3239, 'wave': 3240, 'discount': 3241, 'shapelets': 3242, 'interrupts': 3243, 'ddb': 3244, 'necessity': 3245, 'nature': 3246, 'logically': 3247, 'home': 3248, 'wallet': 3249, 'seemed': 3250, 'tumor': 3251, 'reaching': 3252, 'unsatisfiability': 3253, 'asymptotic': 3254, 'shallow': 3255, 'fix': 3256, 'delimited': 3257, 'heads': 3258, 'graduates': 3259, 'yet': 3260, 'auc': 3261, 'shapes': 3262, 'gradual': 3263, 'dilemma': 3264, 'add': 3265, 'competence': 3266, 'addition': 3267, 'studio': 3268, 'tying': 3269, 'subquery': 3270, 'avoidance': 3271, 'encyclopedic': 3272, 'disc': 3273, 'subtopic': 3274, 'fresh': 3275, 'interacting': 3276, 'marginal': 3277, 'coordinates': 3278, 'channels': 3279, 'drug': 3280, 'sequoia': 3281, 'prefer': 3282, 'observer': 3283, 'costly': 3284, 'explainable': 3285, 'tactical': 3286, 'skewing': 3287, 'storing': 3288, 'frontier': 3289, 'administration': 3290, 'compete': 3291, 'compile': 3292, 'subsumers': 3293, 'eportal': 3294, 'empirically': 3295, 'janus': 3296, 'archiving': 3297, 'hosting': 3298, 'centers': 3299, 'offering': 3300, 'verbmobil': 3301, 'coach': 3302, 'antlima': 3303, 'spreadsheets': 3304, 'autonomy': 3305, 'even': 3306, 'managers': 3307, 'paragraph': 3308, 'kronecker': 3309, 'burst': 3310, 'coping': 3311, 'those': 3312, 'cant': 3313, 'behavioural': 3314, 'justification': 3315, 'dominators': 3316, 'medicine': 3317, 'augmentation': 3318, 'banking': 3319, 'biologically': 3320, 'genes': 3321, 'markets': 3322, 'height': 3323, 'cougar': 3324, 'metonymy': 3325, 'developed': 3326, 'tutor': 3327, 'vp': 3328, 'adjustment': 3329, 'signals': 3330, 'pac': 3331, 'personality': 3332, 'cue': 3333, 'planners': 3334, 'swing': 3335, 'xtra': 3336, 'deletion': 3337, 'semidefinite': 3338, 'corba': 3339, 'wisdom': 3340, 'yield': 3341, 'differing': 3342, 'polyhedral': 3343, 'address': 3344, 'animate': 3345, 'yes': 3346, 'makes': 3347, 'advance': 3348, 'organizer': 3349, 'ltag': 3350, 'ephemeral': 3351, 'bisimulation': 3352, 'ambients': 3353, 'predicted': 3354, 'proportional': 3355, 'chance': 3356, 'advisor': 3357, '2005': 3358, 'wrap': 3359, 'externalities': 3360, 'psychology': 3361, 'portfolio': 3362, 'intellectual': 3363, 'basics': 3364, 'instructors': 3365, 'iceberg': 3366, 'delay': 3367, 'scripts': 3368, 'bridge': 3369, 'philosophical': 3370, 'reducible': 3371, 'modest': 3372, 'oss': 3373, 'encouraging': 3374, 'gmap': 3375, 'huge': 3376, 'select': 3377, 'blogscope': 3378, 'railroad': 3379, 'styles': 3380, 'vdm': 3381, 'strudel': 3382, 'eos': 3383, 'targeted': 3384, 'paradigmatic': 3385, 'mediated': 3386, 'timing': 3387, 'counterfactuals': 3388, 'bibliographic': 3389, 'roc': 3390, 'fragmentation': 3391, 'checkpoints': 3392, 'longevity': 3393, 'dbmss': 3394, 'limiting': 3395, 'preferred': 3396, 'dialectical': 3397, 'trajectory': 3398, 'unexpected': 3399, 'generality': 3400, 'chip': 3401, 'inflectional': 3402, 'platforms': 3403, 'multinomial': 3404, 'normalized': 3405, 'learnable': 3406, 'organize': 3407, 'associating': 3408, 'perceptions': 3409, 'paging': 3410, 'fetches': 3411, 'essence': 3412, 'investment': 3413, 'extensive': 3414, 'populations': 3415, 'inapplicable': 3416, 'introspection': 3417, 'disjunction': 3418, 'known': 3419, 'convergent': 3420, 'plsa': 3421, 'deepening': 3422, 'inexpensive': 3423, 'accelerating': 3424, 'factoid': 3425, 'observational': 3426, 'reasoners': 3427, 'magnetic': 3428, 'strictly': 3429, 'inlining': 3430, 'mcdb': 3431, 'modifying': 3432, 'intermittently': 3433, 'putting': 3434, 'scans': 3435, 'bandwidth': 3436, 'hints': 3437, 'informatics': 3438, 'written': 3439, 'conversations': 3440, 'backbones': 3441, 'backdoors': 3442, 'coordinate': 3443, 'jflap': 3444, 'tac': 3445, 'direction': 3446, 'atlas': 3447, 'authors': 3448, 'maze': 3449, 'targets': 3450, 'unfamiliar': 3451, 'clip': 3452, 'participants': 3453, 'lattices': 3454, 'determine': 3455, 'architecting': 3456, 'gesture': 3457, 'truncated': 3458, 'circular': 3459, 'sublanguage': 3460, 'incentive': 3461, 'synchronisation': 3462, 'damping': 3463, 'exclusion': 3464, 'phonemes': 3465, 'z': 3466, 'idlp': 3467, 'dnnf': 3468, 'relatively': 3469, 'notification': 3470, 'revelation': 3471, 'return': 3472, 'densification': 3473, 'crowds': 3474, 'decomposability': 3475, 'disseminating': 3476, 'amazons': 3477, 'subscription': 3478, 'standardization': 3479, 'debate': 3480, 'malware': 3481, 'offs': 3482, 'money': 3483, 'forum': 3484, 'gradients': 3485, 'brain': 3486, 'fun': 3487, 'rotation': 3488, 'convenient': 3489, 'motor': 3490, 'typechecking': 3491, 'ended': 3492, 'linker': 3493, 'astral': 3494, 'awareness': 3495, 'connectors': 3496, 'guidelines': 3497, 'motifs': 3498, 'resiliency': 3499, 'thresholding': 3500, 'oil': 3501, 'equipment': 3502, 'accelerator': 3503, 'multiprocessors': 3504, 'previews': 3505, 'banks': 3506, 'spider': 3507, 'debugger': 3508, 'prioritizing': 3509, 'quadratically': 3510, 'commitments': 3511, 'perform': 3512, 'jawaa': 3513, 'formations': 3514, 'oid': 3515, 'may': 3516, 'experiencing': 3517, 'literal': 3518, 'cryptographic': 3519, 'percentile': 3520, 'runs': 3521, 'subsets': 3522, 'branches': 3523, 'led': 3524, 'deduplication': 3525, 'overlapped': 3526, 'quantifiers': 3527, 'translational': 3528, 'velocity': 3529, 'derivatives': 3530, 'miss': 3531, 'assertions': 3532, 'eth': 3533, 'zurich': 3534, 'synopsis': 3535, 'mars': 3536, 'customers': 3537, 'required': 3538, 'boat': 3539, 'el': 3540, 'dependable': 3541, 'bcnf': 3542, 'institutions': 3543, 'quizzes': 3544, 'reaction': 3545, 'circuit': 3546, 'burstiness': 3547, 'enriching': 3548, 'negotiating': 3549, 'five': 3550, 'decide': 3551, 'whether': 3552, 'schedule': 3553, 'continuously': 3554, 'therapy': 3555, 'pedagogical': 3556, 'has': 3557, 'reserve': 3558, 'prices': 3559, 'bids': 3560, 'cellular': 3561, 'acoustic': 3562, 'spotting': 3563, 'indian': 3564, 'formatting': 3565, 'teamwork': 3566, 'intra': 3567, 'metatheory': 3568, 'curves': 3569, 'garden': 3570, 'female': 3571, 'critique': 3572, 'rendering': 3573, 'espresso': 3574, 'conjunction': 3575, 'vldb': 3576, 'vectorization': 3577, 'tail': 3578, 'shilling': 3579, 'profit': 3580, 'prima': 3581, 'descriptors': 3582, 'wheel': 3583, 'radar': 3584, 'microcomputer': 3585, 'distributive': 3586, 'stereotype': 3587, 'cinematic': 3588, 'modes': 3589, 'mixing': 3590, 'weather': 3591, 'forecasts': 3592, 'fp': 3593, 'wall': 3594, 'abnormality': 3595, 'recording': 3596, 'reasons': 3597, 'roll': 3598, 'requires': 3599, 'rime': 3600, 'extensional': 3601, 'imbalanced': 3602, 'lifting': 3603, 'srl': 3604, 'pathfinder': 3605, 'holmes': 3606, 'enity': 3607, 'competition': 3608, 'multiway': 3609, 'certain': 3610, 'topss': 3611, 'tournament': 3612, 'equilibrium': 3613, 'abstracts': 3614, 'nonstop': 3615, 'cots': 3616, 'soar': 3617, 'players': 3618, 'disruptions': 3619, 'eliciting': 3620, 'hierarchic': 3621, 'truthful': 3622, 'climbing': 3623, 'laplacian': 3624, 'nf2': 3625, 'perceptual': 3626, 'prospects': 3627, 'token': 3628, 'partitions': 3629, 'metaphors': 3630, 'securely': 3631, 'warping': 3632, 'invention': 3633, 'markup': 3634, 'xxl': 3635, 'implicitly': 3636, 'pcfg': 3637, 'rethinking': 3638, 'eca': 3639, 'oodbms': 3640, 'ida': 3641, 'mereological': 3642, 'insertion': 3643, 'arithmetic': 3644, 'semitic': 3645, 'whose': 3646, 'odometry': 3647, 'id': 3648, 'exogenous': 3649, 'markovian': 3650, 'specify': 3651, 'black': 3652, 'universities': 3653, 'ride': 3654, 'throughout': 3655, 'papers': 3656, 'folding': 3657, 'achievements': 3658, 'photographs': 3659, 'leak': 3660, 'container': 3661, 'reviewers': 3662, 'isomorphisms': 3663, 'formulating': 3664, 'prove': 3665, 'cliques': 3666, 'polysemy': 3667, 'repeat': 3668, 'yahoos': 3669, 'rough': 3670, 'great': 3671, 'insights': 3672, 'cells': 3673, 'close': 3674, 'also': 3675, 'necessary': 3676, 'weakest': 3677, 'sufficient': 3678, 'comic': 3679, 'surrogate': 3680, 'synergistic': 3681, 'recompilation': 3682, 'water': 3683, 'repetition': 3684, 'crawl': 3685, 'marked': 3686, 'problematic': 3687, 'deferred': 3688, 'inferential': 3689, 'multiview': 3690, 'hyperlinks': 3691, 'plus': 3692, 'enforce': 3693, 'se': 3694, 'ramifications': 3695, 'qualifications': 3696, 'smash': 3697, 'interruptions': 3698, 'nomadic': 3699, 'economic': 3700, 'j2ee': 3701, 'normality': 3702, 'hypothetical': 3703, 'literate': 3704, 'tiered': 3705, 'marking': 3706, 'th': 3707, 'prize': 3708, 'unifies': 3709, 'audit': 3710, 'parent': 3711, 'unaware': 3712, 'gsp': 3713, 'aspectual': 3714, 'layers': 3715, 'asking': 3716, 'windowed': 3717, 'ancient': 3718, 'mrfs': 3719, 'triple': 3720, 'beginners': 3721, 'harder': 3722, 'having': 3723, 'protection': 3724, 'restful': 3725, 'contrasting': 3726, 'earley': 3727, 'unbounded': 3728, 'widening': 3729, 'specialized': 3730, 'scattergather': 3731, 'conquer': 3732, 'successes': 3733, 'oov': 3734, 'adequacy': 3735, 'locks': 3736, 'compute': 3737, 'generics': 3738, 'oracle8i': 3739, 'apache': 3740, 'phylogenetic': 3741, 'humming': 3742, 'verified': 3743, 'epic': 3744, 'homogeneous': 3745, 'coordinated': 3746, 'backdoor': 3747, 'upon': 3748, 'assist': 3749, 'retaining': 3750, 'configurations': 3751, 'apparent': 3752, 'book': 3753, 'gestalt': 3754, 'salient': 3755, 'predictability': 3756, 'preserves': 3757, 'being': 3758, 'probing': 3759, 'away': 3760, 'academic': 3761, 'homepage': 3762, 'begin': 3763, 'causality': 3764, 'morph': 3765, 'kinds': 3766, 'compilability': 3767, 'sections': 3768, 'hide': 3769, 'seek': 3770, 'choose': 3771, 'integrative': 3772, 'condition': 3773, 'selected': 3774, 'cohesive': 3775, 'bracketed': 3776, 'observing': 3777, 'adtrees': 3778, 'winwin': 3779, 'hopfield': 3780, 'existence': 3781, 'stm': 3782, 'internationalization': 3783, 'interleaved': 3784, 'allens': 3785, 'multilabel': 3786, 'extent': 3787, 'manifesto': 3788, 'covers': 3789, 'nulls': 3790, 'discriminating': 3791, 'powered': 3792, 'segmented': 3793, 'commercial': 3794, 'signs': 3795, 'geotagging': 3796, 'serf': 3797, 'box': 3798, 'titles': 3799, 'advancement': 3800, 'taggers': 3801, 'reversing': 3802, 'increasing': 3803, 'meet': 3804, 'fail': 3805, 'personalize': 3806, 'onboard': 3807, 'penn': 3808, 'multigram': 3809, 'sigma': 3810, 'cc': 3811, 'contradiction': 3812, 'exam': 3813, 'coming': 3814, 'age': 3815, 'xtract': 3816, '2002': 3817, 'translators': 3818, 'japan': 3819, 'whom': 3820, 'occurrences': 3821, 'icon': 3822, 'timeline': 3823, 'urban': 3824, 'looking': 3825, 'glass': 3826, 'options': 3827, 'reconciliation': 3828, 'scales': 3829, 'preventing': 3830, 'preparation': 3831, 'isolated': 3832, '0': 3833, 'constructivist': 3834, 'compress': 3835, 'interleaving': 3836, 'dissimilarity': 3837, 'moment': 3838, 'delegation': 3839, 'desires': 3840, 'crisis': 3841, 'currying': 3842, 'reservoir': 3843, 'tale': 3844, 'winning': 3845, 'asymmetry': 3846, 'wrappers': 3847, 'transferring': 3848, 'vocabularies': 3849, 'crowdsourcing': 3850, 'ratings': 3851, 'controllability': 3852, 'longest': 3853, 'canadian': 3854, 'traveller': 3855, 'move': 3856, 'mcmc': 3857, 'removing': 3858, 'iconic': 3859, 'created': 3860, 'borealis': 3861, 'frequencies': 3862, 'respect': 3863, 'untrusted': 3864, 'iid': 3865, 'stratified': 3866, 'seeing': 3867, 'dbo': 3868, 'photos': 3869, 'opportunistic': 3870, 'isnt': 3871, 'slot': 3872, 'fielded': 3873, 'orthographic': 3874, 'kanji': 3875, 'faculty': 3876, 'discipline': 3877, 'determinism': 3878, 'iterator': 3879, 'datalog': 3880, 'pictorial': 3881, 'thing': 3882, 'remarks': 3883, 'mined': 3884, 'apples': 3885, 'agility': 3886, 'confusion': 3887, 'educators': 3888, 'working': 3889, 'marketplace': 3890, 'affine': 3891, 'contour': 3892, 'calculations': 3893, 'risky': 3894, 'modulo': 3895, 'ner': 3896, 'multiattribute': 3897, 'preferential': 3898, 'golog': 3899, 'surveillance': 3900, 'keep': 3901, 'systemic': 3902, 'adaboost': 3903, 'calibration': 3904, 'adapt': 3905, 'start': 3906, 'expansions': 3907, 'monotone': 3908, 'primitive': 3909, 'influences': 3910, 'agglutinative': 3911, 'urbana': 3912, 'champaign': 3913, 'needed': 3914, 'throughput': 3915, 'scrolling': 3916, 'improves': 3917, 'plausible': 3918, 'reformulations': 3919, 'fluent': 3920, 'marker': 3921, 'artifacts': 3922, 'intonation': 3923, 'car': 3924, 'holdem': 3925, 'contours': 3926, 'artists': 3927, 'contact': 3928, 'kdd': 3929, 'obligations': 3930, 'sealed': 3931, 'initialization': 3932, 'lead': 3933, 'developments': 3934, 'hyperparameter': 3935, 'copying': 3936, 'raid': 3937, 'elastic': 3938, 'employing': 3939, 'genome': 3940, 'backward': 3941, 'recursively': 3942, 'narrative': 3943, 'allowing': 3944, 'h': 3945, 'spots': 3946, 'banner': 3947, 'matter': 3948, 'monotonicity': 3949, 'pools': 3950, 'innovative': 3951, 'mashups': 3952, 'refresh': 3953, 'retrieve': 3954, 'mesh': 3955, 'supply': 3956, 'decomposable': 3957, 'lesson': 3958, 'successful': 3959, 'microprocessor': 3960, 'tablet': 3961, 'folksonomies': 3962, 'informal': 3963, 'minority': 3964, 'material': 3965, 'oblivious': 3966, 'c45': 3967, 'oar': 3968, 'sap': 3969, 'check': 3970, 'dutch': 3971, 'cis': 3972, 'described': 3973, 'gr8': 3974, 'initial': 3975, 'executive': 3976, 'upper': 3977, 'nonlocal': 3978, 'facial': 3979, 'multiuser': 3980, 'collusion': 3981, 'trenches': 3982, 'connectives': 3983, 'v': 3984, 'czech': 3985, 'grammatically': 3986, 'pro': 3987, 'lifted': 3988, 'person': 3989, 'shading': 3990, 'engaging': 3991, 'structurally': 3992, 'lineage': 3993, 'manifolds': 3994, 'substitutions': 3995, 'personalised': 3996, 'damia': 3997, 'isometric': 3998, 'probe': 3999, 'fit': 4000, 'talking': 4001, 'toolbox': 4002, 'separating': 4003, 'roots': 4004, 'aggregated': 4005, 'combinational': 4006, 'forest': 4007, 'addressable': 4008, 'revolution': 4009, 'gps': 4010, 'terminal': 4011, 'votes': 4012, 'prefetch': 4013, 'floating': 4014, 'intuition': 4015, 'final': 4016, 'neuroevolution': 4017, 'psi': 4018, 'behind': 4019, 'calculation': 4020, 'shelf': 4021, 'qualifiers': 4022, 'professional': 4023, 'agglomerative': 4024, 'contingent': 4025, 'flight': 4026, 'insensitive': 4027, 'usable': 4028, 'additional': 4029, 'actor': 4030, '15': 4031, 'union': 4032, 'usefulness': 4033, 'precedence': 4034, 'conformance': 4035, 'reflective': 4036, 'textes': 4037, 'lexique': 4038, '80': 4039, 'dining': 4040, 'uses': 4041, 'backed': 4042, 'round': 4043, 'repair': 4044, 'coalescing': 4045, 'beam': 4046, 'consequences': 4047, 'opponent': 4048, 'outreach': 4049, 'representative': 4050, 'intonational': 4051, 'spreadsheet': 4052, 'mac': 4053, 'asymmetrical': 4054, 'ds': 4055, 'rigid': 4056, 'scan': 4057, 'pl': 4058, 'categorizing': 4059, 'synonyms': 4060, 'mongolian': 4061, 'lp': 4062, 'norms': 4063, 'multirelational': 4064, 'theme': 4065, 'positioning': 4066, 'deployed': 4067, 'histories': 4068, 'evidential': 4069, 'theres': 4070, 'denial': 4071, 'assessments': 4072, 'effortless': 4073, 'funbase': 4074, 'feaspar': 4075, 'scenic': 4076, 'webanywhere': 4077, 'screen': 4078, 'exsearch': 4079, 'barter': 4080, 'progression': 4081, 'aol': 4082, 'cryptanalytic': 4083, 'pseudorandom': 4084, 'nonexistence': 4085, 'usually': 4086, 'manipulate': 4087, 'contradictory': 4088, 'revival': 4089, 'mouse': 4090, 'rim': 4091, 'bsr': 4092, 'teg': 4093, 'localisation': 4094, 'blood': 4095, 'transfusion': 4096, 'porting': 4097, 'roadmap': 4098, 'members': 4099, 'survive': 4100, 'jungle': 4101, 'customizing': 4102, 'outlines': 4103, 'archived': 4104, 'span': 4105, 'envisioning': 4106, 'clients': 4107, 'itineraries': 4108, 'wellmade': 4109, 't4sql': 4110, 'performamatics': 4111, 'taj': 4112, 'taint': 4113, 'aging': 4114, 'reorderable': 4115, 'freespan': 4116, 'jukebox': 4117, 'benign': 4118, 'racesallusing': 4119, 'replay': 4120, 'dantes': 4121, 'decreased': 4122, 'rdbv1': 4123, 'inline': 4124, 'trains': 4125, 'marketed': 4126, 'scanning': 4127, 'denali': 4128, 'lexeme': 4129, 'computationaily': 4130, 'everything': 4131, 's81': 4132, 'zoomuserviews': 4133, 'latency': 4134, 'gess': 4135, 'interactively': 4136, 'wordnets': 4137, 'freshmen': 4138, 'unbundling': 4139, 'psst': 4140, 'political': 4141, 'outcomes': 4142, 'hospital': 4143, 'disjoint': 4144, 'poor': 4145, 'cognates': 4146, 'added': 4147, 'abuse': 4148, 'signing': 4149, 'rsa': 4150, 'monkeys': 4151, 'african': 4152, 'millennial': 4153, 'classificatory': 4154, 'hyperbf': 4155, 'ipse': 4156, 'anyone': 4157, 'precluding': 4158, 'saiu': 4159, 'nrrc': 4160, 'bfnumdocs': 4161, 'thor': 4162, 'cmradar': 4163, 'pronunciations': 4164, 'wysiwyg': 4165, 'forwarding': 4166, 'shake': 4167, 'bake': 4168, 'paraccel': 4169, 'medusa': 4170, 'xsds': 4171, 'morphographemic': 4172, 'nonconcatenative': 4173, 'redefinitions': 4174, 'encountered': 4175, 'supercompilation': 4176, 'contrastive': 4177, 'encapsualtion': 4178, 'viewed': 4179, 'computerised': 4180, 'express': 4181, 'transposed': 4182, 'jasmin': 4183, 'ethical': 4184, 'societal': 4185, 'memoryless': 4186, 'polyphony': 4187, 'divergences': 4188, 'outsourced': 4189, 'bypass': 4190, 'aerospace': 4191, 'von': 4192, 'neumann': 4193, 'quantminer': 4194, 'micmac': 4195, 'microprogram': 4196, 'adon': 4197, 'certified': 4198, 'track': 4199, 'experiencer': 4200, 'proquel': 4201, 'php': 4202, 'maintain': 4203, 'sqlxnf': 4204, 'reinforcing': 4205, 'cutting': 4206, '8th': 4207, 'manuals': 4208, 'junction': 4209, 'neptune': 4210, 'netserf': 4211, 'medialife': 4212, 'chronicle': 4213, 'sin': 4214, 'algovista': 4215, 'doubly': 4216, 'biin': 4217, 'evaluability': 4218, 'serfing': 4219, 'cabob': 4220, 'fpgas': 4221, 'subtasks': 4222, 'fcl': 4223, 'tribute': 4224, 'memorial': 4225, 'fractionation': 4226, 'refractionation': 4227, 'swarm': 4228, 'adnoun': 4229, 'supernode': 4230, 'hypertalk': 4231, 'overture': 4232, 'flocks': 4233, 'set®': 4234, 'deformable': 4235, 'lrpd': 4236, 'privatization': 4237, 'organizations': 4238, 'pinwheel': 4239, 'sides': 4240, 'coin': 4241, 'anorexic': 4242, 'paranoids': 4243, 'semiautomatic': 4244, 'bb1': 4245, 'orkut': 4246, 'transductions': 4247, 'hyperqueries': 4248, 'immix': 4249, 'mutator': 4250, 'equi': 4251, 'personalisation': 4252, 'telecommunications': 4253, 'invalidation': 4254, 'cam': 4255, 'jazz': 4256, 'impure': 4257, 'reformatting': 4258, 'header': 4259, 'interferring': 4260, 'emulator': 4261, 'helpful': 4262, 'biclustering': 4263, 'pcfgs': 4264, 'indicators': 4265, 'newton': 4266, 'machinima': 4267, 'impressionrank': 4268, 'sectioning': 4269, 'regex': 4270, 'card': 4271, 'swarms': 4272, 'defensive': 4273, 'climate': 4274, 'carefully': 4275, 'swizzling': 4276, 'cohesion': 4277, 'webware': 4278, 'letter': 4279, 'especial': 4280, '1991': 4281, 'incentives': 4282, 'foreign': 4283, 'granularities': 4284, 'analogic': 4285, 'locker': 4286, 'extensiblerule': 4287, 'prune': 4288, 'reconsideration': 4289, 'passenger': 4290, 'airline': 4291, 'apportioning': 4292, 'subtype': 4293, 'baffling': 4294, 'factual': 4295, 'situationactivation': 4296, 'bimodal': 4297, 'fingerprinting': 4298, 'gregress': 4299, 'ohsumed': 4300, 'hol': 4301, 'metapher': 4302, 'sniafl': 4303, 'period': 4304, 'compensations': 4305, 'overseas': 4306, 'discord': 4307, 'ablation': 4308, 'shaping': 4309, 'shadowed': 4310, 'predilection': 4311, 'topigraphy': 4312, 'vita': 4313, 'cmm': 4314, 'dlfm': 4315, 'boxing': 4316, 'symbology': 4317, 'arrangement': 4318, 'ensembling': 4319, 'affiliated': 4320, 'supervision': 4321, 'biwtl': 4322, 'useless': 4323, 'statistice': 4324, 'aspiration': 4325, 'cnn': 4326, 'idiolectic': 4327, 'doctor': 4328, 'matches': 4329, 'ao': 4330, 'myths': 4331, 'sei': 4332, 'repartitioning': 4333, 'days': 4334, 'inspecting': 4335, 'placing': 4336, 'intensities': 4337, 'lars': 4338, 'recommenders': 4339, 'lexicalising': 4340, 'ccgbank': 4341, 'hat': 4342, 'extendible': 4343, 'little': 4344, 'diagrama': 4345, 'turbo': 4346, 'charging': 4347, 'spontaneously': 4348, 'dxq': 4349, 'dust': 4350, 'microeconomic': 4351, 'captions': 4352, 'warp': 4353, 'routine': 4354, 'gio': 4355, 'metu': 4356, 'cubetree': 4357, 'sesame': 4358, 'deceptively': 4359, 'ures': 4360, 'methodological': 4361, 'trey': 4362, 'tempus': 4363, 'fugit': 4364, 'workbench': 4365, 'winrdbi': 4366, 'refitting': 4367, 'slides': 4368, 'tabletpc': 4369, 'uncertainties': 4370, 'circumscribing': 4371, 'demonizing': 4372, 'publication': 4373, 'symbol': 4374, 'sri': 4375, 'carpenter': 4376, 'representativeness': 4377, 'walkthroughs': 4378, 'icicles': 4379, 'ratios': 4380, 'abbreviations': 4381, 'dataplorer': 4382, 'edict': 4383, 'bumps': 4384, 'curvature': 4385, 'zodiac': 4386, 'federation': 4387, 'cim': 4388, 'migrating': 4389, 'electronics': 4390, 'quark': 4391, 'resampling': 4392, 'financially': 4393, 'prioritization': 4394, 'encina': 4395, 'db2xml': 4396, 'representationalist': 4397, 'increase': 4398, 'adlads': 4399, 'upperbounds': 4400, 'streamglobe': 4401, 'youre': 4402, 'turnstile': 4403, 'linda': 4404, 'spmt': 4405, 'rpj': 4406, 'admit': 4407, 'conspiracy': 4408, 'pid': 4409, 'plow': 4410, 'instrumentation': 4411, 'hyperfairness': 4412, 'monadic': 4413, 'eql': 4414, 'bounce': 4415, 'advertisements': 4416, 'slim': 4417, 'adequate': 4418, 'polylingual': 4419, 'bigrams': 4420, 'spotsigs': 4421, 'melbourne': 4422, 'individualism': 4423, 'parameterizable': 4424, 'balance': 4425, 'vickrey': 4426, 'exchanges': 4427, 'prism': 4428, 'chase': 4429, 'framenet': 4430, 'loadstore': 4431, 'solves': 4432, 'semiconductor': 4433, 'assign': 4434, 'crosslingual': 4435, 'inside': 4436, 'giuku': 4437, 'utilities': 4438, 'camouflaged': 4439, 'horting': 4440, 'hatches': 4441, 'egg': 4442, 'exclaim': 4443, 'regeneration': 4444, 'eden': 4445, 'cohersion': 4446, 'rated': 4447, 'master': 4448, 'clp': 4449, 'substrate': 4450, 'davis': 4451, 'putnam': 4452, 'outerplanar': 4453, 'central': 4454, 'tip': 4455, 'informix': 4456, 'artdb': 4457, 'taxation': 4458, 'sustainable': 4459, 'chillers': 4460, 'definitional': 4461, 'functionally': 4462, 'rstar': 4463, 'concentration': 4464, 'ming': 4465, 'statix': 4466, 'automatized': 4467, 'dances': 4468, 'cause': 4469, 'checklist': 4470, 'nah': 4471, 'syndrome': 4472, 'sinuhe': 4473, 'ado': 4474, 'mediating': 4475, 'orientated': 4476, 'scarce': 4477, 'dialogic': 4478, 'walrus': 4479, 'redo': 4480, 'tolerating': 4481, 'disagreement': 4482, 'relief': 4483, 'rapidity': 4484, 'started': 4485, 'clarification': 4486, 'p2cast': 4487, 'patching': 4488, 'vod': 4489, 'symrnetric': 4490, 'guiding': 4491, 'rlsc': 4492, 'agony': 4493, 'interform': 4494, 'cf': 4495, 'gas': 4496, 'turbine': 4497, 'proliant': 4498, 'multimode': 4499, 'summarize': 4500, 'universe': 4501, 'affect': 4502, 'vista': 4503, 'mapgraph': 4504, 'labelled': 4505, 'cpcv': 4506, 'generations': 4507, 'overcome': 4508, 'developmentevolution': 4509, 'deeper': 4510, 'qrelx': 4511, 'geospatially': 4512, 'photograph': 4513, 'perf': 4514, 'bloomjoin': 4515, 'teapot': 4516, 'beaten': 4517, 'tracks': 4518, 'pay': 4519, 'subword': 4520, 'critics': 4521, 'substantional': 4522, 'enclosing': 4523, 'balls': 4524, 'emoticons': 4525, 'eyed': 4526, 'stereo': 4527, 'archjava': 4528, 'crossing': 4529, 'controller': 4530, 'assembler': 4531, 'mrdsm': 4532, 'timer': 4533, 'alerters': 4534, 'rooted': 4535, 'lob': 4536, 'talisman': 4537, 'un': 4538, 'système': 4539, 'gouverné': 4540, 'lois': 4541, 'linguistiques': 4542, 'pour': 4543, 'traitement': 4544, 'langue': 4545, 'naturelle': 4546, 'mcs': 4547, 'reconstruct': 4548, 'regulatory': 4549, 'ascription': 4550, 'dynamo': 4551, 'moded': 4552, 'prime': 4553, 'implicate': 4554, 'quantifiable': 4555, 'qos': 4556, 'incompleteness': 4557, 'chatty': 4558, 'renderman': 4559, 'kernelizing': 4560, 'pls': 4561, 'memoization': 4562, 'fax': 4563, 'proda': 4564, 'ink': 4565, 'exercises': 4566, 'taco': 4567, 'statisticalscientific': 4568, 'bnchmark': 4569, 'ulixes': 4570, 'gpx': 4571, 'paradise': 4572, 'chatting': 4573, 'occasions': 4574, 'factorial': 4575, 'cgcexplorer': 4576, 'treedt': 4577, 'sdss': 4578, 'skyserver': 4579, 'exercising': 4580, 'handy': 4581, 'trac': 4582, 'selforganizing': 4583, 'reuters': 4584, 'poison': 4585, 'pills': 4586, 'topically': 4587, 'miqis': 4588, 'chained': 4589, 'subdialogues': 4590, 'virtualized': 4591, 'seismic': 4592, 'treisman': 4593, 'workshops': 4594, 'rewards': 4595, 'critiquing': 4596, 'hypothesized': 4597, 'occlusion': 4598, 'asserting': 4599, 'preemptive': 4600, 'deoptimization': 4601, 'adms±': 4602, 'workstation': 4603, 'mainframe': 4604, 'gorder': 4605, '17th': 4606, 'inex': 4607, 'ferry': 4608, 'optics': 4609, 'spill': 4610, 'infeasible': 4611, 'stanislavskian': 4612, 'dualminer': 4613, 'lung': 4614, 'markerless': 4615, 'gating': 4616, 'radiotherapy': 4617, 'cybercivics': 4618, 'motivational': 4619, 'gunsat': 4620, 'aktionsarten': 4621, 'gsat': 4622, 'drawings': 4623, 'urgent': 4624, 'subseries': 4625, 'movers': 4626, 'topp': 4627, 'magnitude': 4628, 'comfort': 4629, 'korea': 4630, 'coa': 4631, 'patents': 4632, 'artemis': 4633, 'lagrangian': 4634, 'tails': 4635, 'struggles': 4636, 'compatible': 4637, 'tight': 4638, 'recompression': 4639, 'carousel': 4640, 'morpiiemes': 4641, 'bellman': 4642, 'piloted': 4643, 'rmses': 4644, 'pareto': 4645, 'maturity': 4646, 'presenters': 4647, 'remembering': 4648, 'jule': 4649, 'neuro': 4650, 'muse': 4651, 'tricks': 4652, 'traps': 4653, 'initiating': 4654, 'opsm': 4655, 'epdl': 4656, 'dirty': 4657, 'contained': 4658, 'animated': 4659, 'winmagic': 4660, 'compilable': 4661, 'delicious': 4662, 'xquisite': 4663, 'multitext': 4664, 'pomdp': 4665, 'aviation': 4666, 'rolex': 4667, 'navigable': 4668, 'simplifications': 4669, 'isotonic': 4670, 'programing': 4671, 'worm': 4672, 'discs': 4673, 'glue': 4674, 'carbohydrate': 4675, 'multirobot': 4676, 'eggyolk': 4677, 'sorts': 4678, 'fm91': 4679, 'ocam': 4680, 'spinning': 4681, 'italian': 4682, 'dbcache': 4683, 'splice': 4684, 'doing': 4685, 'satellite': 4686, 'whiteboard': 4687, 'acting': 4688, 'cd': 4689, 'rom': 4690, 'superscalar': 4691, 'superimposed': 4692, 'rainforest': 4693, 'requiring': 4694, 'privatizing': 4695, 'thine': 4696, 'enemy': 4697, 'champion': 4698, 'ut': 4699, 'arlington': 4700, 'whisper': 4701, 'retina': 4702, 'anchorwoman': 4703, 'masses': 4704, 'verifier': 4705, 'modularizing': 4706, 'codescriptive': 4707, 'feedforward': 4708, 'timesten': 4709, 'optional': 4710, 'koref': 4711, 'gossip': 4712, 'slow': 4713, 'illumination': 4714, 'odd': 4715, 'coordinators': 4716, 'responders': 4717, 'shakespeare': 4718, 'rectangle': 4719, 'explication': 4720, 'articulatory': 4721, 'opening': 4722, 'eyes': 4723, 'armor': 4724, 'los': 4725, 'angeles': 4726, 'airport': 4727, 'cone': 4728, 'sqlb': 4729, 'consumers': 4730, 'hydra': 4731, 'auv': 4732, 'wildcards': 4733, 'desktops': 4734, 'motif': 4735, 'surf': 4736, 'gr2': 4737, 'lrtak': 4738, 'trigger': 4739, 'shopsmart': 4740, 'crfs': 4741, 'cascaded': 4742, 'lk': 4743, 'pier': 4744, 'luby': 4745, 'rackoff': 4746, 'negotiators': 4747, 'win': 4748, 'arbus': 4749, 'dbs': 4750, 'iphones': 4751, 'phones': 4752, 'oh': 4753, 'my': 4754, 'advertise': 4755, 'inexact': 4756, 'publications': 4757, 'speechlanguage': 4758, 'spellchecking': 4759, 'autocorrection': 4760, 'inspector': 4761, 'fringe': 4762, 'saving': 4763, 'warning': 4764, 'vulnerability': 4765, 'orderings': 4766, 'connect': 4767, 'radically': 4768, 'statechart': 4769, 'valuable': 4770, 'compared': 4771, 'own': 4772, 'armed': 4773, 'presuppositional': 4774, 'lexicalised': 4775, 'pdms': 4776, 'shard': 4777, 'laura': 4778, 'her': 4779, 'algorithmics': 4780, 'cui': 4781, 'capabilities': 4782, 'spark': 4783, 'beacond': 4784, 'counterexample': 4785, 'xseq': 4786, 'campaign': 4787, 'informatively': 4788, 'meinongian': 4789, 'pintos': 4790, 'prescription': 4791, 'admission': 4792, 'underspecification': 4793, 'transitivity': 4794, 'foregrounding': 4795, 'summarising': 4796, 'martingale': 4797, 'noa': 4798, 'normative': 4799, 'congruences': 4800, 'topologically': 4801, 'fpga': 4802, 'tower': 4803, 'straw': 4804, 'hypotheticals': 4805, 'holder': 4806, 'calling': 4807, 'conventions': 4808, 'filing': 4809, 'stripes': 4810, 'cape': 4811, 'tuned': 4812, 'complementarities': 4813, 'tdlambda': 4814, 'eligibility': 4815, 'further': 4816, 'topaz': 4817, 'parallelizer': 4818, 'sanitization': 4819, 'terminator': 4820, 'unrestrictd': 4821, 'gapping': 4822, 'rely': 4823, 'bigsur': 4824, 'koda': 4825, 'enumerating': 4826, 'popel': 4827, 'counters': 4828, 'sale': 4829, 'scrap': 4830, 'triggering': 4831, 'florid': 4832, 'fluid': 4833, 'centred': 4834, 'incompletely': 4835, 'boltzrank': 4836, 'maximize': 4837, 'translator': 4838, 'matesek': 4839, 'ring': 4840, 'sarms': 4841, 'gait': 4842, 'cocomo': 4843, 'uflip': 4844, 'staggered': 4845, 'striping': 4846, 'statestep': 4847, 'cm': 4848, 'eves': 4849, 'thresholds': 4850, 'tp': 4851, 'counterfactual': 4852, 'conditioning': 4853, 'inferred': 4854, 'decompose': 4855, 'vault': 4856, 'ibe': 4857, 'confidential': 4858, 'drafting': 4859, 'pods': 4860, 'nominals': 4861, 'pylonic': 4862, 'eeg': 4863, 'epileptic': 4864, 'seizures': 4865, 'cacheportal': 4866, 'hosted': 4867, 'dsdt': 4868, 'durable': 4869, 'xvm': 4870, 'credibility': 4871, 'brier': 4872, 'potentialities': 4873, 'reducers': 4874, 'redus': 4875, 'swifft': 4876, 'fft': 4877, 'influencing': 4878, 'constraining': 4879, 'unicorn': 4880, 'seasonality': 4881, 'facile': 4882, 'simulators': 4883, 'parlog': 4884, 'superoperators': 4885, 'screamer': 4886, 'deserialization': 4887, 'fl': 4888, 'cayuga': 4889, 'achievement': 4890, 'dstributed': 4891, 'genealogy': 4892, 'uncovering': 4893, 'ideas': 4894, 'vietnamese': 4895, 'isalog': 4896, 'amongst': 4897, 'outer': 4898, 'california': 4899, 'vital': 4900, 'scopes': 4901, 'randomizing': 4902, 'lilog': 4903, 'virtualization': 4904, 'ims': 4905, 'impedance': 4906, 'syntagmatic': 4907, 'powerdb': 4908, 'involving': 4909, 'abstaining': 4910, 'lingo': 4911, 'totally': 4912, 'recrawl': 4913, 'dark': 4914, 'sgs': 4915, 'uncontrollable': 4916, 'cockpit': 4917, 'senior': 4918, 'concatenative': 4919, 'morphotactics': 4920, 'affects': 4921, 'giving': 4922, 'omt': 4923, 'scaffolding': 4924, 'flexibility': 4925, 'pane': 4926, 'residues': 4927, 'orchestrating': 4928, 'multicore': 4929, 'muvis': 4930, 'motivations': 4931, 'inspiring': 4932, 'pursue': 4933, 'chatbots': 4934, 'imt': 4935, 'pathologies': 4936, 'cooperate': 4937, 'repeated': 4938, 'sparq2l': 4939, 'rendezvous': 4940, 'penalized': 4941, 'determinant': 4942, 'amalgamating': 4943, 'viper': 4944, 'entropic': 4945, 'jmocha': 4946, 'bc': 4947, 'opponents': 4948, 'origins': 4949, 'suppressing': 4950, 'trainable': 4951, 'finders': 4952, 'authentication': 4953, 'adams': 4954, 'alliances': 4955, 'multilayered': 4956, 'aer': 4957, 'warnings': 4958, 'threats': 4959, 'storm': 4960, 'idm': 4961, 'reap': 4962, 'corroborate': 4963, 'mutually': 4964, 'establishment': 4965, 'hybridized': 4966, 'locksmith': 4967, 'challenged': 4968, 'qcsp': 4969, 'workplace': 4970, 'nonprofits': 4971, 'backbone': 4972, 'shoqd': 4973, 'forcing': 4974, 'testability': 4975, 'maximally': 4976, 'pinpointing': 4977, 'dedicated': 4978, 'qursed': 4979, 'restructured': 4980, 'agreements': 4981, 'essentials': 4982, 'bucketing': 4983, 'wheat': 4984, 'voxelwise': 4985, 'resonance': 4986, 'canlogs': 4987, 'gate': 4988, 'seasons': 4989, 'farm': 4990, 'looks': 4991, 'taxis': 4992, 'lime': 4993, 'ups': 4994, 'downs': 4995, 'preposition': 4996, 'esl': 4997, 'trobe': 4998, 'poliqarp': 4999, 'indexer': 5000, 'palka': 5001, 'sifting': 5002, 'sda': 5003, 'cai': 5004, 'superlatives': 5005, 'meetings': 5006, 'csrs': 5007, 'excon': 5008, 'advocating': 5009, 'webview': 5010, 'hyperbolic': 5011, 'plane': 5012, 'adheat': 5013, 'ecosystem': 5014, 'sustainability': 5015, 'blockwise': 5016, 'landscan': 5017, 'alerter': 5018, 'referent': 5019, 'datarace': 5020, 'deadlocks': 5021, 'realizations': 5022, 'interact': 5023, 'scm': 5024, 'passages': 5025, 'scored': 5026, 'expanded': 5027, 'charalign': 5028, 'byte': 5029, 'screens': 5030, 'recasting': 5031, 'sigcse': 5032, 'knack': 5033, '11g': 5034, 'cvdb': 5035, '2004': 5036, 'attracting': 5037, 'keeping': 5038, 'brightest': 5039, 'experienced': 5040, 'hddbs': 5041, 'countability': 5042, 'withouta': 5043, 'priori': 5044, 'personalizing': 5045, 'subgoal': 5046, 'wip': 5047, 'intellimedia': 5048, 'wsqdsq': 5049, 'systemt': 5050, 'accent': 5051, 'interfacile': 5052, 'rasp': 5053, 'asam': 5054, 'odx': 5055, 'oodbs': 5056, 'vyrd': 5057, 'ccal': 5058, 'questionnaire': 5059, 'trailfinding': 5060, 'modularization': 5061, 'logistics': 5062, 'debug': 5063, 'associational': 5064, 'flowcharts': 5065, 'blending': 5066, 'tcoz': 5067, 'algol': 5068, 'ecr': 5069, 'tasktracker': 5070, 'majsat': 5071, 'mierucompiler': 5072, 'ironing': 5073, 'redundancies': 5074, 'propbank': 5075, 'clotho': 5076, 'mentions': 5077, 'awaredav': 5078, 'rollups': 5079, 'parametricity': 5080, 'leveled': 5081, 'pundit': 5082, 'gcx': 5083, 'defacto': 5084, 'incident': 5085, 'commanders': 5086, 'overconstrained': 5087, 'resilient': 5088, 'propagator': 5089, 'sequel': 5090, 'might': 5091, 'thinker': 5092, 'linearizing': 5093, 'agency': 5094, 'closegraph': 5095, 'turk': 5096, 'junit': 5097, 'itemset': 5098, 'gauss': 5099, 'unbalanced': 5100, 'saying': 5101, 'already': 5102, 'capitalized': 5103, 'fintime': 5104, 'exits': 5105, 'reopening': 5106, 'song': 5107, 'tapping': 5108, 'gray': 5109, 'nearly': 5110, 'geominer': 5111, 'coevolving': 5112, 'mice': 5113, 'rewritings': 5114, 'laundering': 5115, 'crimes': 5116, 'fabrication': 5117, 'tangible': 5118, 'creativity': 5119, 'dnf': 5120, 'needle': 5121, 'invasive': 5122, 'actuated': 5123, 'gibbs': 5124, 'detectioncorrection': 5125, 'casee': 5126, 'rediscovering': 5127, 'passion': 5128, 'beauty': 5129, 'joy': 5130, 'awe': 5131, 'continued': 5132, 'webdiplomat': 5133, 'multilist': 5134, 'affiliation': 5135, 'ford': 5136, 'xpathxslt': 5137, 'poogle': 5138, 'lrt': 5139, 'ip': 5140, 'jibiki': 5141, 'lexalp': 5142, 'benchmarking': 5143, 'interbase': 5144, 'ergonomics': 5145, 'siebel': 5146, 'mechanizing': 5147, 'sage': 5148, 'sqout': 5149, 'workblench': 5150, 'dbis': 5151, 'variations': 5152, 'forensic': 5153, 'tampering': 5154, 'dereference': 5155, 'mppm': 5156, 'consolution': 5157, 'www2004': 5158, 'lowell': 5159, 'misclassification': 5160, 'pcb': 5161, 'drilling': 5162, 'redefining': 5163, 'paraphrase': 5164, 'ungreedy': 5165, 'probalistic': 5166, 'evil': 5167, 'flexibly': 5168, 'mergepurge': 5169, 'captioned': 5170, 'figures': 5171, 'mathfind': 5172, 'rights': 5173, 'duties': 5174, 'accessed': 5175, 'scr': 5176, 'uqlips': 5177, 'centralization': 5178, 'whither': 5179, '21': 5180, 'dart': 5181, 'wiki': 5182, 'adaptivity': 5183, 'svg': 5184, 'european': 5185, 'continous': 5186, 'visiprog': 5187, 'abstracting': 5188, 'inherently': 5189, 'want': 5190, 'brooks': 5191, 'coopware': 5192, 'masters': 5193, 'families': 5194, 'timegraphs': 5195, 'suboptimal': 5196, 'singleton': 5197, 'idioms': 5198, 'microprogramming': 5199, 'watch': 5200, 'reminding': 5201, 'drawing': 5202, 'idiomatic': 5203, 'rel': 5204, 'laterally': 5205, 'spiking': 5206, 'neurons': 5207, 'revenue': 5208, 'relying': 5209, 'lof': 5210, 'gnu': 5211, 'mobide': 5212, 'cybertech': 5213, 'sensible': 5214, 'biosurveillance': 5215, 'indexicals': 5216, 'demonstratives': 5217, 'egalitarist': 5218, 'incommensurable': 5219, 'concolic': 5220, 'missed': 5221, 'actual': 5222, 'gamps': 5223, 'amplitude': 5224, 'compaction': 5225, 'overlays': 5226, 'papyrus': 5227, '6th': 5228, 'setl': 5229, 'renaissance': 5230, 'unitran': 5231, 'intents': 5232, 'superior': 5233, 'hgdm': 5234, 'ac': 5235, 'apis': 5236, 'siren': 5237, 'hyperrectangle': 5238, 'declustered': 5239, 'deafault': 5240, 'angular': 5241, 'reputable': 5242, 'servents': 5243, 'subtask': 5244, 'extrapolation': 5245, 'jeroo': 5246, 'majority': 5247, 'aliases': 5248, 'pengi': 5249, 'rivaling': 5250, 'professionals': 5251, 'perplexity': 5252, 'fusing': 5253, 'communicative': 5254, 'subset': 5255, 'mips': 5256, 'snitch': 5257, 'paste': 5258, 'plagiarism': 5259, 'tickets': 5260, 'terminals': 5261, 'occam': 5262, 'gamma': 5263, 'schems': 5264, 'scratch': 5265, 'alphasort': 5266, 'interfacing': 5267, 'colorblind': 5268, 'coallocation': 5269, 'collaborations': 5270, 'punctuated': 5271, 'trips': 5272, 'valuation': 5273, 'sqlem': 5274, 'emergency': 5275, 'triage': 5276, 'wrong': 5277, 'waves': 5278, 'redesigning': 5279, 'plackett': 5280, 'luce': 5281, 'multimediaminer': 5282, 'emperical': 5283, 'redux': 5284, 'qsf': 5285, 'attacking': 5286, 'decipherment': 5287, 'entrans': 5288, 'edsc': 5289, 'vectorial': 5290, 'exprim': 5291, 'rivage': 5292, 'orthotics': 5293, 'custom': 5294, 'reassignment': 5295, 'realization': 5296, 'weaknesses': 5297, 'incoherency': 5298, 'aggregators': 5299, 'obsolescent': 5300, 'warlock': 5301, 'batmobile': 5302, 'taxi': 5303, 'synergy': 5304, 'publish': 5305, 'subscribe': 5306, 'cpoe': 5307, 'eel': 5308, 'stimuli': 5309, 'syntemic': 5310, 'fg': 5311, 'minute': 5312, 'ten': 5313, 'later': 5314, 'thumb': 5315, 'socp': 5316, 'interpreternative': 5317, 'sensitivities': 5318, 'thermodynamics': 5319, 'eddies': 5320, 'xl': 5321, 'expose': 5322, 'cs2cs7': 5323, 'following': 5324, 'validated': 5325, 'tab': 5326, 'emphasis': 5327, 'carrier': 5328, 'hiv': 5329, 'promising': 5330, 'valency': 5331, 'wring': 5332, 'dry': 5333, 'sellers': 5334, 'competing': 5335, 'buyers': 5336, 'shill': 5337, 'fees': 5338, '200': 5339, 'cmerun': 5340, 'tapestry': 5341, 'maneuvering': 5342, 'obstacles': 5343, 'quadtree': 5344, 'positional': 5345, 'vc': 5346, 'exceptional': 5347, 'deliberation': 5348, 'thousands': 5349, 'bubble': 5350, 'archaeological': 5351, 'selc': 5352, 'enactment': 5353, 'playback': 5354, 'continuity': 5355, 'pooled': 5356, 'sampled': 5357, 'slavic': 5358, 'condensed': 5359, 'dtps': 5360, 'tcsps': 5361, 'truecasing': 5362, '78': 5363, 'preceding': 5364, 'ethernet': 5365, 'multigraphs': 5366, 'phonetic': 5367, 'constituents': 5368, 'omes': 5369, 'webkhoj': 5370, 'lsl': 5371, 'selector': 5372, 'componentware': 5373, 'requirementsassurances': 5374, 'explorer': 5375, 'hadoop': 5376, 'netnews': 5377, 'rationality': 5378, 'mdm': 5379, 'mbdp': 5380, 'subsetting': 5381, 'superposition': 5382, 'discotect': 5383, 'traveled': 5384, 'baccalaureate': 5385, 'sustain': 5386, 'ghost': 5387, 'introspective': 5388, 'bitwidth': 5389, 'multipurpose': 5390, 'indeterminancy': 5391, 'memeta': 5392, 'mutable': 5393, 'ss': 5394, 'translingual': 5395, 'sos': 5396, 'evolve': 5397, 'irregularity': 5398, 'hamming': 5399, 'skoll': 5400, 'scaffolded': 5401, 'rbe': 5402, 'harvesting': 5403, 'productions': 5404, 'reductions': 5405, 'phantom': 5406, 'predicative': 5407, 'measured': 5408, 'demands': 5409, 'explosion': 5410, 'bunsetsu': 5411, 'hough': 5412, 'enable': 5413, 'petroglyphs': 5414, 'swiss': 5415, 'listener': 5416, 'reader': 5417, 'exterminator': 5418, 'biographical': 5419, 'independently': 5420, 'safeguard': 5421, 'uc': 5422, 'simlist': 5423, 'lexikon': 5424, 'helps': 5425, 'airphys': 5426, 'indic': 5427, 'train': 5428, 'encompass': 5429, 'interchange': 5430, 'imaged': 5431, 'pdf': 5432, 'biotech': 5433, 'translated': 5434, 'micronet': 5435, 'hypercubes': 5436, 'instantiations': 5437, 'kcat': 5438, 'intervention': 5439, 'darshak': 5440, 'degrading': 5441, 'animator': 5442, 'cl': 5443, 'researchs': 5444, 'fastest': 5445, 'odyssey': 5446, 'codd': 5447, 's5': 5448, 'microfeature': 5449, 'rices': 5450, 'quicklink': 5451, 'residual': 5452, 'heart': 5453, 'decaying': 5454, 'vanity': 5455, 'querylog': 5456, 'bundles': 5457, 'delexical': 5458, 'usenet': 5459, 'gral': 5460, 'c2c': 5461, 'cool': 5462, 'machiavelli': 5463, 'border': 5464, 'redistribution': 5465, 'broaden': 5466, 'resistance': 5467, 'relocation': 5468, 'accelerate': 5469, 'wirelessmobile': 5470, 'metadatabase': 5471, 'rensselaer': 5472, 'engineer': 5473, 'pepx': 5474, 'burden': 5475, 'collinearity': 5476, 'nonnumeric': 5477, 'correctly': 5478, 'picnics': 5479, 'kittens': 5480, 'wigs': 5481, 'satisfy': 5482, 'g': 5483, 'goat': 5484, 'sqlmx': 5485, 'jerpa': 5486, 'cloze': 5487, 'temperature': 5488, '3w': 5489, 'stereotypes': 5490, 'sddm': 5491, 'cypress': 5492, 'taker': 5493, 'verbalizes': 5494, 'discoveries': 5495, 'practicum': 5496, 'trie': 5497, 'perusing': 5498, 'videodisk': 5499, 'tokens': 5500, 'sematically': 5501, 'bell': 5502, 'hebrew': 5503, 'secureblox': 5504, 'shoulders': 5505, 'giants': 5506, 'slices': 5507, 'ansisparc': 5508, 'successive': 5509, 'eigenmaps': 5510, 'honors': 5511, 'adapter': 5512, 'sigmoids': 5513, 'frequently': 5514, 'updated': 5515, 'simplicity': 5516, 'iloc': 5517, 'mtr': 5518, 'corporation': 5519, 'hong': 5520, 'kong': 5521, 'tiled': 5522, 'minimising': 5523, 'automobile': 5524, 'sealing': 5525, 'evolvable': 5526, 'eve': 5527, 'radixzip': 5528, 'menus': 5529, 'rock': 5530, 'contributed': 5531, 'rankcut': 5532, 'rewriter': 5533, 'neuroimagery': 5534, 'embracing': 5535, 'pop': 5536, 'maritime': 5537, 'cracked': 5538, 'amelioration': 5539, 'arieskvl': 5540, 'multiaction': 5541, 'webviews': 5542, 'ocfs': 5543, 'centroid': 5544, 'glr': 5545, 'hundreds': 5546, 'interlisp': 5547, 'paving': 5548, 'diligent': 5549, 'eight': 5550, 'euclidean': 5551, 'scc': 5552, 'dcc': 5553, 'implicature': 5554, 'rbf': 5555, 'weesa': 5556, 'dblearn': 5557, 'xinuwu': 5558, 'xinu': 5559, 'csis': 5560, 'deconstructing': 5561, 'restoration': 5562, 'diacritics': 5563, 'clue': 5564, 'returned': 5565, 'portability': 5566, 'semint': 5567, 'rao': 5568, 'blackwellised': 5569, 'writable': 5570, 'disclosure': 5571, 'hippocratic': 5572, 'abridged': 5573, 'navigator': 5574, 'historically': 5575, 'colleges': 5576, 'objectbase': 5577, 'ucair': 5578, 'toolbar': 5579, 'remora': 5580, 'xslt': 5581, 'triangulated': 5582, '4th': 5583, 'metaphoric': 5584, 'coercion': 5585, 'reminiscences': 5586, 'influential': 5587, '21st': 5588, 'mindset': 5589, 'cyberporn': 5590, 'xrpc': 5591, 'chicago': 5592, 'lognormal': 5593, 'erasure': 5594, 'nusmv': 5595, 'slm': 5596, 'arboreal': 5597, 'prow': 5598, 'shipping': 5599, 'astronomy': 5600, 'serving': 5601, 'submitted': 5602, 'manuscripts': 5603, 'questionanswering': 5604, 'misconceptions': 5605, 'todays': 5606, 'hypercard': 5607, 'accommodating': 5608, 'follower': 5609, 'offset': 5610, 'multiaccess': 5611, 'url': 5612, 'assets': 5613, 'toys': 5614, 'aboutness': 5615, 'gaze': 5616, 'extractive': 5617, 'systolic': 5618, 'udfs': 5619, 'efficacy': 5620, 'invalidity': 5621, 'allocating': 5622, 'eliminate': 5623, 'trnon': 5624, 'ansductive': 5625, 'reexamining': 5626, 'complementary': 5627, 'fourth': 5628, 'airweb': 5629, 'decorrelation': 5630, 'man': 5631, 'lookups': 5632, 'founded': 5633, 'reasoner': 5634, 'repeats': 5635, 'itself': 5636, 'enthusiasm': 5637, 'cook': 5638, 'pet': 5639, 'erroneous': 5640, 'coko': 5641, 'allocator': 5642, 'shifting': 5643, 'agatha': 5644, 'christie': 5645, 'leads': 5646, 'geodesic': 5647, 'boosted': 5648, 'diathesis': 5649, 'alternations': 5650, 'combinators': 5651, 'ariescsa': 5652, 'tribes': 5653, 'knit': 5654, 'employment': 5655, 'montagues': 5656, 'dragon': 5657, 'hunters': 5658, 'splines': 5659, 'nnow': 5660, 'nurbs': 5661, 'minijava': 5662, 'samos': 5663, 'growing': 5664, 'cord': 5665, 'appraoch': 5666, 'ntcir': 5667, 'strongest': 5668, 'disorder': 5669, 'suitable': 5670, 'tridirectional': 5671, 'monothetic': 5672, 'practive': 5673, 'reactions': 5674, 'commentary': 5675, 'applicable': 5676, 'pens': 5677, 'shuffling': 5678, 'stacked': 5679, 'deck': 5680, 'vlkdbs': 5681, 'intermodule': 5682, 'supervaluation': 5683, 'inland': 5684, 'monic': 5685, 'multicluster': 5686, 'grafting': 5687, 'comex': 5688, 'commodities': 5689, 'finance': 5690, 'suspects': 5691, 'laws': 5692, 'shrinking': 5693, 'diameters': 5694, 'comprehensibility': 5695, 'academically': 5696, 'vrifa': 5697, 'nomogram': 5698, 'radial': 5699, 'lrbf': 5700, 'pathfinding': 5701, 'sitemaps': 5702, 'above': 5703, 'duty': 5704, 'lhrs': 5705, 'overtly': 5706, 'uddi': 5707, 'registries': 5708, 'regrets': 5709, 'observability': 5710, 'mood': 5711, 'til': 5712, 'sofis': 5713, 'replace': 5714, 'wsj': 5715, 'mainteinability': 5716, 'transportable': 5717, 'cpus': 5718, 'iterators': 5719, 'readable': 5720, 'unify': 5721, 'filename': 5722, 'nul': 5723, 'maxsat': 5724, 'modification': 5725, 'hahacronym': 5726, 'invocation': 5727, 'ptime': 5728, 'coercive': 5729, 'descriptiveness': 5730, 'caseframe': 5731, 'late': 5732, 'ce2': 5733, 'commandtalk': 5734, 'harry': 5735, 'met': 5736, 'harri': 5737, 'hunter': 5738, 'gatherer': 5739, 'socqet': 5740, 'yap3': 5741, 'seurat': 5742, 'earlier': 5743, 'disciplined': 5744, 'icse99': 5745, 'bifocal': 5746, 'microsurgery': 5747, 'nugget': 5748, 'consolidation': 5749, 'naturalistic': 5750, 'nonstationary': 5751, 'stamps': 5752, 'esa': 5753, 'rays': 5754, 'neurorule': 5755, 'configurable': 5756, 'skeptical': 5757, 'lifelog': 5758, 'bgp': 5759, 'lens': 5760, 'joysticks': 5761, 'mippets': 5762, 'dbir': 5763, 'sigmod': 5764, 'standalone': 5765, 'uncooperative': 5766, 'suspend': 5767, 'resume': 5768, 'rotating': 5769, 'odeview': 5770, 'updatability': 5771, 'malm': 5772, 'old': 5773, 'pharse': 5774, 'progres': 5775, 'scaleable': 5776, 'pessimistic': 5777, 'bt': 5778, 'branched': 5779, 'did': 5780, 'trax': 5781, 'ifo': 5782, 'designer': 5783, 'definites': 5784, 'toy': 5785, 'arm': 5786, 'dags': 5787, 'emperiment': 5788, 'authorizations': 5789, 'lexicalist': 5790, 'icelandic': 5791, 'ruralcafe': 5792, 'rural': 5793, 'w': 5794, 'pan': 5795, 'cb': 5796, 'ranksql': 5797, 'potts': 5798, 'mft': 5799, 'caramel': 5800, 'curry': 5801, 'howard': 5802, 'differentially': 5803, 'netflix': 5804, 'contenders': 5805, 'deobfuscation': 5806, 'preconditioned': 5807, 'algres': 5808, 'chimera': 5809, 'onion': 5810, 'kidney': 5811, 'magead': 5812, 'dialects': 5813, 'disambiguating': 5814, 'transmutation': 5815, 'mccs': 5816, 'didactic': 5817, 'dialectic': 5818, 'headline': 5819, 'intertask': 5820, 'exr': 5821, 'mixin': 5822, 'pivotunpivot': 5823, 'lapses': 5824, 'resumption': 5825, 'interrupted': 5826, 'loads': 5827, 'tempoexpress': 5828, 'expressivity': 5829, 'musical': 5830, 'tempo': 5831, 'impacts': 5832, 'reproduction': 5833, 'ica': 5834, 'wizards': 5835, 'wikispeedia': 5836, 'starving': 5837, 'hitting': 5838, 'kriegspiel': 5839, 'metapositions': 5840, 'harm': 5841, 'mismatch': 5842, 'lama': 5843, 'absolute': 5844, 'pennies': 5845, 'touch': 5846, 'cancer': 5847, 'restricting': 5848, 'aquery': 5849, 'pqc': 5850, 'matchsim': 5851, 'surprising': 5852, 'superdatabases': 5853, 'protel': 5854, 'umlanalyzer': 5855, 'satcsp': 5856, 'expander': 5857, 'nesc': 5858, 'pact': 5859, 'delinearization': 5860, 'break': 5861, 'multiloop': 5862, 'specificity': 5863, 'amnesic': 5864, 'cryptanalysis': 5865, 'snefru': 5866, 'transcripts': 5867, 'polyhedra': 5868, 'consciousness': 5869, 'underapproximation': 5870, 'hyrex': 5871, 'rehist': 5872, 'bundle': 5873, 'fire': 5874, 'bm25': 5875, 'csql': 5876, 'dynamicity': 5877, 'bilvideo': 5878, 'contraction': 5879, 'contemplate': 5880, 'columnsort': 5881, 'subgroups': 5882, 'golden': 5883, 'clickstreams': 5884, 'controversies': 5885, 'syncro': 5886, 'lilithmodula': 5887, 'knows': 5888, 'sovereign': 5889, 'lossy': 5890, 'stamped': 5891, 'smartback': 5892, 'recallprecision': 5893, 'quickmig': 5894, 'diagnosers': 5895, 'controlflow': 5896, 'lack': 5897, 'linux': 5898, 'tapes': 5899, 'hold': 5900, 'investing': 5901, 'thin': 5902, 'featherweight': 5903, 'exposing': 5904, 'internals': 5905, 'leo': 5906, 'db2s': 5907, 'tic': 5908, 'toe': 5909, 'tba': 5910, 'gloss': 5911, 'pointless': 5912, 'pda': 5913, 'tucking': 5914, 'rcc': 5915, 'cycs': 5916, 'xsb': 5917, 'operability': 5918, 'interruptible': 5919, 'insure': 5920, 'granting': 5921, 'binarization': 5922, 'cky': 5923, 'instantaneous': 5924, 'anything': 5925, 'worth': 5926, 'crimson': 5927, 'flexrecs': 5928, 'contacts': 5929, 'belong': 5930, 'theft': 5931, 'ellipsoid': 5932, 'rankboost': 5933, 'facet': 5934, 'landscapes': 5935, 'functor': 5936, 'interpolation': 5937, 'perm': 5938, 'cpr': 5939, 'molecules': 5940, 'flaws': 5941, 'clare': 5942, 'briefings': 5943, 'protdb': 5944, 'cyclone': 5945, 'interventional': 5946, 'pull': 5947, 'rogue': 5948, 'segmental': 5949, 'jitter': 5950, 'eccles': 5951, 'achievent': 5952, 'israeli': 5953, 'neighborhoods': 5954, 'unlocking': 5955, 'awarding': 5956, 'verifiable': 5957, 'allocated': 5958, 'develop': 5959, 'tutorials': 5960, 'mariko': 5961, 'talks': 5962, 'siegfried': 5963, 'japanesegerman': 5964, 'warriors': 5965, 'phobes': 5966, 'attitude': 5967, 'easiest': 5968, 'ridl': 5969, 'bearing': 5970, 'imputing': 5971, 'spatiotemporalspatiotemporal': 5972, 'reversal': 5973, 'utile': 5974, 'distinctions': 5975, 'outside': 5976, 'chiron': 5977, 'simfusion': 5978, 'warfare': 5979, 'expanding': 5980, 'indonesian': 5981, 'pivot': 5982, 'inaccessible': 5983, 'foci': 5984, 'deadline': 5985, 'intersystem': 5986, 'gated': 5987, 'multipipeline': 5988, 'monads': 5989, 'triangle': 5990, 'utaclir': 5991, 'toponym': 5992, 'birch': 5993, 'iepad': 5994, 'collative': 5995, 'straightforward': 5996, 'xmldb': 5997, 'breakout': 5998, 'remember': 5999, 'think': 6000, 'executions': 6001, 'paintingclass': 6002, 'sometimes': 6003, 'aggregating': 6004, 'jpredictor': 6005, 'ecrins86': 6006, 'lets': 6007, 'permanent': 6008, 'transient': 6009, 'compensating': 6010, 'picodmbs': 6011, 'smartcard': 6012, 'adapters': 6013, 'tailored': 6014, 'ggraphlog': 6015, 'transpose': 6016, 'demystified': 6017, 'florida': 6018, 'vambam': 6019, 'omnidirectional': 6020, 'kc3': 6021, 'mash': 6022, 'opinionated': 6023, 'kinematic': 6024, 'articulated': 6025, 'slca': 6026, 'aptitude': 6027, 'attains': 6028, 'death': 6029, 'blast': 6030, 'guarded': 6031, 'redirection': 6032, 'gmine': 6033, 'fixing': 6034, 'inconsistencies': 6035, 'polynominal': 6036, 'packet': 6037, 'tpm': 6038, 'informality': 6039, 'boredom': 6040, 'consolidating': 6041, 'realisation': 6042, 'pachinko': 6043, 'slam': 6044, 'testtube': 6045, 'parses': 6046, 'satellites': 6047, 'knownet': 6048, 'champagne': 6049, 'tulips': 6050, 'teachable': 6051, 'axis': 6052, 'concomitant': 6053, 'medethex': 6054, 'dyc': 6055, 'javanet': 6056, 'opinionminer': 6057, 'luckiness': 6058, 'prefectching': 6059, 'aroma': 6060, 'hepatitis': 6061, 'quantities': 6062, 'visualizations': 6063, 'amateurs': 6064, 'premodifiers': 6065, 'revel8or': 6066, 'capacity': 6067, 'professionalism': 6068, 'rss': 6069, 'transtrl': 6070, 'locator': 6071, 'rethink': 6072, 'inventories': 6073, 'segmentations': 6074, 'democratic': 6075, 'lexicographic': 6076, 'consultation': 6077, 'abbreviation': 6078, 'cla': 6079, 'perturbation': 6080, 'lemma': 6081, 'subclass': 6082, 'plsi': 6083, 'bilexical': 6084, 'adaptability': 6085, 'quarks': 6086, 'combating': 6087, 'trustrank': 6088, 'air': 6089, 'goldilocks': 6090, 'opaque': 6091, 'shangri': 6092, 'recommend': 6093, 'reve': 6094, 'participatory': 6095, 'assumption': 6096, 'hierachy': 6097, 'crocopat': 6098, 'integers': 6099, 'matcher': 6100, 'vipas': 6101, 'galileo': 6102, 'unsegmented': 6103, 'our': 6104, 'stanford': 6105, 'emphasizing': 6106, 'extents': 6107, 'exposed': 6108, 'attibute': 6109, 'diversifying': 6110, 'secret': 6111, 'omissions': 6112, 'format': 6113, 'blas': 6114, 'mammography': 6115, 'isolate': 6116, 'ossd': 6117, 'ldiff': 6118, 'differencing': 6119, 'accelerometer': 6120, 'smdp': 6121, 'homomorphisms': 6122, 'residency': 6123, 'asknet': 6124, 'sytems': 6125, 'species': 6126, 'biosystematics': 6127, 'ofs': 6128, 'odp': 6129, 'sciencecraft': 6130, 'eo': 6131, 'componential': 6132, 'ergodic': 6133, 'bloom': 6134, 'tension': 6135, 'reals': 6136, 'merrier': 6137, 'mini': 6138, 'disease': 6139, 'reflexive': 6140, 'cham': 6141, 'eclipse': 6142, 'demaq': 6143, 'orion': 6144, 'postscript': 6145, 'videoreach': 6146, 'enrichment': 6147, 'misses': 6148, 'paraconsistency': 6149, 'chronologies': 6150, 'raster': 6151, 'tractability': 6152, 'fictitious': 6153, 'continuum': 6154, 'ficsr': 6155, 'eedback': 6156, 'nonistency': 6157, 'esolution': 6158, 'misaligned': 6159, 'ofcourse': 6160, 'materials': 6161, 'soat': 6162, 'peanut': 6163, 'gallery': 6164, 'assessor': 6165, 'lyapunov': 6166, 'clonetracker': 6167, 'pp': 6168, 'treebanking': 6169, 'blazing': 6170, 'lies': 6171, 'synonymy': 6172, 'eager': 6173, 'books': 6174, 'meronyms': 6175, 'unique': 6176, 'passed': 6177, 'restructure': 6178, 'entries': 6179, 'linkages': 6180, 'sql3': 6181, 'uncorrelated': 6182, 'indiana': 6183, 'purdue': 6184, 'convoy': 6185, 'movement': 6186, 'city': 6187, 'alice': 6188, 'front': 6189, 'cardinalities': 6190, 'walkthrough': 6191, 'trail': 6192, 'cutex': 6193, 'lemonade': 6194, 'bright': 6195, 'dr': 6196, 'eventtrigger': 6197, 'unibase': 6198, 'newspaper': 6199, 'xmem': 6200, 'hyperstorm': 6201, 'administering': 6202, 'convolutional': 6203, 'linkclus': 6204, 'identically': 6205, 'progxe': 6206, 'telcordias': 6207, 'unanchored': 6208, 'ignorant': 6209, 'xqbe': 6210, 'blocks': 6211, 'correlational': 6212, 'itinerary': 6213, 'beg': 6214, 'ends': 6215, 'cardio': 6216, 'vascular': 6217, 'app': 6218, 'olympic': 6219, 'equestrian': 6220, 'experiential': 6221, 'roadrunner': 6222, 'suitability': 6223, 'kinesthetic': 6224, 'documented': 6225, 'refinements': 6226, 'converter': 6227, 'semirings': 6228, 'definability': 6229, 'learns': 6230, 'piece': 6231, 'addressed': 6232, '5': 6233, 'iwpse': 6234, 'soon': 6235, 'abbreviated': 6236, 'marie': 6237, 'decoder': 6238, 'resolutions': 6239, 'membership': 6240, '1000': 6241, 'commute': 6242, 'potters': 6243, 'dsl': 6244, 'ssc2': 6245, 'skeletons': 6246, 'reproducing': 6247, 'myerson': 6248, 'satterthwaite': 6249, 'impossibility': 6250, 'unweighted': 6251, 'labelers': 6252, 'relaxations': 6253, 'selectors': 6254, 'behaviosites': 6255, 'parasitic': 6256, 'infection': 6257, 'intentions': 6258, 'invariance': 6259, 'reviewing': 6260, 'relocating': 6261, 'rerankeverything': 6262, 'mindreader': 6263, 'ultimate': 6264, 'cautious': 6265, 'surfer': 6266, 'joulesort': 6267, 'nero': 6268, 'importing': 6269, 'casting': 6270, 'accumulative': 6271, 'multicomputer': 6272, 'rework': 6273, 'yago': 6274, 'billiards': 6275, 'senseclusters': 6276, 'guesstimate': 6277, 'curing': 6278, '1tn': 6279, 'autocompletion': 6280, 'tolerate': 6281, 'linearizable': 6282, 'snowball': 6283, 'elu': 6284, 'cal': 6285, 'aggie': 6286, 'matic': 6287, 'cybersecurity': 6288, 'glory': 6289, 'contestants': 6290, 'contests': 6291, 'topcodercom': 6292, 'always': 6293, 'appc': 6294, 'enrich': 6295, 'attributio': 6296, 'hypercode': 6297, 'serv': 6298, 'seen': 6299, 'crosslinguistic': 6300, 'motivate': 6301, 'bargaining': 6302, 'become': 6303, 'disaggregation': 6304, 'webcq': 6305, 'psycho': 6306, 'engineered': 6307, 'arizona': 6308, 'tdts': 6309, 'joining': 6310, 'blackboards': 6311, 'hedged': 6312, 'purpors': 6313, 'igrid': 6314, 'gateway': 6315, 'deducing': 6316, 'truncations': 6317, 'thresher': 6318, 'unwrapping': 6319, 'wavefront': 6320, 'granular': 6321, 'braid': 6322, 'lag': 6323, 'reasonably': 6324, 'consul': 6325, 'aptness': 6326, 'cast': 6327, 'minimally': 6328, 'cleanly': 6329, 'messy': 6330, 'mv3r': 6331, 'timestamp': 6332, 'ondux': 6333, 'supersense': 6334, 'lisfs': 6335, 'mock': 6336, 'trials': 6337, 'times': 6338, 'asymptotically': 6339, 'qbf': 6340, 'anisotropic': 6341, 'xor': 6342, 'aktionsart': 6343, 'fighting': 6344, 'solvers': 6345, 'mixins': 6346, 'inclination': 6347, 'geared': 6348, 'manifest': 6349, 'separate': 6350, 'pwa': 6351, 'sssalpha': 6352, 'accounts': 6353, 'debit': 6354, 'found': 6355, 'lexnet': 6356, 'dynamical': 6357, 'basedatabase': 6358, 'appropriateness': 6359, 'handheld': 6360, 'accomodation': 6361, 'multiterm': 6362, 'mca': 6363, 'explorations': 6364, 'probabilitstic': 6365, 'vivid': 6366, 'clarity': 6367, 'delaying': 6368, 'unteachable': 6369, 'verifiers': 6370, 'ilog': 6371, 'awa': 6372, 'cassm': 6373, 'whips': 6374, 'cease': 6375, 'because': 6376, 'ignored': 6377, 'relativised': 6378, 'nba': 6379, 'multigranularity': 6380, 'fittest': 6381, 'survives': 6382, 'xcfs': 6383, 'flavers': 6384, 'negations': 6385, 'contradictions': 6386, 'vispedia': 6387, 'deficiencies': 6388, 'borders': 6389, 'neighboring': 6390, 'spot': 6391, 'compostion': 6392, 'tell': 6393, 'turnover': 6394, 'transliterations': 6395, 'schemr': 6396, 'payoff': 6397, 'xrules': 6398, 'deals': 6399, 'contingency': 6400, 'unsuspecting': 6401, 'audience': 6402, 'groupware': 6403, 'explain': 6404, 'discover': 6405, 'strips': 6406, 'realizational': 6407, 'dirt': 6408, 'sbtdiscovery': 6409, 'asynchronously': 6410, 'leaf': 6411, 'pangloss': 6412, 'hadoopdb': 6413, 'optimising': 6414, 'governed': 6415, 'calendars': 6416, 'layering': 6417, 'april': 6418, 'madbot': 6419, 'ihmms': 6420, 'cabinet': 6421, 'sprint': 6422, 'eiffel': 6423, 'conserved': 6424, 'thetenthstrand': 6425, 'ethicaldebates': 6426, 'tiling': 6427, 'checkers': 6428, 'diva': 6429, 'liptus': 6430, 'treat': 6431, 'eclectic': 6432, 'invisible': 6433, 'capital': 6434, 'relates': 6435, 'lurking': 6436, 'sake': 6437, 'themselves': 6438, 'sinhala': 6439, 'grapheme': 6440, 'phoneme': 6441, 'schwa': 6442, 'epenthesis': 6443, 'hisbase': 6444, 'priming': 6445, 'alarms': 6446, 'actionable': 6447, 'genomes': 6448, 'volatile': 6449, 'checkpoint': 6450, 'unparsing': 6451, 'rdfxml': 6452, 'homonymy': 6453, 'authorities': 6454, 'hubs': 6455, 'runways': 6456, 'extremal': 6457, 'baskets': 6458, 'singer': 6459, 'mp3': 6460, 'subregularities': 6461, 'prosody': 6462, 'friends': 6463, 'determinization': 6464, 'formulae': 6465, 'phased': 6466, 'delocalisation': 6467, 'replanning': 6468, 'attractiveness': 6469, 'multiprocessing': 6470, 'pspace': 6471, 'proximus': 6472, 'attributed': 6473, 'perceptrons': 6474, 'wam': 6475, 'contemporary': 6476, 'journals': 6477, 'immc': 6478, 'brittleness': 6479, 'blackout': 6480, 'anywhere': 6481, 'remove': 6482, 'bottlenecks': 6483, 'derbys': 6484, 'bbm': 6485, 'petabyte': 6486, 'handlinh': 6487, 'immediate': 6488, 'phishing': 6489, 'emails': 6490, 'illiterate': 6491, 'lh': 6492, 'reed': 6493, 'solomon': 6494, 'street': 6495, 'journal': 6496, 'linearizability': 6497, 'lsa': 6498, 'soundness': 6499, 'masked': 6500, 'dip': 6501, 'punctuation': 6502, 'obtaining': 6503, 'equalities': 6504, 'ask': 6505, 'groupwise': 6506, 'extremum': 6507, 'sonar': 6508, 'associationrules': 6509, 'electrical': 6510, 'ct': 6511, 'personnel': 6512, 'acceptability': 6513, 'option': 6514, 'drill': 6515, 'degrade': 6516, 'dtds': 6517, 'sie': 6518, 'obi': 6519, 'serpent': 6520, 'hungarian': 6521, 'viewsystem': 6522, 'exhibit': 6523, 'critter': 6524, 'agricultural': 6525, 'fmri': 6526, 'volcano': 6527, 'contribution': 6528, 'contra': 6529, 'xvcl': 6530, 'dot': 6531, 'watson': 6532, 'tele': 6533, 'professor': 6534, 'recorded': 6535, 'pesto': 6536, 'querybrowser': 6537, 'principals': 6538, 'oz': 6539, 'mglair': 6540, 'scaleless': 6541, 'sphere': 6542, 'semmo': 6543, 'multiplayer': 6544, 'row': 6545, 'laplace': 6546, 'albep': 6547, 'caption': 6548, 'loose': 6549, 'stand': 6550, 'synchronizable': 6551, 'preach': 6552, 'predefined': 6553, 'polarized': 6554, 'kiss': 6555, 'powers': 6556, 'aadds': 6557, 'cmu': 6558, 'rover': 6559, 'schematically': 6560, 'centralized': 6561, 'crowdreranking': 6562, 'mmtk': 6563, 'individualized': 6564, 'intensity': 6565, 'forgiving': 6566, 'cream': 6567, 'valuepetri': 6568, 'china': 6569, 'practicioners': 6570, 'managed': 6571, 'ecu': 6572, 'vindicated': 6573, 'cot': 6574, 'detecton': 6575, 'clicks': 6576, 'overfitting': 6577, 'emerge': 6578, 'verbosity': 6579, '25': 6580, 'rise': 6581, 'fall': 6582, 'salton': 6583, 'award': 6584, 'simulating': 6585, 'tactic': 6586, 'gpsm': 6587, 'dissolution': 6588, 'shiq': 6589, 'extremely': 6590, 'fibring': 6591, 'gputerasort': 6592, 'unpartitioned': 6593, 'holonic': 6594, 'pedestrian': 6595, 'rqafqi': 6596, 'indeterminate': 6597, 'constructor': 6598, 'carpediem': 6599, 'ssl': 6600, 'coarticulation': 6601, 'separable': 6602, 'ceteris': 6603, 'paribus': 6604, 'mocha': 6605, 'mirroring': 6606, 'alternating': 6607, 'jeroboam': 6608, 'epilepsy': 6609, 's3': 6610, 'xpress': 6611, 'queriable': 6612, 'textured': 6613, 'bits': 6614, 'termsets': 6615, 'dataset': 6616, 'bacteria': 6617, 'cultures': 6618, 'scattering': 6619, 'vr': 6620, 'shifts': 6621, 'samuel': 6622, 'amarel': 6623, 'cbse': 6624, 'datacycle': 6625, '1978': 6626, 'cst': 6627, 'citizens': 6628, 'psycholinguistically': 6629, 'hardness': 6630, 'ingres': 6631, 'parafac2': 6632, 'mpf': 6633, 'stars': 6634, 'coocurrences': 6635, 'import': 6636, 'limitations': 6637, 'denoising': 6638, 'autoencoders': 6639, 'tabling': 6640, 'quadrupedal': 6641, 'locomotion': 6642, 'diversification': 6643, 'multitheme': 6644, 'markovsemi': 6645, 'destinations': 6646, 'nondirectional': 6647, 'labor': 6648, 'characteristic': 6649, 'ddos': 6650, 'identified': 6651, 'reused': 6652, 'neighbourhood': 6653, 'broadband': 6654, 'v3': 6655, 'analog': 6656, 'clips': 6657, 'keypoints': 6658, 'sister': 6659, 'reclustering': 6660, '3se': 6661, 'widely': 6662, 'proclamation': 6663, 'elaborate': 6664, 'anf': 6665, 'sammie': 6666, 'rufus': 6667, 'television': 6668, 'radio': 6669, 'texas': 6670, 'aems': 6671, 'codds': 6672, 'reformulated': 6673, 'appear': 6674, 'posting': 6675, 'degradation': 6676, 'determined': 6677, 'elision': 6678, 'curio': 6679, 'reviving': 6680, 'removal': 6681, 'fertility': 6682, 'anti': 6683, 'compositions': 6684, 'voted': 6685, 'hdp': 6686, 'concentric': 6687, 'hyperspaces': 6688, 'converting': 6689, 'modula': 6690, 'labellings': 6691, 'cse': 6692, 'volunteers': 6693, 'hillsborough': 6694, 'county': 6695, 'district': 6696, 'labelling': 6697, 'transsformation': 6698, 'dolce': 6699, 'unsound': 6700, 'automateddistributed': 6701, 'multiresolution': 6702, 'mrf': 6703, 'theta': 6704, 'socially': 6705, 'here': 6706, 'pskip': 6707, 'scribble': 6708, 'alikes': 6709, 'chorochronos': 6710, 'folklore': 6711, 'confirmed': 6712, 'larger': 6713, 'widl': 6714, 'inconcert': 6715, 'archive': 6716, 'sqlmed': 6717, 'tenant': 6718, 'telephone': 6719, 'journey': 6720, 'simplifier': 6721, 'gotolessness': 6722, 'infomix': 6723, 'prague': 6724, 'mima': 6725, 'innovation': 6726, 'interim': 6727, 'acmieee': 6728, 'despite': 6729, 'imbalance': 6730, 'stress': 6731, 'realizing': 6732, 'directors': 6733, 'implication': 6734, 'factorizations': 6735, 'datajoiner': 6736, 'collecting': 6737, 'ocean': 6738, 'conservant': 6739, 'multitale': 6740, 'bookmark': 6741, 'designated': 6742, 'sash': 6743, 'sportscast': 6744, 'ancestors': 6745, 'weblab': 6746, 'hyperthesis': 6747, 'grna': 6748, 'spell': 6749, 'crops': 6750, 'soil': 6751, 'multiobjective': 6752, 'situational': 6753, 'presupposition': 6754, 'socratic': 6755, 'exegesis': 6756, 'wake': 6757, 'wlan': 6758, 'repeating': 6759, 'aries': 6760, 'intractability': 6761, 'faces': 6762, 'kap': 6763, 'greediness': 6764, 'memm': 6765, 'segregation': 6766, 'dat': 6767, 'dd': 6768, 'chameleon': 6769, 'spiteful': 6770, 'explanatory': 6771, 'xmill': 6772, 'majorization': 6773, 'instantiation': 6774, 'ailp': 6775, 'p3vi': 6776, 'mtw06': 6777, 'inequality': 6778, 'listening': 6779, 'provisions': 6780, 'operationally': 6781, 'multibuffer': 6782, 'transposition': 6783, 'compliant': 6784, 'statsnowball': 6785, 'dumber': 6786, 'speeddating': 6787, 'systematically': 6788, 'triangulation': 6789, 'plop': 6790, 'ghostdb': 6791, 'visible': 6792, 'leaks': 6793, 'continually': 6794, 'sensory': 6795, 'nico': 6796, 'habermanns': 6797, 'saps': 6798, 'nonmonotonicity': 6799, 'batching': 6800, 'rearrangement': 6801, 'bags': 6802, 'inexperienced': 6803, 'spiral': 6804, 'beat': 6805, 'queens': 6806, 'machined': 6807, 'rrxf': 6808, 'punjabi': 6809, 'speaking': 6810, 'food': 6811, 'complaints': 6812, 'ticket': 6813, 'lore': 6814, 'soquet': 6815, 'crosscutting': 6816, 'rp': 6817, 'liveclassifier': 6818, 'atis': 6819, 'leave': 6820, 'said': 6821, 'debates': 6822, 'snif': 6823, 'sniffing': 6824, 'autocorrelation': 6825, 'topographic': 6826, 'dpop': 6827, 'dcop': 6828, 'datametadata': 6829, 'append': 6830, 'emergence': 6831, 'pres': 6832, 'upside': 6833, 'drosophila': 6834, 'capping': 6835, 'judges': 6836, 'exchangeable': 6837, 'drawn': 6838, 'praire': 6839, 'databasenetwork': 6840, 'phoneticsphonology': 6841, 'u': 6842, 'bird': 6843, 'hisa': 6844, 'committees': 6845, 'understandable': 6846, 'dalí': 6847, 'quantum': 6848, 'fa': 6849, 'metamodeling': 6850, 'noticing': 6851, 'costing': 6852, 'expressed': 6853, 'crosslanguage': 6854, 'obtain': 6855, 'ciphertext': 6856, 'allophonic': 6857, 'phonotactic': 6858, 'deployers': 6859, 'vertically': 6860, 'prompt': 6861, 'coma': 6862, 'unmodified': 6863, 'browsers': 6864, 'backoff': 6865, 'administrators': 6866, 'believable': 6867, 'tourism': 6868, 'prose': 6869, 'generalizaiton': 6870, 'cafeobj': 6871, 'regularised': 6872, 'wishful': 6873, 'viable': 6874, 'handprinted': 6875, 'practicing': 6876, 'judo': 6877, 'boards': 6878, 'essays': 6879, 'jisdos': 6880, 'icp': 6881, 'nonrigid': 6882, 'equal': 6883, 'guis': 6884, 'shrex': 6885, 'appliances': 6886, 'dhts': 6887, 'j2me': 6888, 'heat': 6889, 'candidates': 6890, 'atom': 6891, 'customized': 6892, 'bundling': 6893, 'bregman': 6894, 'dpls': 6895, 'pol': 6896, 'around': 6897, 'incorporation': 6898, 'seller': 6899, 'brazilian': 6900, 'dependences': 6901, 'omega': 6902, 'galax': 6903, 'partitionings': 6904, 'hop': 6905, 'amcr': 6906, 'dispatching': 6907, 'epos': 6908, 'cope': 6909, 'byzantine': 6910, 'generals': 6911, 'magma': 6912, 'fill': 6913, 'dominating': 6914, 'profitably': 6915, 'sed': 6916, 'prf': 6917, 'lends': 6918, 'intersections': 6919, 'mis': 6920, 'dumping': 6921, 'simrank': 6922, 'clickgraph': 6923, 'unlevel': 6924, 'chronology': 6925, 'newswires': 6926, 'bleu': 6927, 'fluxplayer': 6928, 'vowels': 6929, 'quest': 6930, 'viewers': 6931, 'analogue': 6932, 'declaration': 6933, 'closer': 6934, 'wordmeanings': 6935, 'sleeved': 6936, 'coclustering': 6937, 'blacklists': 6938, 'malicious': 6939, 'escape': 6940, 'polyglot': 6941, 'interrelationship': 6942, 'avionics': 6943, 'churn': 6944, 'finalization': 6945, 'spanning': 6946, 'readings': 6947, 'writes': 6948, 'viztree': 6949, 'wakashi': 6950, 'perceptually': 6951, 'efis': 6952, 'paramodulation': 6953, 'controllable': 6954, 'osamt': 6955, 'oqlt': 6956, 'conditioned': 6957, 'ballot': 6958, 'sincerity': 6959, 'proofness': 6960, 'diophantine': 6961, 'adverbials': 6962, 'refreshment': 6963, 'diverging': 6964, 'dissimilarities': 6965, 'bea': 6966, 'chi': 6967, 'validity': 6968, 'create': 6969, 'subgroup': 6970, 'nestream': 6971, 'intuitive': 6972, 'jarap': 6973, 'semcog': 6974, 'huberized': 6975, 'visitor': 6976, 'boomerang': 6977, 'resourceful': 6978, 'lenses': 6979, 'surviving': 6980, '2nd': 6981, 'spread': 6982, 'multiparadigm': 6983, 'idefix': 6984, 'browserank': 6985, 'consideration': 6986, 'eroc': 6987, 'neato': 6988, 'hosts': 6989, 'tolerance': 6990, 'usind': 6991, 'r3': 6992, 'installations': 6993, 'anycast': 6994, 'cdns': 6995, 'ferret': 6996, 'filestore': 6997, 'stdl': 6998, 'clide': 6999, 'defection': 7000, 'calculi': 7001, 'dancing': 7002, 'dynalab': 7003, 'endearing': 7004, 'caede': 7005, 'multitasking': 7006, 'embdedded': 7007, 'traits': 7008, 'guaranteed': 7009, 'errorperformance': 7010, 'rippling': 7011, 'hub': 7012, 'groves': 7013, 'disproportionate': 7014, 'interventions': 7015, 'narrowing': 7016, 'ginga': 7017, 'multiplicative': 7018, 'tangent': 7019, 'sourcing': 7020, 'reloaded': 7021, 'encapsulated': 7022, 'smil': 7023, 'experimenting': 7024, 'revisits': 7025, 'seeding': 7026, 'underpinnings': 7027, 'taggerlemmatiser': 7028, 'collision': 7029, 'calibrated': 7030, 'maxq': 7031, 'mudular': 7032, 'workstyle': 7033, 'hotspots': 7034, 'fgp': 7035, 'kohonen': 7036, 'possibility': 7037, 'girls': 7038, 'cascades': 7039, 'forgettings': 7040, 'ariel': 7041, 'ppcp': 7042, 'clear': 7043, 'supertagging': 7044, 'claim': 7045, 'mathematicians': 7046, 'pymk': 7047, 'friend': 7048, 'myspace': 7049, 'midas': 7050, 'periods': 7051, 'distinction': 7052, 'twittermonitor': 7053, 'twitter': 7054, 'faster': 7055, 'reformulating': 7056, 'primes': 7057, 'drivers': 7058, 'assessors': 7059, 'mistakes': 7060, 'dipra': 7061, 'idef1': 7062, 'pearsons': 7063, 'considering': 7064, 'agglutinativity': 7065, 'spacing': 7066, 'correlativity': 7067, 'obliviousness': 7068, 'photo': 7069, 'hallucination': 7070, 'tioga': 7071, 'drjava': 7072, 'pedagogic': 7073, 'educating': 7074, 'superarchitects': 7075, 'min': 7076, 'disabled': 7077, 'children': 7078, 'commercially': 7079, 'prenominal': 7080, 'bet': 7081, 'humancomputer': 7082, 'things': 7083, 'pubmed': 7084, 'hopper': 7085, 'visits': 7086, 'collocated': 7087, 'ugv': 7088, 'blurring': 7089, 'produces': 7090, 'artistic': 7091, 'calligraphy': 7092, 'fred': 7093, 'csurf': 7094, 'institutional': 7095, 'multipaging': 7096, 'momis': 7097, 'ssd': 7098, 'deeds': 7099, 'thetis': 7100, 'timeout': 7101, 'judgmental': 7102, 'dewild': 7103, 'cards': 7104, 'formalizations': 7105, 'marcus': 7106, 'cxhist': 7107, 'scavenger': 7108, 'hunt': 7109, 'unranked': 7110, 'automaton': 7111, 'semrank': 7112, 'destructors': 7113, 'finalizers': 7114, 'imecho': 7115, 'writers': 7116, 'memex': 7117, 'potentiality': 7118, 'fulltext': 7119, 'retaliate': 7120, 'shooter': 7121, 'consisting': 7122, 'cfg': 7123, 'jive': 7124, 'jove': 7125, 'happens': 7126, 'retrievability': 7127, 'genesis': 7128, 'sliced': 7129, 'whirl': 7130, 'araneus': 7131, 'amount': 7132, 'disparity': 7133, 'anticipatory': 7134, 'multistage': 7135, 'weve': 7136, 'been': 7137, 'requirementsdesign': 7138, 'ucms': 7139, 'vsams': 7140, 'doritos': 7141, 'cylindrical': 7142, 'smoothed': 7143, 'rainbow': 7144, 'actiview': 7145, 'supersql': 7146, 'augmentative': 7147, 'aggregations': 7148, 'hownet': 7149, 'pardes': 7150, 'proto': 7151, 'bistratal': 7152, 'subsentential': 7153, 'regularly': 7154, 'citri': 7155, 'modifier': 7156, 'disima': 7157, 'oddessy': 7158, 'programme': 7159, 'guides': 7160, 'patchwork': 7161, 'profiled': 7162, 'datablitz': 7163, 'offline': 7164, 'maximizationminimization': 7165, 'gulf': 7166, 'deryaft': 7167, 'landmarks': 7168, 'wt10g': 7169, 'proteins': 7170, 'thou': 7171, 'shalt': 7172, 'covet': 7173, 'thy': 7174, 'cake': 7175, 'wordform': 7176, 'compounds': 7177, 'aac': 7178, 'montage': 7179, 'queryable': 7180, 'kbse': 7181, 'checkmate': 7182, 'cornering': 7183, 'checked': 7184, 'adjuncts': 7185, 'cooccurrence': 7186, 'serpentine': 7187, 'drives': 7188, 'sentinel': 7189, 'tone': 7190, 'jazzmatch': 7191, 'introducng': 7192, 'medium': 7193, 'kb': 7194, 'dj': 7195, 'fabric': 7196, 'augeas': 7197, 'authoritativeness': 7198, 'grading': 7199, 'creepy': 7200, 'desired': 7201, 'foral': 7202, 'tweeted': 7203, 'gf': 7204, 'weaker': 7205, 'universality': 7206, 'diag': 7207, '1n': 7208, 'adventures': 7209, 'thesauri': 7210, 'prompter': 7211, 'intelligibility': 7212, 'rcx': 7213, 'understand': 7214, 'qualification': 7215, 'toolset': 7216, 'tedi': 7217, 'marshaling': 7218, 'carrying': 7219, 'commitlsn': 7220, 'latching': 7221, 'synchronizer': 7222, 'ppm': 7223, 'caterogization': 7224, 'sm3': 7225, 'itaca': 7226, 'kbs': 7227, 'diluting': 7228, 'acid': 7229, 'projecting': 7230, 'weekday': 7231, 'thumbnail': 7232, 'mariposa': 7233, 'orchestral': 7234, 'accompaniment': 7235, 'lexica': 7236, 'morphologically': 7237, 'coexistence': 7238, 'reman': 7239, 'saliency': 7240, 'unconcerned': 7241, 'heritage': 7242, 'microcomputers': 7243, 'traveling': 7244, 'salesman': 7245, 'mint': 7246, 'separability': 7247, 'retieval': 7248, 'linearly': 7249, 'pagesim': 7250, 'aimilarity': 7251, 'canonical': 7252, 'permutations': 7253, 'objectives': 7254, 'governors': 7255, 'ubidata': 7256, 'expertconsultation': 7257, 'kl': 7258, 'butterfly\\x99': 7259, 'pulse': 7260, 'testo': 7261, 'ag': 7262, 'proteome': 7263, 'analyst': 7264, 'seeded': 7265, 'codebooks': 7266, 'habitats': 7267, 'adam': 7268, 'fad': 7269, 'untyped': 7270, 'degraded': 7271, 'adaptively': 7272, 'arbitrarily': 7273, 'gaining': 7274, 'tour': 7275, 'retroactive': 7276, 'namur': 7277, 'retrievals': 7278, 'hifi': 7279, 'fan': 7280, 'introduce': 7281, 'coral': 7282, 'unite': 7283, 'mhp': 7284, 'idtv': 7285, 'presentable': 7286, 'underspecified': 7287, 'cascade': 7288, 'detectors': 7289, 'ranks': 7290, 'generalising': 7291, 'recapture': 7292, 'equijoins': 7293, 'apt': 7294, 'ois': 7295, 'numeral': 7296, 'episodic': 7297, 'iv': 7298, 'shuttle': 7299, 'tscan': 7300, 'fluency': 7301, 'tasking': 7302, 'emt': 7303, 'imperfectly': 7304, 'xtag': 7305, 'metarules': 7306, 'nexusscout': 7307, 'symmetries': 7308, 'neat': 7309, 'storytelling': 7310, 'margins': 7311, 'incoherent': 7312, 'degress': 7313, 'liquid': 7314, 'schedulable': 7315, 'daml': 7316, 'received': 7317, 'amazoncom': 7318, 'helpfulness': 7319, 'gpgpu': 7320, 'subtransitive': 7321, 'agreement': 7322, 'mearf': 7323, 'stencils': 7324, 'bengali': 7325, 'greek': 7326, 'deciding': 7327, 'stateless': 7328, 'pigeons': 7329, 'abducing': 7330, 'conclusions': 7331, 'split': 7332, 'clocks': 7333, 'thoughts': 7334, 'octopus': 7335, 'modality': 7336, 'planck': 7337, 'institute': 7338, 'iconism': 7339, 'gains': 7340, 'scheduled': 7341, 'revi': 7342, 'warranty': 7343, 'goodwill': 7344, 'rdfpeers': 7345, 'ur': 7346, 'metaprogramming': 7347, 'deixis': 7348, 'aspectj': 7349, 'formats': 7350, 'chatbot': 7351, 'forums': 7352, 'fruit': 7353, 'embryo': 7354, 'webcrow': 7355, 'crossword': 7356, 'everyday': 7357, 'sketches': 7358, 'neuroscience': 7359, 'semiparametric': 7360, 'concatenation': 7361, 'precursor': 7362, 'traveler': 7363, 'multiversioned': 7364, 'shedding': 7365, 'generalisation': 7366, 'distortion': 7367, 'pape': 7368, 'printing': 7369, 'congestion': 7370, 'existentially': 7371, 'shine': 7372, 'id3': 7373, 'authentic': 7374, 'chat': 7375, 'room': 7376, 'recovered': 7377, 'proximal': 7378, 'rounding': 7379, 'geoplot': 7380, 'knowing': 7381, 'topicrank': 7382, 'bluetooth': 7383, 'nesting': 7384, 'football': 7385, 'moses': 7386, 'arisenisr': 7387, 'sharc': 7388, 'completing': 7389, 'dvss': 7390, 'ionterfaces': 7391, 'visibly': 7392, 'cell': 7393, 'sounding': 7394, 'unpacking': 7395, 'bioscience': 7396, 'opac': 7397, 'permit': 7398, 'disciplines': 7399, 'catalogue': 7400, 'icons': 7401, 'objecttask': 7402, 'imds': 7403, 'swoogle': 7404, 'naos': 7405, 'datascope': 7406, 'spices': 7407, 'murax': 7408, 'mix': 7409, 'domino': 7410, 'undertow': 7411, 'tms': 7412, 'ebay': 7413, 'docqs': 7414, 'aqax': 7415, 'randomised': 7416, 'interpretable': 7417, 'cops': 7418, 'gila': 7419, 'aggregaterank': 7420, 'men': 7421, 'richer': 7422, 'psychological': 7423, 'patches': 7424, 'isis': 7425, 'customizability': 7426, 'c2': 7427, 'matchbox': 7428, 'patr': 7429, 'commutativity': 7430, 'cmic': 7431, 'anchors': 7432, 'shot': 7433, 'tense': 7434, 'crf': 7435, 'opt': 7436, 'extend': 7437, 'conventional': 7438, 'sided': 7439, 'outerjoin': 7440, 'computationally': 7441, 'bdi': 7442, 'smoqe': 7443, 'fist': 7444, 'korat': 7445, 'winners': 7446, 'listwise': 7447, 'unfolding': 7448, 'submodular': 7449, 'gold': 7450, 'classifications': 7451, 'snugglebug': 7452, 'simulate': 7453, 'tangram': 7454, 'recom': 7455, 'vgm': 7456, 'khufu': 7457, 'generativediscriminative': 7458, 'javaxxxl': 7459, 'semdiff': 7460, 'att': 7461, 'netweaver': 7462, 'graphplans': 7463, 'maybms': 7464, 'clustra': 7465, 'telecom': 7466, 'hodfa': 7467, 'homogenizing': 7468, 'kdms': 7469, 'krisys': 7470, 'csv': 7471, 'datacubes': 7472, 'planetary': 7473, 'webml': 7474, 'vip': 7475, 'vml': 7476, 'underrepresented': 7477, 'multicriteria': 7478, 'blosom': 7479, 'reconsidered': 7480, 'bordaconsensus': 7481, 'calin': 7482, 'logarithmic': 7483, 'assertional': 7484, 'munin': 7485, 'electromyographic': 7486, 'findings': 7487, 'nooksack': 7488, 'falls': 7489, 'hydroelectric': 7490, 'station': 7491, 'xanadue': 7492, 'arity': 7493, 'kalman': 7494, 'iliad': 7495, 'oklahoma': 7496, 'fetching': 7497, 'nondeterminism': 7498, 'shadowing': 7499, 'ware': 7500, 'vibe': 7501, 'geotagged': 7502, 'inexpressivity': 7503, 'monad': 7504, 'transformers': 7505, 'myportal': 7506, 'kaleidoscope': 7507, 'menu': 7508, 'vimsys': 7509, 'aptly': 7510, 'summarizatiion': 7511, 'gai': 7512, 'tomita': 7513, 'exquex': 7514, 'geoenvironmental': 7515, 'mismatched': 7516, 'turn': 7517, 'demonstrations': 7518, 'citations': 7519, 'oracles': 7520, 'triples': 7521, 'subscribed': 7522, 'proportion': 7523, 'transportation': 7524, 'raw': 7525, 'forgotten': 7526, 'connective': 7527, 'loaded': 7528, 'xel': 7529, 'hollands': 7530, 'congruence': 7531, 'considered': 7532, 'graduated': 7533, 'exposure': 7534, 'zoning': 7535, 'chemistry': 7536, 'matchmaking': 7537, 'posts': 7538, 'synchronizing': 7539, 'illustrated': 7540, 'er': 7541, 'twicpen': 7542, 'held': 7543, 'scanner': 7544, 'rete': 7545, 'inclusions': 7546, 'textmole': 7547, 'reconstructive': 7548, 'hyperlink': 7549, 'eventually': 7550, 'kit': 7551, 'hyspirit': 7552, 'picky': 7553, 'dsps': 7554, 'cssv': 7555, 'overflows': 7556, 'recsplorer': 7557, 'demeter': 7558, 'keyphrases': 7559, 'fashion': 7560, 'wearable': 7561, 'ddc': 7562, 'genres': 7563, 'lisp7o': 7564, '40': 7565, 'i4e': 7566, 'genie': 7567, 'raising': 7568, 'directionality': 7569, 'clash': 7570, 'intuitions': 7571, 'basenp': 7572, 'vulnerabilities': 7573, 'besoins': 7574, 'lexicaux': 7575, 'lumiere': 7576, 'lanalyse': 7577, 'statistique': 7578, 'projet': 7579, 'bref': 7580, 'bdlex': 7581, 'francais': 7582, 'ecrit': 7583, 'et': 7584, 'oral': 7585, 'crafted': 7586, 'cocqa': 7587, 'eurotra': 7588, 'factorizing': 7589, 'ipodlinux': 7590, 'os': 7591, 'penalties': 7592, 'hyperparamodulation': 7593, 'cleansing': 7594, 'crowded': 7595, 'cooccurance': 7596, 'majic': 7597, 'matlab': 7598, 'responsiveness': 7599, 'rebuild': 7600, 'inquiry': 7601, 'broader': 7602, 'recycling': 7603, 'axiom': 7604, 'failsafe': 7605, 'floor': 7606, 'ebg': 7607, 'limeds': 7608, 'lincks': 7609, 'delayre': 7610, 'eracer': 7611, 'miniconference': 7612, 'paraphraser': 7613, 'entityrank': 7614, 'directly': 7615, 'holistically': 7616, 'cgi': 7617, 'modperl': 7618, 'plangoal': 7619, 'postprocessing': 7620, 'laminar': 7621, 'lifestyle': 7622, 'ilsa': 7623, 'idbd': 7624, 'dbtg': 7625, 'monitors': 7626, 'clir': 7627, 'unsuccessful': 7628, 'expedite': 7629, 'encoded': 7630, 'acquire': 7631, 'investigaton': 7632, 'competitions': 7633, 'sell': 7634, 'conditionally': 7635, 'advertisement': 7636, 'popfed': 7637, 'instace': 7638, 'amn': 7639, '2d': 7640, 'laser': 7641, 'memoizer': 7642, 'supports': 7643, 'ict': 7644, 'enriched': 7645, 'limit': 7646, 'spirit': 7647, 'diagnoses': 7648, 'terraserver': 7649, 'barriers': 7650, 'widespread': 7651, 'pbfilter': 7652, 'tirs': 7653, 'waller': 7654, 'kraft': 7655, 'wish': 7656, 'triplet': 7657, 'targeting': 7658, 'regional': 7659, 'promise': 7660, 'perils': 7661, 'likelihoods': 7662, 'dictations': 7663, 'bind': 7664, 'them': 7665, 'topx': 7666, 'dare': 7667, 'weathra': 7668, 'interrupt': 7669, 'teacher': 7670, 'honorifics': 7671, 'recur': 7672, 'equation': 7673, 'dm': 7674, 'pict': 7675, 'overloading': 7676, 'ccgs': 7677, 'raised': 7678, 'stereotrust': 7679, 'taxonomical': 7680, 'featureide': 7681, 'apprentice': 7682, 'scsl': 7683, 'sox': 7684, 'insite': 7685, 'demon': 7686, 'authorization': 7687, 'lotos': 7688, 'doc': 7689, 'prob': 7690, 'maxn': 7691, 'brained': 7692, 'morphing': 7693, 'rhode': 7694, 'audiovideo': 7695, 'boosts': 7696, 'sac': 7697, 'cleanliness': 7698, 'cdn': 7699, 'zones': 7700, 'comes': 7701, '94': 7702, 'tpr': 7703, 'altricial': 7704, 'precocial': 7705, 'intro': 7706, 'compatibilities': 7707, 'synonym': 7708, 'diabetic': 7709, 'cuber': 7710, 'nodose': 7711, 'subsystems': 7712, 'spectroscopy': 7713, 'eigenspaces': 7714, 'morpheus': 7715, 'mugi': 7716, 'wap': 7717, 'restore': 7718, 'detective': 7719, 'defeating': 7720, 'enforced': 7721, 'xtream': 7722, 'hdsampler': 7723, 'teleputing': 7724, 'corev': 7725, 'averaged': 7726, 'mlcs': 7727, 'urdu': 7728, 'tinycasper': 7729, 'routes': 7730, 'perpetual': 7731, 'cc2001': 7732, 'cited': 7733, 'inection': 7734, 'quantized': 7735, 'parsercompiler': 7736, 'v8': 7737, '4': 7738, 'sintesi': 7739, 'honesty': 7740, 'marketplaces': 7741, 'nonemptiness': 7742, 'scannerless': 7743, 'nslr1': 7744, 'recognizers': 7745, 'lmrp': 7746, 'quickstart': 7747, 'ltrules': 7748, 'rose': 7749, 'retail': 7750, 'outlet': 7751, 'precomputed': 7752, 'mss': 7753, 'mus': 7754, 'thanks': 7755, 'cyberwar': 7756, 'harmless': 7757, 'arsa': 7758, 'impediments': 7759, 'ops5': 7760, 'undesired': 7761, 'anonymization': 7762, 'grammer': 7763, 'newsgroups': 7764, 'arising': 7765, 'invert': 7766, 'guidance': 7767, 'realism': 7768, 'hrdm': 7769, 'lifespans': 7770, 'polyphonic': 7771, 'surrogates': 7772, 'comprehensions': 7773, 'tradeoff': 7774, 'unpredictable': 7775, 'loanwords': 7776, 'leaming': 7777, 'yoopick': 7778, 'sports': 7779, 'arcs': 7780, 'rapidly': 7781, '2pxminer': 7782, 'openrulebench': 7783, 'presenter': 7784, 'lecturing': 7785, 'hugin': 7786, 'universes': 7787, 'phrasetable': 7788, 'medians': 7789, 'insanity': 7790, 'himotoki': 7791, 'diagonal': 7792, 'nightmare': 7793, 'mlisp2': 7794, 'multifractals': 7795, 'nonmontonic': 7796, 'exploit': 7797, 'traitor': 7798, 'comprehensible': 7799, 'fzi': 7800, 'karlsruhe': 7801, 'dfr': 7802, 'setups': 7803, 'satisficing': 7804, 'prisoner': 7805, 'webquilt': 7806, 'offics': 7807, 'telling': 7808, 'toggle': 7809, 'pebm': 7810, 'homomorphism': 7811, 'downward': 7812, 'upward': 7813, 'cfls': 7814, 'stencil': 7815, 'distinctness': 7816, 'dqp': 7817, 'sybase': 7818, 'ase': 7819, 'congolog': 7820, 'investigations': 7821, 'marriage': 7822, 'indexation': 7823, 'lapprentissage': 7824, 'pronomial': 7825, 'mud': 7826, 'damage': 7827, 'quarantine': 7828, 'mission': 7829, 'minesweeper': 7830, 'cocoviz': 7831, 'ambient': 7832, 'vizql': 7833, 'simdb': 7834, 'replies': 7835, 'truth': 7836, 'contextualization': 7837, 'unorganized': 7838, 'empower': 7839, 'privileged': 7840, 'bantu': 7841, 'untagged': 7842, 'psychsim': 7843, 'threat': 7844, 'dcube': 7845, 'penalty': 7846, 'wa': 7847, 'disguised': 7848, 'encounter': 7849, 'symbols': 7850, 'spilling': 7851, 'cws': 7852, 'dec': 7853, 'colorful': 7854, 'factorisation': 7855, 'diffuse': 7856, 'failing': 7857, 'hearsay': 7858, 'reallocation': 7859, 'cpm': 7860, 'wlans': 7861, 'deadliner': 7862, 'niche': 7863, 'velodrome': 7864, 'avoid': 7865, 'drastic': 7866, 'sequentially': 7867, 'numericalvectors': 7868, 'published': 7869, 'confluence': 7870, 'guaranteeing': 7871, 'mangers': 7872, 'weblog': 7873, 'synthesized': 7874, 'dispositions': 7875, 'converses': 7876, 'pumping': 7877, 'lemmas': 7878, 'forth': 7879, 'tuple': 7880, 'homogeneity': 7881, '7': 7882, 'wdas': 7883, '2006': 7884, 'frontal': 7885, 'print': 7886, 'feistel': 7887, 'six': 7888, 'rounds': 7889, 'equip': 7890, 'tourists': 7891, 'travelogues': 7892, 'prepare': 7893, 'martlet': 7894, 'abstracted': 7895, 'parallelisation': 7896, 'inc': 7897, 'rubric': 7898, 'longitudinal': 7899, 'tagmark': 7900, 'estimations': 7901, 'chianti': 7902, 'essay': 7903, 'printed': 7904, 'twigs': 7905, 'undecidable': 7906, 'rdbvms': 7907, 'skeleton': 7908, 'forensics': 7909, 'permanents': 7910, 'polytopes': 7911, 'multidisciplinary': 7912, 'youtube': 7913, 'spc': 7914, 'cwb': 7915, 'interchangeabilities': 7916, 'resolve': 7917, 'venture': 7918, 'threesomes': 7919, 'blame': 7920, 'methodical': 7921, 'fasttrack': 7922, 'tenth': 7923, 'dolap07': 7924, 'fcvw': 7925, 'plug': 7926, 'csd': 7927, 'uoc': 7928, 'inconsisent': 7929, 'revising': 7930, 'seth': 7931, 'gc': 7932, 'themed': 7933, 'ilp': 7934, 'compressive': 7935, 'solo': 7936, 'orthosis': 7937, 'trio': 7938, 'perturb': 7939, 'interruptable': 7940, 'career': 7941, 'disentangling': 7942, 'called': 7943, 'punctuality': 7944, 'hierarchyscan': 7945, 'flexpath': 7946, 'surveys': 7947, 'autotagging': 7948, 'closurize': 7949, 'concentrate': 7950, 'magical': 7951, 'coil': 7952, 'cognate': 7953, 'orthography': 7954, 'workfile': 7955, 'mergesorts': 7956, 'dignosis': 7957, 'alibi': 7958, 'timestamping': 7959, 'wiser': 7960, 'deliberative': 7961, 'apprenticeship': 7962, 'meme': 7963, 'cycle': 7964, 'advantage': 7965, 'nf': 7966, 'bucket': 7967, 'voronoi': 7968, 'ditributed': 7969, 'raddle': 7970, 'consultant': 7971, 'lid': 7972, 'never': 7973, 'spotfire': 7974, 'ale': 7975, 'assume': 7976, 'svd': 7977, 'houston': 7978, 'oxygen': 7979, 'tank': 7980, 'ariesim': 7981, 'broken': 7982, 'plural': 7983, 'billion': 7984, 'synthetic': 7985, 'embeddings': 7986, 'extenders': 7987, 'restart': 7988, 'flattening': 7989, 'grocery': 7990, 'merits': 7991, 'smallest': 7992, 'lcas': 7993, 'humanoid': 7994, 'taming': 7995, 'gemini': 7996, 'funnel': 7997, 'advertisers': 7998, 'marion': 7999, 'retargetable': 8000, 'networkweb': 8001, 'others': 8002, 'esp': 8003, 'nombank': 8004, 'quota': 8005, 'statement': 8006, 'dlv': 8007, 'agora': 8008, 'atm': 8009, 'queuing': 8010, 'dely': 8011, 'collected': 8012, 'pmi': 8013, 'noncorrecting': 8014, 'cubeexplorer': 8015, 'partitional': 8016, 'simplify': 8017, 'deckard': 8018, 'transcription': 8019, 'opium': 8020, 'installuninstall': 8021, 'generational': 8022, 'validator': 8023, 'grassmann': 8024, 'preferable': 8025, 'zooming': 8026, 'gameboy': 8027, 'homebrew': 8028, 'metho': 8029, 'metaclasses': 8030, 'provisioning': 8031, 'unreliable': 8032, 'proposing': 8033, 'substitutability': 8034, 'csiec': 8035, 'bootstrapped': 8036, 'codecrawler': 8037, 'pepsys': 8038, 'ntjfsatnot': 8039, 'downdate': 8040, 'paid': 8041, 'commands': 8042, 'diet': 8043, 'foks': 8044, 'scavenging': 8045, 'concerning': 8046, 'purposeful': 8047, 'dossier': 8048, 'contraints': 8049, 'alen': 8050, 'imperatives': 8051, 'calculating': 8052, 'quirky': 8053, 'sor': 8054, 'sagas': 8055, 'navigations': 8056, 'hinting': 8057, 'indexable': 8058, 'pla': 8059, 'alphanumeric': 8060, 'nlhe': 8061, 'village': 8062, 'conways': 8063, 'datasplash': 8064, 'bagger': 8065, 'extends': 8066, 'generalizes': 8067, 'pasta': 8068, '3s': 8069, 'watermarking': 8070, 'brooklyn': 8071, 'teenage': 8072, 'persons': 8073, 'dementia': 8074, 'cognitively': 8075, 'describe': 8076, 'rigel': 8077, 'prospective': 8078, 'assumeguarantee': 8079, 'verisoft': 8080, 'isomorphic': 8081, 'montague': 8082, 'restarting': 8083, 'codesign': 8084, 'replicator': 8085, 'odesew': 8086, 'pddl': 8087, 'naturally': 8088, 'provable': 8089, 'ituned': 8090, 'lost': 8091, 'gpu': 8092, 'socializing': 8093, 'uksearch': 8094, 'storylines': 8095, 'reality': 8096, 'leadership': 8097, 'metareasoning': 8098, 'orden': 8099, 'volatility': 8100, 'empowering': 8101, 'millenium': 8102, 'mad': 8103, 'abe': 8104, 'selectional': 8105, 'hps': 8106, 'xas': 8107, 'componentized': 8108, 'lexemes': 8109, 'idarex': 8110, 'discernment': 8111, 'reconnaissance': 8112, 'worldwide': 8113, 'telescope': 8114, 'scramble': 8115, 'encrypt': 8116, 'falcon': 8117, 'psr': 8118, 'jkarelrobot': 8119, 'monologue': 8120, 'accadian': 8121, 'mul': 8122, 'green': 8123, 'illustration': 8124, 'corel': 8125, 'pipe': 8126, 'fork': 8127, 'resoution': 8128, 'danaphore': 8129, 'partir': 8130, 'dun': 8131, 'grammaire': 8132, 'verbes': 8133, 'anaphoriques': 8134, 'sparsely': 8135, 'btrees': 8136, 'x86': 8137, 'mrd': 8138, 'mistake': 8139, 'sending': 8140, 'capable': 8141, 'federations': 8142, 'immigration': 8143, 'bolasso': 8144, 'maintainers': 8145, 'utilize': 8146, 'tpc': 8147, 'knapsack': 8148, 'sg': 8149, 'ternary': 8150, 'kda': 8151, 'chaotic': 8152, 'expense': 8153, 'reimbursement': 8154, 'subroutines': 8155, 'goethe': 8156, 'hypersurfaces': 8157, 'quantity': 8158, 'hyperspread': 8159, 'cbir': 8160, 'elicitation': 8161, 'sampler': 8162, 'dp': 8163, 'multikey': 8164, 'quad': 8165, 'password': 8166, 'stretching': 8167, 'salts': 8168, '3dstring': 8169, 'voxelized': 8170, 'recognizer': 8171, 'garlic': 8172, 'flavor': 8173, 'duping': 8174, 'quasigroup': 8175, 'fostering': 8176, 'niagaracq': 8177, 'rendered': 8178, 'doodle': 8179, 'persuasive': 8180, 'aod': 8181, 'tiie': 8182, 'hal': 8183, 'sprinkling': 8184, 'yields': 8185, 'restoring': 8186, 'interpretive': 8187, 'weiner': 8188, 'presenting': 8189, 'microkernels': 8190, 'submodule': 8191, 'nitpick': 8192, 'clearing': 8193, 'quotations': 8194, 'inserted': 8195, 'arena': 8196, 'bodies': 8197, 'infusion': 8198, 'fidelity': 8199, 'imposition': 8200, 'trick': 8201, 'rpref': 8202, 'bpref': 8203, 'chaining': 8204, 'due': 8205, 'ccured': 8206, 'retrofitting': 8207, 'asilomar': 8208, 'isolating': 8209, 'claremont': 8210, 'passwords': 8211, 'absence': 8212, 'cursive': 8213, 'charting': 8214, 'depths': 8215, 'bdd': 8216, 'polytime': 8217, 'schedulers': 8218, 'planarisation': 8219, 'stl': 8220, 'sardsrn': 8221, 'winnowing': 8222, 'subexpression': 8223, 'unknowns': 8224, 'prevent': 8225, 'stages': 8226, 'horizontally': 8227, 'rings': 8228, 'misconfigured': 8229, 'quantative': 8230, 'trackers': 8231, 'mercy': 8232, 'sector': 8233, 'turings': 8234, 'dream': 8235, 'sndocrank': 8236, 'parsetalk': 8237, 'nonrecursive': 8238, 'heavy': 8239, 'tailed': 8240, 'dewey': 8241, 'gp': 8242, 'lvm': 8243, 'dempster': 8244, 'shafers': 8245, 'mirror': 8246, 'moby': 8247, 'disco': 8248, 'novo': 8249, 'gogo': 8250, 'mallows': 8251, 'tge': 8252, 'tlinks': 8253, 'legged': 8254, 'spicy': 8255, 'chomsky': 8256, 'diderichsen': 8257, 'progressing': 8258, 'sim': 8259, 'biases': 8260, 'keyhole': 8261, 'robotstxt': 8262, 'mpsocs': 8263, 'comment': 8264, 'undirected': 8265, 'sgl': 8266, 'asymmetrically': 8267, 'collocational': 8268, 'unconditional': 8269, 'jumps': 8270, 'stick': 8271, 'i11': 8272, 'replicability': 8273, 'peg': 8274, 'towers': 8275, 'hanoi': 8276, 'grabber': 8277, 'quickstore': 8278, 'curb': 8279, 'circumspective': 8280, 'inclusive': 8281, 'myopia': 8282, 'hill': 8283, 'sessionlock': 8284, 'eavesdropping': 8285, 'engagement': 8286, 'egs': 8287, 'kana': 8288, 'expressional': 8289, 'uninteresting': 8290, 'pdl': 8291, 'datapath': 8292, 'revisted': 8293, 'projectron': 8294, 'portlet': 8295, 'tbt': 8296, 'interating': 8297, 'normalisation': 8298, 'sums': 8299, 'customes': 8300, 'port': 8301, 'singapore': 8302, 'psa': 8303, 'dualising': 8304, 'chess': 8305, 'quiescene': 8306, 'sacrifices': 8307, 'ransac': 8308, 'cylinders': 8309, 'ball': 8310, 'lham': 8311, '8': 8312, 'flowgraphs': 8313, 'tensorial': 8314, 'flick': 8315, 'idl': 8316, 'graphscope': 8317, 'lean': 8318, 'alep': 8319, 'approximators': 8320, 'redesign': 8321, 'routines': 8322, 'concernlines': 8323, 'occurring': 8324, 'erknn': 8325, 'behaved': 8326, 'schemata': 8327, 'psiphi': 8328, 'norm': 8329, 'locus': 8330, 'ray': 8331, 'forces': 8332, 'mbrs': 8333, 'rhythms': 8334, 'megaprogramming': 8335, 'once': 8336, 'kemeny': 8337, 'eigentransfer': 8338, 'combinatorical': 8339, 'queues': 8340, 'asp': 8341, 'initiator': 8342, 'gateways': 8343, 'mr': 8344, 'substrings': 8345, 'lrk': 8346, 'graduating': 8347, 'beamforming': 8348, 'destructive': 8349, 'bot': 8350, 'instantiating': 8351, 'coefficients': 8352, 'senselearner': 8353, 'bushy': 8354, 'mereology': 8355, 'modularized': 8356, 'feasible': 8357}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY4q9YOqEKL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_len2 = len(word2index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzJRiadPJemu",
        "colab_type": "text"
      },
      "source": [
        "#### Getting pre-trained Word2Vec by Google\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc0hG4Lq8j7n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://drive.google.com/open?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
        "# !wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4l80j238yRo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "e0478f74-560b-441c-8f30-4de4d20a00e3"
      },
      "source": [
        "# !unzip GoogleNews-vectors-negative300.bin.gz # does not work"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  GoogleNews-vectors-negative300.bin.gz\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of GoogleNews-vectors-negative300.bin.gz or\n",
            "        GoogleNews-vectors-negative300.bin.gz.zip, and cannot find GoogleNews-vectors-negative300.bin.gz.ZIP, period.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKLjoCdS96Wh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from gensim import models - DOES NOT WORK\n",
        "\n",
        "# w = models.KeyedVectors.load_word2vec_format(\n",
        "#     '../GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Jis-OXaAC1d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "d1b6d1b5-5667-4063-c2df-67e0aafb6eff"
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "wv = api.load('word2vec-google-news-300')\n",
        "\n",
        "vec_king = wv['king']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl7XVSCfDjGs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1a877543-cb92-4dd6-f2b6-b86eb5b5bc41"
      },
      "source": [
        "wv['king']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.25976562e-01,  2.97851562e-02,  8.60595703e-03,  1.39648438e-01,\n",
              "       -2.56347656e-02, -3.61328125e-02,  1.11816406e-01, -1.98242188e-01,\n",
              "        5.12695312e-02,  3.63281250e-01, -2.42187500e-01, -3.02734375e-01,\n",
              "       -1.77734375e-01, -2.49023438e-02, -1.67968750e-01, -1.69921875e-01,\n",
              "        3.46679688e-02,  5.21850586e-03,  4.63867188e-02,  1.28906250e-01,\n",
              "        1.36718750e-01,  1.12792969e-01,  5.95703125e-02,  1.36718750e-01,\n",
              "        1.01074219e-01, -1.76757812e-01, -2.51953125e-01,  5.98144531e-02,\n",
              "        3.41796875e-01, -3.11279297e-02,  1.04492188e-01,  6.17675781e-02,\n",
              "        1.24511719e-01,  4.00390625e-01, -3.22265625e-01,  8.39843750e-02,\n",
              "        3.90625000e-02,  5.85937500e-03,  7.03125000e-02,  1.72851562e-01,\n",
              "        1.38671875e-01, -2.31445312e-01,  2.83203125e-01,  1.42578125e-01,\n",
              "        3.41796875e-01, -2.39257812e-02, -1.09863281e-01,  3.32031250e-02,\n",
              "       -5.46875000e-02,  1.53198242e-02, -1.62109375e-01,  1.58203125e-01,\n",
              "       -2.59765625e-01,  2.01416016e-02, -1.63085938e-01,  1.35803223e-03,\n",
              "       -1.44531250e-01, -5.68847656e-02,  4.29687500e-02, -2.46582031e-02,\n",
              "        1.85546875e-01,  4.47265625e-01,  9.58251953e-03,  1.31835938e-01,\n",
              "        9.86328125e-02, -1.85546875e-01, -1.00097656e-01, -1.33789062e-01,\n",
              "       -1.25000000e-01,  2.83203125e-01,  1.23046875e-01,  5.32226562e-02,\n",
              "       -1.77734375e-01,  8.59375000e-02, -2.18505859e-02,  2.05078125e-02,\n",
              "       -1.39648438e-01,  2.51464844e-02,  1.38671875e-01, -1.05468750e-01,\n",
              "        1.38671875e-01,  8.88671875e-02, -7.51953125e-02, -2.13623047e-02,\n",
              "        1.72851562e-01,  4.63867188e-02, -2.65625000e-01,  8.91113281e-03,\n",
              "        1.49414062e-01,  3.78417969e-02,  2.38281250e-01, -1.24511719e-01,\n",
              "       -2.17773438e-01, -1.81640625e-01,  2.97851562e-02,  5.71289062e-02,\n",
              "       -2.89306641e-02,  1.24511719e-02,  9.66796875e-02, -2.31445312e-01,\n",
              "        5.81054688e-02,  6.68945312e-02,  7.08007812e-02, -3.08593750e-01,\n",
              "       -2.14843750e-01,  1.45507812e-01, -4.27734375e-01, -9.39941406e-03,\n",
              "        1.54296875e-01, -7.66601562e-02,  2.89062500e-01,  2.77343750e-01,\n",
              "       -4.86373901e-04, -1.36718750e-01,  3.24218750e-01, -2.46093750e-01,\n",
              "       -3.03649902e-03, -2.11914062e-01,  1.25000000e-01,  2.69531250e-01,\n",
              "        2.04101562e-01,  8.25195312e-02, -2.01171875e-01, -1.60156250e-01,\n",
              "       -3.78417969e-02, -1.20117188e-01,  1.15234375e-01, -4.10156250e-02,\n",
              "       -3.95507812e-02, -8.98437500e-02,  6.34765625e-03,  2.03125000e-01,\n",
              "        1.86523438e-01,  2.73437500e-01,  6.29882812e-02,  1.41601562e-01,\n",
              "       -9.81445312e-02,  1.38671875e-01,  1.82617188e-01,  1.73828125e-01,\n",
              "        1.73828125e-01, -2.37304688e-01,  1.78710938e-01,  6.34765625e-02,\n",
              "        2.36328125e-01, -2.08984375e-01,  8.74023438e-02, -1.66015625e-01,\n",
              "       -7.91015625e-02,  2.43164062e-01, -8.88671875e-02,  1.26953125e-01,\n",
              "       -2.16796875e-01, -1.73828125e-01, -3.59375000e-01, -8.25195312e-02,\n",
              "       -6.49414062e-02,  5.07812500e-02,  1.35742188e-01, -7.47070312e-02,\n",
              "       -1.64062500e-01,  1.15356445e-02,  4.45312500e-01, -2.15820312e-01,\n",
              "       -1.11328125e-01, -1.92382812e-01,  1.70898438e-01, -1.25000000e-01,\n",
              "        2.65502930e-03,  1.92382812e-01, -1.74804688e-01,  1.39648438e-01,\n",
              "        2.92968750e-01,  1.13281250e-01,  5.95703125e-02, -6.39648438e-02,\n",
              "        9.96093750e-02, -2.72216797e-02,  1.96533203e-02,  4.27246094e-02,\n",
              "       -2.46093750e-01,  6.39648438e-02, -2.25585938e-01, -1.68945312e-01,\n",
              "        2.89916992e-03,  8.20312500e-02,  3.41796875e-01,  4.32128906e-02,\n",
              "        1.32812500e-01,  1.42578125e-01,  7.61718750e-02,  5.98144531e-02,\n",
              "       -1.19140625e-01,  2.74658203e-03, -6.29882812e-02, -2.72216797e-02,\n",
              "       -4.82177734e-03, -8.20312500e-02, -2.49023438e-02, -4.00390625e-01,\n",
              "       -1.06933594e-01,  4.24804688e-02,  7.76367188e-02, -1.16699219e-01,\n",
              "        7.37304688e-02, -9.22851562e-02,  1.07910156e-01,  1.58203125e-01,\n",
              "        4.24804688e-02,  1.26953125e-01,  3.61328125e-02,  2.67578125e-01,\n",
              "       -1.01074219e-01, -3.02734375e-01, -5.76171875e-02,  5.05371094e-02,\n",
              "        5.26428223e-04, -2.07031250e-01, -1.38671875e-01, -8.97216797e-03,\n",
              "       -2.78320312e-02, -1.41601562e-01,  2.07031250e-01, -1.58203125e-01,\n",
              "        1.27929688e-01,  1.49414062e-01, -2.24609375e-02, -8.44726562e-02,\n",
              "        1.22558594e-01,  2.15820312e-01, -2.13867188e-01, -3.12500000e-01,\n",
              "       -3.73046875e-01,  4.08935547e-03,  1.07421875e-01,  1.06933594e-01,\n",
              "        7.32421875e-02,  8.97216797e-03, -3.88183594e-02, -1.29882812e-01,\n",
              "        1.49414062e-01, -2.14843750e-01, -1.83868408e-03,  9.91210938e-02,\n",
              "        1.57226562e-01, -1.14257812e-01, -2.05078125e-01,  9.91210938e-02,\n",
              "        3.69140625e-01, -1.97265625e-01,  3.54003906e-02,  1.09375000e-01,\n",
              "        1.31835938e-01,  1.66992188e-01,  2.35351562e-01,  1.04980469e-01,\n",
              "       -4.96093750e-01, -1.64062500e-01, -1.56250000e-01, -5.22460938e-02,\n",
              "        1.03027344e-01,  2.43164062e-01, -1.88476562e-01,  5.07812500e-02,\n",
              "       -9.37500000e-02, -6.68945312e-02,  2.27050781e-02,  7.61718750e-02,\n",
              "        2.89062500e-01,  3.10546875e-01, -5.37109375e-02,  2.28515625e-01,\n",
              "        2.51464844e-02,  6.78710938e-02, -1.21093750e-01, -2.15820312e-01,\n",
              "       -2.73437500e-01, -3.07617188e-02, -3.37890625e-01,  1.53320312e-01,\n",
              "        2.33398438e-01, -2.08007812e-01,  3.73046875e-01,  8.20312500e-02,\n",
              "        2.51953125e-01, -7.61718750e-02, -4.66308594e-02, -2.23388672e-02,\n",
              "        2.99072266e-02, -5.93261719e-02, -4.66918945e-03, -2.44140625e-01,\n",
              "       -2.09960938e-01, -2.87109375e-01, -4.54101562e-02, -1.77734375e-01,\n",
              "       -2.79296875e-01, -8.59375000e-02,  9.13085938e-02,  2.51953125e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGbZ2JBNMvBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CREATING EMBEDDINGS MATRIX FOR OUR WORDS\n",
        "# code adapted from https://www.kaggle.com/marijakekic/cnn-in-keras-with-pretrained-word2vec-weights\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "# does not work...\n",
        "# word_vectors = KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', binary=True)\n",
        "\n",
        "EMBEDDING_DIM=300\n",
        "vocabulary_size=min(len(word2index)+1,NUM_WORDS)\n",
        "embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_DIM))\n",
        "for word, i in word2index.items():\n",
        "    if i>=NUM_WORDS:\n",
        "        continue\n",
        "    try:\n",
        "        embedding_vector = wv[word]\n",
        "        # embedding_vector = word_vectors[word]\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    except KeyError:\n",
        "        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_DIM)\n",
        "\n",
        "# del(word_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLJApcv5L2qE",
        "colab_type": "text"
      },
      "source": [
        "#### LSTM (basic best) with and without Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1o0rqaGGzOV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "d8280715-64f7-44a3-c004-831e17b1c8b2"
      },
      "source": [
        "# baseline - best simple LSTM w. emb=300 - RMSprop\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len + 1, output_dim=300, name=\"Embedding\"))  \n",
        "model.add(LSTM(128, dropout=0.2, name=\"LSTM\")) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=10) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "160/160 [==============================] - 16s 98ms/step - loss: 1.0967 - accuracy: 0.5830 - val_loss: 0.8057 - val_accuracy: 0.7015\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 15s 95ms/step - loss: 0.6697 - accuracy: 0.7676 - val_loss: 0.7342 - val_accuracy: 0.7340\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 15s 95ms/step - loss: 0.5369 - accuracy: 0.8117 - val_loss: 0.7527 - val_accuracy: 0.7371\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 15s 96ms/step - loss: 0.4542 - accuracy: 0.8417 - val_loss: 0.7460 - val_accuracy: 0.7410\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 15s 96ms/step - loss: 0.3921 - accuracy: 0.8617 - val_loss: 0.8003 - val_accuracy: 0.7277\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 15s 95ms/step - loss: 0.3411 - accuracy: 0.8796 - val_loss: 0.8289 - val_accuracy: 0.7297\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 15s 96ms/step - loss: 0.2951 - accuracy: 0.8977 - val_loss: 0.8808 - val_accuracy: 0.7187\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 15s 95ms/step - loss: 0.2574 - accuracy: 0.9104 - val_loss: 0.9616 - val_accuracy: 0.7081\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 15s 97ms/step - loss: 0.2260 - accuracy: 0.9234 - val_loss: 0.9813 - val_accuracy: 0.7113\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 15s 96ms/step - loss: 0.1987 - accuracy: 0.9336 - val_loss: 1.0784 - val_accuracy: 0.6968\n",
            "80/80 [==============================] - 1s 14ms/step - loss: 1.0784 - accuracy: 0.6968\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0784363746643066, 0.6967918872833252]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEMMvBzFQ5tr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "43d8962c-4d89-4046-e613-3d1fc9814bd5"
      },
      "source": [
        "# best simple LSTM, using pre-trained Word2Vec embeddings - RMSprop\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len2 + 1, output_dim=EMBEDDING_DIM, trainable=True,                       \n",
        "                    embeddings_initializer=Constant(embedding_matrix),                       \n",
        "                    input_length=20, name=\"Embedding\"))  \n",
        "model.add(LSTM(128, dropout=0.2, name=\"LSTM\")) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=10) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "160/160 [==============================] - 14s 90ms/step - loss: 1.0486 - accuracy: 0.6013 - val_loss: 0.8237 - val_accuracy: 0.6960\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 14s 88ms/step - loss: 0.7376 - accuracy: 0.7293 - val_loss: 0.7490 - val_accuracy: 0.7293\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 14s 86ms/step - loss: 0.6151 - accuracy: 0.7780 - val_loss: 0.7438 - val_accuracy: 0.7351\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 0.5218 - accuracy: 0.8126 - val_loss: 0.7313 - val_accuracy: 0.7375\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 0.4575 - accuracy: 0.8353 - val_loss: 0.7482 - val_accuracy: 0.7426\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 0.3917 - accuracy: 0.8614 - val_loss: 0.7847 - val_accuracy: 0.7347\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 0.3387 - accuracy: 0.8807 - val_loss: 0.8329 - val_accuracy: 0.7304\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 0.2935 - accuracy: 0.8939 - val_loss: 0.8787 - val_accuracy: 0.7191\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 14s 86ms/step - loss: 0.2518 - accuracy: 0.9110 - val_loss: 0.9194 - val_accuracy: 0.7132\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 14s 87ms/step - loss: 0.2116 - accuracy: 0.9271 - val_loss: 0.9966 - val_accuracy: 0.7109\n",
            "80/80 [==============================] - 1s 13ms/step - loss: 0.9965 - accuracy: 0.7109\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9965320825576782, 0.7108763456344604]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyqIe5t7HT8_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "f20d6771-177a-4c38-bc49-0eb137d76cd5"
      },
      "source": [
        "# CHANGED ONLY ONE PART VS THE PREVIOUS CHUNK - significant difference\n",
        "\n",
        "# best simple LSTM, using pre-trained Word2Vec embeddings - RMSprop\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len2 + 1, output_dim=EMBEDDING_DIM, trainable=True,                       \n",
        "                    weights=[embedding_matrix],  # CHANGED THIS PART                     \n",
        "                    input_length=20, name=\"Embedding\"))  \n",
        "model.add(LSTM(128, dropout=0.2, name=\"LSTM\")) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=7) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "160/160 [==============================] - 15s 96ms/step - loss: 1.0465 - accuracy: 0.5950 - val_loss: 0.8219 - val_accuracy: 0.6956\n",
            "Epoch 2/7\n",
            "160/160 [==============================] - 15s 93ms/step - loss: 0.7396 - accuracy: 0.7288 - val_loss: 0.7504 - val_accuracy: 0.7234\n",
            "Epoch 3/7\n",
            "160/160 [==============================] - 15s 93ms/step - loss: 0.6190 - accuracy: 0.7781 - val_loss: 0.7368 - val_accuracy: 0.7289\n",
            "Epoch 4/7\n",
            "160/160 [==============================] - 15s 93ms/step - loss: 0.5259 - accuracy: 0.8114 - val_loss: 0.7313 - val_accuracy: 0.7363\n",
            "Epoch 5/7\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 0.4612 - accuracy: 0.8368 - val_loss: 0.7470 - val_accuracy: 0.7347\n",
            "Epoch 6/7\n",
            "160/160 [==============================] - 15s 93ms/step - loss: 0.3945 - accuracy: 0.8581 - val_loss: 0.7873 - val_accuracy: 0.7332\n",
            "Epoch 7/7\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 0.3437 - accuracy: 0.8788 - val_loss: 0.8209 - val_accuracy: 0.7320\n",
            "80/80 [==============================] - 1s 14ms/step - loss: 0.8208 - accuracy: 0.7320\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8207780718803406, 0.7320031523704529]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBZ1WjvVMPvu",
        "colab_type": "text"
      },
      "source": [
        "#### GRU basic best\n",
        "\n",
        "I change here emb_dim from 128 to 300, GRU hu from 256 to 128 due to the following:\n",
        "\n",
        " * emb_dim = 300, GRU hu = 256, drop = 0.3: 0.7410 \n",
        " * emb_dim = 300, GRU hu = 128, drop = 0.3: 0.7422 \n",
        " * emb_dim = 300, GRU hu = 128, drop = 0.2: 0.7426 \n",
        "\n",
        "All this is lower than 0.7430 with emb=100 (no pretraining)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr_5FQb6SdUI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "96962bd5-2f91-4110-a9d8-038393f6df0e"
      },
      "source": [
        "# Run best baseline GRU w. emb=100 on newly tokenized data: drop of accuracy from 0.7449 to 0.7430\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len + 1, output_dim=100, name=\"Embedding\"))  \n",
        "model.add(GRU(256, dropout=0.3, name=\"LSTM\")) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=5) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "160/160 [==============================] - 16s 99ms/step - loss: 1.1863 - accuracy: 0.5316 - val_loss: 0.8695 - val_accuracy: 0.6905\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 15s 96ms/step - loss: 0.7586 - accuracy: 0.7294 - val_loss: 0.7654 - val_accuracy: 0.7199\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 15s 97ms/step - loss: 0.6168 - accuracy: 0.7840 - val_loss: 0.7456 - val_accuracy: 0.7316\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 16s 98ms/step - loss: 0.5373 - accuracy: 0.8148 - val_loss: 0.7366 - val_accuracy: 0.7430\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 16s 97ms/step - loss: 0.4784 - accuracy: 0.8316 - val_loss: 0.7856 - val_accuracy: 0.7250\n",
            "80/80 [==============================] - 1s 15ms/step - loss: 0.7854 - accuracy: 0.7250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7854050993919373, 0.7249608635902405]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR2ewat0TloM",
        "colab_type": "text"
      },
      "source": [
        "**GRU=256, drop=0.3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOCPTEX4NAva",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "d7a1c7f8-d197-40ff-81be-b5e47d635f8f"
      },
      "source": [
        "# baseline - best simple GRU w. emb=300 - RMSprop\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len + 1, output_dim=300, name=\"Embedding\"))  \n",
        "model.add(GRU(256, dropout=0.3, name=\"LSTM\")) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=10) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "160/160 [==============================] - 21s 134ms/step - loss: 1.0683 - accuracy: 0.5916 - val_loss: 0.8032 - val_accuracy: 0.7034\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 21s 133ms/step - loss: 0.6779 - accuracy: 0.7590 - val_loss: 0.7384 - val_accuracy: 0.7340\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 21s 132ms/step - loss: 0.5512 - accuracy: 0.8056 - val_loss: 0.7482 - val_accuracy: 0.7351\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 21s 132ms/step - loss: 0.4667 - accuracy: 0.8352 - val_loss: 0.7587 - val_accuracy: 0.7410\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 21s 134ms/step - loss: 0.4074 - accuracy: 0.8577 - val_loss: 0.8055 - val_accuracy: 0.7273\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 21s 134ms/step - loss: 0.3488 - accuracy: 0.8789 - val_loss: 0.8520 - val_accuracy: 0.7250\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 21s 133ms/step - loss: 0.2990 - accuracy: 0.8951 - val_loss: 0.8922 - val_accuracy: 0.7214\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 21s 133ms/step - loss: 0.2565 - accuracy: 0.9119 - val_loss: 0.9837 - val_accuracy: 0.7097\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 21s 133ms/step - loss: 0.2171 - accuracy: 0.9237 - val_loss: 1.0355 - val_accuracy: 0.7027\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 21s 133ms/step - loss: 0.1821 - accuracy: 0.9376 - val_loss: 1.1173 - val_accuracy: 0.6937\n",
            "80/80 [==============================] - 2s 20ms/step - loss: 1.1175 - accuracy: 0.6937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.117499589920044, 0.6936619877815247]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezKC6kuTQKJ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "9015e291-027e-4cc9-8330-4dcfcae2cfeb"
      },
      "source": [
        "# simple GRU, using pre-trained Word2Vec embeddings - RMSprop\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len2 + 1, output_dim=EMBEDDING_DIM, trainable=True,                       \n",
        "                    embeddings_initializer=Constant(embedding_matrix),                       \n",
        "                    input_length=20, name=\"Embedding\"))  \n",
        "model.add(GRU(256, dropout=0.3, name=\"LSTM\")) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=10) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "160/160 [==============================] - 21s 133ms/step - loss: 1.0648 - accuracy: 0.5819 - val_loss: 0.8338 - val_accuracy: 0.6874\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 21s 131ms/step - loss: 0.7765 - accuracy: 0.7139 - val_loss: 0.7661 - val_accuracy: 0.7218\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 21s 131ms/step - loss: 0.6589 - accuracy: 0.7579 - val_loss: 0.7350 - val_accuracy: 0.7308\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 21s 132ms/step - loss: 0.5658 - accuracy: 0.7929 - val_loss: 0.7199 - val_accuracy: 0.7406\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 21s 131ms/step - loss: 0.4999 - accuracy: 0.8211 - val_loss: 0.7407 - val_accuracy: 0.7383\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 21s 132ms/step - loss: 0.4431 - accuracy: 0.8383 - val_loss: 0.7600 - val_accuracy: 0.7390\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 21s 132ms/step - loss: 0.3868 - accuracy: 0.8606 - val_loss: 0.8061 - val_accuracy: 0.7304\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 21s 131ms/step - loss: 0.3364 - accuracy: 0.8788 - val_loss: 0.8846 - val_accuracy: 0.7218\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 21s 132ms/step - loss: 0.2895 - accuracy: 0.8952 - val_loss: 0.8596 - val_accuracy: 0.7332\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 21s 133ms/step - loss: 0.2509 - accuracy: 0.9073 - val_loss: 0.9276 - val_accuracy: 0.7183\n",
            "80/80 [==============================] - 2s 21ms/step - loss: 0.9273 - accuracy: 0.7183\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9272509813308716, 0.7183098793029785]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tgcW_mpQzUm",
        "colab_type": "text"
      },
      "source": [
        "**GRU=128, drop=0.3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsrIpUt8MO09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "d447bf22-6139-449a-8482-9790c69636a3"
      },
      "source": [
        "# baseline - best simple GRU w. emb=300 - RMSprop\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len + 1, output_dim=300, name=\"Embedding\"))  \n",
        "model.add(GRU(128, dropout=0.3, name=\"LSTM\")) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=10) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "160/160 [==============================] - 12s 78ms/step - loss: 1.0762 - accuracy: 0.5867 - val_loss: 0.7934 - val_accuracy: 0.7015\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 12s 75ms/step - loss: 0.6784 - accuracy: 0.7609 - val_loss: 0.7396 - val_accuracy: 0.7324\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 12s 76ms/step - loss: 0.5529 - accuracy: 0.8071 - val_loss: 0.7474 - val_accuracy: 0.7422\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 12s 76ms/step - loss: 0.4713 - accuracy: 0.8329 - val_loss: 0.7424 - val_accuracy: 0.7375\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 12s 76ms/step - loss: 0.4128 - accuracy: 0.8544 - val_loss: 0.7915 - val_accuracy: 0.7308\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 12s 77ms/step - loss: 0.3586 - accuracy: 0.8746 - val_loss: 0.8302 - val_accuracy: 0.7238\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 12s 76ms/step - loss: 0.3145 - accuracy: 0.8915 - val_loss: 0.8705 - val_accuracy: 0.7207\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 12s 76ms/step - loss: 0.2796 - accuracy: 0.9045 - val_loss: 0.9192 - val_accuracy: 0.7105\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 12s 76ms/step - loss: 0.2421 - accuracy: 0.9183 - val_loss: 0.9555 - val_accuracy: 0.7148\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 12s 76ms/step - loss: 0.2121 - accuracy: 0.9289 - val_loss: 1.0462 - val_accuracy: 0.6956\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 1.0461 - accuracy: 0.6956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0460939407348633, 0.6956181526184082]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChFftNumPGtg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "276e8cc0-ccb6-427a-ff66-d670d94905ee"
      },
      "source": [
        "# simple GRU, using pre-trained Word2Vec embeddings - RMSprop\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len2 + 1, output_dim=EMBEDDING_DIM, trainable=True,                       \n",
        "                    embeddings_initializer=Constant(embedding_matrix),                       \n",
        "                    input_length=20, name=\"Embedding\"))  \n",
        "model.add(GRU(128, dropout=0.3, name=\"LSTM\")) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=10) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "160/160 [==============================] - 12s 77ms/step - loss: 1.0894 - accuracy: 0.5699 - val_loss: 0.8298 - val_accuracy: 0.6897\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 12s 74ms/step - loss: 0.7708 - accuracy: 0.7157 - val_loss: 0.7583 - val_accuracy: 0.7210\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 12s 74ms/step - loss: 0.6564 - accuracy: 0.7587 - val_loss: 0.7344 - val_accuracy: 0.7328\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 12s 74ms/step - loss: 0.5698 - accuracy: 0.7940 - val_loss: 0.7201 - val_accuracy: 0.7418\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 12s 74ms/step - loss: 0.5084 - accuracy: 0.8172 - val_loss: 0.7259 - val_accuracy: 0.7422\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 12s 74ms/step - loss: 0.4586 - accuracy: 0.8347 - val_loss: 0.7506 - val_accuracy: 0.7344\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 12s 74ms/step - loss: 0.4098 - accuracy: 0.8501 - val_loss: 0.7717 - val_accuracy: 0.7398\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 12s 73ms/step - loss: 0.3647 - accuracy: 0.8686 - val_loss: 0.8252 - val_accuracy: 0.7324\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 12s 74ms/step - loss: 0.3261 - accuracy: 0.8842 - val_loss: 0.8068 - val_accuracy: 0.7379\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 12s 74ms/step - loss: 0.2931 - accuracy: 0.8969 - val_loss: 0.8715 - val_accuracy: 0.7183\n",
            "80/80 [==============================] - 1s 8ms/step - loss: 0.8713 - accuracy: 0.7183\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8712825775146484, 0.7183098793029785]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3WEB0MAQkQs",
        "colab_type": "text"
      },
      "source": [
        "**GRU=128, drop=0.2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIzsEnvsNwlN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "2188de79-0a12-4e60-943a-5f3b2e5de89d"
      },
      "source": [
        "# baseline - best simple GRU w. emb=300 - RMSprop\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len + 1, output_dim=300, name=\"Embedding\"))  \n",
        "model.add(GRU(128, dropout=0.2, name=\"LSTM\")) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=10) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "160/160 [==============================] - 12s 77ms/step - loss: 1.0598 - accuracy: 0.5961 - val_loss: 0.7870 - val_accuracy: 0.7062\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 12s 74ms/step - loss: 0.6616 - accuracy: 0.7650 - val_loss: 0.7369 - val_accuracy: 0.7316\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 12s 75ms/step - loss: 0.5332 - accuracy: 0.8139 - val_loss: 0.7538 - val_accuracy: 0.7426\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 12s 74ms/step - loss: 0.4488 - accuracy: 0.8412 - val_loss: 0.7520 - val_accuracy: 0.7359\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 12s 75ms/step - loss: 0.3872 - accuracy: 0.8638 - val_loss: 0.8086 - val_accuracy: 0.7261\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 12s 74ms/step - loss: 0.3306 - accuracy: 0.8846 - val_loss: 0.8538 - val_accuracy: 0.7207\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 12s 74ms/step - loss: 0.2867 - accuracy: 0.9021 - val_loss: 0.9065 - val_accuracy: 0.7128\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 12s 75ms/step - loss: 0.2510 - accuracy: 0.9133 - val_loss: 0.9650 - val_accuracy: 0.7101\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 12s 75ms/step - loss: 0.2157 - accuracy: 0.9276 - val_loss: 1.0112 - val_accuracy: 0.7007\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 12s 76ms/step - loss: 0.1847 - accuracy: 0.9382 - val_loss: 1.1219 - val_accuracy: 0.6937\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 1.1219 - accuracy: 0.6937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.121912956237793, 0.6936619877815247]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phdKV8_UM8ZM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "fa12f0ce-1a79-4395-b374-19996521a2d9"
      },
      "source": [
        "# simple GRU, using pre-trained Word2Vec embeddings - RMSprop\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len2 + 1, output_dim=EMBEDDING_DIM, trainable=True,                       \n",
        "                    embeddings_initializer=Constant(embedding_matrix),                       \n",
        "                    input_length=20, name=\"Embedding\"))  \n",
        "model.add(GRU(128, dropout=0.2, name=\"LSTM\")) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=10) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "160/160 [==============================] - 12s 76ms/step - loss: 1.0654 - accuracy: 0.5834 - val_loss: 0.8182 - val_accuracy: 0.6937\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 12s 73ms/step - loss: 0.7418 - accuracy: 0.7277 - val_loss: 0.7535 - val_accuracy: 0.7273\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 12s 74ms/step - loss: 0.6226 - accuracy: 0.7751 - val_loss: 0.7376 - val_accuracy: 0.7300\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 12s 74ms/step - loss: 0.5324 - accuracy: 0.8085 - val_loss: 0.7248 - val_accuracy: 0.7430\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 12s 73ms/step - loss: 0.4651 - accuracy: 0.8336 - val_loss: 0.7401 - val_accuracy: 0.7375\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 12s 73ms/step - loss: 0.4140 - accuracy: 0.8492 - val_loss: 0.7689 - val_accuracy: 0.7304\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 12s 73ms/step - loss: 0.3619 - accuracy: 0.8690 - val_loss: 0.8089 - val_accuracy: 0.7308\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 12s 74ms/step - loss: 0.3122 - accuracy: 0.8896 - val_loss: 0.8888 - val_accuracy: 0.7210\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 12s 76ms/step - loss: 0.2681 - accuracy: 0.9045 - val_loss: 0.8836 - val_accuracy: 0.7222\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 12s 73ms/step - loss: 0.2315 - accuracy: 0.9203 - val_loss: 0.9598 - val_accuracy: 0.7097\n",
            "80/80 [==============================] - 1s 7ms/step - loss: 0.9596 - accuracy: 0.7097\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9595659375190735, 0.7097026705741882]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDgqaPBpp19F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "4a18d265-46e6-4d78-d984-b325ed138247"
      },
      "source": [
        "# simple GRU, using pre-trained Word2Vec embeddings - RMSprop\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len2 + 1, output_dim=EMBEDDING_DIM, trainable=True,                       \n",
        "                    embeddings_initializer=Constant(embedding_matrix),                       \n",
        "                    input_length=20, name=\"Embedding\"))  \n",
        "model.add(GRU(128, dropout=0.2)) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=5) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "160/160 [==============================] - 13s 81ms/step - loss: 1.0661 - accuracy: 0.5812 - val_loss: 0.8174 - val_accuracy: 0.6952\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 13s 78ms/step - loss: 0.7398 - accuracy: 0.7268 - val_loss: 0.7568 - val_accuracy: 0.7199\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 13s 79ms/step - loss: 0.6198 - accuracy: 0.7732 - val_loss: 0.7331 - val_accuracy: 0.7304\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 13s 80ms/step - loss: 0.5291 - accuracy: 0.8095 - val_loss: 0.7238 - val_accuracy: 0.7406\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 13s 80ms/step - loss: 0.4648 - accuracy: 0.8333 - val_loss: 0.7408 - val_accuracy: 0.7359\n",
            "80/80 [==============================] - 1s 9ms/step - loss: 0.7406 - accuracy: 0.7359\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7406185865402222, 0.73591548204422]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyTXA9WoAUFF",
        "colab_type": "text"
      },
      "source": [
        "##### Predict on new dataset for kaggle (4th upload)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mObFCUXOsDa9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "4f0dcfa4-4454-4ee3-fcc8-b0db06175154"
      },
      "source": [
        "# simple GRU, using pre-trained Word2Vec embeddings - RMSprop\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len2 + 1, output_dim=EMBEDDING_DIM, trainable=True,                       \n",
        "                    embeddings_initializer=Constant(embedding_matrix),                       \n",
        "                    input_length=20, name=\"Embedding\"))  \n",
        "model.add(Bidirectional(GRU(128, dropout=0.2))) \n",
        "# model.add(GRU(128, dropout=0.2)) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# Train the model\n",
        "model.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=4) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "160/160 [==============================] - 22s 139ms/step - loss: 1.0723 - accuracy: 0.5817 - val_loss: 0.8123 - val_accuracy: 0.6952\n",
            "Epoch 2/4\n",
            "160/160 [==============================] - 22s 137ms/step - loss: 0.7436 - accuracy: 0.7284 - val_loss: 0.7482 - val_accuracy: 0.7191\n",
            "Epoch 3/4\n",
            "160/160 [==============================] - 22s 137ms/step - loss: 0.6197 - accuracy: 0.7732 - val_loss: 0.7540 - val_accuracy: 0.7265\n",
            "Epoch 4/4\n",
            "160/160 [==============================] - 22s 137ms/step - loss: 0.5381 - accuracy: 0.8050 - val_loss: 0.7160 - val_accuracy: 0.7441\n",
            "80/80 [==============================] - 1s 14ms/step - loss: 0.7159 - accuracy: 0.7441\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7159335613250732, 0.7441314458847046]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRZnOZXTXA0N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "e6e00bf1-0c3e-4b36-f656-39e5796fc3b3"
      },
      "source": [
        "Y_new4 = model.predict_classes(X_new)\n",
        "# show the inputs and predicted outputs\n",
        "print(X_new[:5])\n",
        "for i in range(5):\n",
        "\tprint(\"X=%s, Predicted=%s\" % (X_new[i], Y_new4[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0    0    0    0    0    0    0    0    0    0    3  456\n",
            "     8   34   16    1  136   63]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0 1501  124  715\n",
            "    20   63    1 1304  257  298]\n",
            " [   0    0    0    0    0    0   99    4  121    2   39   23  886 1958\n",
            "  5867    1   22    2  524  175]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0  342  234\n",
            "   837    1   47  247  392   14]\n",
            " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0   47  195  295  559]]\n",
            "X=[  0   0   0   0   0   0   0   0   0   0   0   0   3 456   8  34  16   1\n",
            " 136  63], Predicted=1\n",
            "X=[   0    0    0    0    0    0    0    0    0    0    0 1501  124  715\n",
            "   20   63    1 1304  257  298], Predicted=1\n",
            "X=[   0    0    0    0    0    0   99    4  121    2   39   23  886 1958\n",
            " 5867    1   22    2  524  175], Predicted=0\n",
            "X=[  0   0   0   0   0   0   0   0   0   0   0   0 342 234 837   1  47 247\n",
            " 392  14], Predicted=2\n",
            "X=[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  47 195\n",
            " 295 559], Predicted=2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2onf9q0FXAi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test4 = pd.DataFrame(list(zip(test['id'], Y_new4)), \n",
        "               columns = ['id', 'label'])\n",
        "test4\n",
        "test4.to_csv('test4.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBsiTwWsMF-Y",
        "colab_type": "text"
      },
      "source": [
        "#### CNN basic best (emb changed to 300)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blFrvt2VMNLe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "5c2696a1-03b5-4694-ffd2-80cecd50c2be"
      },
      "source": [
        "# model from keras site, adapted, 500 hu, emb=100\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "kernel_size = 3\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Embedding(dict_len2 + 1, output_dim=EMBEDDING_DIM, trainable=True, \n",
        "                    input_length=20))  \n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(Conv1D(500,\n",
        "                 kernel_size,\n",
        "#  \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input.\n",
        "                 padding='same', # changed padding here; 0.78p better with \"same\"\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model3.add(GlobalMaxPooling1D())\n",
        "model3.add(Dense(250))\n",
        "model3.add(Activation('relu'))\n",
        "model3.add(Dense(5, activation=\"softmax\"))  \n",
        "model3.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "model3.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=10) \n",
        "model3.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "160/160 [==============================] - 24s 153ms/step - loss: 1.0458 - accuracy: 0.5910 - val_loss: 0.7552 - val_accuracy: 0.7304\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 24s 153ms/step - loss: 0.6162 - accuracy: 0.7839 - val_loss: 0.7242 - val_accuracy: 0.7426\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 24s 151ms/step - loss: 0.4379 - accuracy: 0.8521 - val_loss: 0.7508 - val_accuracy: 0.7414\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 24s 151ms/step - loss: 0.3027 - accuracy: 0.8966 - val_loss: 0.8293 - val_accuracy: 0.7375\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 24s 150ms/step - loss: 0.1913 - accuracy: 0.9366 - val_loss: 0.9311 - val_accuracy: 0.7308\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 24s 151ms/step - loss: 0.1083 - accuracy: 0.9667 - val_loss: 1.1119 - val_accuracy: 0.7124\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 0.0628 - accuracy: 0.9805 - val_loss: 1.3304 - val_accuracy: 0.7081\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 0.0322 - accuracy: 0.9899 - val_loss: 1.3886 - val_accuracy: 0.7140\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 24s 151ms/step - loss: 0.0204 - accuracy: 0.9946 - val_loss: 1.9703 - val_accuracy: 0.6768\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 24s 151ms/step - loss: 0.0153 - accuracy: 0.9955 - val_loss: 1.7416 - val_accuracy: 0.7160\n",
            "80/80 [==============================] - 1s 13ms/step - loss: 1.7417 - accuracy: 0.7160\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.7417304515838623, 0.7159624695777893]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwQFoNi24Sil",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "a1f24fb1-2169-4fa0-b0b7-7eeb06c6f4ee"
      },
      "source": [
        "# model from keras site, adapted, 500 hu, emb=100\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "kernel_size = 3\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Embedding(dict_len2 + 1, output_dim=EMBEDDING_DIM, trainable=True,                       \n",
        "                    embeddings_initializer=Constant(embedding_matrix),                       \n",
        "                    input_length=20))  \n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(Conv1D(500,\n",
        "                 kernel_size,\n",
        "#  \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input.\n",
        "                 padding='same', # changed padding here; 0.78p better with \"same\"\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model3.add(GlobalMaxPooling1D())\n",
        "model3.add(Dense(250))\n",
        "model3.add(Activation('relu'))\n",
        "model3.add(Dense(5, activation=\"softmax\"))  \n",
        "model3.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "model3.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=10) \n",
        "model3.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 1.1759 - accuracy: 0.5317 - val_loss: 0.8371 - val_accuracy: 0.6890\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 24s 151ms/step - loss: 0.7418 - accuracy: 0.7261 - val_loss: 0.7711 - val_accuracy: 0.7148\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 25s 153ms/step - loss: 0.5665 - accuracy: 0.7898 - val_loss: 0.7286 - val_accuracy: 0.7359\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 0.4238 - accuracy: 0.8460 - val_loss: 0.7371 - val_accuracy: 0.7453\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 24s 151ms/step - loss: 0.3141 - accuracy: 0.8876 - val_loss: 0.8540 - val_accuracy: 0.7148\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 0.2303 - accuracy: 0.9181 - val_loss: 0.8795 - val_accuracy: 0.7269\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 0.1584 - accuracy: 0.9441 - val_loss: 1.1493 - val_accuracy: 0.7031\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 0.1147 - accuracy: 0.9584 - val_loss: 1.3391 - val_accuracy: 0.6964\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 24s 153ms/step - loss: 0.0872 - accuracy: 0.9709 - val_loss: 1.3041 - val_accuracy: 0.7105\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 24s 151ms/step - loss: 0.0680 - accuracy: 0.9760 - val_loss: 1.3330 - val_accuracy: 0.7195\n",
            "80/80 [==============================] - 1s 13ms/step - loss: 1.3328 - accuracy: 0.7195\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3327656984329224, 0.7194835543632507]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBGkAvnBtv4L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "eb78baf7-11a9-49f1-cb4a-56ba50965e1c"
      },
      "source": [
        "# model from keras site, adapted, 500 hu, emb=100\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "kernel_size = 3\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Embedding(dict_len2 + 1, output_dim=EMBEDDING_DIM, trainable=True,                       \n",
        "                    embeddings_initializer=Constant(embedding_matrix),                       \n",
        "                    input_length=20))  \n",
        "model3.add(Dropout(0.2))\n",
        "model3.add(Conv1D(500,\n",
        "                 kernel_size,\n",
        "#  \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input.\n",
        "                 padding='same', # changed padding here; 0.78p better with \"same\"\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model3.add(GlobalMaxPooling1D())\n",
        "model3.add(Dense(250))\n",
        "model3.add(Activation('relu'))\n",
        "model3.add(Dense(5, activation=\"softmax\"))  \n",
        "model3.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "model3.fit(X_train, Y_train, validation_data = (X_test, Y_test), batch_size=64, epochs=5) \n",
        "model3.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "160/160 [==============================] - 24s 147ms/step - loss: 1.1648 - accuracy: 0.5368 - val_loss: 0.8386 - val_accuracy: 0.6835\n",
            "Epoch 2/5\n",
            "160/160 [==============================] - 23s 147ms/step - loss: 0.7420 - accuracy: 0.7268 - val_loss: 0.7685 - val_accuracy: 0.7160\n",
            "Epoch 3/5\n",
            "160/160 [==============================] - 24s 147ms/step - loss: 0.5606 - accuracy: 0.7908 - val_loss: 0.7398 - val_accuracy: 0.7300\n",
            "Epoch 4/5\n",
            "160/160 [==============================] - 24s 148ms/step - loss: 0.4256 - accuracy: 0.8492 - val_loss: 0.7534 - val_accuracy: 0.7363\n",
            "Epoch 5/5\n",
            "160/160 [==============================] - 26s 165ms/step - loss: 0.3150 - accuracy: 0.8872 - val_loss: 0.8194 - val_accuracy: 0.7269\n",
            "80/80 [==============================] - 1s 13ms/step - loss: 0.8194 - accuracy: 0.7269\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8193970918655396, 0.726917028427124]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_okCZqgojIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = train[['label']]\n",
        "\n",
        "# adapted from https://machinelearningmastery.com/evaluate-performance-deep-learning-models-keras/\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 10\n",
        "np.random.seed(seed)\n",
        "\n",
        "# define 10-fold cross validation split\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "\n",
        "cvscores = []\n",
        "for train_, test_ in kfold.split(X, y):\n",
        "  Y = to_categorical(y)\n",
        "  # create model\n",
        "  np.random.seed(42)\n",
        "  random.seed(12345)\n",
        "  session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                inter_op_parallelism_threads=1)\n",
        "  tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(dict_len2 + 1, output_dim=EMBEDDING_DIM, trainable=True,                       \n",
        "                    embeddings_initializer=Constant(embedding_matrix),                       \n",
        "                    input_length=20)) \n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv1D(500,3,\n",
        "                  padding='same', \n",
        "                  activation='relu',\n",
        "                  strides=1))\n",
        "  model.add(GlobalMaxPooling1D())\n",
        "  model.add(Dense(250))\n",
        "  # model.add(Dropout(0.2)) # REMOVED DROPOUT HERE\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dense(5, activation=\"softmax\"))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  # save the best model\n",
        "  # filepath=\"accuracy-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "  filepath=\"weights.best.hdf5\"\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1)\n",
        "  callbacks_list = [checkpoint] \n",
        "  # earlystop = EarlyStopping(monitor='val_accuracy', verbose=1, patience=0)  # , patience=2 - how many epochs w/o improvement we allow\n",
        "  # Fit the model\n",
        "  model.fit(X[train_], Y[train_], validation_data = (X[test_], Y[test_]), epochs=7, batch_size=64,callbacks=callbacks_list,verbose=0)\n",
        "  # load the best model before evaluation, otherwise a model from the last epoch will be used.\n",
        "  model = load_model(\"weights.best.hdf5\")\n",
        "  scores = model.evaluate(X[test_], Y[test_], verbose=0)\n",
        "  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  cvscores.append(scores[1] * 100)\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8dEr81AJtZ3",
        "colab_type": "text"
      },
      "source": [
        "#### CNN from paper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnFdDSELI1dz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "434328cf-1b3b-4c8a-a422-bc8e7418a792"
      },
      "source": [
        "# NOTHING BETTER\n",
        "# kernel size: 3,4,5\n",
        "dropout = [0, 0.25, 0.35, 0.5]\n",
        "filters = [50, 100, 200, 300]\n",
        "# MaxOverTime pooling\n",
        "from keras import regularizers\n",
        "\n",
        "\n",
        "for i in filters:\n",
        "  for j in dropout:\n",
        "    print(\"Number of hidden units: \", i, \"dropout: \",j)\n",
        "\n",
        "    def custom_CNN(input_length=20,vocab_size=dict_len2+1,emb_dim = 300):\n",
        "      # define CNN layer\n",
        "      inputs1 = Input(shape=(input_length,))\n",
        "      emb1 = Embedding(vocab_size, emb_dim, trainable=True,                       \n",
        "                    embeddings_initializer=Constant(embedding_matrix))(inputs1)\n",
        "      # Embedding(dict_len2 + 1, output_dim=EMBEDDING_DIM, trainable=True,                       \n",
        "      #               embeddings_initializer=Constant(embedding_matrix),                       \n",
        "      #               input_length=20)) \n",
        "      conv1 = Conv1D(filters=i, kernel_size=3, padding='same', activation='relu', strides=1)(emb1)\n",
        "      drop1 = Dropout(j)(conv1)\n",
        "      pool1 = GlobalMaxPooling1D()(drop1) # MaxOverTime\n",
        "      # pool1 = GlobalMaxPooling1D()(conv1)\n",
        "      # pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
        "      flat1 = Flatten()(pool1)\n",
        "\n",
        "      inputs2 = Input(shape=(input_length,))\n",
        "      emb2 = Embedding(vocab_size, emb_dim, trainable=True,                       \n",
        "                    embeddings_initializer=Constant(embedding_matrix))(inputs2)\n",
        "      conv2 = Conv1D(filters=i, kernel_size=4, padding='same', activation='relu', strides=1)(emb2)\n",
        "      drop2 = Dropout(j)(conv2)\n",
        "      pool2 = GlobalMaxPooling1D()(drop2)\n",
        "      # pool2 = GlobalMaxPooling1D()(conv2)\n",
        "      # pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
        "      flat2 = Flatten()(pool2)\n",
        "\n",
        "      inputs3 = Input(shape=(input_length,))\n",
        "      emb3 = Embedding(vocab_size, emb_dim, trainable=True,                       \n",
        "                    embeddings_initializer=Constant(embedding_matrix))(inputs3)\n",
        "      conv3 = Conv1D(filters=i, kernel_size=5, padding='same', activation='relu', strides=1)(emb3)\n",
        "      drop3 = Dropout(j)(conv3)\n",
        "      pool3 = GlobalMaxPooling1D()(drop3)\n",
        "      # pool3 = GlobalMaxPooling1D()(conv3)\n",
        "      # pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
        "      flat3 = Flatten()(pool3)\n",
        "\n",
        "      # merge CNN output with reference stats\n",
        "      merged = concatenate([flat1, flat2, flat3])\n",
        "\n",
        "      dense1 = Dense(500, activation='relu',kernel_regularizer=regularizers.l2(0.01),activity_regularizer=regularizers.l1(0.01))(merged) #\n",
        "\n",
        "      outputs = Dense(5, activation=\"softmax\")(dense1)\n",
        "      model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
        "      model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "      # print(model.summary())\n",
        "      # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "      return model\n",
        "\n",
        "    np.random.seed(5)\n",
        "    random.seed(5)\n",
        "    session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                                  inter_op_parallelism_threads=1)\n",
        "    tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "    # define model\n",
        "    model = custom_CNN(input_length=20, vocab_size=dict_len2+1,emb_dim = 300)\n",
        "    model.fit(x=[X_train,X_train,X_train], y=Y_train, validation_data = ([X_test,X_test,X_test], Y_test), batch_size=64, epochs=10) \n",
        "    # save the model\n",
        "    # model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of hidden units:  50 dropout:  0\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 15s 96ms/step - loss: 1.8652 - accuracy: 0.5079 - val_loss: 1.1116 - val_accuracy: 0.6984\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 15s 95ms/step - loss: 0.9333 - accuracy: 0.7470 - val_loss: 0.9634 - val_accuracy: 0.7187\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 15s 94ms/step - loss: 0.6746 - accuracy: 0.8366 - val_loss: 0.9325 - val_accuracy: 0.7261\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 0.4871 - accuracy: 0.9021 - val_loss: 0.9335 - val_accuracy: 0.7340\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 15s 94ms/step - loss: 0.3494 - accuracy: 0.9465 - val_loss: 0.9447 - val_accuracy: 0.7222\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 15s 93ms/step - loss: 0.2560 - accuracy: 0.9720 - val_loss: 0.9537 - val_accuracy: 0.7273\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 15s 94ms/step - loss: 0.1945 - accuracy: 0.9851 - val_loss: 0.9956 - val_accuracy: 0.7066\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 15s 93ms/step - loss: 0.1505 - accuracy: 0.9919 - val_loss: 1.0160 - val_accuracy: 0.7128\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 15s 94ms/step - loss: 0.1265 - accuracy: 0.9933 - val_loss: 1.0172 - val_accuracy: 0.7191\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 0.1061 - accuracy: 0.9956 - val_loss: 1.0226 - val_accuracy: 0.7207\n",
            "Number of hidden units:  50 dropout:  0.25\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 15s 96ms/step - loss: 1.9235 - accuracy: 0.5023 - val_loss: 1.1660 - val_accuracy: 0.6870\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 15s 94ms/step - loss: 0.9850 - accuracy: 0.7241 - val_loss: 0.9847 - val_accuracy: 0.7038\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 14s 90ms/step - loss: 0.7544 - accuracy: 0.8095 - val_loss: 0.9177 - val_accuracy: 0.7191\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 15s 91ms/step - loss: 0.5967 - accuracy: 0.8576 - val_loss: 0.8775 - val_accuracy: 0.7347\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 15s 91ms/step - loss: 0.4715 - accuracy: 0.8984 - val_loss: 0.9037 - val_accuracy: 0.7183\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 14s 90ms/step - loss: 0.3681 - accuracy: 0.9336 - val_loss: 0.8894 - val_accuracy: 0.7332\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 14s 90ms/step - loss: 0.2954 - accuracy: 0.9536 - val_loss: 0.9079 - val_accuracy: 0.7230\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 15s 91ms/step - loss: 0.2370 - accuracy: 0.9678 - val_loss: 0.9144 - val_accuracy: 0.7332\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 16s 99ms/step - loss: 0.2042 - accuracy: 0.9761 - val_loss: 0.9604 - val_accuracy: 0.7199\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 0.1722 - accuracy: 0.9800 - val_loss: 1.0605 - val_accuracy: 0.6964\n",
            "Number of hidden units:  50 dropout:  0.35\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 15s 93ms/step - loss: 1.9478 - accuracy: 0.4893 - val_loss: 1.1913 - val_accuracy: 0.6839\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 1.0035 - accuracy: 0.7173 - val_loss: 1.0092 - val_accuracy: 0.7011\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 15s 93ms/step - loss: 0.7860 - accuracy: 0.7917 - val_loss: 0.9333 - val_accuracy: 0.7136\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 15s 91ms/step - loss: 0.6418 - accuracy: 0.8388 - val_loss: 0.8689 - val_accuracy: 0.7402\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 0.5196 - accuracy: 0.8760 - val_loss: 0.8700 - val_accuracy: 0.7281\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 15s 91ms/step - loss: 0.4232 - accuracy: 0.9120 - val_loss: 0.8598 - val_accuracy: 0.7363\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 15s 91ms/step - loss: 0.3530 - accuracy: 0.9333 - val_loss: 0.8777 - val_accuracy: 0.7257\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 14s 90ms/step - loss: 0.2903 - accuracy: 0.9502 - val_loss: 0.9093 - val_accuracy: 0.7210\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 14s 90ms/step - loss: 0.2433 - accuracy: 0.9631 - val_loss: 0.9119 - val_accuracy: 0.7187\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 15s 91ms/step - loss: 0.2121 - accuracy: 0.9713 - val_loss: 1.0052 - val_accuracy: 0.6909\n",
            "Number of hidden units:  50 dropout:  0.5\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 15s 93ms/step - loss: 2.0008 - accuracy: 0.4882 - val_loss: 1.2573 - val_accuracy: 0.6741\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 1.0361 - accuracy: 0.7009 - val_loss: 1.0481 - val_accuracy: 0.7117\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 14s 90ms/step - loss: 0.8294 - accuracy: 0.7755 - val_loss: 0.9694 - val_accuracy: 0.7234\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 0.6996 - accuracy: 0.8146 - val_loss: 0.8835 - val_accuracy: 0.7324\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 15s 93ms/step - loss: 0.5879 - accuracy: 0.8515 - val_loss: 0.8885 - val_accuracy: 0.7246\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 0.5066 - accuracy: 0.8778 - val_loss: 0.8518 - val_accuracy: 0.7297\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 15s 92ms/step - loss: 0.4363 - accuracy: 0.9009 - val_loss: 0.8542 - val_accuracy: 0.7320\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 15s 91ms/step - loss: 0.3782 - accuracy: 0.9205 - val_loss: 0.8606 - val_accuracy: 0.7320\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 14s 90ms/step - loss: 0.3216 - accuracy: 0.9385 - val_loss: 0.8612 - val_accuracy: 0.7285\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 14s 91ms/step - loss: 0.2875 - accuracy: 0.9474 - val_loss: 0.8952 - val_accuracy: 0.7105\n",
            "Number of hidden units:  100 dropout:  0\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 25s 153ms/step - loss: 2.1082 - accuracy: 0.5072 - val_loss: 1.1207 - val_accuracy: 0.6948\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 24s 153ms/step - loss: 0.9430 - accuracy: 0.7459 - val_loss: 0.9624 - val_accuracy: 0.7128\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 24s 153ms/step - loss: 0.6878 - accuracy: 0.8357 - val_loss: 0.9323 - val_accuracy: 0.7195\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 24s 153ms/step - loss: 0.5034 - accuracy: 0.8995 - val_loss: 0.9063 - val_accuracy: 0.7332\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 0.3660 - accuracy: 0.9420 - val_loss: 0.9493 - val_accuracy: 0.7203\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 24s 153ms/step - loss: 0.2704 - accuracy: 0.9680 - val_loss: 0.9547 - val_accuracy: 0.7238\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 0.2041 - accuracy: 0.9830 - val_loss: 0.9887 - val_accuracy: 0.7046\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 24s 151ms/step - loss: 0.1611 - accuracy: 0.9899 - val_loss: 0.9751 - val_accuracy: 0.7207\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 0.1358 - accuracy: 0.9913 - val_loss: 0.9736 - val_accuracy: 0.7269\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 24s 153ms/step - loss: 0.1093 - accuracy: 0.9971 - val_loss: 0.9924 - val_accuracy: 0.7191\n",
            "Number of hidden units:  100 dropout:  0.25\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 25s 153ms/step - loss: 2.1816 - accuracy: 0.5024 - val_loss: 1.1663 - val_accuracy: 0.6890\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 24s 150ms/step - loss: 0.9839 - accuracy: 0.7257 - val_loss: 0.9924 - val_accuracy: 0.7066\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 24s 150ms/step - loss: 0.7543 - accuracy: 0.8063 - val_loss: 0.9516 - val_accuracy: 0.7074\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 24s 150ms/step - loss: 0.5979 - accuracy: 0.8599 - val_loss: 0.8783 - val_accuracy: 0.7355\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 24s 153ms/step - loss: 0.4656 - accuracy: 0.9034 - val_loss: 0.8841 - val_accuracy: 0.7320\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 24s 151ms/step - loss: 0.3601 - accuracy: 0.9383 - val_loss: 0.9015 - val_accuracy: 0.7332\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 24s 150ms/step - loss: 0.2917 - accuracy: 0.9544 - val_loss: 0.9525 - val_accuracy: 0.7050\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 24s 151ms/step - loss: 0.2305 - accuracy: 0.9729 - val_loss: 0.9346 - val_accuracy: 0.7257\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 24s 150ms/step - loss: 0.1927 - accuracy: 0.9798 - val_loss: 0.9391 - val_accuracy: 0.7207\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 24s 151ms/step - loss: 0.1625 - accuracy: 0.9870 - val_loss: 1.0801 - val_accuracy: 0.6874\n",
            "Number of hidden units:  100 dropout:  0.35\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 2.2407 - accuracy: 0.4970 - val_loss: 1.2056 - val_accuracy: 0.6882\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 24s 150ms/step - loss: 1.0073 - accuracy: 0.7185 - val_loss: 0.9974 - val_accuracy: 0.7136\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 24s 150ms/step - loss: 0.7839 - accuracy: 0.7960 - val_loss: 0.9569 - val_accuracy: 0.7019\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 24s 150ms/step - loss: 0.6357 - accuracy: 0.8423 - val_loss: 0.8698 - val_accuracy: 0.7433\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 24s 149ms/step - loss: 0.5126 - accuracy: 0.8817 - val_loss: 0.8684 - val_accuracy: 0.7254\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 24s 150ms/step - loss: 0.4103 - accuracy: 0.9173 - val_loss: 0.8730 - val_accuracy: 0.7316\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 24s 149ms/step - loss: 0.3408 - accuracy: 0.9393 - val_loss: 0.8870 - val_accuracy: 0.7199\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 24s 151ms/step - loss: 0.2751 - accuracy: 0.9575 - val_loss: 0.9017 - val_accuracy: 0.7312\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 24s 149ms/step - loss: 0.2280 - accuracy: 0.9704 - val_loss: 0.9308 - val_accuracy: 0.7156\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 24s 148ms/step - loss: 0.1966 - accuracy: 0.9769 - val_loss: 1.1006 - val_accuracy: 0.6639\n",
            "Number of hidden units:  100 dropout:  0.5\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 24s 152ms/step - loss: 2.3304 - accuracy: 0.4783 - val_loss: 1.2670 - val_accuracy: 0.6745\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 24s 149ms/step - loss: 1.0413 - accuracy: 0.7043 - val_loss: 1.0500 - val_accuracy: 0.7081\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 24s 150ms/step - loss: 0.8248 - accuracy: 0.7765 - val_loss: 0.9669 - val_accuracy: 0.7207\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 24s 149ms/step - loss: 0.6906 - accuracy: 0.8191 - val_loss: 0.8966 - val_accuracy: 0.7359\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 24s 149ms/step - loss: 0.5774 - accuracy: 0.8562 - val_loss: 0.8670 - val_accuracy: 0.7328\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 24s 149ms/step - loss: 0.4917 - accuracy: 0.8846 - val_loss: 0.8437 - val_accuracy: 0.7344\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 24s 148ms/step - loss: 0.4164 - accuracy: 0.9108 - val_loss: 0.8637 - val_accuracy: 0.7340\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 24s 149ms/step - loss: 0.3543 - accuracy: 0.9297 - val_loss: 0.8460 - val_accuracy: 0.7402\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 24s 149ms/step - loss: 0.3062 - accuracy: 0.9450 - val_loss: 0.8834 - val_accuracy: 0.7175\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 24s 148ms/step - loss: 0.2596 - accuracy: 0.9577 - val_loss: 0.9370 - val_accuracy: 0.7003\n",
            "Number of hidden units:  200 dropout:  0\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 39s 247ms/step - loss: 2.3260 - accuracy: 0.4896 - val_loss: 1.1143 - val_accuracy: 0.6944\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 39s 244ms/step - loss: 0.9445 - accuracy: 0.7451 - val_loss: 0.9595 - val_accuracy: 0.7152\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 39s 244ms/step - loss: 0.6948 - accuracy: 0.8333 - val_loss: 0.9029 - val_accuracy: 0.7191\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 40s 252ms/step - loss: 0.5178 - accuracy: 0.8925 - val_loss: 0.9034 - val_accuracy: 0.7344\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 38s 239ms/step - loss: 0.3786 - accuracy: 0.9378 - val_loss: 0.9778 - val_accuracy: 0.7148\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 41s 257ms/step - loss: 0.2843 - accuracy: 0.9655 - val_loss: 0.9329 - val_accuracy: 0.7277\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 39s 244ms/step - loss: 0.2171 - accuracy: 0.9810 - val_loss: 0.9568 - val_accuracy: 0.7285\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 39s 245ms/step - loss: 0.1706 - accuracy: 0.9892 - val_loss: 1.0325 - val_accuracy: 0.7261\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 39s 245ms/step - loss: 0.1450 - accuracy: 0.9905 - val_loss: 0.9687 - val_accuracy: 0.7285\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 39s 243ms/step - loss: 0.1195 - accuracy: 0.9948 - val_loss: 1.0402 - val_accuracy: 0.7074\n",
            "Number of hidden units:  200 dropout:  0.25\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 39s 244ms/step - loss: 2.4176 - accuracy: 0.4798 - val_loss: 1.1631 - val_accuracy: 0.6894\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 39s 244ms/step - loss: 0.9847 - accuracy: 0.7285 - val_loss: 0.9811 - val_accuracy: 0.7077\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 39s 245ms/step - loss: 0.7537 - accuracy: 0.8080 - val_loss: 0.9044 - val_accuracy: 0.7254\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 39s 244ms/step - loss: 0.5959 - accuracy: 0.8596 - val_loss: 0.8706 - val_accuracy: 0.7410\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 39s 244ms/step - loss: 0.4684 - accuracy: 0.9019 - val_loss: 0.8881 - val_accuracy: 0.7316\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 39s 243ms/step - loss: 0.3668 - accuracy: 0.9365 - val_loss: 0.8843 - val_accuracy: 0.7371\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 39s 243ms/step - loss: 0.2916 - accuracy: 0.9583 - val_loss: 0.9250 - val_accuracy: 0.7187\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 39s 243ms/step - loss: 0.2325 - accuracy: 0.9731 - val_loss: 0.9344 - val_accuracy: 0.7285\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 39s 244ms/step - loss: 0.1929 - accuracy: 0.9811 - val_loss: 1.0039 - val_accuracy: 0.7117\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 39s 245ms/step - loss: 0.1632 - accuracy: 0.9865 - val_loss: 1.0410 - val_accuracy: 0.6980\n",
            "Number of hidden units:  200 dropout:  0.35\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 39s 245ms/step - loss: 2.4846 - accuracy: 0.4738 - val_loss: 1.2086 - val_accuracy: 0.6866\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 39s 244ms/step - loss: 1.0055 - accuracy: 0.7189 - val_loss: 0.9961 - val_accuracy: 0.7183\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 39s 244ms/step - loss: 0.7790 - accuracy: 0.7997 - val_loss: 0.9129 - val_accuracy: 0.7254\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 39s 245ms/step - loss: 0.6297 - accuracy: 0.8490 - val_loss: 0.8756 - val_accuracy: 0.7414\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 39s 244ms/step - loss: 0.5038 - accuracy: 0.8861 - val_loss: 0.8653 - val_accuracy: 0.7293\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 39s 245ms/step - loss: 0.4070 - accuracy: 0.9208 - val_loss: 0.8672 - val_accuracy: 0.7308\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 39s 245ms/step - loss: 0.3256 - accuracy: 0.9473 - val_loss: 0.9589 - val_accuracy: 0.6976\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 39s 245ms/step - loss: 0.2622 - accuracy: 0.9662 - val_loss: 0.9101 - val_accuracy: 0.7304\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 39s 245ms/step - loss: 0.2195 - accuracy: 0.9747 - val_loss: 0.9446 - val_accuracy: 0.7167\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 39s 246ms/step - loss: 0.1814 - accuracy: 0.9832 - val_loss: 1.1919 - val_accuracy: 0.6577\n",
            "Number of hidden units:  200 dropout:  0.5\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 40s 247ms/step - loss: 2.5843 - accuracy: 0.4741 - val_loss: 1.2782 - val_accuracy: 0.6678\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 40s 247ms/step - loss: 1.0431 - accuracy: 0.7071 - val_loss: 1.0365 - val_accuracy: 0.7187\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 39s 246ms/step - loss: 0.8202 - accuracy: 0.7818 - val_loss: 0.9565 - val_accuracy: 0.7171\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 39s 246ms/step - loss: 0.6812 - accuracy: 0.8263 - val_loss: 0.9008 - val_accuracy: 0.7355\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 39s 244ms/step - loss: 0.5649 - accuracy: 0.8660 - val_loss: 0.8698 - val_accuracy: 0.7383\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 39s 245ms/step - loss: 0.4712 - accuracy: 0.8955 - val_loss: 0.8682 - val_accuracy: 0.7312\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 39s 244ms/step - loss: 0.3947 - accuracy: 0.9215 - val_loss: 0.8900 - val_accuracy: 0.7230\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 39s 243ms/step - loss: 0.3360 - accuracy: 0.9368 - val_loss: 0.9433 - val_accuracy: 0.7136\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 39s 243ms/step - loss: 0.2795 - accuracy: 0.9557 - val_loss: 0.9289 - val_accuracy: 0.7171\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 39s 246ms/step - loss: 0.2379 - accuracy: 0.9668 - val_loss: 0.9765 - val_accuracy: 0.6991\n",
            "Number of hidden units:  300 dropout:  0\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 56s 352ms/step - loss: 2.4571 - accuracy: 0.5060 - val_loss: 1.1174 - val_accuracy: 0.6909\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 54s 334ms/step - loss: 0.9443 - accuracy: 0.7448 - val_loss: 0.9553 - val_accuracy: 0.7183\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 53s 334ms/step - loss: 0.6995 - accuracy: 0.8307 - val_loss: 0.9261 - val_accuracy: 0.7148\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 53s 334ms/step - loss: 0.5242 - accuracy: 0.8916 - val_loss: 0.9061 - val_accuracy: 0.7449\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 53s 334ms/step - loss: 0.3866 - accuracy: 0.9356 - val_loss: 0.9403 - val_accuracy: 0.7297\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 54s 338ms/step - loss: 0.2917 - accuracy: 0.9628 - val_loss: 0.9786 - val_accuracy: 0.7269\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 53s 333ms/step - loss: 0.2208 - accuracy: 0.9816 - val_loss: 1.0266 - val_accuracy: 0.7023\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 53s 334ms/step - loss: 0.1770 - accuracy: 0.9859 - val_loss: 1.0033 - val_accuracy: 0.7304\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 54s 335ms/step - loss: 0.1446 - accuracy: 0.9928 - val_loss: 1.0048 - val_accuracy: 0.7261\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 53s 334ms/step - loss: 0.1275 - accuracy: 0.9929 - val_loss: 1.0367 - val_accuracy: 0.7250\n",
            "Number of hidden units:  300 dropout:  0.25\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 54s 339ms/step - loss: 2.5864 - accuracy: 0.4915 - val_loss: 1.1570 - val_accuracy: 0.6862\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 58s 362ms/step - loss: 0.9807 - accuracy: 0.7300 - val_loss: 0.9732 - val_accuracy: 0.7148\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 55s 341ms/step - loss: 0.7503 - accuracy: 0.8091 - val_loss: 0.9225 - val_accuracy: 0.7175\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 55s 342ms/step - loss: 0.5936 - accuracy: 0.8638 - val_loss: 0.8745 - val_accuracy: 0.7430\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 54s 340ms/step - loss: 0.4633 - accuracy: 0.9044 - val_loss: 0.8904 - val_accuracy: 0.7273\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 54s 338ms/step - loss: 0.3667 - accuracy: 0.9352 - val_loss: 0.8926 - val_accuracy: 0.7379\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 55s 343ms/step - loss: 0.2906 - accuracy: 0.9586 - val_loss: 0.9232 - val_accuracy: 0.7222\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 54s 339ms/step - loss: 0.2320 - accuracy: 0.9731 - val_loss: 0.9468 - val_accuracy: 0.7293\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 55s 342ms/step - loss: 0.1923 - accuracy: 0.9812 - val_loss: 0.9514 - val_accuracy: 0.7269\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 54s 336ms/step - loss: 0.1595 - accuracy: 0.9881 - val_loss: 1.0048 - val_accuracy: 0.7156\n",
            "Number of hidden units:  300 dropout:  0.35\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 54s 338ms/step - loss: 2.6531 - accuracy: 0.4816 - val_loss: 1.1842 - val_accuracy: 0.6917\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 54s 337ms/step - loss: 1.0069 - accuracy: 0.7196 - val_loss: 0.9804 - val_accuracy: 0.7171\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 55s 341ms/step - loss: 0.7834 - accuracy: 0.7962 - val_loss: 0.9378 - val_accuracy: 0.7179\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 56s 349ms/step - loss: 0.6347 - accuracy: 0.8454 - val_loss: 0.8808 - val_accuracy: 0.7383\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 57s 356ms/step - loss: 0.5106 - accuracy: 0.8868 - val_loss: 0.8843 - val_accuracy: 0.7230\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 55s 346ms/step - loss: 0.4098 - accuracy: 0.9196 - val_loss: 0.8835 - val_accuracy: 0.7316\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 56s 351ms/step - loss: 0.3324 - accuracy: 0.9439 - val_loss: 0.9323 - val_accuracy: 0.7132\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 54s 340ms/step - loss: 0.2736 - accuracy: 0.9603 - val_loss: 0.9431 - val_accuracy: 0.7179\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 54s 339ms/step - loss: 0.2222 - accuracy: 0.9744 - val_loss: 0.9453 - val_accuracy: 0.7238\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 54s 340ms/step - loss: 0.1897 - accuracy: 0.9786 - val_loss: 0.9936 - val_accuracy: 0.7066\n",
            "Number of hidden units:  300 dropout:  0.5\n",
            "Epoch 1/10\n",
            "160/160 [==============================] - 54s 340ms/step - loss: 2.7785 - accuracy: 0.4803 - val_loss: 1.2765 - val_accuracy: 0.6667\n",
            "Epoch 2/10\n",
            "160/160 [==============================] - 54s 338ms/step - loss: 1.0352 - accuracy: 0.7108 - val_loss: 1.0335 - val_accuracy: 0.7081\n",
            "Epoch 3/10\n",
            "160/160 [==============================] - 54s 339ms/step - loss: 0.8159 - accuracy: 0.7863 - val_loss: 0.9685 - val_accuracy: 0.7156\n",
            "Epoch 4/10\n",
            "160/160 [==============================] - 55s 341ms/step - loss: 0.6806 - accuracy: 0.8260 - val_loss: 0.9033 - val_accuracy: 0.7347\n",
            "Epoch 5/10\n",
            "160/160 [==============================] - 54s 340ms/step - loss: 0.5636 - accuracy: 0.8676 - val_loss: 0.8830 - val_accuracy: 0.7285\n",
            "Epoch 6/10\n",
            "160/160 [==============================] - 55s 342ms/step - loss: 0.4685 - accuracy: 0.8968 - val_loss: 0.9163 - val_accuracy: 0.7105\n",
            "Epoch 7/10\n",
            "160/160 [==============================] - 55s 342ms/step - loss: 0.3944 - accuracy: 0.9231 - val_loss: 0.8938 - val_accuracy: 0.7187\n",
            "Epoch 8/10\n",
            "160/160 [==============================] - 55s 342ms/step - loss: 0.3261 - accuracy: 0.9441 - val_loss: 0.9031 - val_accuracy: 0.7312\n",
            "Epoch 9/10\n",
            "160/160 [==============================] - 55s 341ms/step - loss: 0.2761 - accuracy: 0.9569 - val_loss: 0.9392 - val_accuracy: 0.7070\n",
            "Epoch 10/10\n",
            "160/160 [==============================] - 55s 342ms/step - loss: 0.2374 - accuracy: 0.9664 - val_loss: 0.9884 - val_accuracy: 0.7031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UniYXldR6o9S",
        "colab_type": "text"
      },
      "source": [
        "# 4. Using own titles + incoming/outgoing references"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsTH-Q4o76_S",
        "colab_type": "text"
      },
      "source": [
        "### Upload and pre-process a new data file created externally\n",
        "\n",
        "*  ref_to concatenates titles of all references pointing towards a given article\n",
        "*  ref_from concatenates titles of all references to which a given article refers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PJTOY1A7_2T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "60c5f9ad-95d6-4505-a079-82020125cce8"
      },
      "source": [
        "cross_ref.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>ref_to</th>\n",
              "      <th>ref_from</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>a framework for clustering evolving data strea...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>implementation techniques for main memory data...</td>\n",
              "      <td>providing better support for a class of decisi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>1.0</td>\n",
              "      <td>statix making xml count answering xml queries ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>temporal databases   status and research direc...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>dynamic itemset counting and implication rules...</td>\n",
              "      <td>pattern lattice traversal by selective jumps</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                           ref_from\n",
              "0           1  ...                                                NaN\n",
              "1           2  ...  providing better support for a class of decisi...\n",
              "2           3  ...                                                NaN\n",
              "3           4  ...                                                NaN\n",
              "4           5  ...       pattern lattice traversal by selective jumps\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "032W2aiSKS03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cross_ref2 = cross_ref.fillna(\"noref\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivQiNumS93aq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "c8884fc9-883a-4de9-cfc0-a952b1ceea22"
      },
      "source": [
        "train3 = train.join(cross_ref2.set_index('id'), how = 'left', on=\"id\", rsuffix=\"cross\")\n",
        "# train3 = train.join(cross_ref.set_index('id'), how = 'left', on=\"id\", rsuffix=\"cross\")\n",
        "train3.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>title</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>labelcross</th>\n",
              "      <th>ref_to</th>\n",
              "      <th>ref_from</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>interactive visual exploration of neighbor bas...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>a framework for clustering evolving data strea...</td>\n",
              "      <td>noref</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>relational division four algorithms and their ...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>implementation techniques for main memory data...</td>\n",
              "      <td>providing better support for a class of decisi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>simplifying xml schema effortless handling of ...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>statix making xml count answering xml queries ...</td>\n",
              "      <td>noref</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>funbase a function based information managemen...</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>temporal databases   status and research direc...</td>\n",
              "      <td>noref</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>inverted matrix efficient discovery of frequen...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>dynamic itemset counting and implication rules...</td>\n",
              "      <td>pattern lattice traversal by selective jumps</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>computational aspects of covering in dominance...</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>noref</td>\n",
              "      <td>noref</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>feaspar   a feature structure parser learning ...</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>gemini a natural language system for spoken la...</td>\n",
              "      <td>noref</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>assessing the scenic route measuring the value...</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>noref</td>\n",
              "      <td>noref</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>webanywhere enabling a screen reading interfac...</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>knowing the users every move user activity tra...</td>\n",
              "      <td>noref</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>non standard semantics for the method of tempo...</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>towards an implementation of database manageme...</td>\n",
              "      <td>generalized events in temporal databases</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                           ref_from\n",
              "0   0  ...                                              noref\n",
              "1   3  ...  providing better support for a class of decisi...\n",
              "2   6  ...                                              noref\n",
              "3   8  ...                                              noref\n",
              "4   9  ...       pattern lattice traversal by selective jumps\n",
              "5  11  ...                                              noref\n",
              "6  13  ...                                              noref\n",
              "7  18  ...                                              noref\n",
              "8  20  ...                                              noref\n",
              "9  24  ...           generalized events in temporal databases\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0WdemAVZSYv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train3[\"merged\"] = train3[\"title\"] +\" \"+ train3[\"ref_to\"] +\" \"+ train3[\"ref_from\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tow9Blfg-OC9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "1d4ef547-96a3-4cb1-f292-8197dafdacbe"
      },
      "source": [
        "# train3 = train3.iloc[:,5:]\n",
        "# train3 = train3.iloc['title']\n",
        "train3.head(10)\n",
        "# train3.loc[7,\"merged\"]#.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>title</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>labelcross</th>\n",
              "      <th>ref_to</th>\n",
              "      <th>ref_from</th>\n",
              "      <th>merged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>interactive visual exploration of neighbor bas...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>a framework for clustering evolving data strea...</td>\n",
              "      <td>noref</td>\n",
              "      <td>interactive visual exploration of neighbor bas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>relational division four algorithms and their ...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>implementation techniques for main memory data...</td>\n",
              "      <td>providing better support for a class of decisi...</td>\n",
              "      <td>relational division four algorithms and their ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>simplifying xml schema effortless handling of ...</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>statix making xml count answering xml queries ...</td>\n",
              "      <td>noref</td>\n",
              "      <td>simplifying xml schema effortless handling of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>funbase a function based information managemen...</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>temporal databases   status and research direc...</td>\n",
              "      <td>noref</td>\n",
              "      <td>funbase a function based information managemen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>inverted matrix efficient discovery of frequen...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>dynamic itemset counting and implication rules...</td>\n",
              "      <td>pattern lattice traversal by selective jumps</td>\n",
              "      <td>inverted matrix efficient discovery of frequen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>computational aspects of covering in dominance...</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>noref</td>\n",
              "      <td>noref</td>\n",
              "      <td>computational aspects of covering in dominance...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>feaspar   a feature structure parser learning ...</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>gemini a natural language system for spoken la...</td>\n",
              "      <td>noref</td>\n",
              "      <td>feaspar   a feature structure parser learning ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>assessing the scenic route measuring the value...</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>noref</td>\n",
              "      <td>noref</td>\n",
              "      <td>assessing the scenic route measuring the value...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>webanywhere enabling a screen reading interfac...</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>knowing the users every move user activity tra...</td>\n",
              "      <td>noref</td>\n",
              "      <td>webanywhere enabling a screen reading interfac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>non standard semantics for the method of tempo...</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>towards an implementation of database manageme...</td>\n",
              "      <td>generalized events in temporal databases</td>\n",
              "      <td>non standard semantics for the method of tempo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                             merged\n",
              "0   0  ...  interactive visual exploration of neighbor bas...\n",
              "1   3  ...  relational division four algorithms and their ...\n",
              "2   6  ...  simplifying xml schema effortless handling of ...\n",
              "3   8  ...  funbase a function based information managemen...\n",
              "4   9  ...  inverted matrix efficient discovery of frequen...\n",
              "5  11  ...  computational aspects of covering in dominance...\n",
              "6  13  ...  feaspar   a feature structure parser learning ...\n",
              "7  18  ...  assessing the scenic route measuring the value...\n",
              "8  20  ...  webanywhere enabling a screen reading interfac...\n",
              "9  24  ...  non standard semantics for the method of tempo...\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BvCFgTFbDPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texto = train3.loc[7,\"merged\"]\n",
        "print(texto)\n",
        "tokenizer.texts_to_sequences(texto) # a very strange tokenization result..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-oiWvV__k9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test3 = test.join(cross_ref2.set_index('id'), how = 'left', on=\"id\", rsuffix=\"cross\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CZa-1uWVp08",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "outputId": "6ba65114-ab08-46d6-fac9-5546de5e9ffc"
      },
      "source": [
        "test3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>ref_to</th>\n",
              "      <th>ref_from</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>autodomainmine a graphical data mining system ...</td>\n",
              "      <td>12780</td>\n",
              "      <td>noref</td>\n",
              "      <td>what is the nearest neighbor in high dimension...</td>\n",
              "      <td>noref</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>anipqo almost non intrusive parametric query o...</td>\n",
              "      <td>12781</td>\n",
              "      <td>noref</td>\n",
              "      <td>parametric query optimization optimization of ...</td>\n",
              "      <td>on the production of anorexic plan diagrams</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>selection and ranking of text from highly impe...</td>\n",
              "      <td>12782</td>\n",
              "      <td>noref</td>\n",
              "      <td>noref</td>\n",
              "      <td>noref</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>conditional random fields for multi agent rein...</td>\n",
              "      <td>12783</td>\n",
              "      <td>noref</td>\n",
              "      <td>sequential optimality and coordination in mult...</td>\n",
              "      <td>noref</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>multi dimensional description logics</td>\n",
              "      <td>12784</td>\n",
              "      <td>noref</td>\n",
              "      <td>noref</td>\n",
              "      <td>noref</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12777</th>\n",
              "      <td>25553</td>\n",
              "      <td>currency based updates to distributed material...</td>\n",
              "      <td>25557</td>\n",
              "      <td>noref</td>\n",
              "      <td>database snapshots maintenance of views implem...</td>\n",
              "      <td>relaxed currency and consistency how to say go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12778</th>\n",
              "      <td>25556</td>\n",
              "      <td>dynamic typing in a statically typed language</td>\n",
              "      <td>25558</td>\n",
              "      <td>noref</td>\n",
              "      <td>quasi static typing an ideal model for recursi...</td>\n",
              "      <td>quasi static typing semantics for communicatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12779</th>\n",
              "      <td>25558</td>\n",
              "      <td>learning sparse metrics via linear programming</td>\n",
              "      <td>25559</td>\n",
              "      <td>noref</td>\n",
              "      <td>fastmap a fast algorithm for indexing data min...</td>\n",
              "      <td>privacy preserving cox regression for survival...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12780</th>\n",
              "      <td>25559</td>\n",
              "      <td>computer assisted reasoning with mizar</td>\n",
              "      <td>25560</td>\n",
              "      <td>noref</td>\n",
              "      <td>noref</td>\n",
              "      <td>noref</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12781</th>\n",
              "      <td>25560</td>\n",
              "      <td>characterization of a large web site populatio...</td>\n",
              "      <td>25561</td>\n",
              "      <td>noref</td>\n",
              "      <td>gigascope a stream database for network applic...</td>\n",
              "      <td>analysis of multimedia workloads with implicat...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12782 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                           ref_from\n",
              "0          1  ...                                              noref\n",
              "1          2  ...        on the production of anorexic plan diagrams\n",
              "2          4  ...                                              noref\n",
              "3          5  ...                                              noref\n",
              "4          7  ...                                              noref\n",
              "...      ...  ...                                                ...\n",
              "12777  25553  ...  relaxed currency and consistency how to say go...\n",
              "12778  25556  ...  quasi static typing semantics for communicatio...\n",
              "12779  25558  ...  privacy preserving cox regression for survival...\n",
              "12780  25559  ...                                              noref\n",
              "12781  25560  ...  analysis of multimedia workloads with implicat...\n",
              "\n",
              "[12782 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhRD7UBhVdFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test3[\"merged\"] = test3[\"title\"] +\" \"+ test3[\"ref_to\"] +\" \"+ test3[\"ref_from\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLfMDW2iFoxZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "outputId": "a484c8dd-1a5e-45e5-fd51-2f04bea4d62f"
      },
      "source": [
        "test3.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>label</th>\n",
              "      <th>ref_to</th>\n",
              "      <th>ref_from</th>\n",
              "      <th>merged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>autodomainmine a graphical data mining system ...</td>\n",
              "      <td>12780</td>\n",
              "      <td>noref</td>\n",
              "      <td>what is the nearest neighbor in high dimension...</td>\n",
              "      <td>noref</td>\n",
              "      <td>autodomainmine a graphical data mining system ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>anipqo almost non intrusive parametric query o...</td>\n",
              "      <td>12781</td>\n",
              "      <td>noref</td>\n",
              "      <td>parametric query optimization optimization of ...</td>\n",
              "      <td>on the production of anorexic plan diagrams</td>\n",
              "      <td>anipqo almost non intrusive parametric query o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>selection and ranking of text from highly impe...</td>\n",
              "      <td>12782</td>\n",
              "      <td>noref</td>\n",
              "      <td>noref</td>\n",
              "      <td>noref</td>\n",
              "      <td>selection and ranking of text from highly impe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>conditional random fields for multi agent rein...</td>\n",
              "      <td>12783</td>\n",
              "      <td>noref</td>\n",
              "      <td>sequential optimality and coordination in mult...</td>\n",
              "      <td>noref</td>\n",
              "      <td>conditional random fields for multi agent rein...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>multi dimensional description logics</td>\n",
              "      <td>12784</td>\n",
              "      <td>noref</td>\n",
              "      <td>noref</td>\n",
              "      <td>noref</td>\n",
              "      <td>multi dimensional description logics noref noref</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10</td>\n",
              "      <td>fast on line index construction by geometric p...</td>\n",
              "      <td>12785</td>\n",
              "      <td>noref</td>\n",
              "      <td>the performance of three database storage stru...</td>\n",
              "      <td>low cost management of inverted files for onli...</td>\n",
              "      <td>fast on line index construction by geometric p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>12</td>\n",
              "      <td>reasoning about rings</td>\n",
              "      <td>12786</td>\n",
              "      <td>noref</td>\n",
              "      <td>abstract interpretation a unified lattice mode...</td>\n",
              "      <td>automatic verification of parameterized linear...</td>\n",
              "      <td>reasoning about rings abstract interpretation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>14</td>\n",
              "      <td>transductive regression piloted by inter manif...</td>\n",
              "      <td>12787</td>\n",
              "      <td>noref</td>\n",
              "      <td>efficient co regularised least squares regress...</td>\n",
              "      <td>noref</td>\n",
              "      <td>transductive regression piloted by inter manif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>15</td>\n",
              "      <td>a fast and usually linear algorithm for global...</td>\n",
              "      <td>12788</td>\n",
              "      <td>noref</td>\n",
              "      <td>a unified approach to global program optimizat...</td>\n",
              "      <td>the program structure tree computing control r...</td>\n",
              "      <td>a fast and usually linear algorithm for global...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>16</td>\n",
              "      <td>conditional constraint satisfaction logical fo...</td>\n",
              "      <td>12789</td>\n",
              "      <td>noref</td>\n",
              "      <td>noref</td>\n",
              "      <td>noref</td>\n",
              "      <td>conditional constraint satisfaction logical fo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  ...                                             merged\n",
              "0   1  ...  autodomainmine a graphical data mining system ...\n",
              "1   2  ...  anipqo almost non intrusive parametric query o...\n",
              "2   4  ...  selection and ranking of text from highly impe...\n",
              "3   5  ...  conditional random fields for multi agent rein...\n",
              "4   7  ...   multi dimensional description logics noref noref\n",
              "5  10  ...  fast on line index construction by geometric p...\n",
              "6  12  ...  reasoning about rings abstract interpretation ...\n",
              "7  14  ...  transductive regression piloted by inter manif...\n",
              "8  15  ...  a fast and usually linear algorithm for global...\n",
              "9  16  ...  conditional constraint satisfaction logical fo...\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_x8MMvk8Hlmt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "8b920c51-1bc9-4edc-d85e-e4e69bf59087"
      },
      "source": [
        "# tokenize train data on the whole TEXT (train+test) to see the max sent_len\n",
        "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
        "tokenizer.fit_on_texts(text.title)\n",
        "t = tokenizer.texts_to_sequences(text.title)\n",
        "print(text.title[:10])\n",
        "print(t[:10])\n",
        "print(len(max(t, key=len)))\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "dict_len3 = len(word_index)\n",
        "print(word_index)\n",
        "sent_len = []\n",
        "for i in t:\n",
        "  sent_len.append(len(i))\n",
        "\n",
        "plt.hist(sent_len,bins=28)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    interactive visual exploration of neighbor bas...\n",
            "1    autodomainmine a graphical data mining system ...\n",
            "2    anipqo almost non intrusive parametric query o...\n",
            "3    relational division four algorithms and their ...\n",
            "4    selection and ranking of text from highly impe...\n",
            "5    conditional random fields for multi agent rein...\n",
            "6    simplifying xml schema effortless handling of ...\n",
            "7                 multi dimensional description logics\n",
            "8    funbase a function based information managemen...\n",
            "9    inverted matrix efficient discovery of frequen...\n",
            "Name: title, dtype: object\n",
            "[[123, 239, 421, 2, 766, 9, 133, 5, 8, 176], [6586, 3, 407, 8, 35, 16, 1, 120, 75], [6587, 1896, 114, 3491, 859, 23, 75, 1, 1002, 244, 264], [49, 2612, 1299, 58, 4, 428, 57], [94, 4, 126, 2, 34, 24, 618, 1436, 3492, 1, 27, 2, 441, 170], [393, 265, 638, 1, 44, 225, 327, 14], [2432, 56, 210, 6588, 530, 2, 2142, 980, 476], [44, 200, 323, 515], [6589, 3, 346, 9, 17, 46, 16], [924, 568, 30, 156, 2, 484, 1626, 5, 45, 662, 5, 6, 106, 2, 123, 35]]\n",
            "28\n",
            "Found 13273 unique tokens.\n",
            "{'for': 1, 'of': 2, 'a': 3, 'and': 4, 'in': 5, 'the': 6, 'to': 7, 'data': 8, 'based': 9, 'on': 10, 'an': 11, 'with': 12, 'using': 13, 'learning': 14, 'web': 15, 'system': 16, 'information': 17, 'database': 18, 'systems': 19, 'model': 20, 'search': 21, 'analysis': 22, 'query': 23, 'from': 24, 'approach': 25, 'language': 26, 'retrieval': 27, 'software': 28, 'databases': 29, 'efficient': 30, 'semantic': 31, 'models': 32, 'by': 33, 'text': 34, 'mining': 35, 'distributed': 36, 'time': 37, 'knowledge': 38, 'design': 39, 'queries': 40, 'programming': 41, 'object': 42, 'processing': 43, 'multi': 44, 'large': 45, 'management': 46, 'oriented': 47, 'evaluation': 48, 'relational': 49, 'computer': 50, 'classification': 51, 'automatic': 52, 'dynamic': 53, 'algorithm': 54, 'clustering': 55, 'xml': 56, 'performance': 57, 'algorithms': 58, 'framework': 59, 'logic': 60, 'networks': 61, 'document': 62, 'machine': 63, 'translation': 64, 'structure': 65, 'reasoning': 66, 'method': 67, 'modeling': 68, 'generation': 69, 'parallel': 70, 'detection': 71, 'study': 72, 'as': 73, 'temporal': 74, 'optimization': 75, 'engineering': 76, 'user': 77, 'parsing': 78, 'programs': 79, 'probabilistic': 80, 'applications': 81, 'application': 82, 'support': 83, 'control': 84, 'program': 85, 'towards': 86, 'new': 87, 'extraction': 88, 'case': 89, 'high': 90, 'tree': 91, 'multiple': 92, 'semantics': 93, 'selection': 94, 'through': 95, 'via': 96, 'network': 97, 'word': 98, 'planning': 99, 'science': 100, 'development': 101, 'methods': 102, 'statistical': 103, 'environment': 104, 'graph': 105, 'context': 106, 'natural': 107, 'rules': 108, 'course': 109, 'fast': 110, 'architecture': 111, 'constraints': 112, 'indexing': 113, 'non': 114, 'real': 115, 'access': 116, 'teaching': 117, 'techniques': 118, 'memory': 119, 'process': 120, 'computing': 121, 'adaptive': 122, 'interactive': 123, 'domain': 124, 'similarity': 125, 'ranking': 126, 'feature': 127, 'over': 128, 'online': 129, 'inference': 130, 'structures': 131, 'constraint': 132, 'patterns': 133, 'theory': 134, 'tool': 135, 'level': 136, 'problem': 137, 'integration': 138, 'languages': 139, 'representation': 140, 'scale': 141, 'implementation': 142, 'structured': 143, 'hierarchical': 144, 'incremental': 145, 'documents': 146, 'improving': 147, 'order': 148, 'base': 149, 'its': 150, 'driven': 151, 'linear': 152, 'objects': 153, 'first': 154, 'matching': 155, 'discovery': 156, 'recognition': 157, 'relevance': 158, 'space': 159, 'effective': 160, 'trees': 161, 'into': 162, 'social': 163, 'active': 164, 'decision': 165, 'type': 166, 'optimal': 167, 'complex': 168, 'integrating': 169, 'content': 170, 'rule': 171, 'image': 172, 'problems': 173, 'supervised': 174, 'spatial': 175, 'streams': 176, 'estimation': 177, 'local': 178, 'state': 179, 'join': 180, 'between': 181, 'code': 182, 'two': 183, 'index': 184, 'pattern': 185, 'bayesian': 186, 'relations': 187, 'semi': 188, 'feedback': 189, 'topic': 190, 'speech': 191, 'graphs': 192, 'answering': 193, 'at': 194, 'class': 195, 'mobile': 196, 'grammars': 197, 'is': 198, 'grammar': 199, 'dimensional': 200, 'filtering': 201, 'automated': 202, 'services': 203, 'combining': 204, 'resolution': 205, 'abstract': 206, 'supporting': 207, 'lexical': 208, 'results': 209, 'schema': 210, 'quality': 211, 'strategies': 212, 'collaborative': 213, 'disambiguation': 214, 'understanding': 215, 'peer': 216, 'syntactic': 217, 'testing': 218, 'finding': 219, 'test': 220, 'robust': 221, 'engine': 222, 'exploiting': 223, 'use': 224, 'agent': 225, 'generalized': 226, 'functional': 227, 'research': 228, 'specification': 229, 'scalable': 230, 'term': 231, 'solving': 232, 'markov': 233, 'formal': 234, 'java': 235, 'evaluating': 236, 'features': 237, 'querying': 238, 'visual': 239, 'types': 240, 'computation': 241, 'acquisition': 242, 'integrated': 243, 'cost': 244, 'about': 245, 'cross': 246, 'complexity': 247, 'summarization': 248, 'concurrency': 249, 'kernel': 250, 'flow': 251, 'generating': 252, 'view': 253, 'prediction': 254, 'project': 255, 'service': 256, 'general': 257, 'dependency': 258, 'approximate': 259, 'building': 260, 'event': 261, 'views': 262, 'unsupervised': 263, 'functions': 264, 'random': 265, 'computational': 266, 'empirical': 267, 'comparison': 268, 'question': 269, 'environments': 270, 'vector': 271, 'association': 272, 'set': 273, 'maintenance': 274, 'concurrent': 275, 'how': 276, 'checking': 277, 'processes': 278, 'transaction': 279, 'students': 280, 'storage': 281, 'value': 282, 'interface': 283, 'self': 284, 'partial': 285, 'experience': 286, 'concept': 287, 'chinese': 288, 'interpretation': 289, 'entity': 290, 'sql': 291, 'machines': 292, 'practical': 293, 'execution': 294, 'verification': 295, 'structural': 296, 'report': 297, 'requirements': 298, 'global': 299, 'hybrid': 300, 'corpora': 301, 'heterogeneous': 302, 'path': 303, 'sense': 304, 'continuous': 305, 'task': 306, 'human': 307, 'world': 308, 'simple': 309, 'introductory': 310, 'training': 311, 'extended': 312, 'open': 313, 'games': 314, 'line': 315, 'role': 316, 'concepts': 317, 'japanese': 318, 'sets': 319, 'construction': 320, 'multimedia': 321, 'corpus': 322, 'description': 323, 'free': 324, 'interaction': 325, 'scheduling': 326, 'reinforcement': 327, 'linguistic': 328, 'extracting': 329, 'behavior': 330, 'k': 331, 'consistency': 332, 'sampling': 333, 'action': 334, 'regression': 335, 'detecting': 336, 'optimizing': 337, 'evolution': 338, 'conceptual': 339, 'searching': 340, 'segmentation': 341, 'resource': 342, 'allocation': 343, 'identification': 344, 'sensitive': 345, 'function': 346, 'bases': 347, 'static': 348, 'scheme': 349, 'domains': 350, 'intelligent': 351, 'english': 352, 'flexible': 353, 'unification': 354, 'privacy': 355, 'robot': 356, 'expert': 357, 'server': 358, 'sources': 359, 'curriculum': 360, 'tools': 361, 'discourse': 362, 'series': 363, 'belief': 364, 'logical': 365, 'monitoring': 366, 'collection': 367, 'file': 368, 'visualization': 369, 'agents': 370, 'dialogue': 371, 'security': 372, 'dependencies': 373, 'calculus': 374, 'parser': 375, 'sequential': 376, 'representations': 377, 'categorization': 378, 'component': 379, 'latent': 380, 'mapping': 381, 'experimental': 382, 'dbms': 383, 'one': 384, 'reduction': 385, 'technique': 386, 'undergraduate': 387, 'projects': 388, 'abstraction': 389, 'stream': 390, 'expansion': 391, 'discovering': 392, 'conditional': 393, 'recovery': 394, 'top': 395, 'heuristic': 396, 'stochastic': 397, 'classifiers': 398, 'source': 399, 'measures': 400, 'that': 401, 'ontology': 402, 'error': 403, 'cs': 404, 'aware': 405, 'deductive': 406, 'graphical': 407, 'independent': 408, 'compiler': 409, 'distance': 410, 'sequence': 411, 'alignment': 412, 'what': 413, 'strategy': 414, 'up': 415, 'without': 416, 'education': 417, 'or': 418, 'experiments': 419, 'caching': 420, 'exploration': 421, 'making': 422, 'sharing': 423, 'preserving': 424, 'communication': 425, 'joins': 426, 'aggregation': 427, 'their': 428, 'page': 429, 'some': 430, 'finite': 431, 'induction': 432, 'spoken': 433, 'specifications': 434, 'recursive': 435, 'link': 436, 'propagation': 437, 'identifying': 438, 'relation': 439, 'c': 440, 'video': 441, 'unified': 442, 'estimating': 443, 'improve': 444, 'rank': 445, 'predicting': 446, 'tracking': 447, 'sensor': 448, 'updates': 449, 'transfer': 450, 'transactions': 451, 'users': 452, 'specific': 453, 'phrase': 454, 'hidden': 455, 'under': 456, 'extending': 457, 'approaches': 458, 'shared': 459, 'qualitative': 460, 'improved': 461, 'issues': 462, 'compression': 463, 'experiences': 464, 'game': 465, 'intelligence': 466, 'exploring': 467, 'toward': 468, 'co': 469, 'community': 470, 'effects': 471, 'sentence': 472, 'product': 473, 'tagging': 474, 'managing': 475, 'expressions': 476, 'cs1': 477, 'labeling': 478, 'interfaces': 479, 'named': 480, 'very': 481, 'approximation': 482, 'update': 483, 'frequent': 484, 'are': 485, 'directed': 486, 'it': 487, 'form': 488, 'technology': 489, 'descriptions': 490, 'workshop': 491, 'relationship': 492, 'internet': 493, 'mechanism': 494, 'discriminative': 495, 'constrained': 496, 'virtual': 497, 'student': 498, 'boosting': 499, 'cluster': 500, 'words': 501, 'properties': 502, 'more': 503, 'pages': 504, 'sparse': 505, 'beyond': 506, 'texts': 507, 'architectures': 508, 'not': 509, 'transformation': 510, 'organization': 511, 'automatically': 512, 'collections': 513, 'change': 514, 'logics': 515, 'novel': 516, 'plans': 517, 'spaces': 518, 'decomposition': 519, 'impact': 520, 'courses': 521, 'annotation': 522, 'personalized': 523, 'modelling': 524, 'simulation': 525, 'maximum': 526, 'scientific': 527, 'metric': 528, 'incorporating': 529, 'handling': 530, 'nested': 531, 'browsing': 532, 'neural': 533, 'perspective': 534, 'attribute': 535, 'dictionary': 536, 'ir': 537, 'cache': 538, 'wide': 539, 'analyzing': 540, 'partitioning': 541, 'representing': 542, 'modular': 543, 'processor': 544, 'digital': 545, 'integrity': 546, 'adaptation': 547, 'weighted': 548, 'theoretic': 549, 'news': 550, 'size': 551, 'incomplete': 552, 'operating': 553, 'bilingual': 554, 'lexicon': 555, 'higher': 556, 'noun': 557, 'syntax': 558, 'operations': 559, 'preferences': 560, 'keyword': 561, 'effectiveness': 562, 'cooperative': 563, 'uncertainty': 564, 'distribution': 565, 'fault': 566, 'composition': 567, 'matrix': 568, 'power': 569, 'do': 570, 'sequences': 571, 'assessment': 572, 'prolog': 573, 'plan': 574, 'engines': 575, 'extension': 576, 'extensible': 577, 'satisfaction': 578, 'measuring': 579, 'generic': 580, 'answer': 581, 'utility': 582, 'can': 583, 'typed': 584, 'reuse': 585, 'group': 586, 'ad': 587, 'actions': 588, 'disk': 589, 'images': 590, 'schemes': 591, 'low': 592, 'classes': 593, 'synthesis': 594, 'debugging': 595, 'algebra': 596, 'artificial': 597, 'textual': 598, 'advanced': 599, 'resources': 600, 'e': 601, 'multidimensional': 602, 'predictive': 603, 'iterative': 604, 'good': 605, 'methodology': 606, 'measure': 607, 'physical': 608, 'full': 609, 'challenges': 610, 'causal': 611, 'olap': 612, 'diagnosis': 613, 'components': 614, 'vs': 615, 'best': 616, 'hashing': 617, 'highly': 618, 'recommendation': 619, 'sentences': 620, 'applying': 621, 'when': 622, 'example': 623, 'implementing': 624, 'graphics': 625, 'production': 626, 'small': 627, 'b': 628, 'kernels': 629, 'business': 630, 'fuzzy': 631, 'garbage': 632, 'part': 633, 'hash': 634, 'compilation': 635, 'reference': 636, 'answers': 637, 'fields': 638, 'multilingual': 639, 'common': 640, 'tasks': 641, 'practice': 642, 'automata': 643, 'you': 644, 'meta': 645, 'assignment': 646, 'efficiency': 647, 'string': 648, 'hierarchies': 649, 'refinement': 650, 'better': 651, 'coordination': 652, 'goal': 653, 'binary': 654, 'cognitive': 655, 'indexes': 656, 'effect': 657, 'boolean': 658, 'files': 659, 'ordering': 660, 'developing': 661, 'datasets': 662, 'parallelism': 663, 'aspect': 664, 'symbolic': 665, 'precision': 666, 'proving': 667, 'three': 668, 'pruning': 669, 'contextual': 670, 'single': 671, 'designing': 672, 'preference': 673, 'protocols': 674, 'comparative': 675, 'n': 676, 'inheritance': 677, 'embedded': 678, 'instance': 679, 'aggregate': 680, 'nearest': 681, 'versus': 682, 'moving': 683, 'scaling': 684, 'explanation': 685, 'dependence': 686, 'enhancing': 687, 'fusion': 688, 'laboratory': 689, 'ai': 690, 'ontologies': 691, 'history': 692, 'validation': 693, 'dependent': 694, 'autonomous': 695, 'variable': 696, 'sites': 697, 'partially': 698, 'efficiently': 699, 'map': 700, 'personal': 701, 'presence': 702, 'policies': 703, 'schemas': 704, 'margin': 705, 'declarative': 706, 'clusters': 707, 'classifier': 708, 'secure': 709, 'probability': 710, 'minimal': 711, 'end': 712, 'range': 713, 'why': 714, 'transformations': 715, 're': 716, 'policy': 717, 'music': 718, 'solution': 719, 'algebraic': 720, 'relevant': 721, 'different': 722, 'universal': 723, 'correlation': 724, 'r': 725, 'mixture': 726, 'constructing': 727, 'gaussian': 728, 'client': 729, 'instruction': 730, 'protocol': 731, 'expression': 732, 'prototype': 733, 'entities': 734, 'bounded': 735, 'modal': 736, 'metrics': 737, 'proof': 738, 'predicate': 739, 'relationships': 740, 'heuristics': 741, 'tables': 742, 'across': 743, 'accurate': 744, 'paradigm': 745, 'examples': 746, 'quantitative': 747, 'errors': 748, 'robots': 749, 'buffer': 750, 'morphological': 751, 'entropy': 752, 'criteria': 753, 'wikipedia': 754, 'locking': 755, 'interactions': 756, 'accuracy': 757, 'tag': 758, 'comparing': 759, 'coverage': 760, 'activity': 761, 'style': 762, 'direct': 763, 'statistics': 764, 'complete': 765, 'neighbor': 766, 'logs': 767, 'electronic': 768, 'principles': 769, 'implicit': 770, 'load': 771, 'opinion': 772, 'platform': 773, 'experiment': 774, 'way': 775, 'motion': 776, 'overview': 777, 'variables': 778, 'log': 779, 'expressive': 780, 'point': 781, 'events': 782, 'version': 783, 'library': 784, 'trust': 785, 'theorem': 786, 'attributes': 787, 'click': 788, 'values': 789, 'definition': 790, 'generative': 791, 'configuration': 792, 'introduction': 793, 'label': 794, 'record': 795, 'workflow': 796, 'demand': 797, 'xquery': 798, 'evidence': 799, 'revisited': 800, 'p2p': 801, 'hoc': 802, 'site': 803, 'uncertain': 804, 'generalization': 805, 'early': 806, 'dimensionality': 807, 'revision': 808, 'terms': 809, 'materialized': 810, 'generator': 811, 'sat': 812, 'enterprise': 813, 'dynamically': 814, 'result': 815, 'diagrams': 816, 'grid': 817, 'deterministic': 818, 'auctions': 819, 'like': 820, 'location': 821, 'survey': 822, 'basis': 823, 'tutorial': 824, 'aspects': 825, 'compact': 826, 'evolving': 827, 'proximity': 828, 'replication': 829, 'array': 830, 'ambiguity': 831, 'synchronous': 832, 'manipulation': 833, 'alternative': 834, 'summary': 835, 'main': 836, 'bounds': 837, 'mechanisms': 838, 'correctness': 839, 'deep': 840, 'streaming': 841, 'architectural': 842, 'factorization': 843, 'propositional': 844, 'polynomial': 845, 'weighting': 846, 'verb': 847, 'merging': 848, 'wireless': 849, '1': 850, 'limited': 851, 'introducing': 852, 'school': 853, 'mt': 854, 'replicated': 855, 'long': 856, 'distributions': 857, 'external': 858, 'parametric': 859, 'phrases': 860, 'demonstration': 861, 'maintaining': 862, 'reducing': 863, 'inductive': 864, 'media': 865, 'reliability': 866, 'down': 867, 'among': 868, 'writing': 869, 'redundancy': 870, 'parameter': 871, 'field': 872, 'modules': 873, 'enhanced': 874, 'selectivity': 875, 'localization': 876, 'questions': 877, 'multimodal': 878, 'guided': 879, 'compiling': 880, 'xpath': 881, 'combination': 882, 'summaries': 883, 'classroom': 884, 'routing': 885, 'genetic': 886, 'spam': 887, 'inferring': 888, 'theories': 889, 'medical': 890, 'navigation': 891, 'spectral': 892, 'uml': 893, 'tuning': 894, 'topics': 895, 'safe': 896, 'negotiation': 897, 'vision': 898, 'subspace': 899, 'changes': 900, 'discrete': 901, 'spatio': 902, 'specifying': 903, 'implications': 904, 'intensive': 905, 'visualizing': 906, 'lessons': 907, 'assessing': 908, 'optimizations': 909, 'massive': 910, 'dynamics': 911, 'correction': 912, 'satisfiability': 913, 'interprocedural': 914, 'compressed': 915, 'shape': 916, 'solutions': 917, 'second': 918, 'key': 919, 'phase': 920, 'joint': 921, 'reverse': 922, 'procedures': 923, 'inverted': 924, 'bound': 925, 'theoretical': 926, 'locality': 927, 'be': 928, 'composite': 929, 'sentiment': 930, 'during': 931, 'pomdps': 932, 'centric': 933, 'rewriting': 934, 'combinatorial': 935, 'ensemble': 936, 'counting': 937, 'default': 938, 'systematic': 939, 'optimizer': 940, 'lazy': 941, 'aided': 942, 'influence': 943, 'infrastructure': 944, 'geometric': 945, 'compositional': 946, 'means': 947, 'evolutionary': 948, 'indices': 949, 'warehouse': 950, 'register': 951, 'classifying': 952, 'goals': 953, 'pointer': 954, 'optimized': 955, 'region': 956, 'fine': 957, 'investigation': 958, 'advertising': 959, 'transitive': 960, 'conversion': 961, 'tractable': 962, 'devices': 963, 'warehousing': 964, 'mixed': 965, 'hardware': 966, 'balancing': 967, 'preliminary': 968, 'hierarchy': 969, 'associative': 970, 'german': 971, 'safety': 972, 'density': 973, 'uniform': 974, 'projection': 975, 'usage': 976, 'rdf': 977, 'reactive': 978, 'multiagent': 979, 'regular': 980, 'iteration': 981, 'attacks': 982, 'near': 983, 'aggregates': 984, 'bottom': 985, 'core': 986, 'all': 987, 'multiprocessor': 988, 'recursion': 989, 'discriminant': 990, 'interval': 991, 'table': 992, 'hypertext': 993, 'reliable': 994, 'applied': 995, 'mappings': 996, 'future': 997, 'svm': 998, 'related': 999, 'year': 1000, 'noisy': 1001, 'nonlinear': 1002, 'closed': 1003, 'length': 1004, 'university': 1005, 'max': 1006, 'equivalence': 1007, 'similar': 1008, 'activities': 1009, 'morphology': 1010, 'points': 1011, 'block': 1012, 'rapid': 1013, 'multidatabase': 1014, 'elimination': 1015, 'proofs': 1016, 'critical': 1017, 'learned': 1018, 'dimension': 1019, 'step': 1020, 'technologies': 1021, 'risk': 1022, 'procedure': 1023, 'output': 1024, 'studies': 1025, 'characterization': 1026, 'selective': 1027, 'name': 1028, 'i': 1029, 'enabling': 1030, 'hard': 1031, 'help': 1032, 'tolerant': 1033, 'team': 1034, 'duplicate': 1035, 'grained': 1036, 'pagerank': 1037, 'call': 1038, 'regularization': 1039, 'learn': 1040, 'cs2': 1041, 'closure': 1042, 'associations': 1043, 'operators': 1044, 'within': 1045, 'focused': 1046, 'argumentation': 1047, 'mutual': 1048, 'federated': 1049, 'commerce': 1050, 'dictionaries': 1051, 'message': 1052, 'international': 1053, 'dual': 1054, 'communities': 1055, 'libraries': 1056, 'determining': 1057, 'consistent': 1058, 'profiling': 1059, 'db2': 1060, 'industrial': 1061, 'expertise': 1062, 'review': 1063, 'gap': 1064, 'synchronization': 1065, 'reordering': 1066, 'gradient': 1067, 'pseudo': 1068, 'relative': 1069, 'paths': 1070, 'oracle': 1071, 'disjunctive': 1072, 'updating': 1073, 'normal': 1074, 'minimization': 1075, 'interoperability': 1076, 'soft': 1077, 'than': 1078, 'experts': 1079, 'd': 1080, 'providing': 1081, 'bridging': 1082, '3d': 1083, 'difference': 1084, 'anaphora': 1085, 'gene': 1086, 'many': 1087, 'partitioned': 1088, 'number': 1089, 'voting': 1090, 'ii': 1091, 'market': 1092, 'independence': 1093, 'cubes': 1094, 'simulator': 1095, 'asynchronous': 1096, 'annotations': 1097, 'stable': 1098, 'we': 1099, 'capturing': 1100, 'negative': 1101, 'paper': 1102, 'korean': 1103, 'pre': 1104, 'formation': 1105, 'right': 1106, 'metadata': 1107, 'adjoining': 1108, 'redundant': 1109, 'scoring': 1110, 'profiles': 1111, 'predicates': 1112, 'polymorphic': 1113, 'customer': 1114, 'lightweight': 1115, 'frequency': 1116, 'simultaneous': 1117, 'smoothing': 1118, 'email': 1119, 'look': 1120, 'progress': 1121, 'decentralized': 1122, 'precise': 1123, 'bayes': 1124, 'skills': 1125, 'speed': 1126, 'reading': 1127, 'ordered': 1128, 'deriving': 1129, 'arrays': 1130, 'operational': 1131, 'animation': 1132, 'informative': 1133, 'protein': 1134, 'arabic': 1135, 'back': 1136, 'life': 1137, 'translating': 1138, 'mdps': 1139, 'measurement': 1140, 'prototyping': 1141, 'abstractions': 1142, 'middleware': 1143, 'dialogues': 1144, 'historical': 1145, 'completeness': 1146, 'taxonomy': 1147, 'minimum': 1148, 'dialog': 1149, 'toolkit': 1150, 'creating': 1151, 'manager': 1152, 'linking': 1153, 'progressive': 1154, 'extensions': 1155, 'only': 1156, 'transition': 1157, 'controlled': 1158, 'your': 1159, 'definitions': 1160, 'links': 1161, 'situation': 1162, 'inter': 1163, 'recommendations': 1164, 'resolving': 1165, 'processors': 1166, 'placement': 1167, 'unifying': 1168, 'reviews': 1169, 'unstructured': 1170, 'template': 1171, 'lisp': 1172, 'unknown': 1173, 'biomedical': 1174, 'programmers': 1175, 'structuring': 1176, 'slicing': 1177, 'blog': 1178, 'ml': 1179, 'maximal': 1180, 'organizing': 1181, 'differences': 1182, 'improvement': 1183, 'planner': 1184, 'projections': 1185, 'importance': 1186, 'teach': 1187, 'embedding': 1188, 'browser': 1189, 'automating': 1190, 'energy': 1191, 'sample': 1192, 'ranked': 1193, 'transactional': 1194, 'categories': 1195, 'argument': 1196, 'assembly': 1197, 'termination': 1198, 'crawling': 1199, 'lattice': 1200, 'nonmonotonic': 1201, 'traffic': 1202, 'centered': 1203, 'valued': 1204, 'make': 1205, 'manifold': 1206, 'standard': 1207, 'analogy': 1208, 'utilizing': 1209, 'window': 1210, 'skyline': 1211, 'tags': 1212, 'failures': 1213, 'net': 1214, 'topical': 1215, 'csp': 1216, 'bootstrapping': 1217, 'chart': 1218, 'input': 1219, 'generated': 1220, 'thesaurus': 1221, 'short': 1222, 'fully': 1223, 'score': 1224, 'normalization': 1225, 'algorithmic': 1226, 'run': 1227, 'warehouses': 1228, 'retrieving': 1229, '3': 1230, 'work': 1231, 'breadth': 1232, 'cube': 1233, 'dissemination': 1234, 'nlp': 1235, 'module': 1236, 'loop': 1237, 'ada': 1238, 'explicit': 1239, 'names': 1240, 'confidence': 1241, 'bias': 1242, 'coreference': 1243, 'trends': 1244, 'enhance': 1245, 'observations': 1246, 'road': 1247, 'no': 1248, 'scope': 1249, 'meaning': 1250, 'weak': 1251, 'computers': 1252, 'frame': 1253, 'lists': 1254, 'topological': 1255, 'layout': 1256, 'undergraduates': 1257, 'semistructured': 1258, 'signature': 1259, 'dirichlet': 1260, 'principle': 1261, 'availability': 1262, 'go': 1263, 'broadcast': 1264, 'zero': 1265, 'depth': 1266, 'anytime': 1267, 'categorial': 1268, 'factors': 1269, 'benchmark': 1270, 'profile': 1271, 'prior': 1272, 'least': 1273, 'collective': 1274, 'investigating': 1275, 'off': 1276, 'interpreter': 1277, 'personalization': 1278, 'svms': 1279, 'biological': 1280, 'formulas': 1281, 'french': 1282, 'mathematics': 1283, 'response': 1284, 'occurrence': 1285, 'family': 1286, 'behaviors': 1287, 'correct': 1288, 'chain': 1289, 'interesting': 1290, '2': 1291, 'generalizing': 1292, 'failure': 1293, 'maps': 1294, 'separation': 1295, 'industry': 1296, 'side': 1297, 'panel': 1298, 'four': 1299, 'parse': 1300, 'useful': 1301, 'perception': 1302, 'remote': 1303, 'mathematical': 1304, 'levels': 1305, 'passing': 1306, 'transliteration': 1307, 'head': 1308, 'expected': 1309, 'noise': 1310, 'persistent': 1311, 'assistant': 1312, 'derived': 1313, 'diverse': 1314, 'playing': 1315, 'pair': 1316, 'deadlock': 1317, 'adapting': 1318, 'servers': 1319, 'adding': 1320, 'unlabeled': 1321, 'less': 1322, 'monotonic': 1323, 'templates': 1324, 'quasi': 1325, 'biased': 1326, 'verifying': 1327, 'purpose': 1328, 'dataflow': 1329, 'labeled': 1330, 'constructive': 1331, 'roles': 1332, 'target': 1333, 'robustness': 1334, 'pragmatic': 1335, 'ensembles': 1336, 'conscious': 1337, 'defined': 1338, 'binding': 1339, 'match': 1340, 'session': 1341, 'operator': 1342, 'logistic': 1343, 'characterizing': 1344, 'surface': 1345, 'randomized': 1346, 'multiclass': 1347, 'derivation': 1348, 'conflict': 1349, 'both': 1350, 'records': 1351, 'current': 1352, 'communications': 1353, 'usability': 1354, 'category': 1355, 'success': 1356, 'restructuring': 1357, 'probabilities': 1358, 'commitment': 1359, 'logging': 1360, 'histograms': 1361, 'explanations': 1362, 'designs': 1363, 'networking': 1364, 'parameterized': 1365, 'predict': 1366, 'workload': 1367, 'assignments': 1368, 'operation': 1369, 'creation': 1370, 'office': 1371, 'analyzer': 1372, 'formalism': 1373, 'presentation': 1374, 'annotated': 1375, 'other': 1376, 'inconsistency': 1377, 'coherence': 1378, 'scene': 1379, 'contexts': 1380, 'directions': 1381, 'exact': 1382, 'branch': 1383, 'cases': 1384, 'versions': 1385, 'choice': 1386, 'publishing': 1387, 'symmetric': 1388, 'convex': 1389, 'vocabulary': 1390, 'educational': 1391, 'reconstruction': 1392, 'formulation': 1393, 'reduce': 1394, 'groups': 1395, 'focus': 1396, 'judgments': 1397, 'eliminating': 1398, 'sort': 1399, 'sorting': 1400, 'axiomatic': 1401, 'quantified': 1402, 'suite': 1403, 'typing': 1404, 'forward': 1405, 'workflows': 1406, 'secondary': 1407, 'batch': 1408, 'archives': 1409, 'decisions': 1410, 'orientation': 1411, 'parts': 1412, 'granularity': 1413, 'leveraging': 1414, 'against': 1415, 'abduction': 1416, 'lexicalized': 1417, 'parsers': 1418, 'behaviour': 1419, 'practices': 1420, 'portable': 1421, 'challenge': 1422, 'rate': 1423, 'passage': 1424, 'itemsets': 1425, 'formalization': 1426, 'just': 1427, 'public': 1428, 'arbitrary': 1429, 'geometry': 1430, 'legacy': 1431, 'lab': 1432, 'sound': 1433, 'analyses': 1434, 'gram': 1435, 'imperfect': 1436, 'vertical': 1437, 'windows': 1438, 'shallow': 1439, 'manipulating': 1440, 'intent': 1441, 'locating': 1442, 'encoding': 1443, 'majors': 1444, 'proactive': 1445, 'approximations': 1446, 'layered': 1447, 'positive': 1448, 'thinking': 1449, 'relaxed': 1450, 'www': 1451, 'agile': 1452, 'filters': 1453, 'comprehension': 1454, 'next': 1455, 'item': 1456, 'runtime': 1457, 'easy': 1458, 'costs': 1459, 'formalisms': 1460, 'loss': 1461, 'laboratories': 1462, 'behavioral': 1463, 'extreme': 1464, 'middle': 1465, 'beliefs': 1466, 'subtyping': 1467, 'lingual': 1468, 'io': 1469, 'factor': 1470, 'nets': 1471, 'connectionist': 1472, 'distributional': 1473, 'status': 1474, 'inverse': 1475, 'people': 1476, 'signatures': 1477, 'breaking': 1478, 'technical': 1479, 'forms': 1480, 'recommender': 1481, 'private': 1482, 'treatment': 1483, 'regularized': 1484, 'geographic': 1485, 'generate': 1486, 'procedural': 1487, 'edge': 1488, 'articles': 1489, 'observation': 1490, 'walk': 1491, 'foundations': 1492, 'correlated': 1493, 'controlling': 1494, 'repositories': 1495, 'effort': 1496, 'adaptable': 1497, 'acquiring': 1498, 'reorganization': 1499, 'imprecise': 1500, 'cardinality': 1501, 'light': 1502, 'mental': 1503, 'backtracking': 1504, 'pairs': 1505, 'need': 1506, 'frameworks': 1507, 'recall': 1508, 'optimality': 1509, 'account': 1510, 'broad': 1511, 'teachers': 1512, 'coupling': 1513, 'optimistic': 1514, 'clickthrough': 1515, 'factored': 1516, 'selecting': 1517, 'clause': 1518, 'terminological': 1519, 'inclusion': 1520, 'find': 1521, 'db': 1522, 'suggestion': 1523, 'opportunities': 1524, 'does': 1525, 'missing': 1526, 'sensing': 1527, 'subsequence': 1528, 'area': 1529, 'list': 1530, 'considerations': 1531, 'reranking': 1532, 'prefetching': 1533, 'poster': 1534, 'regions': 1535, 'parameters': 1536, '20': 1537, 'pairwise': 1538, 'states': 1539, 'weight': 1540, 'balanced': 1541, 'interpreting': 1542, 'potential': 1543, 'foundation': 1544, 'center': 1545, 'meets': 1546, 'unit': 1547, 'cleaning': 1548, 'specialization': 1549, 'modularity': 1550, 'repository': 1551, 'stage': 1552, 'filter': 1553, 'microsoft': 1554, 'wordnet': 1555, 'build': 1556, 'changing': 1557, 'minimizing': 1558, 'cooperation': 1559, 'display': 1560, 'circumscription': 1561, 'neighborhood': 1562, 'estimates': 1563, 'they': 1564, 'compound': 1565, 'refining': 1566, 'bidirectional': 1567, 'messages': 1568, 'ellipsis': 1569, 'bug': 1570, 'sum': 1571, 'grammatical': 1572, 'contract': 1573, 'splitting': 1574, 'provenance': 1575, 'well': 1576, 'theorems': 1577, 'blind': 1578, 'out': 1579, 'collaboration': 1580, 'commit': 1581, 'determination': 1582, 'diversity': 1583, 'trajectories': 1584, 'describing': 1585, 'infinite': 1586, 'solver': 1587, 'multilevel': 1588, 'entailment': 1589, 'polymorphism': 1590, 'disks': 1591, 'categorical': 1592, 'standards': 1593, 'quantifying': 1594, 'diagnostic': 1595, 'observable': 1596, 'exploratory': 1597, 'interest': 1598, 'isolation': 1599, 'monte': 1600, 'carlo': 1601, 'read': 1602, 'know': 1603, 'hypothesis': 1604, 'channel': 1605, 'conversational': 1606, 'anomaly': 1607, 'store': 1608, 'elicitation': 1609, 'verbs': 1610, 'summarizing': 1611, 'csps': 1612, 'women': 1613, 'approximating': 1614, 'instructions': 1615, 'lines': 1616, 'histogram': 1617, 'coding': 1618, 'analytical': 1619, 'naive': 1620, 'networked': 1621, 'instances': 1622, 'robotics': 1623, 'sketch': 1624, 'semantically': 1625, 'items': 1626, 'arguments': 1627, 'generators': 1628, 'deployment': 1629, 'hmm': 1630, 'modern': 1631, 'concerns': 1632, 'transducers': 1633, 'shift': 1634, 'bitmap': 1635, 'containment': 1636, 'auction': 1637, 'principal': 1638, 'loops': 1639, 'lfg': 1640, 'refactoring': 1641, 'guide': 1642, 'curricula': 1643, 'html': 1644, 'paradigms': 1645, 'parallelization': 1646, 'fixed': 1647, 'authority': 1648, 'conjunctive': 1649, 'horn': 1650, 'referring': 1651, 'implementations': 1652, 'story': 1653, 'write': 1654, 'computations': 1655, 'robotic': 1656, 'twig': 1657, 'lambda': 1658, 'intensional': 1659, 'aid': 1660, 'extracted': 1661, 'interests': 1662, 'bi': 1663, 'transparent': 1664, 'inspection': 1665, 'pos': 1666, 'rewrite': 1667, 'performing': 1668, 'alias': 1669, 'outlier': 1670, 'multiversion': 1671, 'outliers': 1672, 'average': 1673, 'spelling': 1674, 'likelihood': 1675, 'art': 1676, 'threads': 1677, 'where': 1678, 'discrimination': 1679, 'gender': 1680, 'ontological': 1681, 'analogical': 1682, 'tutoring': 1683, 'possibilistic': 1684, 'iterated': 1685, 'genre': 1686, 'pipelined': 1687, 'characteristics': 1688, 'college': 1689, 'vehicle': 1690, 'another': 1691, 'coherent': 1692, 'senses': 1693, 'recognizing': 1694, 'perspectives': 1695, 'expectation': 1696, 'validating': 1697, 'fragments': 1698, 'whats': 1699, 'em': 1700, 'individual': 1701, 'clustered': 1702, 'restricted': 1703, 'comparable': 1704, 'correspondence': 1705, 'initiative': 1706, 'divide': 1707, 'transductive': 1708, 'strong': 1709, 'threshold': 1710, 'aligning': 1711, 'combined': 1712, 'boundary': 1713, 'interdisciplinary': 1714, 'serializability': 1715, 'deduction': 1716, 'schemata': 1717, 'segments': 1718, 'clauses': 1719, 'symmetry': 1720, 'taxonomies': 1721, 'exceptions': 1722, 'alternatives': 1723, 'existing': 1724, 'facility': 1725, 'company': 1726, 'comparisons': 1727, 'varying': 1728, 'lr': 1729, 'left': 1730, 'analytic': 1731, 'metasearch': 1732, 'basic': 1733, 'skew': 1734, 'proper': 1735, 'rdbms': 1736, 'holistic': 1737, 'cad': 1738, 'orthogonal': 1739, 'subjectivity': 1740, 'ambiguous': 1741, 'character': 1742, 'intention': 1743, 'similarities': 1744, 'connection': 1745, 'recovering': 1746, 'invariant': 1747, 'inducing': 1748, 'arts': 1749, 'law': 1750, 'greedy': 1751, 'background': 1752, 'dealing': 1753, 'device': 1754, 'tradeoffs': 1755, 'imperative': 1756, 'nonparametric': 1757, 'trace': 1758, 'variance': 1759, 'connected': 1760, 'past': 1761, 'augmented': 1762, 'directory': 1763, 'testbed': 1764, 'difficult': 1765, 'assisted': 1766, 'oodb': 1767, 'numeric': 1768, 'focusing': 1769, 'column': 1770, 'defect': 1771, 'getting': 1772, 'advice': 1773, 'wrapper': 1774, 'ethics': 1775, 'ahead': 1776, 'face': 1777, 'overlapping': 1778, 'hpsg': 1779, 'conditions': 1780, 'searches': 1781, 'perfect': 1782, 'primitives': 1783, 'trajectory': 1784, 'recent': 1785, 'quantification': 1786, 'multivariate': 1787, 'phrasal': 1788, 'needs': 1789, 'intermediate': 1790, 'comprehensive': 1791, 'indexed': 1792, 'pronoun': 1793, 'numerical': 1794, 'partition': 1795, 'guarantees': 1796, 'scenarios': 1797, 'classical': 1798, 'capabilities': 1799, 'attachment': 1800, 'delivery': 1801, 'vectors': 1802, 'reusable': 1803, 'taking': 1804, 'seeking': 1805, 'atomic': 1806, 'contents': 1807, 'checker': 1808, 'mediator': 1809, 'conquer': 1810, 'novelty': 1811, 'buffering': 1812, 'tensor': 1813, 'qa': 1814, 'differential': 1815, 'chemical': 1816, 'node': 1817, 'live': 1818, 'relatedness': 1819, 'versioning': 1820, 'arc': 1821, 'mass': 1822, 'applicative': 1823, 'note': 1824, 'vlsi': 1825, 'ubiquitous': 1826, 'coupled': 1827, 'but': 1828, 'position': 1829, 'terminology': 1830, 'boundaries': 1831, 'massively': 1832, 'nothing': 1833, 'weakly': 1834, 'integer': 1835, 'objective': 1836, 'made': 1837, 'coalition': 1838, 'utterances': 1839, 'grouping': 1840, 'enhancement': 1841, 'benefits': 1842, 'faults': 1843, 'liberal': 1844, 'metaphor': 1845, 'p': 1846, 'retention': 1847, 'supported': 1848, 'bioinformatics': 1849, 'taming': 1850, 'elements': 1851, 'predictions': 1852, 'population': 1853, 'trading': 1854, 'experimentation': 1855, 'stability': 1856, 'connecting': 1857, 'negation': 1858, 'smart': 1859, 'exchange': 1860, 'stratified': 1861, 'rich': 1862, 'written': 1863, 'navigational': 1864, 'evaluate': 1865, 'traversal': 1866, 'literature': 1867, 'maximization': 1868, 'executable': 1869, 'synopses': 1870, 'composing': 1871, 'particle': 1872, 'correspondences': 1873, 'nonnegative': 1874, 'reformulation': 1875, 'most': 1876, 'decoding': 1877, 'meanings': 1878, 'initial': 1879, 'native': 1880, 'government': 1881, 'trec': 1882, 'competitive': 1883, 'invariants': 1884, 'commercial': 1885, 'multithreaded': 1886, 'used': 1887, 'inconsistent': 1888, 'consensus': 1889, 'trade': 1890, 'dimensions': 1891, 'suffix': 1892, 'perceptual': 1893, 'accessing': 1894, 'revisiting': 1895, 'almost': 1896, 'covering': 1897, 'dominance': 1898, 'reduced': 1899, 'opinions': 1900, 'speculative': 1901, 'compressing': 1902, 'pointers': 1903, 'false': 1904, 'whole': 1905, 'comments': 1906, 'directional': 1907, 'reachability': 1908, 'thematic': 1909, 'achieving': 1910, 'denotational': 1911, 'replacement': 1912, 'treebank': 1913, 'walks': 1914, 'delayed': 1915, 'dont': 1916, 'steps': 1917, 'enough': 1918, 'strings': 1919, 'weights': 1920, 'datalog': 1921, 'rankings': 1922, 'monolingual': 1923, 'documentation': 1924, 'detect': 1925, 'reusing': 1926, 'api': 1927, 'samples': 1928, 'instructional': 1929, 'worlds': 1930, 'flash': 1931, 'diffusion': 1932, 'variation': 1933, 'squares': 1934, 'keyphrase': 1935, 'instant': 1936, 'wise': 1937, 'website': 1938, 'act': 1939, 'forums': 1940, 'rfid': 1941, 'poisson': 1942, 'characters': 1943, 'lock': 1944, 'spontaneous': 1945, 'compounds': 1946, 'constant': 1947, 'topology': 1948, 'citation': 1949, 'autonomic': 1950, 'fly': 1951, 'few': 1952, 'equality': 1953, 'shapes': 1954, 'travel': 1955, 'choosing': 1956, 'maximizing': 1957, 'invited': 1958, 'exponential': 1959, 'helping': 1960, 'switching': 1961, 'facilities': 1962, 'stored': 1963, 'reports': 1964, 'interpretations': 1965, 'available': 1966, 'executing': 1967, 'migration': 1968, 'anatomy': 1969, 'micro': 1970, 'audio': 1971, 'pass': 1972, 'transforming': 1973, 'owl': 1974, 'correcting': 1975, 'pc': 1976, 'relaxation': 1977, 'rare': 1978, 'pipeline': 1979, 'race': 1980, 'linked': 1981, 'bit': 1982, 'fact': 1983, 'frames': 1984, 'property': 1985, 'persistence': 1986, 'augmenting': 1987, 'cyclic': 1988, 'capture': 1989, 'grounded': 1990, 'protection': 1991, 'hand': 1992, 'mail': 1993, 'spectrum': 1994, 'heap': 1995, 'chunking': 1996, 'bringing': 1997, 'novice': 1998, 'reputation': 1999, 'paraphrasing': 2000, 'blogs': 2001, 'intervals': 2002, 'communicating': 2003, 'situated': 2004, 'auxiliary': 2005, 'heterogeneity': 2006, 'perceptron': 2007, 'merge': 2008, 'abductive': 2009, 'increasing': 2010, 'internal': 2011, 'grams': 2012, 'quantifier': 2013, 'has': 2014, 'declustering': 2015, 'distributing': 2016, 'really': 2017, 'collector': 2018, 'constituent': 2019, 'tracing': 2020, 'attention': 2021, 'priors': 2022, 'tests': 2023, 'double': 2024, 'paraphrases': 2025, 'sensors': 2026, 'chains': 2027, 'organizational': 2028, 'contention': 2029, 'strictness': 2030, 'loosely': 2031, 'examination': 2032, 'synthetic': 2033, 'hypermedia': 2034, 'blocking': 2035, 'temporally': 2036, 'circuits': 2037, 'there': 2038, 'verbal': 2039, 'desktop': 2040, 'publishsubscribe': 2041, 'assurance': 2042, 'faceted': 2043, 'overlay': 2044, 'numbers': 2045, 'asymmetric': 2046, 'forecasting': 2047, 'equations': 2048, 'roc': 2049, 'stores': 2050, 'continuations': 2051, 'equilibria': 2052, 'subcategorization': 2053, 'indirect': 2054, 'automation': 2055, 'defaults': 2056, 'influential': 2057, 'prosodic': 2058, 'calls': 2059, 'hits': 2060, 'major': 2061, 'significant': 2062, 'mutation': 2063, 'pascal': 2064, 'accesses': 2065, 'completion': 2066, 'criterion': 2067, 'descent': 2068, 'memories': 2069, 'us': 2070, 'who': 2071, 'parallelizing': 2072, 'possible': 2073, 'epistemic': 2074, 'collocation': 2075, 'anonymous': 2076, 'compilers': 2077, 'notes': 2078, 'extract': 2079, 'branching': 2080, 'transitions': 2081, 'centering': 2082, 'principled': 2083, 'feasibility': 2084, 'informed': 2085, 'meaningful': 2086, 'constructs': 2087, 'sponsored': 2088, 'relating': 2089, 'proxy': 2090, 'manufacturing': 2091, 'coalitional': 2092, 'automotive': 2093, 'admissible': 2094, 'periodic': 2095, 'requirement': 2096, 'dynamical': 2097, 'loading': 2098, 'mode': 2099, 'google': 2100, 'third': 2101, 'intersection': 2102, 'price': 2103, 'significance': 2104, 'cs1cs2': 2105, 'brain': 2106, 'star': 2107, 'sensitivity': 2108, 'microarray': 2109, 'restrictions': 2110, 'truth': 2111, 'axioms': 2112, 'marketing': 2113, 'modified': 2114, 'null': 2115, 'combinatory': 2116, 'labels': 2117, 'papers': 2118, 'person': 2119, 'conversations': 2120, 'learners': 2121, 'ability': 2122, 'running': 2123, 'formalizing': 2124, 'engineers': 2125, 'piecewise': 2126, 'skill': 2127, 'coordinate': 2128, 'affective': 2129, 'academic': 2130, 'living': 2131, 'benchmarking': 2132, 'optimizers': 2133, 'codasyl': 2134, 'prioritized': 2135, 'subset': 2136, 'built': 2137, 'portals': 2138, 'exception': 2139, 'codes': 2140, 'convergence': 2141, 'nondeterministic': 2142, 'route': 2143, 'locally': 2144, 'hypergraph': 2145, 'specified': 2146, 'priority': 2147, 'addressing': 2148, 'tense': 2149, 'explaining': 2150, 'hierarchically': 2151, 'russian': 2152, 'stemming': 2153, 'should': 2154, 'encryption': 2155, 'financial': 2156, 'javascript': 2157, 'collocations': 2158, '2003': 2159, 'lambek': 2160, 'grading': 2161, 'author': 2162, 'bag': 2163, 'after': 2164, 'interoperable': 2165, 'ibm': 2166, 'issue': 2167, 'resident': 2168, 'unrestricted': 2169, 'copy': 2170, 'correlations': 2171, 'stack': 2172, 'gathering': 2173, 'defining': 2174, 'nash': 2175, 'lecture': 2176, 'pure': 2177, 'environmental': 2178, 'accessibility': 2179, 'distillation': 2180, 'subject': 2181, 'known': 2182, 'contracts': 2183, 'tagger': 2184, 'engaging': 2185, 'teams': 2186, 'speeding': 2187, 'emerging': 2188, 'biology': 2189, 'responses': 2190, 's': 2191, 'bulk': 2192, 'petri': 2193, 'mind': 2194, 'idea': 2195, 'de': 2196, 'anonymity': 2197, 'workloads': 2198, 'bibliography': 2199, 'edit': 2200, 'x': 2201, 'which': 2202, 'equilibrium': 2203, 'linguistically': 2204, 'customizable': 2205, 'smalltalk': 2206, 'count': 2207, 'urls': 2208, 'visually': 2209, 'measurements': 2210, 'stationary': 2211, 'required': 2212, 'prover': 2213, 'post': 2214, 'sub': 2215, 'transform': 2216, 'dense': 2217, 'products': 2218, 'serial': 2219, 'facts': 2220, 'algebras': 2221, 'methodologies': 2222, 'stories': 2223, 'synthesizing': 2224, 'autoepistemic': 2225, 'essential': 2226, 'timed': 2227, 'bipartite': 2228, 'candidate': 2229, 'permutation': 2230, 'nominal': 2231, 'incrementally': 2232, 'itemset': 2233, 'labs': 2234, 'tertiary': 2235, 'discussion': 2236, 'decidable': 2237, 'segment': 2238, 'settings': 2239, 'blogosphere': 2240, 'styles': 2241, 'horizontal': 2242, 'mechanical': 2243, 'have': 2244, 'corporate': 2245, 'acts': 2246, 'repair': 2247, 'estimators': 2248, 'studying': 2249, 'membership': 2250, 'growth': 2251, 'keywords': 2252, 'bounding': 2253, 'friendly': 2254, 'neighbors': 2255, 'inputs': 2256, 'hot': 2257, 'translations': 2258, 'avoiding': 2259, 'anonymization': 2260, 'expectations': 2261, 'snapshot': 2262, 'place': 2263, 'grounding': 2264, 'anchor': 2265, 'coloring': 2266, 'identify': 2267, 'induced': 2268, 'webpage': 2269, 'shortest': 2270, 'utilization': 2271, 'sliding': 2272, 'deletion': 2273, 'eye': 2274, 'coarse': 2275, 'corner': 2276, 'expensive': 2277, 'editing': 2278, 'theme': 2279, 'hyperlinks': 2280, 'avoidance': 2281, 'statements': 2282, 'clinical': 2283, 'patient': 2284, 'fair': 2285, 'magic': 2286, 'pictorial': 2287, 'conflicts': 2288, 'tractability': 2289, 'referential': 2290, 'rates': 2291, 'traditional': 2292, 'readers': 2293, 'mixtures': 2294, 'setting': 2295, 'limits': 2296, 'sentential': 2297, 'cues': 2298, 'connectivity': 2299, 'oo': 2300, 'cut': 2301, 'flickr': 2302, 'nodes': 2303, 'preservation': 2304, 'adversarial': 2305, 'gaps': 2306, 'cohesion': 2307, 'solve': 2308, 'materialization': 2309, 'faster': 2310, 'if': 2311, 'subgraphs': 2312, 'mapreduce': 2313, 'hiding': 2314, 'identity': 2315, 'oodbms': 2316, 'expressing': 2317, 'important': 2318, 'ocr': 2319, 'fragment': 2320, 'summer': 2321, 'subsystem': 2322, 'gui': 2323, 'element': 2324, 'indefinite': 2325, 'spatiotemporal': 2326, 'analytics': 2327, 'attitudes': 2328, 'scalability': 2329, 'additive': 2330, 'anomalies': 2331, 'definite': 2332, 'pronominal': 2333, 'adoption': 2334, 'enforcement': 2335, 'too': 2336, 'geographical': 2337, 'awareness': 2338, 'globally': 2339, 'concise': 2340, 'localized': 2341, 'transport': 2342, 'extensibility': 2343, 'prepositional': 2344, 'acm': 2345, 'conversation': 2346, 'matrices': 2347, 'selections': 2348, 'predictors': 2349, 'realistic': 2350, 'inversion': 2351, 'player': 2352, 'triggers': 2353, 'rational': 2354, 'flows': 2355, 'variants': 2356, 'wavelet': 2357, 'preparation': 2358, 'smt': 2359, 'earth': 2360, 'orders': 2361, 'regret': 2362, 'nl': 2363, 'directories': 2364, 'economic': 2365, 'optical': 2366, 'strategic': 2367, '2000': 2368, 'fundamental': 2369, 'construct': 2370, 'presentations': 2371, 'play': 2372, 'improvements': 2373, 'scores': 2374, 'transformational': 2375, 'videos': 2376, 'linkage': 2377, 'precedence': 2378, 'capstone': 2379, 'evaluations': 2380, 'homogeneous': 2381, 'defeasible': 2382, 'proposal': 2383, 'enforcing': 2384, 'protecting': 2385, 'attack': 2386, 'synchronized': 2387, 'reason': 2388, 'normalized': 2389, 'facilitate': 2390, 'things': 2391, 'bottleneck': 2392, 'poker': 2393, 'lasso': 2394, 'factoring': 2395, 'entry': 2396, 'personalizing': 2397, 'fractal': 2398, 'closures': 2399, 'bad': 2400, 'dl': 2401, 'everyone': 2402, 'retrospective': 2403, 'me': 2404, 'may': 2405, 'certification': 2406, 'skewed': 2407, 'aliasing': 2408, 'configurable': 2409, 'simplified': 2410, 'trend': 2411, 'difficulty': 2412, 'specialized': 2413, 'q': 2414, 'modes': 2415, 'subsumption': 2416, 'edges': 2417, 'improves': 2418, 'assistance': 2419, 'capability': 2420, 'o': 2421, 'hypotheses': 2422, 'simulated': 2423, 'annealing': 2424, 'pervasive': 2425, 'yahoo': 2426, 'decompositions': 2427, 'scan': 2428, 'descriptive': 2429, 'accurately': 2430, 'keys': 2431, 'simplifying': 2432, 'readable': 2433, 'upper': 2434, 'threaded': 2435, 'designed': 2436, 'scientists': 2437, 'emergence': 2438, 'establishing': 2439, 'choices': 2440, 'charts': 2441, 'duplicates': 2442, 'intrusion': 2443, 'equivalent': 2444, 'markers': 2445, 'overhead': 2446, 'push': 2447, 'simplification': 2448, 'pedagogical': 2449, 'chip': 2450, 'sky': 2451, 'accessible': 2452, 'f': 2453, 'agreement': 2454, 'strength': 2455, 'compliant': 2456, 'functionality': 2457, 'tagged': 2458, 'clique': 2459, 'degree': 2460, 'mu': 2461, 'optimize': 2462, 'interpolation': 2463, 'activation': 2464, 'cs0': 2465, 'participation': 2466, 'sessions': 2467, 'cooperating': 2468, 'requests': 2469, 'integrate': 2470, 'modification': 2471, 'ciphers': 2472, 'pca': 2473, 'viewing': 2474, 'convolution': 2475, 'tier': 2476, 'repairs': 2477, 'mean': 2478, 'turning': 2479, 'repairing': 2480, 'patent': 2481, 'thread': 2482, 'nn': 2483, 'interacting': 2484, 'starburst': 2485, 'bytecode': 2486, 'curve': 2487, 'representative': 2488, 'postgres': 2489, 'volume': 2490, 'drift': 2491, 'productivity': 2492, 'encyclopedic': 2493, 'create': 2494, 'notion': 2495, 'connections': 2496, 'workbench': 2497, 'will': 2498, 'concrete': 2499, 'humans': 2500, 'visualisation': 2501, 'phonology': 2502, 'party': 2503, 'lite': 2504, 'annotating': 2505, 'mediated': 2506, 'perceived': 2507, 'enabled': 2508, 'readability': 2509, 'acquired': 2510, 'treewidth': 2511, 'definitional': 2512, 'substring': 2513, 'm': 2514, 'trained': 2515, 'much': 2516, 'observed': 2517, 'while': 2518, 'distances': 2519, 'bidding': 2520, 'geo': 2521, 'sorted': 2522, 'viewpoint': 2523, 'uses': 2524, 'manual': 2525, 'transduction': 2526, 'elementary': 2527, 'exercise': 2528, 'bootstrap': 2529, 'markets': 2530, 'throughput': 2531, 'motivated': 2532, 'vague': 2533, 'deferred': 2534, 'ground': 2535, 'bucket': 2536, 'simulations': 2537, 'molecular': 2538, 'so': 2539, 'home': 2540, 'seed': 2541, 'scans': 2542, 'timestamp': 2543, 'clusterings': 2544, 'something': 2545, 'ccg': 2546, 'archiving': 2547, 'tailoring': 2548, 'color': 2549, 'packing': 2550, 'package': 2551, 'ill': 2552, 'classify': 2553, 'gain': 2554, 'icse': 2555, 'intra': 2556, 'acyclic': 2557, 'lifetime': 2558, 'units': 2559, 'categorizing': 2560, 'wavelets': 2561, 'lineage': 2562, 'request': 2563, 'legal': 2564, 'staged': 2565, 'traces': 2566, 'crawler': 2567, 'adjusting': 2568, 'bibliographic': 2569, 'containing': 2570, 'split': 2571, 'preprocessing': 2572, 'disambiguating': 2573, 'continuation': 2574, 'sketching': 2575, 'revealing': 2576, 'guidance': 2577, 'situations': 2578, 'combine': 2579, 'multinomial': 2580, 'locations': 2581, 'portal': 2582, 'contribution': 2583, 'accelerating': 2584, 'bpel': 2585, 'compatibility': 2586, 'phenomena': 2587, 'benchmarks': 2588, 'nouns': 2589, 'creative': 2590, 'spreadsheet': 2591, 'pipelining': 2592, 'subsets': 2593, 'np': 2594, 'recognize': 2595, 'reversible': 2596, 'physics': 2597, 'working': 2598, 'cellular': 2599, 'mashup': 2600, 'linguistics': 2601, 'assertion': 2602, 'emotions': 2603, 'chaining': 2604, 'atomicity': 2605, 'lower': 2606, 'asking': 2607, 'ws': 2608, 'randomization': 2609, 'limitations': 2610, 'narrative': 2611, 'division': 2612, 'old': 2613, 'psychological': 2614, 'any': 2615, 'interference': 2616, 'taught': 2617, 'scoping': 2618, 'macro': 2619, 'ambiguities': 2620, 'motivation': 2621, 'cots': 2622, 'avoid': 2623, 'total': 2624, 'clients': 2625, 'knn': 2626, 'optimally': 2627, 'gpsg': 2628, 'rationale': 2629, 'thin': 2630, 'outer': 2631, 'reconfigurable': 2632, 'cycle': 2633, 'intended': 2634, 'solvers': 2635, 'authoring': 2636, 'snippets': 2637, 'storing': 2638, 'outsourced': 2639, 'courseware': 2640, 't': 2641, 'implemented': 2642, 'currency': 2643, 'cheap': 2644, 'clouds': 2645, 'years': 2646, 'divergence': 2647, 'taxonomic': 2648, 'pictures': 2649, 'spreading': 2650, 'inferences': 2651, 'elections': 2652, 'pronouns': 2653, 'scripting': 2654, 'clicks': 2655, 'compliance': 2656, 'pragmatics': 2657, 'ideal': 2658, 'essence': 2659, 'imbalanced': 2660, 'organizations': 2661, 'command': 2662, 'blackboard': 2663, 'handle': 2664, 'destructive': 2665, 'distinguishing': 2666, 'nsf': 2667, 'mediation': 2668, 'them': 2669, 'start': 2670, 'intranet': 2671, 'consumer': 2672, 'options': 2673, 'smooth': 2674, 'special': 2675, 'editor': 2676, 'assumption': 2677, 'recurrent': 2678, 'foreign': 2679, 'show': 2680, 'cover': 2681, 'facilitating': 2682, 'canonical': 2683, 'pi': 2684, 'dominant': 2685, 'guiding': 2686, 'reengineering': 2687, 'times': 2688, 'insertion': 2689, 'abstracting': 2690, 'forests': 2691, 'effectively': 2692, 'before': 2693, 'existential': 2694, 'editors': 2695, 'substitution': 2696, 'empty': 2697, 'calculation': 2698, 'understand': 2699, 'bodies': 2700, 'bandwidth': 2701, 'duality': 2702, 'mandarin': 2703, 'clues': 2704, 'according': 2705, 'lexicons': 2706, '2008': 2707, 'interpreters': 2708, 'lda': 2709, 'attribution': 2710, 'risc': 2711, 'families': 2712, 'tolerance': 2713, 'reflection': 2714, 'spanish': 2715, 'lexicalization': 2716, 'injection': 2717, 'idiom': 2718, 'get': 2719, 'newspaper': 2720, 'pronunciation': 2721, 'scenes': 2722, 'hyperlink': 2723, 'la': 2724, 'abstracts': 2725, 'plausible': 2726, 'equational': 2727, 'seminar': 2728, 'constructed': 2729, 'going': 2730, 'defense': 2731, 'learner': 2732, 'job': 2733, 'quickly': 2734, 'visualizations': 2735, 'organized': 2736, 'durations': 2737, 'paraphrase': 2738, 'together': 2739, 'arithmetic': 2740, 'cycles': 2741, 'freshness': 2742, 'exploitation': 2743, 'tale': 2744, 'authors': 2745, 'boost': 2746, 'formed': 2747, 'coping': 2748, 'check': 2749, 'metonymy': 2750, 'layer': 2751, 'extractive': 2752, 'portability': 2753, 'rough': 2754, 'corba': 2755, 'wisdom': 2756, 'bandit': 2757, 'makes': 2758, 'locks': 2759, 'adjectives': 2760, 'phonetic': 2761, 'auditing': 2762, 'propagating': 2763, 'advisor': 2764, 'guarantee': 2765, 'resistant': 2766, 'translator': 2767, 'assertions': 2768, 'shell': 2769, 'select': 2770, 'sequencing': 2771, 'multiuser': 2772, 'combinations': 2773, 'guessing': 2774, 'spin': 2775, 'culture': 2776, 'debugger': 2777, 'dbmss': 2778, 'unexpected': 2779, 'super': 2780, 'clones': 2781, 'alignments': 2782, 'meet': 2783, 'minimally': 2784, 'supports': 2785, 'examining': 2786, 'math': 2787, 'individuals': 2788, 'o2': 2789, 'cultural': 2790, 'multiprocessors': 2791, 'oltp': 2792, 'scenario': 2793, 'outreach': 2794, 'stanford': 2795, 'front': 2796, 'centralized': 2797, 'morpho': 2798, 'selectional': 2799, '10': 2800, 'quorum': 2801, 'rigorous': 2802, 'accelerated': 2803, 'capacity': 2804, 'diagnosing': 2805, 'fitting': 2806, 'aids': 2807, 'quantile': 2808, 'literacy': 2809, 'underlying': 2810, 'authorship': 2811, 'interrelated': 2812, 'developer': 2813, 'encodings': 2814, 'mismatch': 2815, 'critique': 2816, 'metaphors': 2817, 'shedding': 2818, 'title': 2819, 'telecommunication': 2820, 'bid': 2821, 'marketplace': 2822, 'flat': 2823, 'euclidean': 2824, 'successful': 2825, 'generalised': 2826, 'statically': 2827, 'offline': 2828, 'removal': 2829, 'sizes': 2830, 'reality': 2831, 'mashups': 2832, 'innovative': 2833, 'air': 2834, 'informal': 2835, 'tpc': 2836, 'assistants': 2837, 'formulae': 2838, 'pyramid': 2839, 'cell': 2840, 'force': 2841, 'programmable': 2842, 'matchmaking': 2843, 'medium': 2844, 'material': 2845, 'coordinated': 2846, 'ambients': 2847, 'passive': 2848, 'discussions': 2849, 'scratch': 2850, 'movements': 2851, 'paragraph': 2852, 'url': 2853, 'baseline': 2854, 'anonymizing': 2855, 'healthcare': 2856, 'assumptions': 2857, 'condition': 2858, 'underspecified': 2859, 'prototypes': 2860, 'collectors': 2861, 'competence': 2862, 'alpha': 2863, 'projected': 2864, 'multidatabases': 2865, 'indicators': 2866, 'polyhedral': 2867, 'parsed': 2868, 'reporting': 2869, 'aggregated': 2870, 'simd': 2871, 'pac': 2872, 'lego': 2873, 'polarity': 2874, 'pedagogy': 2875, 'aqualogic': 2876, 'graded': 2877, 'ingres': 2878, 'neutral': 2879, 'bridge': 2880, 'decoupling': 2881, 'pay': 2882, 'provide': 2883, 'expressiveness': 2884, 'six': 2885, 'behind': 2886, 'variant': 2887, 'channels': 2888, 'experimenting': 2889, 'ethical': 2890, 'controls': 2891, 'argumentative': 2892, 'represent': 2893, 'landmarks': 2894, 'provisioning': 2895, 'targeted': 2896, 'beta': 2897, 'gis': 2898, 'health': 2899, 'interestingness': 2900, 'emotion': 2901, 'certified': 2902, 'track': 2903, 'transportation': 2904, 'signals': 2905, 'movement': 2906, 'variational': 2907, 'exemplar': 2908, 'warping': 2909, 'address': 2910, 'release': 2911, 'same': 2912, 'last': 2913, 'fraud': 2914, 'targeting': 2915, 'optimisation': 2916, 'continual': 2917, 'hardness': 2918, 'authorization': 2919, 'universities': 2920, 'norm': 2921, 'forgetting': 2922, 'walking': 2923, 'messaging': 2924, 'worst': 2925, 'satisfying': 2926, 'statistically': 2927, 'delta': 2928, 'meeting': 2929, 'minimax': 2930, 'projective': 2931, 'typical': 2932, 'rating': 2933, 'associated': 2934, 'extendible': 2935, 'anaphoric': 2936, 'transferring': 2937, 'catalog': 2938, 'lookahead': 2939, 'alternating': 2940, 'titles': 2941, 'deduplication': 2942, 'regulatory': 2943, 'curse': 2944, 'publication': 2945, 'spanning': 2946, 'inspections': 2947, 'acceleration': 2948, 'revised': 2949, 'conformant': 2950, 'prioritization': 2951, 'implement': 2952, 'manage': 2953, 'black': 2954, 'box': 2955, 'producing': 2956, 'multiscale': 2957, 'instrumentation': 2958, 'fairness': 2959, 'transient': 2960, 'factory': 2961, 'inflectional': 2962, 'prism': 2963, 'per': 2964, 'affinity': 2965, 'replica': 2966, 'redesign': 2967, 'syntactically': 2968, 'mediators': 2969, 'prefix': 2970, 'sparql': 2971, 'cp': 2972, 'diagnosability': 2973, 'subjective': 2974, 'overlap': 2975, 'strongly': 2976, 'selected': 2977, 'expressed': 2978, 'atms': 2979, 'monotone': 2980, 'contrast': 2981, 'counts': 2982, 'succinct': 2983, 'iceberg': 2984, 'discovered': 2985, 'evidential': 2986, 'salient': 2987, 'conservative': 2988, 'degrees': 2989, 'exercises': 2990, 'must': 2991, 'mobility': 2992, 'patents': 2993, 'configuring': 2994, 'tutor': 2995, 'causality': 2996, 'yet': 2997, 'segmenting': 2998, 'maturity': 2999, 'constructions': 3000, 'miner': 3001, 'subspaces': 3002, 'bugs': 3003, 'throughout': 3004, 'giving': 3005, 'references': 3006, 'frontier': 3007, 'administration': 3008, 'coalescing': 3009, 'compile': 3010, 'developers': 3011, 'putting': 3012, 'filling': 3013, 'spreadsheets': 3014, 'imitation': 3015, 'probing': 3016, 'cant': 3017, 'generational': 3018, 'crash': 3019, 'suites': 3020, 'exhaustive': 3021, 'stopping': 3022, 'vp': 3023, 'cognition': 3024, 'trie': 3025, 'tuple': 3026, 'wild': 3027, 'customized': 3028, 'curves': 3029, 'monitor': 3030, 'restarts': 3031, 'reminiscences': 3032, 'ansi': 3033, 'brokering': 3034, 'tokenization': 3035, 'relaxations': 3036, 'closing': 3037, 'factoid': 3038, 'fit': 3039, 'notation': 3040, 'pool': 3041, 'fundamentals': 3042, 'exodus': 3043, 'revising': 3044, 'distinct': 3045, 'checkpointing': 3046, 'traceability': 3047, 'agenda': 3048, 'looking': 3049, 'scheduler': 3050, 'sigmod': 3051, 'competition': 3052, 'auto': 3053, 'passages': 3054, 'direction': 3055, 'hands': 3056, '2001': 3057, 'interleaving': 3058, 'watermarking': 3059, 'stop': 3060, 'pilot': 3061, 'wrapping': 3062, 'encoded': 3063, 'compute': 3064, 'offs': 3065, 'picture': 3066, 'posterior': 3067, 'checks': 3068, 'haskell': 3069, 'talk': 3070, 'signal': 3071, 'powerful': 3072, 'spider': 3073, 'backup': 3074, 'idioms': 3075, 'rethinking': 3076, 'promoting': 3077, 'translational': 3078, 'slam': 3079, '0': 3080, 'given': 3081, 'shelf': 3082, 'five': 3083, 'million': 3084, 'advances': 3085, 'infer': 3086, 'teamwork': 3087, 'every': 3088, 'urban': 3089, 'descriptors': 3090, 'camera': 3091, 'pushing': 3092, 'corrective': 3093, 'removing': 3094, 'invention': 3095, 'vehicles': 3096, 'clone': 3097, 'primitive': 3098, 'polysemy': 3099, 'spacecraft': 3100, 'growing': 3101, 'achieve': 3102, 'unix': 3103, 'multivalued': 3104, 'inferential': 3105, 'hypothetical': 3106, 'turing': 3107, 'cancer': 3108, 'enumeration': 3109, 'verified': 3110, 'consequences': 3111, 'assigning': 3112, 'collecting': 3113, 'catalogs': 3114, 'websites': 3115, 'estimate': 3116, 'odmg': 3117, 'preconditions': 3118, 'phoneme': 3119, 'discriminating': 3120, 'segmented': 3121, 'anomalous': 3122, 'oral': 3123, 'phonological': 3124, 'cfg': 3125, 'learns': 3126, 'advantages': 3127, 'reconciliation': 3128, 'blocks': 3129, 'outputs': 3130, 'graduate': 3131, 'grids': 3132, 'article': 3133, 'sketches': 3134, 'move': 3135, 'cloud': 3136, 'final': 3137, 'bagging': 3138, 'reflective': 3139, 'trusted': 3140, 'girls': 3141, 'forest': 3142, 'trails': 3143, 'progression': 3144, 'subscription': 3145, 'dag': 3146, 'computable': 3147, 'satisfy': 3148, 'clientserver': 3149, 'commonsense': 3150, 'harmful': 3151, 'necessary': 3152, 'proposed': 3153, 'gloss': 3154, 'tape': 3155, 'ssa': 3156, 'troubleshooting': 3157, 'parsimonious': 3158, 'inferencing': 3159, 'great': 3160, 'consequence': 3161, 'drt': 3162, 'taggers': 3163, 'political': 3164, '6': 3165, 'mindstorms': 3166, 'interleaved': 3167, 'validity': 3168, 'fluents': 3169, 'lifecycle': 3170, 'sciences': 3171, 'perceptions': 3172, 'say': 3173, 'stereo': 3174, 'express': 3175, 'affine': 3176, 'bio': 3177, 'inspired': 3178, 'customization': 3179, 'various': 3180, 'estimated': 3181, 'labelling': 3182, 'winner': 3183, 'decade': 3184, 'spammers': 3185, 'transforms': 3186, 'coherency': 3187, 'outsourcing': 3188, 'weaving': 3189, 'reconstructing': 3190, 'macros': 3191, 'present': 3192, 'boosted': 3193, 'symmetries': 3194, 'simplicity': 3195, 'misconceptions': 3196, 'seamless': 3197, 'telecommunications': 3198, 'ten': 3199, 'deviation': 3200, 'trainable': 3201, 'mark': 3202, 'fresh': 3203, 'skylines': 3204, 'boltzmann': 3205, 'navigating': 3206, '10g': 3207, 'think': 3208, 'analysing': 3209, 'incentives': 3210, 'thesauri': 3211, '2009': 3212, 'ode': 3213, 'elaboration': 3214, 'notions': 3215, 'histories': 3216, 'tradeoff': 3217, 'sized': 3218, 'upon': 3219, 'emails': 3220, 'providers': 3221, 'sales': 3222, 'female': 3223, 'supervision': 3224, 'snippet': 3225, 'rhetorical': 3226, 'placing': 3227, 'computed': 3228, 'captions': 3229, 'works': 3230, 'handwritten': 3231, 'transducer': 3232, 'exclusive': 3233, 'dp': 3234, 'backward': 3235, 'infosleuth': 3236, 'neighbour': 3237, 'influences': 3238, 'andor': 3239, 'refined': 3240, 'stock': 3241, 'tactical': 3242, 'soccer': 3243, 'balance': 3244, 'provably': 3245, 'chunks': 3246, 'tuples': 3247, 'crawlers': 3248, 'texture': 3249, 'subexpressions': 3250, 'inside': 3251, 'reusability': 3252, 'wrappers': 3253, 'thing': 3254, 'sign': 3255, 'norms': 3256, 'earley': 3257, 'flexibility': 3258, 'feeds': 3259, 'see': 3260, 'equivalents': 3261, 'anonymized': 3262, 'compatible': 3263, 'quantiles': 3264, '2005': 3265, 'multiparty': 3266, 'conjunctions': 3267, 'indoor': 3268, 'revenue': 3269, 'tracks': 3270, 'preferred': 3271, 'demo': 3272, 'heterogenous': 3273, 'cascade': 3274, 'brief': 3275, 'barrier': 3276, 'controller': 3277, 'nlg': 3278, 'des': 3279, 'voice': 3280, 'modality': 3281, 'prime': 3282, 'ratio': 3283, 'qos': 3284, 'emergent': 3285, 'sgml': 3286, 'tunable': 3287, 'commodity': 3288, 'morpheme': 3289, 'board': 3290, 'humor': 3291, 'unbiased': 3292, 'authentication': 3293, 'including': 3294, 'critiquing': 3295, 'certifying': 3296, 'century': 3297, 'weather': 3298, 'forecasts': 3299, 'retargetable': 3300, 'mpeg': 3301, '7': 3302, '12': 3303, 'pareto': 3304, 'ide': 3305, 'simultaneously': 3306, 'dissimilarity': 3307, 'dilemma': 3308, 'bigram': 3309, 'timing': 3310, 'adjustment': 3311, 'pooling': 3312, 'instructors': 3313, 'doing': 3314, 'engagement': 3315, 'skewing': 3316, 'empirically': 3317, 'fixpoint': 3318, 'centers': 3319, 'contraction': 3320, 'bank': 3321, 'also': 3322, 'tabular': 3323, 'basket': 3324, 'investigations': 3325, 'trigger': 3326, 'fragmentation': 3327, 'czech': 3328, 'cue': 3329, 'modulo': 3330, 'my': 3331, 'lexicalised': 3332, 'drifting': 3333, 'candidates': 3334, 'analyze': 3335, 'coordinating': 3336, 'bisimulation': 3337, 'internals': 3338, 'searchers': 3339, 'musical': 3340, 'eos': 3341, 'vectorization': 3342, 'purchase': 3343, 'screening': 3344, 'portfolio': 3345, 'harvesting': 3346, 'displays': 3347, 'delay': 3348, 'versatile': 3349, 'weblog': 3350, 'suggestions': 3351, 'man': 3352, 'turkish': 3353, 'quadratic': 3354, 'caches': 3355, 'limiting': 3356, 'packages': 3357, 'multiset': 3358, 'extensive': 3359, 'promises': 3360, 'compare': 3361, 'dependability': 3362, 'terminologies': 3363, 'priorities': 3364, 'rss': 3365, 'shrinking': 3366, 'ads': 3367, 'objectives': 3368, 'desk': 3369, 'opportunistic': 3370, 'mixing': 3371, 'salience': 3372, 'broker': 3373, 'clir': 3374, 'exclusion': 3375, 'recording': 3376, 'fourier': 3377, 'crowds': 3378, 'big': 3379, 'multikey': 3380, 'modula': 3381, 'standardization': 3382, 'rotation': 3383, 'strict': 3384, 'recycling': 3385, 'guidelines': 3386, 'motifs': 3387, 'european': 3388, '3rd': 3389, 'rights': 3390, 'commitments': 3391, 'sparsity': 3392, 'centroid': 3393, 'perform': 3394, 'educators': 3395, 'cryptographic': 3396, 'hyper': 3397, 'analyser': 3398, 'hit': 3399, 'leaks': 3400, 'customers': 3401, 'photos': 3402, 'golog': 3403, 'dependable': 3404, 'successive': 3405, 'thought': 3406, 'discontinuities': 3407, 'narratives': 3408, 'embeddings': 3409, 'prospects': 3410, 'indian': 3411, 'delivering': 3412, 'overload': 3413, 'plus': 3414, 'profit': 3415, 'script': 3416, 'diversification': 3417, 'tv': 3418, 'unique': 3419, 'ease': 3420, 'topss': 3421, 'confusion': 3422, 'conference': 3423, 'laplacian': 3424, 'supply': 3425, 'quest': 3426, 'prevention': 3427, 'simulating': 3428, 'benefit': 3429, 'malicious': 3430, 'xslt': 3431, 'sided': 3432, 'child': 3433, 'leak': 3434, 'reviewers': 3435, 'groupware': 3436, 'surrogate': 3437, 'encapsulation': 3438, 'popularity': 3439, 'laws': 3440, 'crawl': 3441, 'expanding': 3442, 'dutch': 3443, 'plausibility': 3444, 'wsd': 3445, 'reward': 3446, 'several': 3447, 'primary': 3448, 'unbounded': 3449, 'iconic': 3450, 'mdl': 3451, 'age': 3452, 'monads': 3453, 'diagram': 3454, 'executions': 3455, 'telecom': 3456, 'bdds': 3457, 'frequencies': 3458, 'nmf': 3459, 'covers': 3460, 'nulls': 3461, 'threading': 3462, 'genome': 3463, 'ownership': 3464, 'puzzles': 3465, 'conventional': 3466, 'bin': 3467, 'ratings': 3468, 'preferential': 3469, 'exploit': 3470, 'handwriting': 3471, 'kanji': 3472, 'aspectj': 3473, 'du': 3474, 'talking': 3475, 'mined': 3476, 'likely': 3477, 'predictor': 3478, 'anti': 3479, 'obligations': 3480, 'developments': 3481, 'h': 3482, 'enriched': 3483, 'lifted': 3484, 'vote': 3485, '2d': 3486, 'floating': 3487, 'decidability': 3488, 'decoupled': 3489, 'penalty': 3490, 'intrusive': 3491, 'transcripts': 3492, 'generalizations': 3493, 'proximal': 3494, 'bursty': 3495, 'cheshire': 3496, 'sms': 3497, 'snapshots': 3498, 'statistic': 3499, 'datr': 3500, 'crosscutting': 3501, 'ajax': 3502, 'considered': 3503, 'bindings': 3504, 'staging': 3505, 'scalar': 3506, 'aqua': 3507, 'phi': 3508, 'replay': 3509, 'sim': 3510, 'economics': 3511, 'grace': 3512, 'latency': 3513, 'variations': 3514, 'informational': 3515, 'populated': 3516, 'j2ee': 3517, 'poor': 3518, 'american': 3519, 'knowing': 3520, 'leakage': 3521, 'gmap': 3522, 'ria': 3523, 'calendar': 3524, 'pushdown': 3525, 'cat': 3526, 'again': 3527, 'apprentice': 3528, 'viewed': 3529, 'raising': 3530, 'ghost': 3531, 'gray': 3532, 'revolution': 3533, 'numbering': 3534, 'increase': 3535, 'abnormal': 3536, 'emotional': 3537, 'entire': 3538, 'calculi': 3539, 'generics': 3540, 'clarification': 3541, 'dataspace': 3542, 'linux': 3543, 'paradigmatic': 3544, 'italian': 3545, 'give': 3546, 'hilbert': 3547, 'fractals': 3548, 'accommodating': 3549, 'mid': 3550, 'queueing': 3551, 'performances': 3552, 'iris': 3553, 'determine': 3554, 'roll': 3555, 'funding': 3556, 'ebl': 3557, 'pcfgs': 3558, 'card': 3559, 'swarms': 3560, 'summarisation': 3561, 'hindi': 3562, 'purely': 3563, 'detector': 3564, 'mini': 3565, 'cosine': 3566, 'multicore': 3567, 'discontinuous': 3568, 'constituency': 3569, 'repeating': 3570, 'subtype': 3571, 'care': 3572, 'cpu': 3573, 'ecommerce': 3574, 'programmer': 3575, 'feed': 3576, 'shaping': 3577, 'synonyms': 3578, 'multifaceted': 3579, 'infrastructures': 3580, 'popular': 3581, 'compositions': 3582, 'detailed': 3583, 'enactment': 3584, 'catching': 3585, 'appropriate': 3586, 'cd': 3587, 'fifteen': 3588, 'encyclopedia': 3589, 'u': 3590, 'dyadic': 3591, 'contest': 3592, 'copying': 3593, 'satisfiable': 3594, 'gibbs': 3595, 'posting': 3596, 'focal': 3597, 'richer': 3598, 'subqueries': 3599, 'linda': 3600, 'frequently': 3601, 'reviewing': 3602, 'acoustic': 3603, 'sigcse': 3604, 'beginners': 3605, 'visibility': 3606, 'disconnected': 3607, 'disjunctions': 3608, 'hong': 3609, 'kong': 3610, 'intrusions': 3611, 'viewpoints': 3612, 'controllers': 3613, 'lattices': 3614, 'liveness': 3615, 'fold': 3616, 'variability': 3617, 'plots': 3618, 'stemmer': 3619, 'framenet': 3620, 'violation': 3621, 'reciprocal': 3622, 'udfs': 3623, 'tough': 3624, 'pcfg': 3625, 'knowledgeable': 3626, 'acronym': 3627, 'credit': 3628, 'retrieve': 3629, 'subgraph': 3630, 'onto': 3631, 'applicability': 3632, 'concentration': 3633, 'root': 3634, 'characterizations': 3635, 'schools': 3636, 'pearl': 3637, 'disabilities': 3638, 'reconciling': 3639, 'impaired': 3640, 'hp': 3641, 'opportunity': 3642, 'conjunction': 3643, 'nonmyopic': 3644, 'semijoin': 3645, 'htn': 3646, '99': 3647, 'simpler': 3648, 'actively': 3649, 'generativediscriminative': 3650, 'calibrating': 3651, 'prospective': 3652, 'grain': 3653, 'insurance': 3654, 'pitch': 3655, 'hypergraphs': 3656, 'un': 3657, 'dom': 3658, 'goods': 3659, 'mine': 3660, 'firm': 3661, 'incompleteness': 3662, 'ensuring': 3663, 'inequalities': 3664, 'memoization': 3665, 'employing': 3666, 'upgrading': 3667, 'alloy': 3668, 'disambiguate': 3669, 'subjects': 3670, 'mcmc': 3671, 'formulating': 3672, 'resolve': 3673, 'deception': 3674, 'tighter': 3675, 'recency': 3676, 'oop': 3677, 'inexpensive': 3678, 'semantical': 3679, 'rewards': 3680, 'mls': 3681, 'workstation': 3682, 'causes': 3683, 'externalities': 3684, 'this': 3685, 'magnitude': 3686, 'manifesto': 3687, 'variety': 3688, 'reductions': 3689, 'computerized': 3690, 'compensation': 3691, 'gradual': 3692, 'add': 3693, 'reversing': 3694, 'adaptively': 3695, 'exposing': 3696, 'studio': 3697, 'matcher': 3698, 'securing': 3699, 'intractable': 3700, 'distinction': 3701, 'eclipse': 3702, 'toolset': 3703, 'wall': 3704, 'dataknowledge': 3705, 'clio': 3706, 'drug': 3707, 'personalize': 3708, 'satellite': 3709, 'prefer': 3710, 'citations': 3711, 'costly': 3712, 'hosting': 3713, 'masses': 3714, 'managers': 3715, 'valency': 3716, 'dominators': 3717, 'medicine': 3718, 'augmentation': 3719, 'motivate': 3720, 'implication': 3721, 'further': 3722, 'genes': 3723, 'explorations': 3724, 'exactly': 3725, 'cascaded': 3726, 'kdd': 3727, 'personality': 3728, 'mentions': 3729, 'ordinal': 3730, 'partitions': 3731, 'yes': 3732, 'spatially': 3733, 'quantifiers': 3734, 'cached': 3735, 'decide': 3736, 'admission': 3737, 'enhancements': 3738, 'proportional': 3739, 'queues': 3740, 'printed': 3741, 'chance': 3742, 'existence': 3743, 'wrap': 3744, 'ranks': 3745, 'striping': 3746, 'thresholds': 3747, 'multiobjective': 3748, 'revelation': 3749, 'nominals': 3750, 'postprocessing': 3751, 'scripts': 3752, 'reducible': 3753, 'influencing': 3754, 'compromise': 3755, 'epsilon': 3756, 'derive': 3757, 'polyphonic': 3758, 'permission': 3759, 'dialectical': 3760, 'generality': 3761, 'spilling': 3762, 'realization': 3763, 'populations': 3764, 'collected': 3765, 'introspection': 3766, 'negotiating': 3767, 'workplace': 3768, 'backbone': 3769, 'book': 3770, 'dedicated': 3771, 'sqlxml': 3772, 'inlining': 3773, 'integrative': 3774, 'modifying': 3775, 'interpret': 3776, 'escape': 3777, 'hints': 3778, 'informatics': 3779, 'motor': 3780, 'aerial': 3781, 'multiresolution': 3782, 'jflap': 3783, 'optimum': 3784, 'intensity': 3785, 'come': 3786, 'credulous': 3787, 'accreditation': 3788, 'accent': 3789, 'architecting': 3790, 'sublanguage': 3791, 'synchronisation': 3792, 'modularization': 3793, 'z': 3794, 'metatheory': 3795, 'introspective': 3796, 'aligned': 3797, 'discretization': 3798, 'determinism': 3799, 'negotiations': 3800, 'resilient': 3801, 'matter': 3802, 'nearly': 3803, 'haystack': 3804, 'fun': 3805, 'circuit': 3806, 'sharable': 3807, 'ie': 3808, 'ugly': 3809, 'insensitive': 3810, 'deployed': 3811, 'scales': 3812, 'accelerator': 3813, 'zooming': 3814, 'nasa': 3815, 'figures': 3816, 'gains': 3817, 'wiki': 3818, 'philosophy': 3819, 'uncooperative': 3820, 'bushy': 3821, 'observability': 3822, 'leap': 3823, 'interlingual': 3824, 'velocity': 3825, 'marketplaces': 3826, 'min': 3827, 'plagiarism': 3828, 'beam': 3829, 'academia': 3830, 'vertically': 3831, 'folding': 3832, 'tasking': 3833, 'identifiers': 3834, 'angle': 3835, 'outline': 3836, 'enriching': 3837, 'publish': 3838, 'subscribe': 3839, 'advertisement': 3840, 'stimuli': 3841, 'haplotype': 3842, 'continuously': 3843, 'monitors': 3844, 'positional': 3845, 'timely': 3846, 'inquiry': 3847, 'valid': 3848, 'vldb': 3849, 'broadening': 3850, 'categorisation': 3851, 'enrichment': 3852, 'interchange': 3853, 'pp': 3854, 'car': 3855, 'monocular': 3856, 'microcomputer': 3857, 'commutative': 3858, 'surfaces': 3859, 'reasons': 3860, 'extensional': 3861, 'scavenging': 3862, 'multiway': 3863, 'recognizer': 3864, 'tournament': 3865, 'date': 3866, 'actor': 3867, 'eliciting': 3868, 'hierarchic': 3869, 'opponent': 3870, 'hebrew': 3871, 'climbing': 3872, 'slices': 3873, 'books': 3874, 'pursuit': 3875, 'evolvable': 3876, 'qbf': 3877, 'disease': 3878, 'discipline': 3879, 'posts': 3880, 'minority': 3881, 'disclosure': 3882, 'navigator': 3883, 'specify': 3884, '4th': 3885, 'coercion': 3886, 'locomotion': 3887, 'systolic': 3888, 'cliques': 3889, 'vulnerabilities': 3890, 'anchoring': 3891, 'syllable': 3892, 'recompilation': 3893, 'invariance': 3894, 'oracles': 3895, 'introduce': 3896, 'substructure': 3897, 'licensing': 3898, 'body': 3899, 'shading': 3900, 'schedules': 3901, 'differently': 3902, 'learnability': 3903, 'kinds': 3904, 'dags': 3905, 'multiplicative': 3906, 'marking': 3907, 'rural': 3908, 'journal': 3909, 'emphasizing': 3910, 'powered': 3911, 'fujaba': 3912, 'audit': 3913, 'aspectual': 3914, 'land': 3915, 'green': 3916, 'automaton': 3917, 'adequacy': 3918, 'beginning': 3919, 'pull': 3920, 'recommending': 3921, 'obtaining': 3922, 'aggressive': 3923, 'facial': 3924, 'outside': 3925, 'pivot': 3926, 'irrelevance': 3927, 'covariance': 3928, 'departments': 3929, 'sometimes': 3930, 'intentions': 3931, 'sections': 3932, 'cohesive': 3933, 'naming': 3934, 'preparing': 3935, 'hopfield': 3936, 'subclass': 3937, 'recommend': 3938, 'microprocessor': 3939, 'unsegmented': 3940, 'visible': 3941, 'bloom': 3942, 'nondeterminism': 3943, 'respect': 3944, 'bookmark': 3945, 'multiword': 3946, 'whom': 3947, 'lectures': 3948, 'raid': 3949, 'separating': 3950, 'usable': 3951, 'guis': 3952, 'refinements': 3953, 'folksonomies': 3954, 'cipher': 3955, 'geospatial': 3956, 'summarizer': 3957, 'trip': 3958, 'separate': 3959, 'accounts': 3960, 'tiling': 3961, 'simplify': 3962, 'contingency': 3963, 'iterator': 3964, 'mesh': 3965, 'pdas': 3966, 'actionable': 3967, 'quick': 3968, 'attributed': 3969, 'coral': 3970, 'soundness': 3971, 'contour': 3972, 'multiattribute': 3973, 'calibration': 3974, 'needed': 3975, 'fluent': 3976, 'institute': 3977, 'incorporation': 3978, 'around': 3979, 'intonation': 3980, 'folksonomy': 3981, 'converting': 3982, 'reclamation': 3983, 'fisher': 3984, 'national': 3985, 'genomic': 3986, 'monotonicity': 3987, 'structurally': 3988, 'ds': 3989, 'gps': 3990, 'consideration': 3991, 'coefficient': 3992, 'indicator': 3993, 'connectives': 3994, 'v': 3995, 'isometric': 3996, 'manifolds': 3997, 'personalised': 3998, 'probe': 3999, 'cryptography': 4000, 'bitmaps': 4001, 'gold': 4002, 'union': 4003, 'referencing': 4004, 'apprenticeship': 4005, 'impression': 4006, 'directly': 4007, 'ternary': 4008, 'feasible': 4009, 'teacher': 4010, 'pl': 4011, 'restart': 4012, 'deploying': 4013, 'lifting': 4014, 'pomdp': 4015, 'pseudorandom': 4016, 'jointly': 4017, 'factorial': 4018, 'combinator': 4019, 'mouse': 4020, 'adapted': 4021, 'island': 4022, 'members': 4023, 'jungle': 4024, 'surprising': 4025, 'lexico': 4026, 'doubly': 4027, 'secret': 4028, 'archived': 4029, 'infosphere': 4030, 'positions': 4031, 'gist': 4032, 'cadcam': 4033, 'singular': 4034, 'follow': 4035, 'aging': 4036, 'promotion': 4037, 'outerjoins': 4038, 'degradation': 4039, 'homogeneity': 4040, 'intuitive': 4041, 'salsa': 4042, 'scanning': 4043, 'prepositions': 4044, 'lsh': 4045, 'ink': 4046, 'everything': 4047, 'unlexicalized': 4048, 'lp': 4049, 'hindsight': 4050, 'classic': 4051, 'thrashing': 4052, 'interactively': 4053, 'neuro': 4054, 'mariposa': 4055, 'freshmen': 4056, 'credibility': 4057, 'vocabularies': 4058, 'billion': 4059, 'disaster': 4060, 'rest': 4061, 'african': 4062, 'essay': 4063, 'day': 4064, 'statecharts': 4065, 'relatively': 4066, 'contrastive': 4067, 'decomposing': 4068, 'survivability': 4069, 'accounting': 4070, 'jim': 4071, 'dataspaces': 4072, 'abandonment': 4073, 'animating': 4074, 'tutors': 4075, 'led': 4076, 'jump': 4077, 'novices': 4078, 'pedagogically': 4079, 'routines': 4080, 'ccfinder': 4081, 'doll': 4082, 'manuals': 4083, 'junction': 4084, 'derivations': 4085, 'duplication': 4086, 'aboutness': 4087, 'dialogs': 4088, 'firing': 4089, 'coalitions': 4090, 'concert': 4091, 'incrementality': 4092, 'animations': 4093, 'deformable': 4094, 'sift': 4095, 'outbreak': 4096, 'speaking': 4097, 'os': 4098, 'cooking': 4099, 'prevent': 4100, 'categorized': 4101, 'fortran': 4102, 'mosaic': 4103, 'tsimmis': 4104, 'provision': 4105, 'subtypes': 4106, 'invalidation': 4107, 'respond': 4108, 'cartesian': 4109, 'codd': 4110, 'impure': 4111, 'water': 4112, 'syntagmatic': 4113, 'lotos': 4114, 'newton': 4115, 'payment': 4116, 'swizzling': 4117, 'squashing': 4118, 'letter': 4119, 'pieces': 4120, 'superscalar': 4121, 'skip': 4122, 'kl': 4123, 'judgements': 4124, 'underspecification': 4125, 'due': 4126, 'lack': 4127, 'bimodal': 4128, 'newsgroup': 4129, 'optimising': 4130, 'tcp': 4131, 'g': 4132, 'interoperation': 4133, 'leadership': 4134, 'marker': 4135, 'terabyte': 4136, 'backend': 4137, 'cmm': 4138, 'spamming': 4139, 'formally': 4140, 'interpreted': 4141, 'geographically': 4142, 'duration': 4143, 'lookup': 4144, 'decentralised': 4145, 'kriegspiel': 4146, 'rl': 4147, 'axiom': 4148, 'algol': 4149, 'finance': 4150, 'days': 4151, 'stride': 4152, 'department': 4153, 'thai': 4154, 'developed': 4155, 'anticipation': 4156, 'little': 4157, 'interbase': 4158, 'uncertainties': 4159, 'surrogates': 4160, 'cm': 4161, 'routine': 4162, 'intentional': 4163, 'metu': 4164, 'collapsed': 4165, 'hyperlinked': 4166, 'zoo': 4167, 'sketched': 4168, 'symbol': 4169, 'branches': 4170, 'scaled': 4171, 'asked': 4172, 'committee': 4173, 'cyc': 4174, 'rainbow': 4175, 'cumulative': 4176, 'cleansing': 4177, 'assign': 4178, 'campaign': 4179, 'glue': 4180, 'bloggers': 4181, 'c45': 4182, 'backwards': 4183, 'erroneous': 4184, 'cpus': 4185, 'oblivious': 4186, 'uniqueness': 4187, 'misuse': 4188, 'bigrams': 4189, 'edits': 4190, 'budget': 4191, '98': 4192, 'far': 4193, 'intrinsic': 4194, 'fix': 4195, 'speculation': 4196, 'formulations': 4197, 'blogspace': 4198, 'preposition': 4199, 'diam': 4200, 'ascription': 4201, 'decomposable': 4202, 'central': 4203, 'informix': 4204, '95': 4205, 'nuggets': 4206, 'generations': 4207, 'cause': 4208, 'coach': 4209, 'overcoming': 4210, 'ims': 4211, 'institutional': 4212, 'suspicious': 4213, 'clear': 4214, 'redo': 4215, 'residual': 4216, 'mistakes': 4217, 'pluggable': 4218, 'atoms': 4219, 'disagreement': 4220, 'relief': 4221, 'vod': 4222, 'movie': 4223, 'thumbs': 4224, 'compacting': 4225, 'semijoins': 4226, 'affect': 4227, 'vista': 4228, 'labelled': 4229, 'motivations': 4230, 'guarded': 4231, 'constructors': 4232, 'predictable': 4233, 'occurring': 4234, 'always': 4235, 'unnesting': 4236, 'iro': 4237, 'member': 4238, 'spirit': 4239, 'bracketing': 4240, 'pixel': 4241, 'maybe': 4242, 'mention': 4243, 'crossing': 4244, 'maxent': 4245, 'randomised': 4246, 'determiners': 4247, 'par': 4248, 'pour': 4249, 'successes': 4250, 'envy': 4251, 'isolated': 4252, 'selling': 4253, 'disciplines': 4254, 'terrain': 4255, 'irrelevant': 4256, 'autonomously': 4257, 'usefulness': 4258, 'freedom': 4259, 'rasdaman': 4260, 'catalogue': 4261, 'unfamiliar': 4262, 'illustrating': 4263, 'paradise': 4264, 'grocery': 4265, 'sending': 4266, 'liquid': 4267, 'shuttle': 4268, 'rigid': 4269, 'sloan': 4270, 'happens': 4271, 'dissecting': 4272, 'recurrence': 4273, 'abbreviation': 4274, 'topically': 4275, 'agnostic': 4276, 'wave': 4277, 'oversubscribed': 4278, 'typings': 4279, 'threats': 4280, 'chess': 4281, 'necessity': 4282, 'logically': 4283, 'aliases': 4284, 'spill': 4285, 'asymptotic': 4286, 'universality': 4287, 'rosetta': 4288, 'drawings': 4289, 'stacking': 4290, 'perceptrons': 4291, 'naos': 4292, 'stacked': 4293, 'artemis': 4294, 'heads': 4295, 'verbose': 4296, 'tight': 4297, 'interruptible': 4298, 'goes': 4299, 'companion': 4300, 'tricks': 4301, 'china': 4302, 'provided': 4303, 'paging': 4304, 'referent': 4305, 'heart': 4306, 'abnormality': 4307, 'subtopic': 4308, 'caseframe': 4309, 'cloning': 4310, 'envelope': 4311, 'rom': 4312, 'windowed': 4313, 'acting': 4314, 'browsers': 4315, 'society': 4316, 'subsumers': 4317, 'requiring': 4318, 'janus': 4319, 'offering': 4320, 'robocup': 4321, 'stand': 4322, 'mutually': 4323, 'mock': 4324, 'interpretable': 4325, 'autonomy': 4326, 'even': 4327, 'longest': 4328, 'those': 4329, 'justification': 4330, 'kb': 4331, 'sums': 4332, 'lets': 4333, 'biologically': 4334, 'wildcards': 4335, 'cougar': 4336, 'assessments': 4337, 'platforms': 4338, 'inexact': 4339, 'adjuncts': 4340, 'helps': 4341, 'dbs': 4342, 'eddies': 4343, 'sliced': 4344, 'vulnerability': 4345, 'featuring': 4346, 'statechart': 4347, 'compared': 4348, 'armed': 4349, 'animate': 4350, 'advance': 4351, 'organizer': 4352, 'chat': 4353, 'assets': 4354, 'martingale': 4355, 'calling': 4356, 'conventions': 4357, 'filing': 4358, 'knapsack': 4359, 'gamma': 4360, 'once': 4361, 'shopping': 4362, 'tour': 4363, 'precomputed': 4364, 'fluid': 4365, 'prima': 4366, 'ring': 4367, 'basics': 4368, 'markovian': 4369, 'tp': 4370, 'counterfactual': 4371, 'conditioning': 4372, 'flaws': 4373, 'eeg': 4374, 'constraining': 4375, 'simulators': 4376, 'achievement': 4377, 'adt': 4378, 'uncovering': 4379, 'ideas': 4380, 'transmission': 4381, 'railroad': 4382, 'row': 4383, 'scopes': 4384, 'plug': 4385, 'vdm': 4386, 'womens': 4387, 'involving': 4388, 'counterfactuals': 4389, 'hippocratic': 4390, 'concatenative': 4391, 'attempt': 4392, 'omt': 4393, 'harder': 4394, 'untagged': 4395, 'learnable': 4396, 'compressor': 4397, 'organize': 4398, 'published': 4399, 'dc': 4400, 'socially': 4401, 'exploits': 4402, 'fetches': 4403, 'barriers': 4404, 'consolidation': 4405, 'inapplicable': 4406, 'agility': 4407, 'convergent': 4408, 'naga': 4409, 'plsa': 4410, 'cultures': 4411, 'gateway': 4412, 'persons': 4413, '21st': 4414, 'intermittently': 4415, 'imbalance': 4416, 'blogging': 4417, 'pathfinder': 4418, 'axiomatization': 4419, 'meetings': 4420, 'plane': 4421, 'backbones': 4422, 'tune': 4423, 'deictic': 4424, 'gestures': 4425, 'mash': 4426, 'skeptical': 4427, 'landing': 4428, 'keeping': 4429, 'participants': 4430, 'subgoal': 4431, 'steganography': 4432, 'gesture': 4433, 'distributive': 4434, 'incentive': 4435, 'oodbs': 4436, 'se': 4437, 'fails': 4438, 'embodied': 4439, 'damping': 4440, 'synonym': 4441, 'separable': 4442, 'blending': 4443, 'raw': 4444, 'redundancies': 4445, 'rete': 4446, 'propbank': 4447, 'webdav': 4448, 'notification': 4449, 'deal': 4450, 'distortion': 4451, 'disseminating': 4452, 'held': 4453, 'cuts': 4454, 'malware': 4455, 'money': 4456, 'artifacts': 4457, 'invasive': 4458, 'facet': 4459, 'ended': 4460, 'bcnf': 4461, 'connectors': 4462, 'iid': 4463, 'interactivity': 4464, 'resiliency': 4465, 'encrypted': 4466, 'weblogs': 4467, 'specificity': 4468, 'tightly': 4469, 'thresholding': 4470, 'mac': 4471, 'bandits': 4472, 'lrk': 4473, 'previews': 4474, 'banks': 4475, 'bids': 4476, 'collocational': 4477, 'quadratically': 4478, 'tell': 4479, 'spectra': 4480, 'primal': 4481, 'formations': 4482, 'supertagging': 4483, 'adaptivity': 4484, 'experiencing': 4485, 'estimations': 4486, 'drawing': 4487, 'runs': 4488, 'actual': 4489, 'overlays': 4490, 'mergesort': 4491, 'square': 4492, 'conflicting': 4493, 'secrecy': 4494, 'bloat': 4495, 'synopsis': 4496, 'mars': 4497, 'ida': 4498, 'allocated': 4499, 'isnt': 4500, 'cryptographically': 4501, 'era': 4502, 'collaborations': 4503, 'outcome': 4504, 'realizing': 4505, 'redesigning': 4506, 'institutions': 4507, 'quizzes': 4508, 'seeded': 4509, 'unreliable': 4510, 'reaction': 4511, 'sql3': 4512, 'cleanroom': 4513, 'implicatures': 4514, 'preventing': 4515, 'daily': 4516, 'burstiness': 4517, 'slot': 4518, 'thumb': 4519, 'pdp': 4520, 'rolap': 4521, 'clickstreams': 4522, 'following': 4523, 'seeker': 4524, 'therapy': 4525, 'metal': 4526, 'obstacles': 4527, 'thousands': 4528, 'menu': 4529, 'continuity': 4530, 'sampled': 4531, 'substitutions': 4532, 'hypertree': 4533, 'spotting': 4534, 'constituents': 4535, 'curved': 4536, 'employment': 4537, 'explorer': 4538, 'hadoop': 4539, 'rationality': 4540, 'denial': 4541, '8': 4542, 'garden': 4543, 'rendering': 4544, 'tail': 4545, 'train': 4546, 'street': 4547, 'asymmetry': 4548, 'along': 4549, 'timeline': 4550, 'animator': 4551, 'idf': 4552, 'dominating': 4553, 'technological': 4554, 'requires': 4555, 'rime': 4556, 'resistance': 4557, 'biconnected': 4558, 'lru': 4559, 'insight': 4560, 'interchangeability': 4561, 'opaque': 4562, 'versioned': 4563, 'certain': 4564, 'nonstop': 4565, 'webs': 4566, 'injecting': 4567, 'rock': 4568, 'soar': 4569, 'rufus': 4570, 'translate': 4571, 'decay': 4572, 'nf2': 4573, 'evasion': 4574, 'token': 4575, 'normalizing': 4576, 'compiled': 4577, 'cast': 4578, 'serv': 4579, 'markup': 4580, 'puzzle': 4581, 'episodes': 4582, 'shot': 4583, 'restoration': 4584, 'clue': 4585, 'computability': 4586, 'whose': 4587, 'facets': 4588, 'priming': 4589, 'beat': 4590, 'since': 4591, 'photographs': 4592, 'isomorphisms': 4593, 'gaze': 4594, 'rue': 4595, 'complementary': 4596, 'fourth': 4597, 'founded': 4598, 'casual': 4599, 'cells': 4600, 'symbols': 4601, 'kinematic': 4602, 'twitter': 4603, 'prefetch': 4604, 'handheld': 4605, 'problematic': 4606, 'comprehensibility': 4607, 'pathfinding': 4608, 'dispatching': 4609, 'develop': 4610, 'phonotactic': 4611, 'http': 4612, 'unordered': 4613, 'bp': 4614, 'multiview': 4615, 'projecting': 4616, 'hill': 4617, 'configurations': 4618, 'axis': 4619, 'disciplined': 4620, 'nomadic': 4621, 'materials': 4622, 'phishing': 4623, 'shiq': 4624, 'borealis': 4625, 'designer': 4626, 'arm': 4627, 'themes': 4628, 'layers': 4629, 'impacts': 4630, 'ica': 4631, 'philosophers': 4632, 'hitting': 4633, 'homomorphisms': 4634, 'computationally': 4635, 'dates': 4636, 'separability': 4637, 'having': 4638, 'jointree': 4639, 'contrasting': 4640, 'cryptanalysis': 4641, 'multicomputer': 4642, 'scattergather': 4643, 'created': 4644, 'knows': 4645, 'forming': 4646, 'helpfulness': 4647, 'hdp': 4648, 'unl': 4649, 'oracle8i': 4650, 'bed': 4651, 'substitutability': 4652, 'password': 4653, 'grammatically': 4654, 'apache': 4655, 'humming': 4656, 'drive': 4657, 'israeli': 4658, 'format': 4659, 'dataset': 4660, 'food': 4661, 'definability': 4662, 'aggregating': 4663, 'analog': 4664, 'visibly': 4665, 'tailored': 4666, 'pddl': 4667, 'competitors': 4668, 'hide': 4669, 'seek': 4670, 'choose': 4671, 'inconsistencies': 4672, 'economical': 4673, 'dtds': 4674, 'here': 4675, 'allowing': 4676, 'bracketed': 4677, 'observing': 4678, 'confluence': 4679, 'swoogle': 4680, 'overloading': 4681, 'internationalization': 4682, 'inventories': 4683, 'streamed': 4684, 'plain': 4685, 'consultation': 4686, 'perturbation': 4687, 'multilabel': 4688, 'extent': 4689, 'contours': 4690, 'multiplication': 4691, 'our': 4692, 'japan': 4693, 'signs': 4694, 'serf': 4695, 'modifier': 4696, 'predator': 4697, 'asknet': 4698, 'species': 4699, 'trenches': 4700, 'penn': 4701, 'specializing': 4702, 'sigma': 4703, 'cc': 4704, 'misses': 4705, 'raster': 4706, 'translators': 4707, 'eager': 4708, 'occurrences': 4709, 'overfitting': 4710, 'city': 4711, 'glass': 4712, 'alice': 4713, 'dr': 4714, 'deciding': 4715, 'partnership': 4716, 'signaling': 4717, 'surveillance': 4718, 'bookmarking': 4719, 'hci': 4720, 'suitability': 4721, 'dpop': 4722, 'ice': 4723, 'interconnection': 4724, 'constructivist': 4725, 'refutation': 4726, 'crisis': 4727, 'listwise': 4728, 'winning': 4729, 'senseclusters': 4730, 'controllability': 4731, 'bargaining': 4732, 'joining': 4733, 'granular': 4734, 'appropriateness': 4735, 'latin': 4736, 'found': 4737, 'untrusted': 4738, 'treating': 4739, 'childrens': 4740, 'factorizing': 4741, 'rollback': 4742, 'propositions': 4743, 'spot': 4744, 'faculty': 4745, 'audience': 4746, 'strips': 4747, 'sounds': 4748, 'remarks': 4749, 'dun': 4750, 'grapheme': 4751, 'voted': 4752, 'volatile': 4753, 'kinematics': 4754, 'fostering': 4755, 'authorities': 4756, 'prosody': 4757, 'pspace': 4758, 'apples': 4759, 'obtain': 4760, 'closest': 4761, 'collision': 4762, 'recorded': 4763, 'loose': 4764, 'disco': 4765, 'adaboost': 4766, 'adapt': 4767, 'agglutinative': 4768, 'clearing': 4769, 'illinois': 4770, 'shifts': 4771, 'cedar': 4772, 'stars': 4773, 'skeleton': 4774, 'sensory': 4775, 'keyframe': 4776, 'iii': 4777, 'holdem': 4778, 'aries': 4779, 'larger': 4780, 'mentor': 4781, 'telephone': 4782, 'innovation': 4783, 'factorizations': 4784, 'initialization': 4785, 'eigen': 4786, 'explanatory': 4787, 'instantiation': 4788, 'heavy': 4789, 'rearrangement': 4790, 'ambient': 4791, 'recursively': 4792, 'absence': 4793, 'tablet': 4794, 'surfing': 4795, 'pitfalls': 4796, 'banner': 4797, 'quantum': 4798, 'tangent': 4799, 'refresh': 4800, 'aggregations': 4801, 'phrasing': 4802, 'multidisciplinary': 4803, 'educating': 4804, 'horizon': 4805, 'spread': 4806, 'origin': 4807, 'sap': 4808, 'terminal': 4809, 'fork': 4810, 'cis': 4811, 'ariel': 4812, 'executive': 4813, 'commutativity': 4814, 'particles': 4815, 'considering': 4816, 'di': 4817, 'collusion': 4818, 'pro': 4819, 'hunt': 4820, 'traveling': 4821, 'retrievability': 4822, 'these': 4823, 'multistage': 4824, 'esp': 4825, 'qualification': 4826, 'wait': 4827, 'toolbox': 4828, 'races': 4829, 'combinational': 4830, '4': 4831, 'easier': 4832, 'degraded': 4833, 'detectors': 4834, 'winnowing': 4835, 'recapture': 4836, 'metarules': 4837, 'votes': 4838, 'damage': 4839, 'additional': 4840, 'auditory': 4841, 'concatenation': 4842, 'funnel': 4843, 'hypernym': 4844, 'ordinary': 4845, 'room': 4846, 'completing': 4847, 'neuroevolution': 4848, 'psi': 4849, 'never': 4850, 'qualifiers': 4851, 'professional': 4852, 'anchors': 4853, 'extend': 4854, 'outerjoin': 4855, 'timber': 4856, 'sector': 4857, 'now': 4858, 'contingent': 4859, 'flight': 4860, 'findings': 4861, 'kaleidoscope': 4862, 'jobs': 4863, 'apl': 4864, 'directing': 4865, '80': 4866, 'rebuild': 4867, 'round': 4868, 'assess': 4869, 'diagnoses': 4870, 'wish': 4871, 'backtrack': 4872, 'receptive': 4873, 'brand': 4874, 'intonational': 4875, 'comes': 4876, 'cubing': 4877, 'anaphors': 4878, 'take': 4879, 'python': 4880, 'disguised': 4881, 'dec': 4882, 'dead': 4883, 'guaranteeing': 4884, 'quantity': 4885, 'patients': 4886, 'practically': 4887, 'imprecision': 4888, 'glossary': 4889, 'dempster': 4890, 'buy': 4891, 'x86': 4892, 'efforts': 4893, 'still': 4894, 'flux': 4895, 'integrator': 4896, 'quotient': 4897, 'reorganizing': 4898, 'raid5': 4899, 'reconfiguration': 4900, 'mpe': 4901, 'rings': 4902, 'piloted': 4903, 'usually': 4904, 'shrinkage': 4905, 'estimator': 4906, 'barter': 4907, 'exist': 4908, 'periods': 4909, 'csbots': 4910, 'opac': 4911, 'attitude': 4912, 'persuasive': 4913, 'upward': 4914, 'expository': 4915, 'erp': 4916, 'bsr': 4917, 'conditionals': 4918, 'porting': 4919, 'customizing': 4920, 'quaternary': 4921, 'completely': 4922, 'freshman': 4923, 'remembering': 4924, 'forget': 4925, 'singer': 4926, 'appraisal': 4927, 'taint': 4928, 'freely': 4929, 'redescription': 4930, 'inline': 4931, 'positives': 4932, 'governed': 4933, 'incorrect': 4934, 'superoptimizer': 4935, 'freeform': 4936, 'learnt': 4937, 'stepwise': 4938, 'corrector': 4939, 'foral': 4940, 'identifier': 4941, 'draw': 4942, 'wordnets': 4943, 'outcomes': 4944, 'hospital': 4945, 'disjoint': 4946, 'rsa': 4947, 'him': 4948, 'broadcasts': 4949, 'backjumping': 4950, 'nrrc': 4951, 'ap': 4952, 'ndcg': 4953, 'minimalist': 4954, 'letting': 4955, 'shake': 4956, 'bake': 4957, 'defects': 4958, 'eufid': 4959, 'kernelized': 4960, 'je': 4961, 'emoticons': 4962, 'stylistic': 4963, 'transposed': 4964, 'w3qs': 4965, 'jasmin': 4966, 'countermeasures': 4967, 'societal': 4968, 'polyphony': 4969, 'webpages': 4970, 'divergences': 4971, 'bypass': 4972, 'aerospace': 4973, 'von': 4974, 'microprogram': 4975, 'subproblems': 4976, 'speak': 4977, 'php': 4978, 'maintain': 4979, 'echo': 4980, 'anticipating': 4981, 'electromyographic': 4982, 'harmonic': 4983, 'reinforcing': 4984, 'cutting': 4985, 'dado': 4986, 'chronicle': 4987, 'pronominalization': 4988, 'polynominal': 4989, 'figure': 4990, 'merit': 4991, 'fixpoints': 4992, 'kbmss': 4993, 'pinyin': 4994, 'swarm': 4995, 'nfa': 4996, 'exponentially': 4997, 'privatization': 4998, 'encipherment': 4999, 'textbooks': 5000, 'coin': 5001, 'semiautomatic': 5002, 'realism': 5003, 'securities': 5004, 'orkut': 5005, 'continuum': 5006, 'transductions': 5007, 'bernoulli': 5008, 'cam': 5009, 'boyce': 5010, 'jazz': 5011, 'telegraph': 5012, 'drinking': 5013, 'treebanks': 5014, 'portlets': 5015, 'retroactive': 5016, 'biclustering': 5017, 'enaction': 5018, 'entering': 5019, 'dls': 5020, 'semnews': 5021, 'climate': 5022, 'schemasql': 5023, 'guest': 5024, '1999': 5025, 'tone': 5026, 'rivaling': 5027, 'granularities': 5028, 'deadlocks': 5029, 'prune': 5030, 'reconsideration': 5031, 'episodic': 5032, 'passenger': 5033, 'ontonotes': 5034, 'planetary': 5035, 'factual': 5036, 'fingerprinting': 5037, 'diathesis': 5038, 'alternations': 5039, 'orchestra': 5040, 'chunk': 5041, 'nd': 5042, 'unusual': 5043, 'universum': 5044, 'mermaid': 5045, 'metadatabase': 5046, 'inherited': 5047, 'departmental': 5048, 'agree': 5049, 'identifiability': 5050, 'approximately': 5051, 'apply': 5052, 'matches': 5053, 'multiprocessing': 5054, 'irs': 5055, 'myths': 5056, 'hoare': 5057, 'canonicalization': 5058, 'dragon': 5059, 'adventures': 5060, 'jdbc': 5061, 'recommenders': 5062, 'ccgbank': 5063, 'hat': 5064, 'believable': 5065, 'xp': 5066, 'turbo': 5067, 'charging': 5068, 'irregular': 5069, 'recursions': 5070, 'experienced': 5071, 'ultra': 5072, 'dust': 5073, 'pmi': 5074, 'cited': 5075, 'cubetree': 5076, 'methodological': 5077, 'datbase': 5078, 'interfering': 5079, 'circumscribing': 5080, 'cardinal': 5081, 'isomorphism': 5082, 'centrality': 5083, 'spacing': 5084, 'representativeness': 5085, 'braid': 5086, 'generalisation': 5087, 'gating': 5088, 'federation': 5089, 'resampling': 5090, 'occam': 5091, 'lift': 5092, 'drifts': 5093, 'nail': 5094, 'late': 5095, 'realising': 5096, 'syntactified': 5097, 'reflect': 5098, 'tomography': 5099, 'monadic': 5100, 'gpus': 5101, 'datapath': 5102, 'storylines': 5103, 'adequate': 5104, 'polylingual': 5105, 'uct': 5106, 'chase': 5107, 'tdt': 5108, 'subtrees': 5109, 'bilateral': 5110, 'l2': 5111, 'crosslingual': 5112, 'regeneration': 5113, 'master': 5114, 'l1': 5115, 'planar': 5116, 'clp': 5117, 'communicative': 5118, 'hermes': 5119, 'sizing': 5120, 'tip': 5121, 'buddy': 5122, 'modularizing': 5123, 'metalanguage': 5124, 'ado': 5125, 'mediating': 5126, 'orientated': 5127, 'scarce': 5128, 'decipherment': 5129, 'writes': 5130, 'trap': 5131, 'tolerating': 5132, 'corporation': 5133, 'started': 5134, 'replanning': 5135, 'analysts': 5136, 'managed': 5137, 'quantificational': 5138, 'cf': 5139, 'summarize': 5140, 'universe': 5141, 'workshops': 5142, 'iqis': 5143, '2004': 5144, 'mat': 5145, 'datablade': 5146, 'xprs': 5147, 'datatype': 5148, 'metalevel': 5149, 'weird': 5150, 'teapot': 5151, 'gossiping': 5152, 'readings': 5153, 'devise': 5154, 'preserve': 5155, 'dialect': 5156, 'section': 5157, 'archjava': 5158, 'steroids': 5159, 'cameras': 5160, 'trial': 5161, 'guides': 5162, 'accents': 5163, 'suppressed': 5164, 'rooted': 5165, 'le': 5166, 'crossroads': 5167, 'taken': 5168, 'indeterminacy': 5169, 'freeness': 5170, 'indivisible': 5171, 'mailing': 5172, 'mcs': 5173, 'graphplans': 5174, 'disciplinary': 5175, 'implicate': 5176, 'alc': 5177, 'pen': 5178, 'kernelizing': 5179, 'immune': 5180, 'packed': 5181, 'differencing': 5182, 'pic': 5183, 'chatting': 5184, 'acid': 5185, 'oxygen': 5186, 'disequilibrium': 5187, 'subdialogues': 5188, 'origins': 5189, 'paradox': 5190, 'discount': 5191, 'occlusion': 5192, 'shapelets': 5193, 'interrupts': 5194, 'preemptive': 5195, 'ddb': 5196, 'forensic': 5197, 'nature': 5198, 'bands': 5199, 'redefining': 5200, 'inex': 5201, 'wallet': 5202, 'seemed': 5203, 'lung': 5204, 'tumor': 5205, 'reaching': 5206, 'motivational': 5207, 'unsatisfiability': 5208, 'esl': 5209, 'codesign': 5210, 'movers': 5211, 'delimited': 5212, 'graduates': 5213, 'iterators': 5214, 'auc': 5215, 'hazards': 5216, 'addition': 5217, 'muse': 5218, 'initiating': 5219, 'sentimental': 5220, 'dirty': 5221, 'objectrank': 5222, 'lh': 5223, 'tying': 5224, 'contained': 5225, 'animated': 5226, 'subquery': 5227, 'aes': 5228, 'finalists': 5229, 'multitext': 5230, 'navigable': 5231, 'wanted': 5232, 'did': 5233, 'dare': 5234, 'ask': 5235, 'isotonic': 5236, 'familiarity': 5237, 'accenting': 5238, 'disc': 5239, 'worm': 5240, 'multirobot': 5241, 'sorts': 5242, 'venus': 5243, 'marginal': 5244, 'coordinates': 5245, 'gaming': 5246, 'sequoia': 5247, 'boomerang': 5248, 'observer': 5249, 'explainable': 5250, 'compete': 5251, 'lookups': 5252, 'superimposed': 5253, 'eportal': 5254, 'verbmobil': 5255, 'champion': 5256, 'retina': 5257, 'feedforward': 5258, 'optional': 5259, 'antlima': 5260, 'alone': 5261, 'gossip': 5262, 'coordinators': 5263, 'advantage': 5264, 'gigascope': 5265, 'rectangle': 5266, 'kronecker': 5267, 'corrupted': 5268, 'burst': 5269, 'opening': 5270, 'eyes': 5271, 'behavioural': 5272, 'indexation': 5273, 'gricean': 5274, 'banking': 5275, 'motif': 5276, 'surf': 5277, 'height': 5278, 'muitilingual': 5279, 'lrtak': 5280, 'professionalism': 5281, 'crfs': 5282, 'katakana': 5283, 'rtdp': 5284, 'planners': 5285, 'bootstrapped': 5286, 'phones': 5287, 'swing': 5288, 'advertise': 5289, 'ariadne': 5290, 'xtra': 5291, 'ripple': 5292, 'publications': 5293, 'saving': 5294, 'semidefinite': 5295, 'contextualization': 5296, 'multitasking': 5297, 'connect': 5298, 'yield': 5299, 'differing': 5300, 'valuable': 5301, 'checkers': 5302, 'photoslap': 5303, 'cure': 5304, 'billions': 5305, 'counterexample': 5306, 'ltag': 5307, 'rox': 5308, 'ephemeral': 5309, 'summarising': 5310, 'en': 5311, 'fpga': 5312, 'tower': 5313, 'explore': 5314, 'verbnet': 5315, 'stripes': 5316, 'predicted': 5317, 'cape': 5318, 'parallelizer': 5319, 'phoenix': 5320, 'enumerating': 5321, 'sale': 5322, 'adam': 5323, 'scrap': 5324, 'append': 5325, 'maximize': 5326, 'psychology': 5327, 'gait': 5328, 'cocomo': 5329, 'intellectual': 5330, 'redirection': 5331, 'composable': 5332, 'interventional': 5333, 'ram': 5334, 'multiaccess': 5335, 'confidential': 5336, 'lean': 5337, 'durable': 5338, 'philosophical': 5339, 'modest': 5340, 'proportions': 5341, 'oss': 5342, 'reloaded': 5343, 'merits': 5344, 'encouraging': 5345, 'huge': 5346, 'blogscope': 5347, 'california': 5348, 'vital': 5349, 'utah': 5350, 'lilog': 5351, 'virtualization': 5352, 'strudel': 5353, 'schematic': 5354, 'melody': 5355, 'impedance': 5356, 'postgraduate': 5357, 'share': 5358, 'directionality': 5359, 'lingo': 5360, 'hundreds': 5361, 'totally': 5362, 'checkpoints': 5363, 'longevity': 5364, 'dark': 5365, 'lie': 5366, 'pressure': 5367, 'steam': 5368, 'affects': 5369, 'substantial': 5370, 'scaffolding': 5371, 'orchestrating': 5372, 'anycast': 5373, 'imt': 5374, 'repeated': 5375, 'sting': 5376, 'rendezvous': 5377, 'atn': 5378, 'reconstructed': 5379, 'reflexive': 5380, 'been': 5381, 'associating': 5382, 'determinant': 5383, 'entropic': 5384, 'extracts': 5385, 'alliances': 5386, 'opponents': 5387, 'artistic': 5388, 'suppressing': 5389, 'investment': 5390, 'warnings': 5391, 'storm': 5392, 'antecedents': 5393, 'disjunction': 5394, 'algorithma': 5395, 'establishment': 5396, 'deepening': 5397, 'hybridized': 5398, 'subgroup': 5399, 'ldap': 5400, 'tabu': 5401, 'simrank': 5402, 'qcsp': 5403, 'tms': 5404, 'testability': 5405, 'yourself': 5406, 'maximally': 5407, 'intractability': 5408, 'agreements': 5409, 'appearance': 5410, 'observational': 5411, 'reasoners': 5412, 'wheat': 5413, 'magnetic': 5414, 'autocorrelation': 5415, 'gate': 5416, 'themselves': 5417, 'strictly': 5418, 'trouble': 5419, 'tioga': 5420, 'taxis': 5421, 'lime': 5422, 'ups': 5423, 'mcdb': 5424, 'dtd': 5425, 'irisnet': 5426, 'superlatives': 5427, 'fuzziness': 5428, 'viewers': 5429, 'csse': 5430, 'pathway': 5431, 'backdoors': 5432, 'linearly': 5433, 'dd': 5434, 'datarace': 5435, 'maker': 5436, 'tac': 5437, 'loving': 5438, 'atlas': 5439, 'byte': 5440, 'maze': 5441, 'biographical': 5442, 'qstream': 5443, 'targets': 5444, 'clip': 5445, 'statement': 5446, 'red': 5447, 'countability': 5448, 'thou': 5449, 'ptime': 5450, 'systemt': 5451, 'zone': 5452, 'suitable': 5453, 'bypassing': 5454, 'truncated': 5455, 'circular': 5456, 'desert': 5457, 'conditioned': 5458, 'nonmajors': 5459, 'inclusive': 5460, 'potts': 5461, 'pegasus': 5462, 'phonemes': 5463, 'debug': 5464, 'bilinear': 5465, 'spiral': 5466, 'idlp': 5467, 'dnnf': 5468, 'cascading': 5469, 'pipelines': 5470, 'strip': 5471, 'dangers': 5472, 'parametricity': 5473, 'kalman': 5474, 'leveled': 5475, 'return': 5476, 'densification': 5477, 'authentic': 5478, 'decomposability': 5479, 'incident': 5480, 'commanders': 5481, 'avionics': 5482, 'might': 5483, 'linearizing': 5484, 'amazons': 5485, 'punctuated': 5486, 'mindset': 5487, 'debate': 5488, 'coevolving': 5489, 'crimes': 5490, 'forum': 5491, 'creativity': 5492, 'gradients': 5493, 'needle': 5494, 'tutorials': 5495, 'rediscovering': 5496, 'passion': 5497, 'beauty': 5498, 'joy': 5499, 'awe': 5500, 'pseudolikelihood': 5501, 'travelling': 5502, 'convenient': 5503, 'typechecking': 5504, 'linker': 5505, 'astral': 5506, 'buzz': 5507, 'conditionally': 5508, 'neither': 5509, 'crowd': 5510, 'adjectival': 5511, 'oil': 5512, 'equipment': 5513, 'selectors': 5514, 'revisions': 5515, 'misclassification': 5516, 'decoder': 5517, 'prioritizing': 5518, 'captioned': 5519, 'accessed': 5520, 'scr': 5521, 'ssd': 5522, 'lex': 5523, 'centralization': 5524, 'jawaa': 5525, 'killer': 5526, 'tfidf': 5527, 'oid': 5528, 'want': 5529, 'con': 5530, 'pachinko': 5531, 'singleton': 5532, 'watch': 5533, 'literal': 5534, 'percentile': 5535, 'possibly': 5536, 'reorderings': 5537, 'parameterised': 5538, 'papyrus': 5539, 'intents': 5540, 'sis': 5541, 'superior': 5542, 'qr': 5543, 'overlapped': 5544, 'condorcet': 5545, 'derivatives': 5546, 'miss': 5547, 'extrapolation': 5548, 'unfolding': 5549, 'reviving': 5550, 'sheets': 5551, 'stroke': 5552, 'eth': 5553, 'zurich': 5554, 'professionals': 5555, 'perplexity': 5556, 'mips': 5557, 'alternation': 5558, 'tips': 5559, 'had': 5560, 'interfacing': 5561, 'boat': 5562, 'el': 5563, 'trips': 5564, 'decomposed': 5565, 'emergency': 5566, 'triage': 5567, 'wrong': 5568, 'redux': 5569, 'broadcasting': 5570, 'vectorial': 5571, 'custom': 5572, 'odyssey': 5573, 'taxi': 5574, 'flavers': 5575, 'mereology': 5576, 'stuff': 5577, 'cascades': 5578, 'later': 5579, 'whether': 5580, 'schedule': 5581, 'teenage': 5582, 'modulation': 5583, 'validated': 5584, 'tab': 5585, 'emphasis': 5586, 'carrier': 5587, 'hiv': 5588, 'voxelized': 5589, 'competing': 5590, 'buyers': 5591, 'reserve': 5592, 'prices': 5593, 'analyzers': 5594, 'roadrunner': 5595, 'quadtree': 5596, 'breakpoints': 5597, 'deliberation': 5598, 'bubble': 5599, 'ldl': 5600, 'slavic': 5601, 'segmentations': 5602, 'bm25': 5603, 'formatting': 5604, 'mdm': 5605, 'safely': 5606, 'gp': 5607, 'etl': 5608, 'consulting': 5609, 'guardians': 5610, 'bitwidth': 5611, 'todays': 5612, 'multipurpose': 5613, 'mutable': 5614, 'babel': 5615, 'cdns': 5616, 'hamming': 5617, 'phenomenon': 5618, 'vienna': 5619, 'comprehending': 5620, 'apt': 5621, 'espresso': 5622, 'quota': 5623, 'proneness': 5624, 'phantom': 5625, 'measured': 5626, 'pathways': 5627, 'explosion': 5628, 'hough': 5629, 'swiss': 5630, 'cs4hs': 5631, 'shilling': 5632, 'gem': 5633, 'uc': 5634, 'subscribed': 5635, 'translated': 5636, 'airphys': 5637, 'wheel': 5638, 'encompass': 5639, 'pdf': 5640, 'refine': 5641, 'radar': 5642, 'micronet': 5643, 'transportable': 5644, 'stereotype': 5645, 'intervention': 5646, 'cinematic': 5647, 'mountains': 5648, 'assimilation': 5649, 'nps': 5650, 'fastest': 5651, 'fp': 5652, 'tf': 5653, 'maintainers': 5654, 'decaying': 5655, 'winnow': 5656, 'bubbles': 5657, 'relocation': 5658, 'accelerate': 5659, 'engineer': 5660, 'persistency': 5661, 'srl': 5662, 'stateful': 5663, 'breakout': 5664, 'holmes': 5665, 'enity': 5666, 'mdp': 5667, 'teachable': 5668, 'annotator': 5669, 'heritage': 5670, 'nogood': 5671, 'fmri': 5672, 'bleu': 5673, 'stereotypes': 5674, 'players': 5675, 'disruptions': 5676, 'discoveries': 5677, 'tokens': 5678, 'details': 5679, 'declarations': 5680, 'truthful': 5681, 'movies': 5682, 'eigenmaps': 5683, 'honors': 5684, 'updated': 5685, 'calculating': 5686, 'reconnaissance': 5687, 'excellence': 5688, 'contributed': 5689, 'securely': 5690, 'embracing': 5691, 'subtree': 5692, 'regulation': 5693, 'reset': 5694, 'sophisticates': 5695, 'maritime': 5696, 'imposing': 5697, 'xxl': 5698, 'sail': 5699, 'implicitly': 5700, 'converges': 5701, 'amounts': 5702, 'concern': 5703, 'localizing': 5704, 'semester': 5705, 'hotspots': 5706, 'reproducing': 5707, 'dcop': 5708, 'eca': 5709, 'adverbials': 5710, 'mereological': 5711, 'survival': 5712, 'dblearn': 5713, 'transliterations': 5714, 'csis': 5715, 'deconstructing': 5716, 'semitic': 5717, 'odometry': 5718, 'id': 5719, 'concerning': 5720, 'isa': 5721, 'exogenous': 5722, 'abridged': 5723, 'colleges': 5724, 'ride': 5725, 'triangulated': 5726, 'achievements': 5727, 'circumscriptive': 5728, 'bandera': 5729, 'xrpc': 5730, 'utterance': 5731, 'proto': 5732, 'developmental': 5733, 'spi': 5734, 'svd': 5735, 'astronomy': 5736, 'catch': 5737, 'container': 5738, 'submitted': 5739, 'combat': 5740, 'hypercard': 5741, 'prove': 5742, 'disconnection': 5743, 'obj2': 5744, 'efficacy': 5745, 'derivational': 5746, 'reexamining': 5747, 'repeats': 5748, 'repeat': 5749, 'yahoos': 5750, 'samos': 5751, 'insights': 5752, 'datacubes': 5753, 'shifting': 5754, 'geodesic': 5755, 'combinators': 5756, 'close': 5757, 'splines': 5758, 'ntcir': 5759, 'weakest': 5760, 'sufficient': 5761, 'interplay': 5762, 'comic': 5763, 'synergistic': 5764, 'proofreading': 5765, 'commentary': 5766, 'applicable': 5767, 'shuffling': 5768, 'repetition': 5769, 'grafting': 5770, 'done': 5771, 'utile': 5772, 'marked': 5773, 'discriminants': 5774, 'ethnographic': 5775, 'miro': 5776, 'unify': 5777, 'inscape': 5778, 'diagonal': 5779, 'hahacronym': 5780, 'alphabetic': 5781, 'inspiration': 5782, 'enforce': 5783, 'ramifications': 5784, 'qualifications': 5785, 'smash': 5786, 'minimality': 5787, 'nonstationary': 5788, 'separators': 5789, 'rays': 5790, 'interruptions': 5791, 'punctuation': 5792, 'thoughts': 5793, 'dbir': 5794, 'calos': 5795, 'resume': 5796, 'rotating': 5797, 'normality': 5798, 'housing': 5799, 'literate': 5800, 'interpretive': 5801, 'tourist': 5802, 'tiered': 5803, 'mechanically': 5804, 'shop': 5805, 'lexicalist': 5806, 'ranksql': 5807, 'th': 5808, 'differentially': 5809, 'netflix': 5810, 'prize': 5811, 'dj': 5812, 'provider': 5813, 'unifies': 5814, 'cautious': 5815, 'parent': 5816, 'unaware': 5817, 'refreshing': 5818, 'headline': 5819, 'intertask': 5820, 'gsp': 5821, 'averaged': 5822, 'mixin': 5823, 'interrupted': 5824, 'downward': 5825, 'ancient': 5826, 'caption': 5827, 'mrfs': 5828, 'triple': 5829, 'entertainment': 5830, 'overheads': 5831, 'informativeness': 5832, 'touch': 5833, 'quantify': 5834, 'produces': 5835, 'parsetalk': 5836, 'restful': 5837, 'pact': 5838, 'break': 5839, 'amnesic': 5840, 'sox': 5841, 'faces': 5842, 'polyhedra': 5843, 'consciousness': 5844, 'widening': 5845, 'bundle': 5846, 'rs': 5847, 'stamped': 5848, 'oov': 5849, 'topologies': 5850, 'motivating': 5851, 'judging': 5852, 'underrepresented': 5853, 'violations': 5854, 'chord': 5855, 'occurence': 5856, 'rcc': 5857, 'isis': 5858, 'habits': 5859, 'binarization': 5860, 'instantaneous': 5861, 'anything': 5862, 'phylogenetic': 5863, 'ellipsoid': 5864, 'atis': 5865, 'landscapes': 5866, 'functor': 5867, 'epic': 5868, 'densitometric': 5869, 'hyperplane': 5870, 'pipes': 5871, 'reestimation': 5872, 'backdoor': 5873, 'excerpts': 5874, 'alive': 5875, 'sure': 5876, 'assist': 5877, 'verifiable': 5878, 'peripheral': 5879, 'crashes': 5880, 'japanesegerman': 5881, 'retaining': 5882, 'ciphertext': 5883, 'apparent': 5884, 'chiron': 5885, 'gestalt': 5886, 'indonesian': 5887, 'inaccessible': 5888, 'alzheimers': 5889, 'deadline': 5890, 'predictability': 5891, 'retrievals': 5892, 'clv': 5893, 'preserves': 5894, 'acceptable': 5895, 'being': 5896, 'discrepancy': 5897, 'straightforward': 5898, 'wishful': 5899, 'flavor': 5900, 'away': 5901, 'seen': 5902, 'homepage': 5903, 'begin': 5904, 'permanent': 5905, 'morph': 5906, 'opinionated': 5907, 'compilability': 5908, 'absorbing': 5909, 'death': 5910, 'advisory': 5911, 'lotus': 5912, 'fixing': 5913, 'conciseness': 5914, 'awesome': 5915, 'slice': 5916, 'forgotten': 5917, 'subroutines': 5918, 'ready': 5919, 'realisation': 5920, 'cataloging': 5921, 'skicat': 5922, 'parses': 5923, 'regulations': 5924, 'adtrees': 5925, 'bribery': 5926, 'winwin': 5927, 'bdd': 5928, 'quantities': 5929, 'stm': 5930, 'cortex': 5931, 'upgrade': 5932, 'lemma': 5933, 'allens': 5934, 'plsi': 5935, 'bilexical': 5936, 'combating': 5937, 'trustrank': 5938, 'admixture': 5939, 'participatory': 5940, 'transcription': 5941, 'integers': 5942, 'decompression': 5943, 'webcluster': 5944, 'harnessing': 5945, 'nero': 5946, 'deviations': 5947, 'mechanization': 5948, 'antonymy': 5949, 'geotagging': 5950, 'diversifying': 5951, 'omissions': 5952, 'ltsa': 5953, 'companies': 5954, 'eurotra': 5955, 'kind': 5956, 'advancement': 5957, 'particular': 5958, 'homophily': 5959, 'fail': 5960, 'dewey': 5961, 'tina': 5962, 'odp': 5963, 'sciencecraft': 5964, 'onboard': 5965, 'ergodic': 5966, 'multigram': 5967, 'deleted': 5968, 'thresholded': 5969, 'contradiction': 5970, 'merged': 5971, 'deliberative': 5972, 'exam': 5973, 'voltage': 5974, 'coming': 5975, 'breaks': 5976, 'squeezing': 5977, 'xtract': 5978, 'carrying': 5979, '2002': 5980, 'tera': 5981, 'syllogistic': 5982, 'entries': 5983, 'icon': 5984, 'uncorrelated': 5985, 'componentized': 5986, 'cardinalities': 5987, 'trail': 5988, 'quantized': 5989, 'exchanged': 5990, 'alarms': 5991, 'aggregative': 5992, 'ends': 5993, 'kinesthetic': 5994, 'codds': 5995, 'military': 5996, 'attractiveness': 5997, 'strategyproof': 5998, '5': 5999, 'xforms': 6000, 'compress': 6001, 'checkpoint': 6002, 'resolutions': 6003, 'dsl': 6004, 'moment': 6005, 'impossibility': 6006, 'delegation': 6007, 'exchanging': 6008, 'desires': 6009, 'currying': 6010, 'reservoir': 6011, 'importing': 6012, 'yago': 6013, 'civil': 6014, 'regional': 6015, 'autocompletion': 6016, 'tolerate': 6017, 'leave': 6018, 'valuations': 6019, 'doc': 6020, 'crowdsourcing': 6021, 'lore': 6022, 'architect': 6023, 'crosslinguistic': 6024, 'become': 6025, 'sparsely': 6026, 'hux': 6027, 'canadian': 6028, 'traveller': 6029, 'graphic': 6030, 'engineered': 6031, 'triggered': 6032, 'forces': 6033, 'disparate': 6034, 'mostly': 6035, 'deducing': 6036, 'reasonably': 6037, 'consul': 6038, 'whips': 6039, 'anaphoricity': 6040, 'weaker': 6041, 'supersense': 6042, 'fitness': 6043, 'disjointness': 6044, 'manifest': 6045, 'seeing': 6046, 'keyphrases': 6047, 'dbo': 6048, 'chameleon': 6049, 'delaying': 6050, 'cassm': 6051, 'negations': 6052, 'contradictions': 6053, 'dft': 6054, 'fielded': 6055, 'neighboring': 6056, 'idle': 6057, 'orthographic': 6058, 'btg': 6059, 'dirt': 6060, 'b2b': 6061, 'possibility': 6062, 'shortcuts': 6063, 'untyped': 6064, 'treat': 6065, 'intermittent': 6066, 'et': 6067, 'genomes': 6068, 'bill': 6069, 'mrf': 6070, 'hubs': 6071, 'mp3': 6072, 'friends': 6073, 'dat': 6074, 'phased': 6075, 'cognate': 6076, 'subsequences': 6077, 'bombay': 6078, 'anywhere': 6079, 'escrow': 6080, 'reed': 6081, 'masked': 6082, 'starts': 6083, 'equalities': 6084, 'copies': 6085, 'sonar': 6086, 'electrical': 6087, 'acceptability': 6088, 'option': 6089, 'deductively': 6090, 'cbr': 6091, 'serpent': 6092, 'hungarian': 6093, 'calculations': 6094, 'volcano': 6095, 'dot': 6096, 'trick': 6097, 'risky': 6098, 'tele': 6099, 'save': 6100, 'oz': 6101, 'ner': 6102, 'jumps': 6103, 'amd': 6104, 'sphere': 6105, 'verisoft': 6106, 'multiplayer': 6107, 'keep': 6108, 'systemic': 6109, 'certificates': 6110, 'bags': 6111, 'iso': 6112, '9001': 6113, 'hop': 6114, 'hole': 6115, 'fall': 6116, 'award': 6117, 'expansions': 6118, 'extremely': 6119, 'spell': 6120, 'honesty': 6121, 'switch': 6122, 'ceteris': 6123, 'paribus': 6124, 'morphosyntactic': 6125, 'xtag': 6126, 'mirroring': 6127, 's3': 6128, 'arbitrarily': 6129, 'limit': 6130, 'nightmare': 6131, 'textured': 6132, 'urbana': 6133, 'champaign': 6134, 'bits': 6135, 'presupposition': 6136, 'analogue': 6137, 'vr': 6138, '1978': 6139, 'scrolling': 6140, 'denoising': 6141, 'reformulations': 6142, 'characteristic': 6143, 'cse': 6144, 'clips': 6145, 'crafted': 6146, 'widely': 6147, 'hearsay': 6148, 'texas': 6149, 'journey': 6150, 'extractors': 6151, 'disparity': 6152, 'linearity': 6153, 'dop': 6154, 'mrd': 6155, 'smaller': 6156, 'joke': 6157, 'theta': 6158, 'latching': 6159, 'artists': 6160, 'sqlmed': 6161, 'contact': 6162, 'chronological': 6163, 'contractual': 6164, 'stress': 6165, 'visitor': 6166, 'designated': 6167, 'exponentiated': 6168, 'ancestors': 6169, 'fargo': 6170, 'grna': 6171, 'socratic': 6172, 'sealed': 6173, 'evaluator': 6174, 'lead': 6175, 'leaders': 6176, 'roi': 6177, 'hyperparameter': 6178, 'inequality': 6179, 'transposition': 6180, 'ghostdb': 6181, 'hitters': 6182, 'elastic': 6183, 'triangulation': 6184, 'granger': 6185, 'formalizations': 6186, 'ticket': 6187, 'east': 6188, '05': 6189, 'judgmental': 6190, 'debates': 6191, 'sniffing': 6192, 'workspaces': 6193, 'winners': 6194, 'spots': 6195, 'htns': 6196, 'amount': 6197, 'nutshell': 6198, 'drawn': 6199, 'personalizable': 6200, 'bird': 6201, 'understandable': 6202, 'undirected': 6203, 'sibling': 6204, 'pools': 6205, 'piazza': 6206, 'incorporate': 6207, 'coma': 6208, 'som': 6209, 'registers': 6210, 'essays': 6211, 'incidents': 6212, 'equal': 6213, 'bundling': 6214, 'bregman': 6215, 'gai': 6216, 'dcg': 6217, 'procurement': 6218, 'cope': 6219, 'pradigms': 6220, 'risks': 6221, 'fill': 6222, 'icons': 6223, 'lesson': 6224, 'quickstore': 6225, 'mapped': 6226, 'occams': 6227, 'razor': 6228, 'declaration': 6229, 'closer': 6230, 'perceptually': 6231, 'presburger': 6232, 'proofness': 6233, 'dissimilarities': 6234, 'bea': 6235, 'semcog': 6236, '2nd': 6237, 'encounter': 6238, 'oar': 6239, 'r3': 6240, 'ferret': 6241, 'smo': 6242, 'dynalab': 6243, 'smil': 6244, 'ttp': 6245, 'described': 6246, 'gr8': 6247, 'friend': 6248, 'containers': 6249, 'pq': 6250, 'nonlocal': 6251, 'photo': 6252, 'pedagogic': 6253, 'pyro': 6254, 'calligraphy': 6255, 'deltas': 6256, 'blame': 6257, 'stateless': 6258, 'timeout': 6259, 'modularized': 6260, 'memex': 6261, 'drives': 6262, 'salesman': 6263, 'hal': 6264, 'trustworthy': 6265, 'anticipatory': 6266, 'consultant': 6267, 'smoothed': 6268, 'looping': 6269, 'moby': 6270, 'supersql': 6271, 'parsable': 6272, 'hoeffding': 6273, 'xmas': 6274, 'inserted': 6275, 'proteins': 6276, 'montage': 6277, 'nestedness': 6278, 'endorsement': 6279, 'omission': 6280, 'prismadb': 6281, 'cooccurrence': 6282, 'sentinel': 6283, 'dimensionally': 6284, 'damia': 6285, 'sm3': 6286, 'mirror': 6287, 'morphologically': 6288, 'roots': 6289, 'coexistence': 6290, 'damloil': 6291, 'acceptance': 6292, 'pulse': 6293, 'habitats': 6294, 'fad': 6295, 'interpolated': 6296, 'assuring': 6297, 'addressable': 6298, 'numeral': 6299, 'fluency': 6300, 'rectangles': 6301, 'neat': 6302, 'storytelling': 6303, 'lca': 6304, 'bengali': 6305, 'conclusions': 6306, 'tableaux': 6307, 'mix': 6308, 'dream': 6309, 'smarter': 6310, 'niche': 6311, 'deixis': 6312, 'formats': 6313, 'educe': 6314, 'everyday': 6315, 'metamodel': 6316, 'printing': 6317, 'intuition': 6318, 'contributing': 6319, 'illustrated': 6320, 'nesting': 6321, 'football': 6322, 'lcas': 6323, 'domino': 6324, 'customizability': 6325, 'lemmatization': 6326, 'patr': 6327, 'relevancy': 6328, 'bdi': 6329, 'submodular': 6330, 'classifications': 6331, 'constantly': 6332, 'tsp': 6333, 'agglomerative': 6334, 'maybms': 6335, '40': 6336, 'anniversary': 6337, 'bernstein': 6338, 'scanner': 6339, 'multiprogramming': 6340, 'responsive': 6341, 'reconsidered': 6342, 'logarithmic': 6343, 'assertional': 6344, 'station': 6345, 'jade': 6346, 'practicality': 6347, 'median': 6348, 'finder': 6349, 'dots': 6350, 'driving': 6351, 'demonstrations': 6352, '15': 6353, 'garlic': 6354, 'exposure': 6355, 'chemistry': 6356, 'randomize': 6357, 'synchronizing': 6358, 'inclusions': 6359, 'kit': 6360, 'career': 6361, 'picky': 6362, 'overflows': 6363, 'genres': 6364, 'conformance': 6365, 'clash': 6366, 'intuitions': 6367, 'textes': 6368, 'lexique': 6369, 'equation': 6370, 'matlab': 6371, 'tods': 6372, 'dining': 6373, 'incorporated': 6374, 'backed': 6375, 'parameterizing': 6376, 'linguists': 6377, 'grand': 6378, 'objectstore': 6379, 'alert': 6380, 'shapley': 6381, 'instrumented': 6382, 'wifi': 6383, 'interrupt': 6384, 'parity': 6385, 'choreography': 6386, 'wants': 6387, 'mr': 6388, 'secured': 6389, 'mergesorts': 6390, 'ilp': 6391, 'sensemaking': 6392, 'audiovideo': 6393, 'cords': 6394, 'cdn': 6395, 'church': 6396, 'ngram': 6397, 'gc': 6398, 'asymmetrical': 6399, 'diabetic': 6400, 'nodose': 6401, 'presumed': 6402, 'morpheus': 6403, 'maintainability': 6404, 'detective': 6405, 'morphemes': 6406, 'diagrammatic': 6407, 'rose': 6408, 'retail': 6409, 'thanks': 6410, 'newsgroups': 6411, 'oasis': 6412, 'mongolian': 6413, 'inhomogeneous': 6414, 'distorted': 6415, 'mirrors': 6416, 'authenticated': 6417, 'sybase': 6418, 'ase': 6419, 'multirelational': 6420, 'vm': 6421, 'metaclasses': 6422, 'describe': 6423, 'composed': 6424, 'sleep': 6425, 'conjuncts': 6426, 'msn': 6427, 'mangers': 6428, '2006': 6429, 'listings': 6430, 'sqlj': 6431, 'inc': 6432, 'rubric': 6433, 'longitudinal': 6434, 'compressive': 6435, 'imagery': 6436, 'multitask': 6437, 'converse': 6438, 'positioning': 6439, 'capable': 6440, 'gateways': 6441, 'tenth': 6442, 'noninterference': 6443, 'themed': 6444, 'trio': 6445, 'ale': 6446, 'theres': 6447, 'dfs': 6448, 'humanoid': 6449, 'gemini': 6450, 'psycholinguistic': 6451, 'nombank': 6452, 'atm': 6453, 'queuing': 6454, 'lixto': 6455, 'dimac': 6456, 'validator': 6457, 'slashdot': 6458, 'preferable': 6459, 'regularizing': 6460, 'proposing': 6461, 'agm': 6462, 'paid': 6463, 'deletions': 6464, 'imperatives': 6465, 'alphanumeric': 6466, 'searchable': 6467, 'shafer': 6468, 'pointcuts': 6469, 'isomorphic': 6470, 'claims': 6471, 'replicator': 6472, 'host': 6473, 'bpref': 6474, 'encrypt': 6475, 'rows': 6476, 'sg': 6477, 'proceedings': 6478, 'synergies': 6479, 'sampler': 6480, 'stretching': 6481, 'amilcare': 6482, 'offloading': 6483, 'columbia': 6484, 'propel': 6485, 'fidelity': 6486, 'imposition': 6487, 'restriction': 6488, 'ccured': 6489, 'isolating': 6490, 'subexpression': 6491, 'charting': 6492, 'horizontally': 6493, 'quantative': 6494, 'license': 6495, 'mismatches': 6496, 'jan': 6497, 'biases': 6498, 'stick': 6499, 'curb': 6500, 'kana': 6501, 'dist': 6502, 'alarm': 6503, 'normalisation': 6504, 'critic': 6505, 'conjecture': 6506, 'button': 6507, 'approximators': 6508, 'deadlines': 6509, 'kemeny': 6510, 'p2': 6511, 'steiner': 6512, 'ungrammatical': 6513, 'organic': 6514, 'qualified': 6515, 'sirius': 6516, 'lsd': 6517, 'dominator': 6518, 'pads': 6519, 'faithful': 6520, 'corrigendum': 6521, 'interpersonal': 6522, 'lexicography': 6523, 'telegraphic': 6524, 'highlight': 6525, 'scriptease': 6526, 'xmdvtool': 6527, 'reflections': 6528, 'protected': 6529, 'complements': 6530, 'sorter': 6531, 'camps': 6532, 'consistently': 6533, 'shortcut': 6534, 'responding': 6535, 'tripartite': 6536, 'losses': 6537, 'dct': 6538, 'subgoals': 6539, 'formalized': 6540, 'remotely': 6541, 'dtls': 6542, 'dataspot': 6543, 'fagin': 6544, 'shrink': 6545, 'vliw': 6546, 'silicon': 6547, 'descriptor': 6548, 'hyperj': 6549, 'surprise': 6550, 'genomics': 6551, 'adhoc': 6552, 'heteroscedastic': 6553, 'retargeting': 6554, 'xqueries': 6555, 'captcha': 6556, 'healing': 6557, 'explicitly': 6558, 'distinguish': 6559, 'ecoinformatics': 6560, 'brute': 6561, 'oql': 6562, 'recruitment': 6563, 'cite': 6564, 'scholarly': 6565, 'functors': 6566, 'aide': 6567, 'copyright': 6568, 'scratchpad': 6569, 'interlingua': 6570, 'whitebox': 6571, 'fuzzing': 6572, 'protect': 6573, 'anyway': 6574, 'typology': 6575, 'darpa': 6576, 'asset': 6577, 'packaging': 6578, 'produce': 6579, 'dwt': 6580, 'highlighting': 6581, 'true': 6582, 'immersive': 6583, 'equivalences': 6584, 'convenience': 6585, 'autodomainmine': 6586, 'anipqo': 6587, 'effortless': 6588, 'funbase': 6589, 'feaspar': 6590, 'nosvo': 6591, 'scenic': 6592, 'webanywhere': 6593, 'screen': 6594, 'cug': 6595, 'exsearch': 6596, 'aol': 6597, 'cryptanalytic': 6598, 'nonexistence': 6599, 'manipulate': 6600, 'contradictory': 6601, 'revival': 6602, 'revtolc': 6603, 'marian': 6604, 'transferred': 6605, 'budding': 6606, 'ipage': 6607, 'helicopter': 6608, 'alaska': 6609, 'mace': 6610, 'rim': 6611, 'teg': 6612, 'localisation': 6613, 'blood': 6614, 'transfusion': 6615, 'multiplatformmultilanguage': 6616, 'roadmap': 6617, 'survive': 6618, 'mapdupreducer': 6619, 'outlines': 6620, 'span': 6621, 'qed': 6622, 'postroom': 6623, 'envisioning': 6624, 'unlabelled': 6625, 'itineraries': 6626, 'wellmade': 6627, 't4sql': 6628, 'arcube': 6629, 'performamatics': 6630, 'agglomerating': 6631, 'taj': 6632, 'overlaps': 6633, 'reorderable': 6634, 'freespan': 6635, 'jukebox': 6636, 'markedness': 6637, 'benign': 6638, 'racesallusing': 6639, 'graceful': 6640, 'smm': 6641, 'dantes': 6642, 'decreased': 6643, 'rumors': 6644, 'rdbv1': 6645, 'sonet': 6646, 'openpm': 6647, 'construcuon': 6648, 'trains': 6649, 'invariability': 6650, 'marketed': 6651, 'normalize': 6652, 'nonintersecting': 6653, 'sophomore': 6654, 'denali': 6655, 'lexeme': 6656, 'computationaily': 6657, 'uniformity': 6658, 'wysiwym': 6659, 's81': 6660, 'parc': 6661, 'depbank': 6662, 'zoomuserviews': 6663, 'overprvning': 6664, 'tempered': 6665, 'semaphore': 6666, 'huffman': 6667, 'gess': 6668, 'humanitarian': 6669, 'concord': 6670, 'xuml': 6671, 'fipa': 6672, 'unbundling': 6673, 'psst': 6674, 'irlbot': 6675, 'avatar': 6676, 'cognates': 6677, 'added': 6678, 'abuse': 6679, 'signing': 6680, 'monkeys': 6681, 'millennial': 6682, 'classificatory': 6683, 'hyperbf': 6684, 'ipse': 6685, 'anyone': 6686, 'precluding': 6687, 'glance': 6688, 'saiu': 6689, 'accociative': 6690, 'keeps': 6691, 'lexeed': 6692, 'hinoki': 6693, 'calculussql': 6694, 'disfluency': 6695, 'bfnumdocs': 6696, 'thor': 6697, 'cmradar': 6698, 'pronunciations': 6699, 'wysiwyg': 6700, 'commonalities': 6701, 'paratucker': 6702, 'forwarding': 6703, 'gib': 6704, 'principar': 6705, 'paraccel': 6706, 'medusa': 6707, 'xsds': 6708, 'morphographemic': 6709, 'nonconcatenative': 6710, 'replications': 6711, 'redefinitions': 6712, 'encountered': 6713, 'supercompilation': 6714, 'thirty': 6715, 'encapsualtion': 6716, 'computerised': 6717, 'semiorder': 6718, 'picashow': 6719, 'processibility': 6720, 'pilots': 6721, 'memoryless': 6722, 'krom': 6723, 'explicitely': 6724, 'reinforcers': 6725, 'xtango': 6726, 'xmltm': 6727, 'conversationally': 6728, 'represented': 6729, 'lengths': 6730, 'tolerances': 6731, 'neumann': 6732, 'quantminer': 6733, 'micmac': 6734, 'adon': 6735, 'decades': 6736, 'experiencer': 6737, 'proquel': 6738, 'jaat': 6739, 'sqlxnf': 6740, '8th': 6741, 'cursor': 6742, 'neptune': 6743, 'netserf': 6744, 'medialife': 6745, 'sin': 6746, 'algovista': 6747, 'biin': 6748, 'evaluability': 6749, 'neuroelectromagnetic': 6750, 'ontologiesnemo': 6751, 'brainwave': 6752, 'serfing': 6753, 'cabob': 6754, 'growrange': 6755, 'vcg': 6756, 'adjective': 6757, 'gradability': 6758, 'bhunt': 6759, 'fpgas': 6760, 'subtasks': 6761, 'transformantions': 6762, 'jungl': 6763, 'fcl': 6764, 'tribute': 6765, 'memorial': 6766, 'allinonenews': 6767, 'fractionation': 6768, 'refractionation': 6769, 'rubacon': 6770, 'mas': 6771, 'gstp': 6772, 'angluin': 6773, 'adnoun': 6774, 'supernode': 6775, 'hypertalk': 6776, 'overture': 6777, 'flocks': 6778, 'excel': 6779, 'set®': 6780, 'lrpd': 6781, 'pinwheel': 6782, 'sides': 6783, 'anorexic': 6784, 'paranoids': 6785, 'bb1': 6786, 'modifiers': 6787, 'rfa': 6788, 'inflection': 6789, 'scriptframe': 6790, 'hyperqueries': 6791, 'gigaflops': 6792, 'judicial': 6793, 'immix': 6794, 'mutator': 6795, 'babyos': 6796, 'stardardized': 6797, 'equi': 6798, 'personalisation': 6799, 'fluxquery': 6800, 'reformatting': 6801, 'header': 6802, 'interferring': 6803, 'emulator': 6804, 'helpful': 6805, 'ehr': 6806, 'cise': 6807, 'diffsets': 6808, 'extender': 6809, 'rotational': 6810, 'machinima': 6811, 'impressionrank': 6812, 'sectioning': 6813, 'regex': 6814, 'handsets': 6815, 'dmaic': 6816, 'retrival': 6817, 'defensive': 6818, 'carefully': 6819, 'fractional': 6820, 'webware': 6821, 'multilanguage': 6822, 'formerly': 6823, 'especial': 6824, 'draft': 6825, 'cho': 6826, 'cccs': 6827, 'sweetdeal': 6828, 'emphasize': 6829, 'richness': 6830, 'offsets': 6831, '1991': 6832, 'subcategorisation': 6833, 'foss': 6834, '101': 6835, 'analogic': 6836, 'locker': 6837, 'extensiblerule': 6838, 'buckets': 6839, 'enabler': 6840, 'airline': 6841, 'sabre': 6842, 'cleanup': 6843, 'mistaken': 6844, 'apportioning': 6845, 'manycore': 6846, 'nvram': 6847, 'nvramos': 6848, 'isomorphs': 6849, 'trivial': 6850, 'cancelled': 6851, 'reinspections': 6852, 'baffling': 6853, 'situationactivation': 6854, 'gregress': 6855, 'ohsumed': 6856, 'hol': 6857, 'whiz': 6858, 'racist': 6859, 'metapher': 6860, 'sniafl': 6861, 'period': 6862, 'compensations': 6863, 'demonic': 6864, 'overseas': 6865, 'succssus': 6866, 'chief': 6867, 'minimisation': 6868, 'orthonormalized': 6869, 'bridges': 6870, 'discord': 6871, 'clgn': 6872, 'ablation': 6873, 'parsec': 6874, 'gaea': 6875, 'shadowed': 6876, 'buckshot': 6877, 'spheresearch': 6878, 'distributionally': 6879, 'gelfond': 6880, 'lifschitz': 6881, 'predilection': 6882, 'topigraphy': 6883, 'vita': 6884, 'diffusionrank': 6885, 'penicillin': 6886, 'implicitness': 6887, 'dlfm': 6888, 'tanenbaums': 6889, 'mic': 6890, 'simplenpkl': 6891, 'boxing': 6892, 'dok': 6893, 'symbology': 6894, 'arrangement': 6895, 'ensembling': 6896, 'affiliated': 6897, 'fol': 6898, 'expiration': 6899, 'nestd': 6900, 'descriptional': 6901, 'biwtl': 6902, 'useless': 6903, 'statistice': 6904, 'aspiration': 6905, 'cnn': 6906, 'idiolectic': 6907, 'doctor': 6908, 'ao': 6909, 'faim': 6910, 'microplanning': 6911, 'skilled': 6912, 'stationarity': 6913, 'hotman': 6914, 'sei': 6915, 'norn': 6916, 'forecaster': 6917, 'oscillatory': 6918, 'repartitioning': 6919, 'primordial': 6920, 'soup': 6921, 'inspecting': 6922, 'servlets': 6923, 'wikify': 6924, 'intensities': 6925, 'lars': 6926, 'elmr': 6927, 'lexicalising': 6928, 'leases': 6929, 'diagrama': 6930, 'treescape': 6931, 'spontaneously': 6932, 'dxq': 6933, 'autoadmin': 6934, 'microeconomic': 6935, 'warp': 6936, 'pathology': 6937, 'gio': 6938, 'lupsort': 6939, 'lifestreams': 6940, 'marine': 6941, 'irank': 6942, 'sesame': 6943, 'interpreded': 6944, 'deceptively': 6945, 'ures': 6946, 'clustermap': 6947, 'comlex': 6948, 'trey': 6949, 'spartan': 6950, 'tempus': 6951, 'fugit': 6952, 'winrdbi': 6953, 'nations': 6954, 'refitting': 6955, 'slides': 6956, 'tabletpc': 6957, 'demonizing': 6958, 'idisks': 6959, 'joyce': 6960, 'metalogic': 6961, 'sri': 6962, 'capitalizing': 6963, 'carpenter': 6964, 'structurization': 6965, 'walkthroughs': 6966, 'icicles': 6967, 'aidb': 6968, 'ratios': 6969, 'abbreviations': 6970, 'lightening': 6971, 'dataplorer': 6972, 'rote': 6973, 'extractor': 6974, 'dataless': 6975, 'viewer': 6976, 'sv3d': 6977, 'edict': 6978, 'polibox': 6979, 'inmaf': 6980, 'bumps': 6981, 'curvature': 6982, 'zodiac': 6983, 'cim': 6984, 'migrating': 6985, 'electronics': 6986, 'anlex': 6987, 'ansin': 6988, 'quark': 6989, 'financially': 6990, 'encina': 6991, 'db2xml': 6992, 'spend': 6993, 'representationalist': 6994, 'beeps': 6995, 'empathize': 6996, 'involved': 6997, 'ipog': 6998, 'reputations': 6999, 'invertible': 7000, 'adlads': 7001, 'convexity': 7002, 'upperbounds': 7003, 'efendi': 7004, 'cadlab': 7005, 'streamglobe': 7006, 'simse': 7007, 'youre': 7008, 'turnstile': 7009, 'spmt': 7010, 'rpj': 7011, 'admit': 7012, 'conspiracy': 7013, 'pid': 7014, 'plow': 7015, 'hyperfairness': 7016, 'eql': 7017, 'classified': 7018, 'mycbr': 7019, 'bounce': 7020, 'advertisements': 7021, 'microtiger': 7022, 'microcode': 7023, 'hypernyms': 7024, 'prestige': 7025, 'jsd': 7026, 'implementor': 7027, 'slim': 7028, 'odb': 7029, 'qoptimizer': 7030, 'spotsigs': 7031, 'refactor': 7032, 'melbourne': 7033, 'assault': 7034, 'individualism': 7035, 'parameterizable': 7036, 'vickrey': 7037, 'exchanges': 7038, 'cscw': 7039, 'populating': 7040, 'cyc\\x99': 7041, 'hierarchization': 7042, 'liped': 7043, 'loadstore': 7044, 'ocelot': 7045, 'omcat': 7046, 'solves': 7047, 'semiconductor': 7048, 'ws3': 7049, 'csssia': 7050, 'determiner': 7051, 'udrss': 7052, 'giuku': 7053, 'utilities': 7054, 'camouflaged': 7055, 'horting': 7056, 'hatches': 7057, 'egg': 7058, 'exclaim': 7059, 'asic': 7060, 'eden': 7061, 'cohersion': 7062, 'slate': 7063, 'rated': 7064, 'mosaico': 7065, 'circles': 7066, 'substrate': 7067, 'connector': 7068, 'oo7': 7069, 'davis': 7070, 'putnam': 7071, 'outerplanar': 7072, 'artdb': 7073, 'essentiality': 7074, 'moore': 7075, 'taxation': 7076, 'intersentential': 7077, 'sustainable': 7078, 'chillers': 7079, 'regrouping': 7080, 'multiplex': 7081, 'fusionplex': 7082, 'autoplex': 7083, 'cint': 7084, 'coindexing': 7085, 'contexted': 7086, 'functionally': 7087, 'rstar': 7088, 'ming': 7089, 'statix': 7090, 'automatized': 7091, 'goodevil': 7092, 'lcs': 7093, 'trim': 7094, 'dances': 7095, 'checklist': 7096, 'nah': 7097, 'syndrome': 7098, 'sinuhe': 7099, 'seniors': 7100, 'dialogic': 7101, 'walrus': 7102, 'hierarchial': 7103, 'feeding': 7104, 'frenzy': 7105, 'selectively': 7106, 'materializing': 7107, 'coterie': 7108, 'eigenvalue': 7109, 'rapidity': 7110, 'mitre': 7111, 'focussed': 7112, 'p2cast': 7113, 'patching': 7114, 'crm': 7115, 'symrnetric': 7116, 'rlsc': 7117, 'agony': 7118, 'unimodal': 7119, 'nonmodal': 7120, 'interform': 7121, 'gas': 7122, 'turbine': 7123, 'prolific': 7124, 'proliant': 7125, 'subordination': 7126, 'clefts': 7127, 'multimode': 7128, 'sigmodpods': 7129, 'conferences': 7130, 'dichotomies': 7131, 'mapgraph': 7132, 'ocl': 7133, 'cpcv': 7134, 'rql': 7135, 'overcome': 7136, 'developmentevolution': 7137, 'deeper': 7138, 'qrelx': 7139, 'geospatially': 7140, 'photograph': 7141, 'perf': 7142, 'bloomjoin': 7143, 'trafic': 7144, 'beaten': 7145, 'iac': 7146, 'subword': 7147, 'critics': 7148, 'obfuscating': 7149, 'stylometry': 7150, 'closet': 7151, 'substantional': 7152, 'enclosing': 7153, 'balls': 7154, 'eyed': 7155, 'w4f': 7156, 'perceiving': 7157, 'chime': 7158, 'mystiq': 7159, 'cyk': 7160, 'assembler': 7161, 'mrdsm': 7162, 'guardian': 7163, 'multimicroprocessor': 7164, 'timer': 7165, 'alerters': 7166, 'finiteness': 7167, 'lob': 7168, 'karel': 7169, 'talisman': 7170, 'système': 7171, 'gouverné': 7172, 'lois': 7173, 'linguistiques': 7174, 'traitement': 7175, 'langue': 7176, 'naturelle': 7177, 'reconstruct': 7178, 'economies': 7179, 'submarkets': 7180, 'spending': 7181, 'dynamo': 7182, 'moded': 7183, 'indicating': 7184, 'erq': 7185, 'quantifiable': 7186, 'chatty': 7187, 'peoplefinder': 7188, 'interconnecting': 7189, 'staff': 7190, 'renderman': 7191, 'pls': 7192, 'sustained': 7193, 'fax': 7194, 'smartcis': 7195, 'wisa': 7196, 'cartwheels': 7197, 'redescriptions': 7198, 'proda': 7199, 'dynalloy': 7200, 'taco': 7201, 'statisticalscientific': 7202, 'mytag': 7203, 'bnchmark': 7204, 'ulixes': 7205, 'gpx': 7206, 'as400': 7207, 'beds': 7208, 'occasions': 7209, 'probcons': 7210, 'amino': 7211, 'stitch': 7212, 'smps': 7213, 'cgcexplorer': 7214, 'treedt': 7215, 'graphplan': 7216, 'aktive': 7217, 'sdss': 7218, 'skyserver': 7219, 'exercising': 7220, 'stay': 7221, 'handy': 7222, 'trac': 7223, 'gadts': 7224, 'unilateral': 7225, 'selforganizing': 7226, 'reuters': 7227, 'poison': 7228, 'pills': 7229, 't2': 7230, 'miqis': 7231, 'chained': 7232, 'virtualized': 7233, 'veritable': 7234, 'imperfective': 7235, 'seismic': 7236, 'treisman': 7237, 'consortia': 7238, 'hypothesized': 7239, 'accommodation': 7240, 'retraction': 7241, 'problog': 7242, 'asserting': 7243, 'deterrent': 7244, 'spoofing': 7245, 'odbms': 7246, 'gridunit': 7247, 'deoptimization': 7248, 'umrao': 7249, 'endgame': 7250, 'adms±': 7251, 'mainframe': 7252, 'gorder': 7253, '17th': 7254, 'bitmapped': 7255, 'prottle': 7256, 'hacking': 7257, 'ferry': 7258, 'optics': 7259, 'infeasible': 7260, 'stanislavskian': 7261, 'dualminer': 7262, 'markerless': 7263, 'radiotherapy': 7264, 'cybercivics': 7265, 'gunsat': 7266, 'aktionsarten': 7267, 'gsat': 7268, 'plenty': 7269, 'margie': 7270, 'resolved': 7271, 'failed': 7272, 'urgent': 7273, 'hardwaresoftware': 7274, 'subseries': 7275, 'mlps': 7276, 'topp': 7277, 'protyotype': 7278, '22': 7279, 'l': 7280, 'comfort': 7281, 'korea': 7282, 'coa': 7283, 'junitmx': 7284, 'softwarehardware': 7285, 'lagrangian': 7286, 'tails': 7287, 'struggles': 7288, 'calculational': 7289, 'syslog': 7290, 'psychotherapy': 7291, 'circumstance': 7292, 'recompression': 7293, 'carousel': 7294, 'morpiiemes': 7295, 'bellman': 7296, 'askalon': 7297, 'rmses': 7298, 'labeler': 7299, 'swedish': 7300, 'qpipe': 7301, 'democracy': 7302, 'ester': 7303, 'snare': 7304, 'presenters': 7305, 'jule': 7306, 'unions': 7307, 'hos': 7308, 'outlying': 7309, 'linky': 7310, 'pocket': 7311, 'traps': 7312, 'opsm': 7313, 'epdl': 7314, 'phonographic': 7315, 'asynchrony': 7316, 'winmagic': 7317, 'compilable': 7318, 'delicious': 7319, 'xquisite': 7320, 'bmir': 7321, 'j2': 7322, 'aviation': 7323, 'plcv': 7324, 'precis': 7325, 'rolex': 7326, 'simplifications': 7327, 'suppletment': 7328, 'marama': 7329, 'programing': 7330, 'ultrasound': 7331, 'discs': 7332, 'carbohydrate': 7333, 'similitude': 7334, 'eggyolk': 7335, 'fm91': 7336, 'ocam': 7337, 'spinning': 7338, 'esql': 7339, 'dbcache': 7340, 'amalgamation': 7341, 'defeats': 7342, 'boosters': 7343, 'splice': 7344, 'whiteboard': 7345, 'ccube': 7346, 'feat': 7347, 'fingerprinted': 7348, 'ogle': 7349, 'recoloring': 7350, 'maintainable': 7351, 'pais': 7352, 'coagulating': 7353, 'rainforest': 7354, 'textbook': 7355, 'privatizing': 7356, 'frills': 7357, 'submissions': 7358, 'toxicology': 7359, 'thine': 7360, 'enemy': 7361, 'ut': 7362, 'arlington': 7363, 'whisper': 7364, 'anchorwoman': 7365, 'verifier': 7366, 'codescriptive': 7367, 'timesten': 7368, 'koref': 7369, 'ramification': 7370, 'dbmt': 7371, 'lidia': 7372, 'slow': 7373, 'illumination': 7374, 'odd': 7375, 'responders': 7376, 'shakespeare': 7377, 'america': 7378, 'utilitarian': 7379, 'devied': 7380, 'explication': 7381, 'tableau': 7382, 'articulatory': 7383, 'armor': 7384, 'los': 7385, 'angeles': 7386, 'airport': 7387, 'cone': 7388, 'quist': 7389, 'cap': 7390, 'sqlb': 7391, 'consumers': 7392, 'attentional': 7393, 'hydra': 7394, 'xorsat': 7395, 'auv': 7396, 'desktops': 7397, 'polygen': 7398, 'scfgs': 7399, 'simsa': 7400, 'mems': 7401, 'gr2': 7402, 'consider': 7403, 'dms®': 7404, 'shopsmart': 7405, 'conneced': 7406, 'multicomputers': 7407, 'multy': 7408, 'lk': 7409, 'ditabbu': 7410, 'schism': 7411, 'datacomputer': 7412, 'pier': 7413, 'luby': 7414, 'rackoff': 7415, 'negotiators': 7416, 'win': 7417, 'arbus': 7418, 'rigi': 7419, 'doulion': 7420, 'triangles': 7421, 'hybrids': 7422, 'costperformance': 7423, 'iphones': 7424, 'oh': 7425, 'probabilistically': 7426, 'survivable': 7427, 'valido': 7428, 'febrl': 7429, 'speechlanguage': 7430, 'spellchecking': 7431, 'autocorrection': 7432, 'inspector': 7433, 'fringe': 7434, 'warning': 7435, 'generalistexperts': 7436, 'orderings': 7437, 'proportionality': 7438, 'radically': 7439, '736': 7440, 'own': 7441, 'ddts': 7442, 'apparatus': 7443, 'hipair': 7444, 'presuppositional': 7445, 'pdms': 7446, 'shard': 7447, 'laura': 7448, 'her': 7449, 'algorithmics': 7450, 'orientstore': 7451, 'svad': 7452, 'annotate': 7453, 'cui': 7454, 'ontoquest': 7455, 'rml': 7456, 'nests': 7457, 'contain': 7458, 'gigahash': 7459, 'spark': 7460, 'coroutining': 7461, 'formedness': 7462, 'beacond': 7463, 'solvability': 7464, 'xseq': 7465, 'coreferential': 7466, 'determinate': 7467, 'literals': 7468, 'informatively': 7469, 'meinongian': 7470, 'pintos': 7471, 'prescription': 7472, 'liabilities': 7473, 'transitivity': 7474, 'foregrounding': 7475, 'noa': 7476, 'normative': 7477, 'congruences': 7478, 'systeme': 7479, 'inferentiel': 7480, 'oriente': 7481, 'objet': 7482, 'langues': 7483, 'naturelles': 7484, 'topologically': 7485, 'plan2d': 7486, 'aesthetics': 7487, 'straw': 7488, 'hypotheticals': 7489, 'holder': 7490, 'tuned': 7491, 'complementarities': 7492, 'tdlambda': 7493, 'eligibility': 7494, 'mutatis': 7495, 'mutandis': 7496, 'topaz': 7497, 'sublinear': 7498, 'cal500': 7499, 'recoverable': 7500, 'sanitization': 7501, 'terminator': 7502, 'unrestrictd': 7503, 'gapping': 7504, 'rely': 7505, 'invoice': 7506, 'cash': 7507, 'bigsur': 7508, 'koda': 7509, 'saam': 7510, 'popel': 7511, 'nimble': 7512, 'counters': 7513, 'triggering': 7514, 'proficiency': 7515, 'florid': 7516, 'metro': 7517, 'tours': 7518, 'webvise': 7519, 'consenting': 7520, 'centred': 7521, 'incompletely': 7522, 'boltzrank': 7523, 'concavo': 7524, 'matesek': 7525, 'sarms': 7526, 'uflip': 7527, 'staggered': 7528, 'statestep': 7529, 'eves': 7530, 'juzi': 7531, 'adjacent': 7532, 'inferred': 7533, 'decompose': 7534, 'vault': 7535, 'ibe': 7536, 'smpsoc': 7537, 'drafting': 7538, 'pods': 7539, 'pylonic': 7540, 'eigenspace': 7541, 'epileptic': 7542, 'seizures': 7543, 'pin': 7544, 'cacheportal': 7545, 'hosted': 7546, 'indegs': 7547, 'cfd': 7548, 'radiation': 7549, 'dsdt': 7550, 'xvm': 7551, 'brier': 7552, 'potentialities': 7553, 'reducers': 7554, 'redus': 7555, 'swifft': 7556, 'fft': 7557, 'unicorn': 7558, 'seasonality': 7559, 'facile': 7560, 'parlog': 7561, 'superoperators': 7562, 'screamer': 7563, 'deserialization': 7564, 'fl': 7565, 'cayuga': 7566, 'dstributed': 7567, 'qagen': 7568, 'ne': 7569, 'constructivism': 7570, 'genealogy': 7571, 'lsdis': 7572, 'vietnamese': 7573, 'isalog': 7574, 'amongst': 7575, 'motions': 7576, 'safecode': 7577, 'mumble': 7578, 'simpledb': 7579, 'syst': 7580, 'unapparent': 7581, 'appearances': 7582, '500': 7583, 'peculiarity': 7584, 'randomizing': 7585, 'extragrammaticality': 7586, 'prepostions': 7587, 'grow': 7588, 'xpathlearner': 7589, 'adonet': 7590, 'terabytes': 7591, 'discourses': 7592, 'multihomogeneous': 7593, 'shoring': 7594, 'diversify': 7595, 'powerdb': 7596, 'quilt': 7597, 'determinants': 7598, 'abstaining': 7599, 'adabas': 7600, 'recrawl': 7601, 'occurences': 7602, 'would': 7603, 'misrepresentation': 7604, 'sgs': 7605, 'mqx': 7606, 'adjustable': 7607, 'll1': 7608, 'diamondhelp': 7609, 'uncontrollable': 7610, 'cockpit': 7611, 'sparcom': 7612, 'grows': 7613, 'senior': 7614, 'morphotactics': 7615, 'misunderstandings': 7616, 'graphicsmentor': 7617, 'opened': 7618, 'netbook': 7619, 'pane': 7620, 'residues': 7621, 'muvis': 7622, 'inspiring': 7623, 'pursue': 7624, 'chatbots': 7625, 'sqlmm': 7626, 'pathologies': 7627, '50000': 7628, 'oracle8': 7629, 'cooperate': 7630, 'sparq2l': 7631, 'floatcascade': 7632, 'socket': 7633, 'penalized': 7634, 'amalgamating': 7635, 'viper': 7636, 'jmocha': 7637, 'bc': 7638, 'painted': 7639, 'renditions': 7640, 'finders': 7641, 'pizza': 7642, 'adams': 7643, 'multilayered': 7644, 'aer': 7645, 'volunteer': 7646, 'contributors': 7647, 'idm': 7648, 'boostcluster': 7649, 'reap': 7650, 'schemapath': 7651, 'acronyms': 7652, 'efficacious': 7653, 'corroborate': 7654, 'drproject': 7655, 'css2': 7656, 'original': 7657, 'uncoils': 7658, 'collaborating': 7659, 'seq': 7660, 'mashing': 7661, 'locksmith': 7662, 'challenged': 7663, 'opsis': 7664, 'entailments': 7665, 'strategyfalse': 7666, 'rationing': 7667, 'nonprofits': 7668, 'shoqd': 7669, 'forcing': 7670, 'cobase': 7671, 'sailer': 7672, 'prophet': 7673, 'flexpref': 7674, 'branding': 7675, 'pinpointing': 7676, 'qursed': 7677, 'restructured': 7678, 'recognising': 7679, 'fingerspelling': 7680, 'alphabets': 7681, 'essentials': 7682, 'rid': 7683, 'anding': 7684, 'bucketing': 7685, 'voxelwise': 7686, 'resonance': 7687, 'codb': 7688, 'canlogs': 7689, 'seasons': 7690, 'farm': 7691, 'traceable': 7692, 'anthropocentric': 7693, 'assesment': 7694, 'looks': 7695, 'gignomda': 7696, 'advancements': 7697, 'ariesnt': 7698, 'treeview': 7699, '20th': 7700, 'jdii': 7701, 'whistle': 7702, 'blower': 7703, 'aggregator': 7704, 'downs': 7705, 'infomod': 7706, 'moderator': 7707, 'trobe': 7708, 'poliqarp': 7709, 'indexer': 7710, 'euclid': 7711, 'ooa': 7712, 'unconstrained': 7713, 'voi': 7714, 'palka': 7715, 'sifting': 7716, 'sttitudes': 7717, 'sda': 7718, 'grays': 7719, 'contributions': 7720, 'cai': 7721, 'borderinterior': 7722, 'blended': 7723, 'csrs': 7724, 'sentimenttopic': 7725, 'excon': 7726, 'advocating': 7727, 'tps': 7728, 'idmesh': 7729, 'webview': 7730, 'parametrized': 7731, 'incrementalized': 7732, 'hyperbolic': 7733, 'adheat': 7734, 'denodo': 7735, 'ecosystem': 7736, 'sustainability': 7737, 'metalabeler': 7738, 'qcluster': 7739, 'relinquishment': 7740, 'repeatability': 7741, 'workability': 7742, 'blockwise': 7743, 'pref': 7744, 'landscan': 7745, 'alerter': 7746, 'documentum': 7747, 'eci': 7748, 'intel': 7749, 'schemexerox': 7750, 'realizations': 7751, 'interact': 7752, 'scm': 7753, 'tutored': 7754, 'scored': 7755, 'precomputation': 7756, 'expanded': 7757, 'marchitecture': 7758, 'baby': 7759, 'whence': 7760, 'charalign': 7761, 'screens': 7762, 'recasting': 7763, 'knack': 7764, '11g': 7765, 'cigar': 7766, 'articulation': 7767, 'adept': 7768, 'cvdb': 7769, 'attracting': 7770, 'brightest': 7771, 'hddbs': 7772, 'centibots': 7773, 'brick': 7774, 'numerals': 7775, 'representable': 7776, 'biterm': 7777, 'withouta': 7778, 'priori': 7779, 'judicious': 7780, 'workstations': 7781, 'wip': 7782, 'intellimedia': 7783, 'workspace': 7784, '2pl': 7785, 'wherefore': 7786, 'r3579x': 7787, 'wsqdsq': 7788, 'incspan': 7789, 'lambertian': 7790, 'deformation': 7791, 'deliver': 7792, 'interfacile': 7793, 'abstractionimplementation': 7794, 'rasp': 7795, 'asam': 7796, 'odx': 7797, 'proactivity': 7798, 'interactiveness': 7799, 'quadtrees': 7800, 'hausdorff': 7801, 'king': 7802, 'iml': 7803, 'inscribed': 7804, 'metabase': 7805, 'matters': 7806, 'vyrd': 7807, 'osiris': 7808, 'ccal': 7809, 'questionnaire': 7810, 'trailfinding': 7811, 'deepsemantic': 7812, 'logistics': 7813, 'impairments': 7814, 'bruns': 7815, 'wings': 7816, 'silhouettes': 7817, 'associational': 7818, 'flowcharts': 7819, 'tcoz': 7820, 'smem': 7821, 'casper': 7822, 'compromising': 7823, 'makespan': 7824, 'ecr': 7825, 'tasktracker': 7826, 'majsat': 7827, 'prosem': 7828, 'mierucompiler': 7829, 'superjoin': 7830, 'ironing': 7831, 'mutators': 7832, 'clotho': 7833, 'awaredav': 7834, 'rollups': 7835, 'divorcing': 7836, 'redistricting': 7837, 'seggen': 7838, 'pundit': 7839, 'gcx': 7840, 'multinomials': 7841, 'defacto': 7842, 'overconstrained': 7843, 'propagator': 7844, 'organisations': 7845, 'sequel': 7846, 'thinker': 7847, 'bead': 7848, 'agency': 7849, 'closegraph': 7850, 'externally': 7851, 'turk': 7852, 'mds': 7853, 'junit': 7854, 'gauss': 7855, 'unbalanced': 7856, 'saying': 7857, 'already': 7858, 'bisimilarity': 7859, 'capitalized': 7860, 'fintime': 7861, 'exits': 7862, 'reopening': 7863, 'song': 7864, 'tapping': 7865, 'geominer': 7866, 'mice': 7867, 'stardom': 7868, 'rewritings': 7869, 'soire': 7870, 'laundering': 7871, 'fabrication': 7872, 'tangible': 7873, 'labyrinth': 7874, 'dnf': 7875, 'secd': 7876, 'shopbots': 7877, 'pricebots': 7878, 'softbound': 7879, 'smarttutor': 7880, 'editable': 7881, 'pocl': 7882, 'actuated': 7883, 'detectioncorrection': 7884, 'vetting': 7885, 'casee': 7886, 'allowed': 7887, 'continued': 7888, 'syntactical': 7889, 'treatments': 7890, 'salesperson': 7891, 'webdiplomat': 7892, 'supertags': 7893, 'michi': 7894, 'annai': 7895, 'bun': 7896, 'flashlogging': 7897, 'remys': 7898, 'multilist': 7899, 'affiliation': 7900, 'paradoxes': 7901, 'ford': 7902, 'xpathxslt': 7903, 'poogle': 7904, 'lrt': 7905, 'ip': 7906, 'slash': 7907, 'jibiki': 7908, 'lexalp': 7909, 'spade': 7910, 'ergonomics': 7911, 'donet': 7912, 'domotic': 7913, 'siebel': 7914, 'mechanizing': 7915, 'sage': 7916, 'sqout': 7917, 'gammatella': 7918, 'ma': 7919, 'workblench': 7920, 'dbis': 7921, 'paradoxical': 7922, 'tampering': 7923, 'dereference': 7924, 'xproj': 7925, 'paragrab': 7926, 'scrambling': 7927, 'delays': 7928, 'mppm': 7929, 'successfully': 7930, 'directives': 7931, 'consolution': 7932, 'resulting': 7933, 'dueling': 7934, 'constitutive': 7935, 'hausslers': 7936, 'www2004': 7937, 'lowell': 7938, 'goaldebug': 7939, 'thistle': 7940, 'interarbora': 7941, 'camex': 7942, 'cnc': 7943, 'ndb': 7944, 'pcb': 7945, 'drilling': 7946, 'approximated': 7947, 'ungreedy': 7948, 'probalistic': 7949, 'evil': 7950, 'flexibly': 7951, 'mergepurge': 7952, 'mathfind': 7953, 'deaf': 7954, 'coco': 7955, 'viability': 7956, 'learnpads': 7957, 'duties': 7958, 'uqlips': 7959, 'sememe': 7960, 'whither': 7961, '21': 7962, 'dart': 7963, 'medoid': 7964, 'pitman': 7965, 'yor': 7966, 'counter': 7967, 'hpsgs': 7968, 'visualgraph': 7969, 'svg': 7970, 'continous': 7971, 'visiprog': 7972, 'week': 7973, 'wiktionary': 7974, 'inherently': 7975, 'brooks': 7976, 'coopware': 7977, 'masters': 7978, 'entropyminimum': 7979, 'timegraphs': 7980, 'bamboo': 7981, 'coreex': 7982, 'knoesphere': 7983, 'suboptimal': 7984, 'bodhi': 7985, 'habitat': 7986, 'microprogramming': 7987, 'reminding': 7988, 'idiomatic': 7989, 'rel': 7990, 'laterally': 7991, 'spiking': 7992, 'neurons': 7993, 'hfp': 7994, 'unweaving': 7995, 'relying': 7996, 'lof': 7997, 'gnu': 7998, 'mobide': 7999, 'cybertech': 8000, 'programmed': 8001, 'sensible': 8002, 'biosurveillance': 8003, 'chatter': 8004, 'parzen': 8005, 'indexicals': 8006, 'demonstratives': 8007, 'egalitarist': 8008, 'incommensurable': 8009, 'concolic': 8010, 'missed': 8011, 'wh': 8012, 'gamps': 8013, 'amplitude': 8014, 'compaction': 8015, 'attributions': 8016, 'flowcube': 8017, 'constructuing': 8018, 'flowcubes': 8019, 'lap': 8020, '6th': 8021, 'setl': 8022, 'baton': 8023, 'renaissance': 8024, 'threatening': 8025, 'unitran': 8026, 'amdb': 8027, 'interview': 8028, 'hgdm': 8029, 'ac': 8030, 'hprl': 8031, 'apis': 8032, 'fell': 8033, 'swoop': 8034, 'kullback': 8035, 'leibler': 8036, 'siren': 8037, 'multifrontal': 8038, 'hyperrectangle': 8039, 'declustered': 8040, 'deafault': 8041, 'outperforms': 8042, 'knightian': 8043, 'angular': 8044, 'reputable': 8045, 'servents': 8046, 'vinci': 8047, 'subtask': 8048, 'banded': 8049, 'jeroo': 8050, 'majority': 8051, 'weakening': 8052, 'pengi': 8053, 'templating': 8054, 'regime': 8055, 'metaquerier': 8056, 'precisely': 8057, 'dql': 8058, 'fusing': 8059, 'coalescevalid': 8060, 'snitch': 8061, 'paste': 8062, 'tickets': 8063, 'terminals': 8064, 'quickdraw': 8065, 'unleashing': 8066, 'schems': 8067, 'combinatorially': 8068, 'erds': 8069, 'emulab': 8070, 'socs': 8071, 'burs': 8072, 'mps': 8073, 'alphasort': 8074, 'electric': 8075, 'appliance': 8076, 'colorblind': 8077, 'nauda': 8078, 'doubt': 8079, 'coallocation': 8080, 'okapi': 8081, 'multiregister': 8082, 'coached': 8083, 'nonblocking': 8084, 'valuation': 8085, 'sqlem': 8086, 'waves': 8087, 'grin': 8088, 'colored': 8089, 'plackett': 8090, 'luce': 8091, 'multimediaminer': 8092, 'snow': 8093, 'supertagger': 8094, 'emperical': 8095, 'qsf': 8096, 'attacking': 8097, 'entrans': 8098, 'edsc': 8099, 'virtue': 8100, 'exprim': 8101, 'rivage': 8102, 'orthotics': 8103, 'dos': 8104, 'reassignment': 8105, 'fishers': 8106, 'weaknesses': 8107, 'backpropagation': 8108, 'amnesia': 8109, 'incoherency': 8110, 'aggregators': 8111, 'wayfinding': 8112, 'obsolescent': 8113, 'warlock': 8114, 'medlda': 8115, 'dbglobe': 8116, 'archictecture': 8117, 'batmobile': 8118, 'synergy': 8119, 'cpoe': 8120, 'oganizing': 8121, 'eel': 8122, 'integral': 8123, 'portions': 8124, 'valgrind': 8125, 'heavyweight': 8126, 'mpmc': 8127, 'syntemic': 8128, 'filler': 8129, 'fg': 8130, 'minute': 8131, '1110': 8132, 'socp': 8133, 'interpreternative': 8134, 'sensitivities': 8135, 'thermodynamics': 8136, 'lobs': 8137, 'residential': 8138, 'hormonal': 8139, 'cubetrees': 8140, 'atypical': 8141, 'crawls': 8142, 'cto': 8143, 'xl': 8144, 'expose': 8145, 'cs2cs7': 8146, 'odpop': 8147, 'opendistributed': 8148, 'semtag': 8149, 'promising': 8150, 'filming': 8151, 'probahilistic': 8152, 'bare': 8153, 'geekos': 8154, 'lecturers': 8155, 'wring': 8156, 'dry': 8157, 'sellers': 8158, 'shill': 8159, 'fees': 8160, 'contextualizing': 8161, 'harmony': 8162, '200': 8163, 'representational': 8164, 'cmerun': 8165, 'reproductive': 8166, 'tapestry': 8167, 'maneuvering': 8168, 'sax': 8169, 'aaqua': 8170, 'vc': 8171, 'altering': 8172, 'pvm': 8173, 'exceptional': 8174, 'attraction': 8175, 'repulsion': 8176, 'sem': 8177, 'archaeological': 8178, 'preaggregation': 8179, 'clusteredness': 8180, 'mrssa': 8181, 'selc': 8182, 'facebook': 8183, 'mgen': 8184, 'playback': 8185, 'else': 8186, 'pooled': 8187, 'condensed': 8188, 'xtage': 8189, 'dtps': 8190, 'tcsps': 8191, 'overkill': 8192, 'truecasing': 8193, '78': 8194, 'preceding': 8195, 'ethernet': 8196, 'multigraphs': 8197, 'compass': 8198, 'omes': 8199, 'webkhoj': 8200, 'lsl': 8201, 'selector': 8202, 'concession': 8203, 'homefinder': 8204, 'estate': 8205, 'achieves': 8206, 'burned': 8207, 'cmd': 8208, 'bridged': 8209, 'componentware': 8210, 'requirementsassurances': 8211, 'ski': 8212, 'netnews': 8213, 'macroscopic': 8214, 'mbdp': 8215, 'subsetting': 8216, 'superposition': 8217, 'discotect': 8218, 'beholder': 8219, 'woodss': 8220, 'ifind': 8221, 'similary': 8222, 'traveled': 8223, 'baccalaureate': 8224, 'sustain': 8225, 'cobra': 8226, 'qox': 8227, 'engagements': 8228, 'productive': 8229, 'styling': 8230, 'indeterminancy': 8231, 'memeta': 8232, 'ss': 8233, 'indirection': 8234, 'translingual': 8235, 'sos': 8236, 'evolve': 8237, 'irregularity': 8238, 'cohabit': 8239, 'skoll': 8240, 'imagistic': 8241, 'gestural': 8242, 'scaffolded': 8243, 'microwulf': 8244, 'beowulf': 8245, 'gea': 8246, 'semanics': 8247, 'nile': 8248, 'pdt': 8249, 'inseparability': 8250, 'rbe': 8251, 'figurative': 8252, 'omniscient': 8253, 'resoning': 8254, 'productions': 8255, 'gmin': 8256, 'quiescing': 8257, 'predicative': 8258, 'demands': 8259, 'relatable': 8260, 'lhip': 8261, 'dcgs': 8262, 'bunsetsu': 8263, 'alfresco': 8264, 'enable': 8265, 'petroglyphs': 8266, 'listener': 8267, 'disciple': 8268, 'reader': 8269, 'ambiguation': 8270, 'recommended': 8271, 'cn': 8272, 'cpcn': 8273, 'exterminator': 8274, 'calo': 8275, 'dsac': 8276, 'independently': 8277, 'safeguard': 8278, 'simlist': 8279, 'glosses': 8280, 'semql': 8281, 'lexikon': 8282, 'indic': 8283, 'wi': 8284, 'imaged': 8285, 'biotech': 8286, 'dragpushing': 8287, 'youth': 8288, 'volumetric': 8289, 'tabulation': 8290, 'reduces': 8291, 'hypercubes': 8292, 'teli': 8293, 'instantiations': 8294, 'kcat': 8295, 'darshak': 8296, 'optic': 8297, 'uload': 8298, 'thesis': 8299, 'unity': 8300, 'twenty': 8301, 'degrading': 8302, 'ios': 8303, 'sofware': 8304, 'cl': 8305, 'researchs': 8306, 'uptrieval': 8307, 'auxiliaries': 8308, 'genitive': 8309, 'cs262': 8310, 'informatic': 8311, 's5': 8312, 'microfeature': 8313, 'rices': 8314, 'quicklink': 8315, 'bns': 8316, 'dmdcon': 8317, 'religious': 8318, 'wars': 8319, 'landmark': 8320, 'vanity': 8321, 'querylog': 8322, 'bundles': 8323, 'delexical': 8324, 'streamlining': 8325, 'captchas': 8326, 'transference': 8327, 'lcf': 8328, 'usenet': 8329, 'irobot': 8330, 'gral': 8331, 'techies': 8332, 'multimediahypermedia': 8333, 'fnc': 8334, 'c2c': 8335, 'cool': 8336, 'peterlee': 8337, 'rwth': 8338, 'aachen': 8339, 'machiavelli': 8340, 'pause': 8341, 'demarcator': 8342, 'border': 8343, 'redistribution': 8344, 'broaden': 8345, 'transferral': 8346, 'wirelessmobile': 8347, 'buffers': 8348, 'rensselaer': 8349, 'dpll': 8350, 'pepx': 8351, 'burden': 8352, 'superhighway': 8353, 'collinearity': 8354, 'unstoppable': 8355, 'stealthy': 8356, 'nonnumeric': 8357, 'correctly': 8358, 'picnics': 8359, 'kittens': 8360, 'wigs': 8361, 'dml': 8362, 'goat': 8363, 'tile': 8364, 'tdms': 8365, 'philosophies': 8366, 'sqlmx': 8367, 'annotators': 8368, 'rationales': 8369, 'jerpa': 8370, 'cloze': 8371, 'temperature': 8372, '3w': 8373, 'sddm': 8374, 'anonymisation': 8375, '73': 8376, 'cypress': 8377, 'archival': 8378, 'taker': 8379, 'verbalizes': 8380, 'practicum': 8381, 'perusing': 8382, 'videodisk': 8383, 'sematically': 8384, 'bell': 8385, 'scrabble': 8386, 'wmxml': 8387, 'secureblox': 8388, 'blooms': 8389, 'assessable': 8390, 'shoulders': 8391, 'giants': 8392, 'ansisparc': 8393, 'collaborate': 8394, 'adapter': 8395, 'sic': 8396, 'transit': 8397, 'gloria': 8398, 'telae': 8399, 'sigmoids': 8400, 'deductions': 8401, 'iloc': 8402, 'meteorologists': 8403, 'mtr': 8404, 'tiled': 8405, 'minimising': 8406, 'firewalling': 8407, 'automobile': 8408, 'completions': 8409, 'sealing': 8410, 'eve': 8411, 'radixzip': 8412, 'delaunay': 8413, 'menus': 8414, 'farmer': 8415, 'rankcut': 8416, 'rewriter': 8417, 'neuroimagery': 8418, 'pop': 8419, 'cracked': 8420, 'tetrahedral': 8421, 'meshes': 8422, 'latex': 8423, 'amelioration': 8424, 'arieskvl': 8425, 'multiaction': 8426, 'webviews': 8427, 'ocfs': 8428, 'glr': 8429, 'adjacency': 8430, 'fastslam': 8431, 'supplement': 8432, 'lixquery': 8433, 'immortal': 8434, 'autotag': 8435, 'symptom': 8436, 'interlisp': 8437, 'controversy': 8438, 'triplify': 8439, 'ep': 8440, 'paving': 8441, 'diligent': 8442, 'noteblogging': 8443, 'dial': 8444, 'prearranged': 8445, 'eight': 8446, 'scc': 8447, 'dcc': 8448, 'imagining': 8449, 'postediting': 8450, 'cox': 8451, 'finer': 8452, 'implicature': 8453, 'rbf': 8454, 'dolores': 8455, 'genesys': 8456, 'weesa': 8457, 'alphabetical': 8458, 'xinuwu': 8459, 'xinu': 8460, 'packets': 8461, 'weave': 8462, 'runtimes': 8463, 'modifications': 8464, 'ontologizing': 8465, 'continents': 8466, 'hangups': 8467, 'diacritics': 8468, 'enabledness': 8469, 'webangels': 8470, 'violent': 8471, 'returned': 8472, 'homeviews': 8473, 'semint': 8474, 'rao': 8475, 'blackwellised': 8476, 'writable': 8477, 'analyzed': 8478, 'farsi': 8479, 'notifications': 8480, 'historically': 8481, 'radioactive': 8482, 'objectbase': 8483, 'ucair': 8484, 'toolbar': 8485, 'remora': 8486, 'metaphoric': 8487, 'raisins': 8488, 'sultanas': 8489, 'currants': 8490, 'preventive': 8491, 'demeterjava': 8492, 'cyberporn': 8493, 'grammaticality': 8494, 'hipac': 8495, 'chicago': 8496, 'lognormal': 8497, 'erasure': 8498, 'nusmv': 8499, 'multicores': 8500, 'toshibas': 8501, 'slm': 8502, 'arboreal': 8503, 'prow': 8504, 'sequentiality': 8505, 'shipping': 8506, 'serving': 8507, 'manuscripts': 8508, 'questionanswering': 8509, 'gk': 8510, 'adversaries': 8511, '700': 8512, 'generates': 8513, 'follower': 8514, 'loquacious': 8515, 'offset': 8516, 'dtwiki': 8517, 'intermittency': 8518, 'severely': 8519, 'toys': 8520, 'performatives': 8521, 'rationally': 8522, 'rdbmss': 8523, 'expect': 8524, 'colt': 8525, 'portuguese': 8526, 'invalidity': 8527, 'compounding': 8528, 'allocating': 8529, 'eliminate': 8530, 'trnon': 8531, 'ansductive': 8532, 'trustguard': 8533, 'countering': 8534, 'airweb': 8535, 'decorrelation': 8536, 'reasoner': 8537, 'itself': 8538, 'enthusiasm': 8539, 'cook': 8540, 'pet': 8541, 'coko': 8542, 'allocator': 8543, 'agatha': 8544, 'christie': 8545, 'leads': 8546, 'ariescsa': 8547, 'tribes': 8548, 'knit': 8549, 'montagues': 8550, 'ape': 8551, 'hunters': 8552, 'logicbase': 8553, 'nnow': 8554, 'nurbs': 8555, 'minijava': 8556, 'grapevine': 8557, 'cord': 8558, 'appraoch': 8559, 'lane': 8560, 'platypus': 8561, 'rol': 8562, 'intractible': 8563, 'strongest': 8564, 'disorder': 8565, 'officially': 8566, 'unrecognized': 8567, 'drugs': 8568, 'xsd': 8569, 'tridirectional': 8570, 'indistinct': 8571, 'monothetic': 8572, 'practive': 8573, 'referencial': 8574, 'reactions': 8575, 'frozen': 8576, 'pens': 8577, 'breakpoint': 8578, 'deck': 8579, 'vlkdbs': 8580, 'gembase': 8581, 'sextant': 8582, 'unexplored': 8583, 'seof': 8584, 'intermodule': 8585, 'supervaluation': 8586, 'inland': 8587, 'monic': 8588, 'multicluster': 8589, 'm2ical': 8590, 'hc': 8591, 'gammon': 8592, 'turns': 8593, 'comex': 8594, 'commodities': 8595, 'suspects': 8596, 'diameters': 8597, 'academically': 8598, 'vrifa': 8599, 'nomogram': 8600, 'radial': 8601, 'lrbf': 8602, 'sitemaps': 8603, 'above': 8604, 'duty': 8605, 'lhrs': 8606, 'overtly': 8607, 'uddi': 8608, 'registries': 8609, 'regrets': 8610, 'mood': 8611, 'organisational': 8612, 'til': 8613, 'sofis': 8614, 'mauritius': 8615, 'replace': 8616, 'wsj': 8617, 'mainteinability': 8618, 'lrtdp': 8619, 'clarifying': 8620, 'filename': 8621, 'nul': 8622, 'characterize': 8623, 'normatives': 8624, 'clearability': 8625, 'mon': 8626, 'maxsat': 8627, 'sring': 8628, 'dht': 8629, 'invocation': 8630, 'coercive': 8631, 'descriptiveness': 8632, 'tanner': 8633, 'wong': 8634, 'interclass': 8635, 'ska': 8636, 'ce2': 8637, 'commandtalk': 8638, 'heaps': 8639, 'harry': 8640, 'met': 8641, 'harri': 8642, 'iambic': 8643, 'palindrome': 8644, 'hunter': 8645, 'gatherer': 8646, 'socqet': 8647, 'videoanywhere': 8648, 'yap3': 8649, 'sdl': 8650, 'seurat': 8651, 'earlier': 8652, 'icse99': 8653, 'bifocal': 8654, 'ntu': 8655, 'athens': 8656, 'spain': 8657, 'specialisation': 8658, 'microsurgery': 8659, 'nugget': 8660, 'photometric': 8661, 'inpainting': 8662, 'grade': 8663, 'naturalistic': 8664, 'reinvented': 8665, 'arieslhs': 8666, 'stamps': 8667, 'esa': 8668, 'neurorule': 8669, 'subdocument': 8670, 'lifelog': 8671, 'listen': 8672, 'hippo': 8673, 'bgp': 8674, 'lens': 8675, 'joysticks': 8676, 'mippets': 8677, 'unless': 8678, 'standalone': 8679, 'kahn': 8680, 'synchrony': 8681, 'cantina': 8682, 'suspend': 8683, 'opposite': 8684, 'odeview': 8685, 'updatability': 8686, 'fads': 8687, 'malm': 8688, 'overconfidence': 8689, 'paranoia': 8690, 'pharse': 8691, 'printers': 8692, 'emulating': 8693, 'nullable': 8694, 'progres': 8695, 'scaleable': 8696, 'pessimistic': 8697, 'bt': 8698, 'branched': 8699, 'analogies': 8700, 'trax': 8701, 'supplied': 8702, 'ifo': 8703, 'definites': 8704, 'toy': 8705, 'emperiment': 8706, 'nonmanipulable': 8707, 'authorizations': 8708, 'icelandic': 8709, 'ruralcafe': 8710, 'w': 8711, 'homeland': 8712, 'pan': 8713, 'cb': 8714, 'mft': 8715, 'permu': 8716, 'memsat': 8717, 'caramel': 8718, 'monetdbxquery': 8719, 'curry': 8720, 'howard': 8721, 'contenders': 8722, 'ghm': 8723, 'azure': 8724, 'adsm': 8725, 'grn': 8726, 'effecient': 8727, 'deobfuscation': 8728, 'preconditioned': 8729, 'algres': 8730, 'chimera': 8731, 'onion': 8732, 'kidney': 8733, 'magead': 8734, 'dialects': 8735, 'dwq': 8736, 'demonstrators': 8737, 'dating': 8738, 'transmutation': 8739, 'mccs': 8740, 'didactic': 8741, 'dialectic': 8742, 'eigentrust': 8743, 'skycube': 8744, 'exr': 8745, 'pivotunpivot': 8746, 'lapses': 8747, 'below': 8748, 'polyphonet': 8749, 'resumption': 8750, 'loads': 8751, 'tempoexpress': 8752, 'expressivity': 8753, 'tempo': 8754, 'reject': 8755, 'jasminec': 8756, 'adasum': 8757, 'reproduction': 8758, 'cubesvd': 8759, 'wizards': 8760, 'sqlmp': 8761, 'wikispeedia': 8762, 'starving': 8763, 'memetic': 8764, 'titan': 8765, 'patrol': 8766, 'bandwith': 8767, 'straw03': 8768, 'sld': 8769, 'elint': 8770, 'poligon': 8771, 'awdrat': 8772, 'metapositions': 8773, 'coevolutionary': 8774, 'harm': 8775, 'microscopic': 8776, 'polyrepresentation': 8777, 'flirting': 8778, 'misperception': 8779, 'lama': 8780, 'absolute': 8781, 'pennies': 8782, 'monotonically': 8783, 'inaccurate': 8784, 'restricting': 8785, 'wap5': 8786, 'aquery': 8787, 'pqc': 8788, 'matchsim': 8789, 'pops': 8790, 'minerva': 8791, 'tricluster': 8792, 'timeliness': 8793, 'superdatabases': 8794, 'kadbase': 8795, 'cae': 8796, 'protel': 8797, 'umlanalyzer': 8798, 'satcsp': 8799, 'expander': 8800, 'rationalism': 8801, 'nesc': 8802, 'lesion': 8803, 'deficit': 8804, 'sofias': 8805, 'airborne': 8806, 'trigs': 8807, 'delinearization': 8808, 'multiloop': 8809, 'fas': 8810, 'ebl2': 8811, 'obe': 8812, 'purple': 8813, 'archaeology': 8814, 'snefru': 8815, 'optimism': 8816, 'underapproximation': 8817, 'hyrex': 8818, 'rehist': 8819, 'quiet': 8820, 'multilayer': 8821, 'fire': 8822, 'icot': 8823, 'csql': 8824, 'dynamicity': 8825, 'bilvideo': 8826, 'pitfall': 8827, 'submit': 8828, 'submission': 8829, 'width': 8830, 'contemplate': 8831, 'columnsort': 8832, 'subgroups': 8833, 'golden': 8834, 'controversies': 8835, 'syncro': 8836, 'lilithmodula': 8837, 'illusion': 8838, 'prefizes': 8839, 'suffixes': 8840, 'sovereign': 8841, 'lossy': 8842, 'diagnosting': 8843, 'smartback': 8844, 'recallprecision': 8845, 'quickmig': 8846, 'diagnosers': 8847, 'blowing': 8848, 'controlflow': 8849, 'cads': 8850, 'intelliclean': 8851, 'cleaner': 8852, 'tapes': 8853, 'hold': 8854, 'investing': 8855, 'featherweight': 8856, 'leo': 8857, 'db2s': 8858, 'cadvlsi': 8859, 'tic': 8860, 'toe': 8861, 'tba': 8862, 'assyst': 8863, 'customisation': 8864, 'pointless': 8865, 'idiosyncratic': 8866, 'microscale': 8867, '16': 8868, 'hospitable': 8869, 'inferior': 8870, 'graphd': 8871, 'malleable': 8872, 'progressions': 8873, 'psychoacoustic': 8874, 'scratching': 8875, 'pda': 8876, 'deconverter': 8877, 'tucking': 8878, 'cycs': 8879, 'versioncontrol': 8880, 'fastmap': 8881, 'breadcrumbs': 8882, 'xsb': 8883, 'operability': 8884, 'ucigame': 8885, 'commensurable': 8886, 'insure': 8887, 'granting': 8888, 'arguing': 8889, 'cky': 8890, 'worth': 8891, 'crimson': 8892, 'flexrecs': 8893, 'proteus': 8894, 'contacts': 8895, 'belong': 8896, 'theft': 8897, 'riskit': 8898, 'rankboost': 8899, 'lachesis': 8900, 'extenable': 8901, 'perm': 8902, 'cpr': 8903, 'molecules': 8904, 'clare': 8905, 'briefings': 8906, 'download': 8907, 'liars': 8908, 'protdb': 8909, 'cyclone': 8910, 'rogue': 8911, 'segmental': 8912, 'jitter': 8913, 'weblogic': 8914, 'eccles': 8915, 'achievent': 8916, 'competences': 8917, 'ibms': 8918, 'modify': 8919, 'tid': 8920, 'metaquerying': 8921, 'neighborhoods': 8922, 'unlocking': 8923, 'swat': 8924, 'concavities': 8925, 'awarding': 8926, 'collide': 8927, 'physiological': 8928, 'masking': 8929, 'infant': 8930, 'iam': 8931, 'mariko': 8932, 'talks': 8933, 'siegfried': 8934, 'warriors': 8935, 'phobes': 8936, 'easiest': 8937, 'ridl': 8938, 'bearing': 8939, 'unforgeable': 8940, 'chosen': 8941, 'imputing': 8942, 'spatiotemporalspatiotemporal': 8943, 'reversal': 8944, 'distinctions': 8945, 'infobox': 8946, 'simfusion': 8947, 'pascalr': 8948, 'warfare': 8949, 'sara': 8950, 'foci': 8951, 'intersystem': 8952, 'cogito': 8953, 'ergo': 8954, 'gated': 8955, 'multipipeline': 8956, 'wizard': 8957, '70': 8958, 'triangle': 8959, 'utaclir': 8960, 'practitioner': 8961, 'investigate': 8962, 'dichotomy': 8963, 'toponym': 8964, 'feedex': 8965, 'birch': 8966, 'iepad': 8967, 'collative': 8968, 'fsadvisor': 8969, 'tbsam': 8970, 'lossless': 8971, 'metacost': 8972, 'tides': 8973, 'xmldb': 8974, 'qarla': 8975, 'resurrecting': 8976, 'applet': 8977, 'remember': 8978, 'paintingclass': 8979, 'ive': 8980, 'websources': 8981, 'distrust': 8982, 'jpredictor': 8983, 'ecrins86': 8984, 'compensating': 8985, 'picodmbs': 8986, 'smartcard': 8987, 'sewnet': 8988, 'adapters': 8989, 'ggraphlog': 8990, 'transpose': 8991, 'lambdarank': 8992, 'demystified': 8993, 'florida': 8994, 'vambam': 8995, 'omnidirectional': 8996, 'kc3': 8997, 'xclust': 8998, 'websom': 8999, 'egomotion': 9000, 'binocular': 9001, 'articulated': 9002, 'slca': 9003, 'mincuts': 9004, 'highspec': 9005, 'ozta': 9006, 'sadt': 9007, 'discouse': 9008, 'aptitude': 9009, 'joshua': 9010, 'joshing': 9011, 'conniving': 9012, 'attains': 9013, 'blast': 9014, 'dominonotes': 9015, 'typicality': 9016, 'prefiltering': 9017, 'biologists': 9018, 'gmine': 9019, 'weaves': 9020, 'packet': 9021, 'dreams': 9022, 'syllabus': 9023, 'tpm': 9024, 'informality': 9025, 'boredom': 9026, 'consolidating': 9027, 'connectionism': 9028, 'zstream': 9029, 'testtube': 9030, 'repaired': 9031, 'satellites': 9032, 'knownet': 9033, 'champagne': 9034, 'ising': 9035, 'tulips': 9036, 'roommate': 9037, 'spouse': 9038, 'cabma': 9039, 'concomitant': 9040, 'medethex': 9041, 'freezing': 9042, 'inferable': 9043, 'dyc': 9044, 'polus': 9045, 'frem': 9046, 'jedd': 9047, 'javanet': 9048, 'opinionminer': 9049, 'luckiness': 9050, 'superword': 9051, 'prefectching': 9052, 'sorec': 9053, 'aroma': 9054, 'hepatitis': 9055, 'injuries': 9056, 'realizer': 9057, 'lagged': 9058, 'identifiable': 9059, 'gaussianity': 9060, 'amateurs': 9061, 'premodifiers': 9062, 'cmvf': 9063, 'laughing': 9064, 'incompatibility': 9065, 'revel8or': 9066, 'transtrl': 9067, 'locator': 9068, 'mauvedb': 9069, 'rethink': 9070, 'cerebral': 9071, 'democratic': 9072, 'lexicographic': 9073, 'workforce': 9074, 'hydro': 9075, 'sit': 9076, 'scorecard': 9077, 'pharos': 9078, 'cla': 9079, 'gambit': 9080, 'remindin': 9081, 'overviews': 9082, 'gtt': 9083, 'patterned': 9084, 'webformulate': 9085, 'adaptability': 9086, 'russell': 9087, 'pascals': 9088, 'emulation': 9089, 'macrobehavior': 9090, 'guanxi': 9091, 'quarks': 9092, 'goldilocks': 9093, 'sigmods': 9094, 'shangri': 9095, 'reve': 9096, 'admixing': 9097, 'allele': 9098, 'mutations': 9099, 'yale': 9100, 'hierachy': 9101, 'crocopat': 9102, 'rib': 9103, 'chest': 9104, 'radiographs': 9105, 'researcher': 9106, 'vipas': 9107, 'galileo': 9108, 'dynamat': 9109, 'monolingually': 9110, 'qpatr': 9111, 'squint': 9112, 'barely': 9113, 'extents': 9114, 'exposed': 9115, 'predicts': 9116, 'explains': 9117, 'attibute': 9118, 'matchings': 9119, 'nemofinder': 9120, 'meso': 9121, 'graphdb': 9122, 'windowless': 9123, 'contaminated': 9124, 'blas': 9125, 'sqlx': 9126, 'theoretically': 9127, 'committed': 9128, 'mammography': 9129, 'isolate': 9130, 'eta': 9131, 'slovene': 9132, 'ossd': 9133, 'ldiff': 9134, 'accelerometer': 9135, 'posix': 9136, 'solved': 9137, 'fascicles': 9138, 'foremost': 9139, 'smdp': 9140, 'residency': 9141, 'umls': 9142, 'metathesaurus': 9143, 'sytems': 9144, 'follows': 9145, 'indeterminism': 9146, 'userlibrarian': 9147, 'nesta': 9148, 'telemetry': 9149, 'biosystematics': 9150, 'ofs': 9151, 'arms': 9152, 'dde': 9153, 'neurolinguistics': 9154, 'powerset': 9155, 'ace': 9156, 'eo': 9157, 'classclass': 9158, 'componential': 9159, 'tension': 9160, 'lexequal': 9161, 'multilexical': 9162, 'reals': 9163, 'merrier': 9164, 'cham': 9165, 'demaq': 9166, 'orion': 9167, 'columnar': 9168, 'postscript': 9169, 'videoreach': 9170, 'assembling': 9171, 'dckr': 9172, 'glacier': 9173, 'ones': 9174, 'paraconsistency': 9175, 'perhaps': 9176, 'cupid': 9177, 'noc': 9178, 'consumption': 9179, 'topicality': 9180, 'chronologies': 9181, 'coffee': 9182, 'nonintrusive': 9183, 'fictitious': 9184, 'ficsr': 9185, 'eedback': 9186, 'nonistency': 9187, 'esolution': 9188, 'misaligned': 9189, 'carpet': 9190, 'entirely': 9191, 'gridvine': 9192, 'instuctions': 9193, 'ofcourse': 9194, 'fido': 9195, 'fetch': 9196, 'soat': 9197, 'peanut': 9198, 'gallery': 9199, 'assessor': 9200, 'impacting': 9201, 'sex': 9202, 'topiccomment': 9203, 'lyapunov': 9204, 'mfom': 9205, 'clonetracker': 9206, 'cliqueness': 9207, 'treebanking': 9208, 'blazing': 9209, 'lies': 9210, 'synonymy': 9211, 'cheshire3': 9212, 'meronyms': 9213, 'contextserv': 9214, 'extendeing': 9215, 'passed': 9216, 'restructure': 9217, 'linkages': 9218, 'constancy': 9219, 'lida': 9220, 'indiana': 9221, 'purdue': 9222, 'compacted': 9223, 'convoy': 9224, 'kfoil': 9225, 'walkthrough': 9226, 'cutex': 9227, 'lemonade': 9228, 'bright': 9229, 'atributes': 9230, 'eventtrigger': 9231, 'typability': 9232, 'nthu': 9233, 'itri': 9234, 'unibase': 9235, 'industryacademic': 9236, 'xmem': 9237, 'hyperstorm': 9238, 'administering': 9239, 'asdl': 9240, 'convolutional': 9241, 'linkclus': 9242, 'identically': 9243, 'progxe': 9244, 'cliff': 9245, 'telcordias': 9246, 'hyperlibrary': 9247, 'unanchored': 9248, 'grasp': 9249, 'streamminer': 9250, 'ignorant': 9251, 'xqbe': 9252, 'evalution': 9253, 'paleontology': 9254, 'sees': 9255, 'correlational': 9256, 'tcc': 9257, 'agraph': 9258, 'itinerary': 9259, 'liberty': 9260, 'beg': 9261, 'cardio': 9262, 'vascular': 9263, 'lenient': 9264, 'app': 9265, 'olympic': 9266, 'equestrian': 9267, 'ibundler': 9268, 'experiential': 9269, 'cfl': 9270, 'collabsum': 9271, 'summarizations': 9272, 'documented': 9273, 'argo': 9274, 'dialogued': 9275, 'converter': 9276, 'semirings': 9277, 'serious': 9278, 'tea': 9279, 'piece': 9280, 'addressed': 9281, 'iwpse': 9282, 'soon': 9283, 'abbreviated': 9284, 'marie': 9285, 'armadillo': 9286, 'andragogy': 9287, '1000': 9288, 'commute': 9289, 'coincidental': 9290, 'potters': 9291, 'hoares': 9292, 'skippy': 9293, 'ssc2': 9294, 'skeletons': 9295, 'myerson': 9296, 'satterthwaite': 9297, 'markgraf': 9298, 'karl': 9299, 'unweighted': 9300, 'labelers': 9301, 'behaviosites': 9302, 'parasitic': 9303, 'infection': 9304, 'graphminer': 9305, 'gram2l': 9306, 'lithe': 9307, 'pva': 9308, 'relocating': 9309, 'rerankeverything': 9310, 'topk': 9311, 'sqak': 9312, 'mindreader': 9313, 'resilent': 9314, 'ultimate': 9315, 'surfer': 9316, 'derivability': 9317, 'interdocument': 9318, 'joulesort': 9319, 'detectives': 9320, 'inflation': 9321, 'asymptotics': 9322, 'casting': 9323, 'accumulative': 9324, 'siemens': 9325, 'nine': 9326, 'equijoin': 9327, 'rework': 9328, 'carsh': 9329, 'billiards': 9330, 'criminal': 9331, 'discounting': 9332, 'molecule': 9333, 'guesstimate': 9334, 'curing': 9335, '1tn': 9336, 'quantifiying': 9337, 'credal': 9338, 'xsqirrel': 9339, 'linearizable': 9340, 'realtime': 9341, 'snowball': 9342, 'straight': 9343, 'allomorphy': 9344, 'websource': 9345, 'elu': 9346, 'cal': 9347, 'aggie': 9348, 'matic': 9349, 'semiring': 9350, 'cybersecurity': 9351, 'glory': 9352, 'contestants': 9353, 'contests': 9354, 'topcodercom': 9355, 'appc': 9356, 'enrich': 9357, 'syndication': 9358, 'phran': 9359, 'understander': 9360, 'attributio': 9361, 'hypercode': 9362, 'cbrrl': 9363, 'bibfinderstatminer': 9364, 'remembrance': 9365, 'sweep': 9366, 'recoding': 9367, 'rtmonitor': 9368, 'hurt': 9369, 'spotlight': 9370, 'ctm': 9371, 'permuting': 9372, 'trex': 9373, 'conforming': 9374, 'disaggregation': 9375, 'lord': 9376, 'resolver': 9377, 'webcq': 9378, 'psycho': 9379, 'arizona': 9380, 'rondo': 9381, 'atmen': 9382, 'tdts': 9383, 'metalinguistic': 9384, 'mop': 9385, 'guillotine': 9386, 'blackboards': 9387, 'hedged': 9388, 'weightlifting': 9389, 'purpors': 9390, 'igrid': 9391, 'jflow': 9392, 'truncations': 9393, 'thresher': 9394, 'unwrapping': 9395, 'wavefront': 9396, 'lag': 9397, 'manuscript': 9398, 'superimposition': 9399, 'hypercube': 9400, 'aptness': 9401, 'clustergrams': 9402, 'biclusters': 9403, 'udk': 9404, 'xrank': 9405, 'cleanly': 9406, 'messy': 9407, 'sirio': 9408, 'mv3r': 9409, 'ondux': 9410, 'lisfs': 9411, 'nk': 9412, 'landscape': 9413, 'internetworking': 9414, 'trials': 9415, 'asymptotically': 9416, 'procrustes': 9417, 'aha': 9418, 'illuminating': 9419, 'anisotropic': 9420, 'polaris': 9421, 'xor': 9422, 'aktionsart': 9423, 'fighting': 9424, 'mixins': 9425, 'softrank': 9426, 'inclination': 9427, 'asadal': 9428, 'geared': 9429, 'itemrank': 9430, 'pwa': 9431, 'sssalpha': 9432, 'approximability': 9433, 'debit': 9434, 'exhaustivity': 9435, 'symmetrical': 9436, 'vlsd': 9437, 'ksr1': 9438, 'lvcsr': 9439, 'uncovered': 9440, 'implicates': 9441, 'implicants': 9442, 'lexnet': 9443, 'twc': 9444, 'gov': 9445, 'datagov': 9446, 'reprogrammable': 9447, 'purposes': 9448, 'basedatabase': 9449, 'accomodation': 9450, 'phrasier': 9451, 'jokes': 9452, 'differentiated': 9453, 'langages': 9454, 'multiterm': 9455, 'mca': 9456, 'nict': 9457, 'atr': 9458, 'probabilitstic': 9459, 'vivid': 9460, 'clarity': 9461, 'unteachable': 9462, 'falcons': 9463, 'verifiers': 9464, 'ilog': 9465, 'awa': 9466, 'orientedobject': 9467, 'cease': 9468, 'because': 9469, 'ignored': 9470, 'relativised': 9471, 'nba': 9472, 'multigranularity': 9473, 'subordinate': 9474, 'fittest': 9475, 'survives': 9476, 'washington': 9477, 'xcfs': 9478, 'xperanto': 9479, 'accociation': 9480, 'sowes': 9481, 'discrepancies': 9482, 'vispedia': 9483, 'phenotype': 9484, 'deficiencies': 9485, 'definettis': 9486, 'habitual': 9487, 'vps': 9488, 'fluids': 9489, 'borders': 9490, 'compostion': 9491, 'careful': 9492, 'faulting': 9493, 'tracked': 9494, 'turnover': 9495, 'schemr': 9496, '2007': 9497, 'valiant': 9498, 'payoff': 9499, 'xrules': 9500, 'deals': 9501, 'unsuspecting': 9502, 'explain': 9503, 'sleepers': 9504, 'workaholics': 9505, 'discover': 9506, 'formalisation': 9507, 'realizational': 9508, 'sbtdiscovery': 9509, 'asynchronously': 9510, 'leaf': 9511, 'nccr': 9512, 'mics': 9513, 'pangloss': 9514, 'arithmetical': 9515, 'hadoopdb': 9516, 'spacey': 9517, 'drfx': 9518, 'waiting': 9519, 'calendars': 9520, 'layering': 9521, 'ksql': 9522, 'seattle': 9523, 'april': 9524, 'madbot': 9525, 'ihmms': 9526, 'twigstack': 9527, 'cabinet': 9528, 'sprint': 9529, 'eiffel': 9530, 'bubba': 9531, 'conserved': 9532, 'retrase': 9533, 'thetenthstrand': 9534, 'ethicaldebates': 9535, 'uldbs': 9536, 'diva': 9537, 'couplets': 9538, 'liptus': 9539, 'eclectic': 9540, 'storhouse': 9541, 'metanoia': 9542, 'invisible': 9543, 'capital': 9544, 'relates': 9545, 'lurking': 9546, 'clavius': 9547, 'wol': 9548, 'pegasos': 9549, 'otherwise': 9550, 'sophia': 9551, 'sake': 9552, 'heuristiques': 9553, 'recherche': 9554, 'discours': 9555, 'lantecedent': 9556, 'pronom': 9557, 'sinhala': 9558, 'schwa': 9559, 'epenthesis': 9560, 'backuprecovery': 9561, 'hisbase': 9562, 'demystifying': 9563, 'serendipitous': 9564, 'innovators': 9565, 'sts': 9566, 'unparsing': 9567, 'rdfxml': 9568, 'homonymy': 9569, 'graffiti': 9570, 'runways': 9571, 'extremal': 9572, 'permuterm': 9573, 'visualrank': 9574, 'baskets': 9575, 'lexically': 9576, 'nantonac': 9577, 'subregularities': 9578, 'parnas': 9579, 'dea': 9580, 'determinization': 9581, 'deuter': 9582, 'shere': 9583, 'resc': 9584, 'delocalisation': 9585, 'dragonfly': 9586, 'qc': 9587, 'asteroid': 9588, 'proximus': 9589, 'wam': 9590, 'contemporary': 9591, 'journals': 9592, 'commanding': 9593, 'officers': 9594, 'immc': 9595, 'misalignments': 9596, 'defscriber': 9597, 'distinctive': 9598, 'brittleness': 9599, 'blackout': 9600, 'iit': 9601, 'remove': 9602, 'bottlenecks': 9603, 'derbys': 9604, 'bbm': 9605, 'petabyte': 9606, 'rot13': 9607, 'ronl': 9608, 'handlinh': 9609, 'hypertags': 9610, 'immediate': 9611, 'illiterate': 9612, 'solomon': 9613, 'vmldb': 9614, 'heterogenity': 9615, 'metafac': 9616, 'linearizability': 9617, 'lsa': 9618, '00': 9619, 'dip': 9620, 'groupwise': 9621, 'extremum': 9622, 'reasoned': 9623, 'associationrules': 9624, 'regenerating': 9625, 'ct': 9626, 'personnel': 9627, 'hooking': 9628, 'drill': 9629, 'degrade': 9630, 'sie': 9631, 'obi': 9632, 'visdb': 9633, 'pm3': 9634, 'linkbase': 9635, 'viewsystem': 9636, 'exhibit': 9637, 'critter': 9638, 'agricultural': 9639, 'precedences': 9640, 'voikiosk': 9641, 'kiosks': 9642, 'contra': 9643, 'xvcl': 9644, 'cogsketch': 9645, 'diagnostics': 9646, 'attributive': 9647, 'watson': 9648, 'kaos': 9649, 'kmp': 9650, 'manipulators': 9651, 'retrieved': 9652, 'symmetrically': 9653, 'professor': 9654, 'pesto': 9655, 'querybrowser': 9656, 'multilinear': 9657, 'bytes': 9658, 'principals': 9659, 'rigour': 9660, 'multicast': 9661, 'mglair': 9662, 'scaleless': 9663, 'interpolants': 9664, 'confidentiality': 9665, 'voltaire': 9666, 'rmp': 9667, 'dispatched': 9668, 'betatext': 9669, 'semmo': 9670, 'laplace': 9671, 'albep': 9672, 'statics': 9673, 'forced': 9674, 'duce': 9675, 'synchronizable': 9676, 'preach': 9677, 'predefined': 9678, 'morphonology': 9679, 'polarized': 9680, 'kiss': 9681, 'powers': 9682, 'aadds': 9683, 'infeasibility': 9684, 'cmu': 9685, 'rover': 9686, 'schematically': 9687, 'eprum': 9688, 'hyponyms': 9689, 'crowdreranking': 9690, 'mmtk': 9691, 'stackelberg': 9692, 'paraphrasis': 9693, 'synonymous': 9694, 'individualized': 9695, 'visualconceptual': 9696, 'forgiving': 9697, 'cream': 9698, 'valuepetri': 9699, 'multilinguality': 9700, 'practicioners': 9701, 'opera': 9702, 'idlog': 9703, 'formulabuilder': 9704, 'ecu': 9705, 'vindicated': 9706, 'cot': 9707, 'detecton': 9708, 'lsi': 9709, 'adage': 9710, 'uncalibrated': 9711, 'tipster': 9712, 'merlin': 9713, 'tweaks': 9714, 'epoch': 9715, 'klee': 9716, 'emerge': 9717, 'verbosity': 9718, 'corroboration': 9719, '25': 9720, 'rise': 9721, 'salton': 9722, 'tactic': 9723, 'gpsm': 9724, 'ql': 9725, 'multilingualism': 9726, 'dissolution': 9727, 'webhawk': 9728, 'fibring': 9729, 'gputerasort': 9730, 'unpartitioned': 9731, 'holonic': 9732, 'pedestrian': 9733, 'rqafqi': 9734, 'multipe': 9735, 'indeterminate': 9736, 'constructor': 9737, 'carpediem': 9738, 'ssl': 9739, 'coarticulation': 9740, 'mocha': 9741, 'webservers': 9742, 'gordion': 9743, 'wherenext': 9744, 'disambiguator': 9745, 'forl': 9746, 'subwebs': 9747, 'jeroboam': 9748, 'epilepsy': 9749, 'suppression': 9750, 'xpress': 9751, 'queriable': 9752, 'westwood': 9753, 'avenue': 9754, 'termsets': 9755, 'bulgarian': 9756, 'quickxplain': 9757, 'slater': 9758, 'hyperspace': 9759, 'bacteria': 9760, 'scattering': 9761, 'signalling': 9762, 'indicrect': 9763, 'samuel': 9764, 'amarel': 9765, 'cbse': 9766, 'datacycle': 9767, 'evolved': 9768, 'icl': 9769, 'cst': 9770, 'treatmemt': 9771, 'phish': 9772, 'citizens': 9773, 'footprints': 9774, 'booleans': 9775, 'dynamod': 9776, 'invertable': 9777, 'psycholinguistically': 9778, 'osqr': 9779, 'parafac2': 9780, 'mpf': 9781, 'tdl': 9782, 'bantam': 9783, 'calculator': 9784, 'infotraffic': 9785, 'lr0': 9786, 'coocurrences': 9787, 'import': 9788, 'autoencoders': 9789, 'tabling': 9790, 'locative': 9791, 'untapped': 9792, 'quadrupedal': 9793, 'polymer': 9794, 'flumejava': 9795, 'multitheme': 9796, 'lanaguage': 9797, 'markovsemi': 9798, 'destinations': 9799, 'x2': 9800, 'nondirectional': 9801, 'labor': 9802, 'cannot': 9803, 'mathematica': 9804, 'germ': 9805, 'ddos': 9806, 'svmcrf': 9807, 'niagarast': 9808, 'latte': 9809, 'identified': 9810, 'reused': 9811, 'beltway': 9812, 'gridlock': 9813, 'neighbourhood': 9814, 'prelude': 9815, 'broadband': 9816, 'v3': 9817, 'cqlf': 9818, 'keypoints': 9819, 'sister': 9820, 'reclustering': 9821, 'remit': 9822, '3se': 9823, 'cased': 9824, 'vodak': 9825, 'deduce': 9826, 'proclamation': 9827, 'elaborate': 9828, 'anf': 9829, 'parce': 9830, 'quebecause': 9831, 'puisquesince': 9832, 'lexicographical': 9833, 'sammie': 9834, 'dboxes': 9835, 'kleisli': 9836, 'db1': 9837, 'lopix': 9838, 'television': 9839, 'radio': 9840, 'periodicities': 9841, 'bursts': 9842, 'enlightenment': 9843, 'aems': 9844, 'reformulated': 9845, 'appear': 9846, 'determined': 9847, 'elision': 9848, 'berkeley': 9849, 'curio': 9850, 'mashroom': 9851, 'convengent': 9852, 'distributedness': 9853, 'lolitas': 9854, 'coevolution': 9855, 'gaode': 9856, 'haode': 9857, 'proposals': 9858, 'aode': 9859, 'busy': 9860, 'claude': 9861, 'rubinsons': 9862, 'twoprime': 9863, 'fertility': 9864, 'motors': 9865, 'adviser': 9866, 'objectbehavior': 9867, 'console': 9868, 'sourcebook': 9869, 'differentiate': 9870, 'instruments': 9871, 'pivotbrowser': 9872, 'creatures': 9873, 'ceiling': 9874, 'serialization': 9875, 'concentric': 9876, 'hyperspaces': 9877, 'told': 9878, 'labellings': 9879, 'volunteers': 9880, 'hillsborough': 9881, 'county': 9882, 'district': 9883, 'transsformation': 9884, 'dialectal': 9885, 'dolce': 9886, 'unsound': 9887, 'automateddistributed': 9888, 'rrh': 9889, 'rtp': 9890, 'emd': 9891, 'pskip': 9892, 'scribble': 9893, 'alikes': 9894, 'inexpert': 9895, 'chorochronos': 9896, 'udl': 9897, 'folklore': 9898, 'confirmed': 9899, 'widl': 9900, 'inconcert': 9901, 'archive': 9902, 'bionav': 9903, 'literatures': 9904, 'tenant': 9905, 'fca': 9906, 'broom': 9907, 'simplifier': 9908, 'xmg': 9909, 'gotolessness': 9910, 'prtv': 9911, 'cancellation': 9912, 'gravitation': 9913, 'infomix': 9914, 'datawarehousing': 9915, 'colours': 9916, 'white': 9917, 'prague': 9918, 'petabricks': 9919, 'mima': 9920, 'interim': 9921, 'acmieee': 9922, 'dbtool': 9923, 'fds': 9924, 'r2': 9925, 'numerosity': 9926, 'subcubic': 9927, 'despite': 9928, 'reevaluation': 9929, 'directors': 9930, 'confident': 9931, 'demonstrative': 9932, 'datajoiner': 9933, 'ocean': 9934, 'conservant': 9935, 'multitale': 9936, 'sash': 9937, 'sportscast': 9938, 'inserting': 9939, 'deleting': 9940, 'subjuncts': 9941, 'weblab': 9942, 'hyperthesis': 9943, 'crops': 9944, 'soil': 9945, 'situational': 9946, 'desperately': 9947, 'infinitives': 9948, 'storyboarding': 9949, 'exegesis': 9950, 'wake': 9951, 'wlan': 9952, 'pep': 9953, 'thoroughly': 9954, 'descendent': 9955, 'wep': 9956, 'beaxqrl': 9957, 'kap': 9958, '2lip': 9959, 'web3d': 9960, 'greediness': 9961, 'mimus': 9962, 'memm': 9963, 'segregation': 9964, 'edmas': 9965, 'outdoor': 9966, 'sparsification': 9967, 'isometry': 9968, 'pricing': 9969, 'spiteful': 9970, 'froma': 9971, 'earl': 9972, 'recognizable': 9973, 'subclasses': 9974, 'xmill': 9975, 'majorization': 9976, 'ailp': 9977, 'p3vi': 9978, 'mtw06': 9979, 'midst': 9980, 'listening': 9981, 'provisions': 9982, 'operationally': 9983, 'accompany': 9984, 'multibuffer': 9985, 'statsnowball': 9986, 'prying': 9987, 'phenotypes': 9988, 'dumber': 9989, 'schweizer': 9990, 'wolff': 9991, 'hyperwebs': 9992, 'multext': 9993, 'speeddating': 9994, 'summable': 9995, 'systematically': 9996, 'gblender': 9997, 'leveling': 9998, 'plop': 9999, 'continually': 10000, 'diasumm': 10001, 'twin': 10002, 'john': 10003, 'smiths': 10004, 'nico': 10005, 'habermanns': 10006, 'trigram': 10007, 'perlocutionary': 10008, 'tivo': 10009, 'cactis': 10010, 'grouped': 10011, 'saps': 10012, 'nonmonotonicity': 10013, 'batching': 10014, 'odiset': 10015, 'grafon': 10016, 'duth': 10017, 'inexperienced': 10018, 'queens': 10019, 'machined': 10020, 'rrxf': 10021, 'discontinuity': 10022, 'punjabi': 10023, 'infoanalyzer': 10024, 'skimming': 10025, 'coloured': 10026, 'complaints': 10027, 'soquet': 10028, 'coursework': 10029, 'rp': 10030, 'tactex': 10031, 'tactics': 10032, 'liveclassifier': 10033, 'portos': 10034, 'gramcheck': 10035, 'said': 10036, 'snif': 10037, 'parking': 10038, 'lot': 10039, 'cocs': 10040, 'topographic': 10041, 'datametadata': 10042, 'transparency': 10043, 'respecting': 10044, 'pres': 10045, 'seven': 10046, 'upside': 10047, 'globetp': 10048, 'drosophila': 10049, 'capping': 10050, 'judges': 10051, 'exchangeable': 10052, 'navigationaided': 10053, 'praire': 10054, 'aof': 10055, 'databasenetwork': 10056, 'cafe': 10057, 'phoneticsphonology': 10058, 'powerbookmarks': 10059, 'was': 10060, 'gernerated': 10061, 'hisa': 10062, 'committees': 10063, 'strikes': 10064, 'dalí': 10065, 'fa': 10066, 'metamodeling': 10067, 'keying': 10068, 'foreword': 10069, 'noticing': 10070, 'costing': 10071, 'natix': 10072, 'crosslanguage': 10073, 'coroutined': 10074, 'vandalism': 10075, 'analogyspace': 10076, 'allophonic': 10077, 'uqbe': 10078, 'dereferee': 10079, 'mismanagement': 10080, 'deployers': 10081, 'prompt': 10082, 'gardeners': 10083, 'unmodified': 10084, 'cellsort': 10085, 'backoff': 10086, 'administrators': 10087, 'tourism': 10088, 'conical': 10089, 'prose': 10090, 'generalizaiton': 10091, 'decisive': 10092, 'rio': 10093, 'cafeobj': 10094, 'regularised': 10095, 'predicalc': 10096, 'viable': 10097, 'handprinted': 10098, 'practicing': 10099, 'judo': 10100, 'boards': 10101, 'clope': 10102, 'degenerate': 10103, 'pbir': 10104, 'amybe': 10105, 'aslm': 10106, 'subgradient': 10107, 'jisdos': 10108, 'icp': 10109, 'nonrigid': 10110, 'compressibility': 10111, 'authoritative': 10112, 'actors': 10113, 'propagate': 10114, 'expiring': 10115, 'cdpranking': 10116, 'shrex': 10117, 'sre': 10118, 'appliances': 10119, 'dhts': 10120, 'j2me': 10121, 'kassys': 10122, 'heat': 10123, 'ininverted': 10124, 'paralleling': 10125, 'inventing': 10126, 'melodies': 10127, 'percentage': 10128, 'atom': 10129, 'equivalential': 10130, 'dpls': 10131, 'pol': 10132, 'conceptualization': 10133, 'osamkbms': 10134, 'seller': 10135, 'brazilian': 10136, 'dependences': 10137, 'omega': 10138, 'galax': 10139, 'milner': 10140, 'intemon': 10141, 'partitionings': 10142, 'amcr': 10143, 'epos': 10144, 'rug': 10145, '60': 10146, 'byzantine': 10147, 'generals': 10148, 'algorthmic': 10149, 'magma': 10150, 'execute': 10151, 'organizationarchitecture': 10152, 'profitably': 10153, 'elaborating': 10154, 'sed': 10155, 'prf': 10156, 'lends': 10157, 'intersections': 10158, 'mis': 10159, 'dumping': 10160, 'qbi': 10161, 'clickgraph': 10162, 'showdown': 10163, 'retraining': 10164, 'reviewed': 10165, 'unlevel': 10166, 'semaphores': 10167, 'chronology': 10168, 'opossum': 10169, 'newswires': 10170, 'propinquity': 10171, 'envelopes': 10172, 'fluxplayer': 10173, 'vowels': 10174, 'spp': 10175, '1600': 10176, 'precompiler': 10177, 'krypton': 10178, 'affix': 10179, 'frustration': 10180, 'wordmeanings': 10181, 'sleeved': 10182, 'coclustering': 10183, 'blacklists': 10184, 'polyglot': 10185, 'interrelationship': 10186, 'augment': 10187, 'churn': 10188, 'imp': 10189, 'finalization': 10190, 'ifc': 10191, 'misfit': 10192, 'slovenian': 10193, 'diphone': 10194, 'viztree': 10195, 'wakashi': 10196, 'efis': 10197, 'mehtod': 10198, 'formules': 10199, 'paramodulation': 10200, 'controllable': 10201, 'osamt': 10202, 'oqlt': 10203, 'quonto': 10204, 'rocks': 10205, 'reflectance': 10206, 'ballot': 10207, 'sincerity': 10208, 'diophantine': 10209, 'lucid': 10210, 'refreshment': 10211, 'diverging': 10212, 'chi': 10213, 'swan': 10214, 'wasa2': 10215, 'rematerialization': 10216, 'nestream': 10217, 'ranker': 10218, 'jarap': 10219, 'huberized': 10220, 'resourceful': 10221, 'lenses': 10222, 'surviving': 10223, 'sqlse': 10224, 'jfast': 10225, 'tackling': 10226, 'multiparadigm': 10227, 'idefix': 10228, 'browserank': 10229, 'difficulties': 10230, 'provers': 10231, 'eroc': 10232, 'neato': 10233, 'hosts': 10234, 'pela': 10235, 'lbkeogh': 10236, 'usind': 10237, 'initialize': 10238, 'uwat': 10239, 'installations': 10240, 'isomap': 10241, 'xissr': 10242, 'catts': 10243, 'riltering': 10244, 'filestore': 10245, 'stdl': 10246, 'clide': 10247, 'summarise': 10248, 'factorized': 10249, 'defection': 10250, 'dancing': 10251, 'endearing': 10252, 'caede': 10253, 'embdedded': 10254, 'pretenuring': 10255, 'traits': 10256, 'guaranteed': 10257, 'errorperformance': 10258, 'boilerplate': 10259, 'illustrations': 10260, 'rippling': 10261, 'arrows': 10262, 'hub': 10263, 'pak': 10264, 'groves': 10265, 'disproportionate': 10266, 'interventions': 10267, 'narrowing': 10268, 'ginga': 10269, 'paris': 10270, 'sourcing': 10271, 'encapsulated': 10272, 'revisits': 10273, 'seeding': 10274, 'underpinnings': 10275, 'taggerlemmatiser': 10276, 'xcalibur': 10277, 'carpentry': 10278, 'randomly': 10279, 'calibrated': 10280, 'maxq': 10281, 'blankets': 10282, 'atomos': 10283, 'mudular': 10284, 'workstyle': 10285, 'retinal': 10286, 'fgp': 10287, 'kohonen': 10288, 'fallible': 10289, 'scot': 10290, 'confinement': 10291, 'forgettings': 10292, 'kanervas': 10293, 'ppcp': 10294, 'claim': 10295, 'mathematicians': 10296, 'operationality': 10297, 'pymk': 10298, 'myspace': 10299, 'lig': 10300, 'midas': 10301, 'flexsync': 10302, 'twittermonitor': 10303, 'reformulating': 10304, 'sdc': 10305, 'shoestring': 10306, 'primes': 10307, 'drivers': 10308, 'assessors': 10309, 'undecidability': 10310, 'dipra': 10311, 'idef1': 10312, 'llo': 10313, 'chronons': 10314, 'pearsons': 10315, 'agglutinativity': 10316, 'correlativity': 10317, 'obliviousness': 10318, 'interferences': 10319, 'hallucination': 10320, 'drjava': 10321, 'superarchitects': 10322, 'disabled': 10323, 'children': 10324, 'ssat': 10325, 'commercially': 10326, 'demonstrate': 10327, 'prenominal': 10328, 'interlanguage': 10329, 'bet': 10330, 'dock': 10331, 'humancomputer': 10332, 'decdtm': 10333, 'proceesing': 10334, 'llparse': 10335, 'lrparse': 10336, 'pubmed': 10337, 'hopper': 10338, 'visits': 10339, 'collocated': 10340, 'ugv': 10341, 'blurring': 10342, 'flatter': 10343, 'cameo': 10344, 'responsibility': 10345, 'fred': 10346, 'webspace': 10347, 'gnatdb': 10348, 'footprint': 10349, 'csurf': 10350, 'photolithography': 10351, 'multipaging': 10352, 'timedtextrank': 10353, 'subformulas': 10354, 'momis': 10355, 'transactors': 10356, 'worker': 10357, 'awt': 10358, 'tcpte': 10359, 'deeds': 10360, 'representatives': 10361, 'dyda': 10362, 'thetis': 10363, 'allow': 10364, 'dewild': 10365, 'cards': 10366, 'marcus': 10367, 'cxhist': 10368, 'scavenger': 10369, 'vnet': 10370, 'unranked': 10371, 'semrank': 10372, 'destructors': 10373, 'finalizers': 10374, 'imecho': 10375, 'writers': 10376, 'potentiality': 10377, 'transfers': 10378, 'fulltext': 10379, 'retaliate': 10380, 'shooter': 10381, 'consisting': 10382, 'operationalitygenerality': 10383, 'vida': 10384, 'comprehenrank': 10385, 'solid': 10386, 'jive': 10387, 'jove': 10388, 'anonymizers': 10389, 'genesis': 10390, 'seeds': 10391, 'insertions': 10392, 'puma': 10393, '560': 10394, 'val': 10395, 'whirl': 10396, 'psychiatry': 10397, 'ips': 10398, 'araneus': 10399, 'fossilized': 10400, 'linchpin': 10401, 'alterable': 10402, 'weve': 10403, 'requirementsdesign': 10404, 'ucms': 10405, 'vsams': 10406, 'jungloid': 10407, 'navigate': 10408, 'glp': 10409, 'symbiote': 10410, 'streammanagement': 10411, 'rladsms': 10412, 'tesseract': 10413, 'socio': 10414, 'doritos': 10415, 'cylindrical': 10416, 'regenerable': 10417, 'witnesses': 10418, 'actiview': 10419, 'supplementary': 10420, 'transducing': 10421, 'augmentative': 10422, 'hownet': 10423, 'destruction': 10424, 'onine': 10425, 'pseudocode': 10426, 'sigplan': 10427, 'pardes': 10428, 'stabilization': 10429, 'sofie': 10430, 'bistratal': 10431, 'remaining': 10432, 'staircase': 10433, 'subsentential': 10434, 'regularly': 10435, 'citri': 10436, 'disima': 10437, 'oddessy': 10438, 'wrongly': 10439, 'substituted': 10440, 'ecrc': 10441, 'programme': 10442, 'patchwork': 10443, 'profiled': 10444, 'datablitz': 10445, 'warped': 10446, 'maximizationminimization': 10447, 'gulf': 10448, 'xmark': 10449, 'deryaft': 10450, 'aces': 10451, 'wt10g': 10452, 'shalt': 10453, 'covet': 10454, 'thy': 10455, 'cake': 10456, 'wordform': 10457, 'aac': 10458, 'queryable': 10459, 'ccam': 10460, 'unfoldfold': 10461, 'kbse': 10462, 'checkmate': 10463, 'cornering': 10464, 'checked': 10465, 'dscl': 10466, 'mailrank': 10467, 'serpentine': 10468, 'polar': 10469, 'jazzmatch': 10470, 'introducng': 10471, 'tabbed': 10472, '2q': 10473, 'hg': 10474, 'socialtrust': 10475, 'fabric': 10476, 'augeas': 10477, 'authoritativeness': 10478, 'creepy': 10479, 'desired': 10480, 'tweeted': 10481, 'gf': 10482, 'ioc': 10483, 'cornell': 10484, 'jaguar': 10485, 'tremer': 10486, 'sociable': 10487, 'diag': 10488, '1n': 10489, 'prompter': 10490, 'intelligibility': 10491, 'transportability': 10492, 'compoweb': 10493, 'rcx': 10494, 'researchers': 10495, 'tedi': 10496, 'marshaling': 10497, 'proponents': 10498, 'commitlsn': 10499, 'predeclared': 10500, 'writesets': 10501, 'radicals': 10502, 'candide': 10503, 'synchronizer': 10504, 'ppm': 10505, 'bayan': 10506, 'caterogization': 10507, 'baccii': 10508, 'referee': 10509, 'researchindex': 10510, 'itaca': 10511, 'kbs': 10512, 'acme': 10513, 'microblog': 10514, 'diluting': 10515, 'evaluative': 10516, 'knowitall': 10517, 'weekday': 10518, 'lute': 10519, 'texquery': 10520, 'nuits': 10521, 'pthinc': 10522, 'mmdbms': 10523, 'headmodifier': 10524, 'thumbnail': 10525, 'orchestral': 10526, 'accompaniment': 10527, 'lexica': 10528, 'psj': 10529, 'reman': 10530, 'zeves': 10531, 'sunos': 10532, 'inefficiently': 10533, 'saliency': 10534, 'unconcerned': 10535, 'interdependence': 10536, 'microcomputers': 10537, 'mint': 10538, 'retieval': 10539, 'pagesim': 10540, 'aimilarity': 10541, 'bel': 10542, 'permutations': 10543, 'anaphor': 10544, 'governors': 10545, 'mailbox': 10546, 'ubidata': 10547, 'inservice': 10548, 'expertconsultation': 10549, 'preprocessor': 10550, 'butterfly\\x99': 10551, 'diehard': 10552, 'unsafe': 10553, 'dataguides': 10554, 'learnwhat': 10555, 'testo': 10556, 'ag': 10557, 'proteome': 10558, 'analyst': 10559, 'ongoing': 10560, 'nasd': 10561, 'rads': 10562, 'programmingobject': 10563, 'cocktail': 10564, 'naiveexpert': 10565, 'codebooks': 10566, 'truncating': 10567, 'band': 10568, 'qbix': 10569, 'bidirectionalization': 10570, 'periscopesq': 10571, 'gaining': 10572, 'tagommenders': 10573, 'polyadic': 10574, 'inculcating': 10575, 'namur': 10576, 'hifi': 10577, 'fan': 10578, 'unite': 10579, 'mhp': 10580, 'idtv': 10581, 'presentable': 10582, 'satenstein': 10583, 'chaff': 10584, 'generalising': 10585, 'drete': 10586, 'cupld': 10587, 'opss': 10588, 'equijoins': 10589, 'ois': 10590, 'iv': 10591, 'tscan': 10592, 'emt': 10593, 'imperfectly': 10594, 'phobic': 10595, 'half': 10596, 'mystery': 10597, 'nexusscout': 10598, 'hack': 10599, 'margins': 10600, 'isotc97sc5wg3': 10601, 'incoherent': 10602, 'degress': 10603, 'conservatively': 10604, 'radical': 10605, 'pixels': 10606, 'schedulable': 10607, 'daml': 10608, 'received': 10609, 'amazoncom': 10610, 'gpgpu': 10611, 'metabolomic': 10612, 'healthy': 10613, 'subtransitive': 10614, 'mearf': 10615, 'stencils': 10616, 'greek': 10617, 'pigeons': 10618, 'abducing': 10619, 'shoiq': 10620, 'clocks': 10621, '1971': 10622, 'symposium': 10623, 'hypersum': 10624, 'tablerank': 10625, 'octopus': 10626, 'planck': 10627, 'piment': 10628, 'iconism': 10629, 'preknowledge': 10630, 'borrowing': 10631, 'requesting': 10632, 'suspect': 10633, 'octagons': 10634, 'scheduled': 10635, 'revi': 10636, 'warranty': 10637, 'goodwill': 10638, 'rdfpeers': 10639, 'pagesense': 10640, 'ebizsearch': 10641, 'fluxcapacitor': 10642, 'ur': 10643, 'metaprogramming': 10644, 'snakes': 10645, 'sandwiches': 10646, 'laptop': 10647, 'residue': 10648, 'molap': 10649, 'impromptu': 10650, 'chatbot': 10651, 'fruit': 10652, 'embryo': 10653, 'webcrow': 10654, 'crossword': 10655, 'paralocks': 10656, 'united': 10657, 'republic': 10658, 'neuroscience': 10659, 'semiparametric': 10660, 'precursor': 10661, 'traveler': 10662, 'slang': 10663, 'multiversioned': 10664, 'mcqs': 10665, 'moflon': 10666, 'loc': 10667, 'grew': 10668, 'pape': 10669, 'rna': 10670, 'sweeping': 10671, 'logres': 10672, 'congestion': 10673, 'existentially': 10674, 'shine': 10675, 'zip': 10676, 'searched': 10677, 'revealed': 10678, 'id3': 10679, 'uw': 10680, 'favorable': 10681, 'proton': 10682, 'poka': 10683, 'trans': 10684, 'recovered': 10685, 'deforestation': 10686, 'rounding': 10687, 'geoplot': 10688, 'topicrank': 10689, 'bluetooth': 10690, 'svmc': 10691, 'warm': 10692, 'oodesigner': 10693, 'lce': 10694, 'moses': 10695, 'arisenisr': 10696, 'sharc': 10697, 'dvss': 10698, 'ionterfaces': 10699, 'apex': 10700, 'oregon': 10701, 'xseek': 10702, 'vlsicad': 10703, 'conjoint': 10704, 'today': 10705, 'trivia': 10706, 'beings': 10707, 'sounding': 10708, 'condensing': 10709, 'unpacking': 10710, 'verbalism': 10711, 'humanoids': 10712, 'ubc': 10713, 'bioscience': 10714, 'approaching': 10715, 'dgx': 10716, 'hancock': 10717, 'reply': 10718, 'aloud': 10719, 'prive': 10720, 'permit': 10721, 'objecttask': 10722, 'imds': 10723, 'cambodia': 10724, 'ghana': 10725, 'datascope': 10726, 'spices': 10727, 'murax': 10728, 'gum': 10729, 'aiding': 10730, 'hacker': 10731, 'yacc': 10732, 'purexml': 10733, 'hyperplanes': 10734, 'undertow': 10735, 'ebay': 10736, 'lego®': 10737, 'mindstorms®': 10738, 'docqs': 10739, 'librarian': 10740, 'aqax': 10741, 'eradicate': 10742, 'junk': 10743, 'cops': 10744, 'gila': 10745, 'aggregaterank': 10746, 'men': 10747, 'mathcomputer': 10748, 'patches': 10749, 'finnish': 10750, 'sometime': 10751, 'c2': 10752, 'matchbox': 10753, 'danish': 10754, 'multisensory': 10755, 'sewep': 10756, 'gendered': 10757, 'cmic': 10758, 'agreed': 10759, 'bellwether': 10760, 'abc': 10761, 'chirp': 10762, 'crickets': 10763, 'irv': 10764, 'crf': 10765, 'opt': 10766, 'algorithims': 10767, 'hypertabular': 10768, 'smoqe': 10769, 'pairing': 10770, 'sophisticated': 10771, 'fist': 10772, 'korat': 10773, 'parsody': 10774, 'superviews': 10775, 'zips': 10776, 'nonstationarity': 10777, 'userinterest': 10778, 'snugglebug': 10779, 'simulate': 10780, 'literace': 10781, 'tangram': 10782, 'recom': 10783, 'ueman': 10784, 'raids': 10785, 'contamination': 10786, 'vgm': 10787, 'khufu': 10788, 'adverbial': 10789, 'javaxxxl': 10790, 'semdiff': 10791, 'att': 10792, 'treelet': 10793, 'netweaver': 10794, 'unscrambling': 10795, 'uims': 10796, 'monoids': 10797, 'medsearch': 10798, 'immutability': 10799, 'drama': 10800, 'streamon': 10801, 'clustra': 10802, 'moon': 10803, 'commemorate': 10804, 'afrikaans': 10805, 'hodfa': 10806, 'homogenizing': 10807, 'nepotistic': 10808, 'kdms': 10809, 'krisys': 10810, 'secubat': 10811, 'csv': 10812, 'asumption': 10813, 'webml': 10814, 'vip': 10815, 'vml': 10816, 'piql': 10817, 'insightful': 10818, 'groupme': 10819, 'congressional': 10820, 'dba': 10821, 'magnet': 10822, 'orleans': 10823, 'untangling': 10824, 'director': 10825, 'bitext': 10826, 'inverses': 10827, 'multicriteria': 10828, 'blosom': 10829, 'orientations': 10830, 'bordaconsensus': 10831, 'calin': 10832, 'thm': 10833, 'nlu': 10834, 'datadepot': 10835, 'munin': 10836, 'nooksack': 10837, 'falls': 10838, 'hydroelectric': 10839, 'multisensor': 10840, 'xanadue': 10841, 'textbases': 10842, 'arity': 10843, 'iliad': 10844, 'oklahoma': 10845, 'fetching': 10846, 'shadowing': 10847, 'zoomrdf': 10848, 'fisheye': 10849, 'budgeted': 10850, 'metonymic': 10851, 'ware': 10852, 'hiti': 10853, 'topographical': 10854, 'roadmaps': 10855, 'planlog': 10856, 'vibe': 10857, 'geotagged': 10858, 'acknowledgement': 10859, 'exochi': 10860, 'inexpressivity': 10861, 'evidences': 10862, 'roving': 10863, 'buzzrank': 10864, 'kojak': 10865, 'meteor': 10866, 'monad': 10867, 'transformers': 10868, 'compositemap': 10869, 'biomolecular': 10870, 'myportal': 10871, 'sea': 10872, 'semidirectional': 10873, 'deputy': 10874, 'vimsys': 10875, 'aptly': 10876, 'summarizatiion': 10877, 'parsability': 10878, 'tomita': 10879, 'morphj': 10880, 'sqljdbc': 10881, 'exquex': 10882, 'geoenvironmental': 10883, 'mismatched': 10884, 'deduclive': 10885, 'cancelling': 10886, 'overshadowing': 10887, 'defeasibility': 10888, 'deontic': 10889, 'crop': 10890, 'turn': 10891, 'fbrl': 10892, 'rdfi': 10893, 'cps': 10894, 'triples': 10895, 'careers': 10896, 'odbmss': 10897, 'proportion': 10898, 'longer': 10899, 'connective': 10900, 'loaded': 10901, 'myocardial': 10902, 'thallium': 10903, 'scintigrams': 10904, 'xel': 10905, 'hollands': 10906, 'congruence': 10907, 'clowns': 10908, 'jokers': 10909, 'dynamite': 10910, 'conservation': 10911, 'smith': 10912, 'graduated': 10913, 'bang': 10914, 'shaving': 10915, 'zoning': 10916, 'orthogonally': 10917, 'reactor': 10918, 'er': 10919, 'unrolling': 10920, 'twicpen': 10921, 'softguess': 10922, 'sensordcsp': 10923, 'textmole': 10924, 'moodview': 10925, 'oodbmss': 10926, 'qurator': 10927, 'playful': 10928, 'reconstructive': 10929, 'eventually': 10930, 'gpuqp': 10931, 'hyspirit': 10932, 'dsps': 10933, 'cssv': 10934, 'skeptics': 10935, 'menagerie': 10936, 'conflictors': 10937, 'preemptors': 10938, 'reinstaters': 10939, 'zombies': 10940, 'nonrnonotonic': 10941, 'recsplorer': 10942, 'adts': 10943, 'messageworld': 10944, 'demeter': 10945, 'crisp': 10946, 'fashion': 10947, 'wearable': 10948, 'sl': 10949, 'trans2': 10950, 'ddc': 10951, 'jpl': 10952, 'reappraising': 10953, 'lisp7o': 10954, 'i4e': 10955, 'genie': 10956, 'fakyr': 10957, 'basenp': 10958, 'summerization': 10959, 'besoins': 10960, 'lexicaux': 10961, 'lumiere': 10962, 'lanalyse': 10963, 'statistique': 10964, 'projet': 10965, 'bref': 10966, 'bdlex': 10967, 'francais': 10968, 'ecrit': 10969, 'cocqa': 10970, 'deletes': 10971, 'transformed': 10972, 'dynascope': 10973, 'mediatory': 10974, 'peng': 10975, 'ipodlinux': 10976, 'penalties': 10977, 'hyperparamodulation': 10978, 'solar': 10979, 'terrestrial': 10980, 'observatory': 10981, 'crowded': 10982, 'multisets': 10983, 'cooccurance': 10984, 'majic': 10985, 'responsiveness': 10986, 'individuality': 10987, 'corpular': 10988, 'setup': 10989, 'casebase': 10990, 'marrying': 10991, 'unformatted': 10992, 'nonholonomic': 10993, 'broader': 10994, 'elicitations': 10995, 'failsafe': 10996, 'floor': 10997, 'ebg': 10998, 'limeds': 10999, 'lincks': 11000, 'delayre': 11001, 'eracer': 11002, 'miniconference': 11003, 'paraphraser': 11004, 'larank': 11005, 'entityrank': 11006, 'holistically': 11007, 'hbp': 11008, 'hb': 11009, 'cgi': 11010, 'modperl': 11011, 'plangoal': 11012, 'house': 11013, 'cataclysm': 11014, 'policing': 11015, 'overloads': 11016, 'laminar': 11017, 'dex': 11018, 'lifestyle': 11019, 'ilsa': 11020, 'idbd': 11021, 'dbtg': 11022, 'ricardo': 11023, 'unsuccessful': 11024, 'expedite': 11025, 'acquire': 11026, 'planned': 11027, 'ontos': 11028, 'beautiful': 11029, 'investigaton': 11030, 'competitions': 11031, 'unnecessary': 11032, 'sell': 11033, 'serviceglobe': 11034, 'popfed': 11035, 'instace': 11036, 'amn': 11037, 'laser': 11038, 'memoizer': 11039, 'angelic': 11040, 'str': 11041, 'minmax': 11042, 'stativity': 11043, 'utilisation': 11044, 'parallelisme': 11045, 'traduction': 11046, 'automatisee': 11047, 'ordinateur': 11048, 'saves': 11049, 'restores': 11050, 'ict': 11051, 'immunisation': 11052, 'terraserver': 11053, 'widespread': 11054, 'pbfilter': 11055, 'nara': 11056, 'tirs': 11057, 'waller': 11058, 'kraft': 11059, 'triplet': 11060, 'overriding': 11061, 'managment': 11062, 'dublin': 11063, 'testers': 11064, 'visualizers': 11065, 'promise': 11066, 'perils': 11067, 'closely': 11068, 'likelihoods': 11069, 'lutess': 11070, 'dictations': 11071, 'bind': 11072, 'tournaments': 11073, 'topx': 11074, 'multitiered': 11075, 'lyric': 11076, 'objectbases': 11077, 'unidirectional': 11078, 'tse': 11079, 'weathra': 11080, 'soloman': 11081, 'felder': 11082, 'honorifics': 11083, 'recur': 11084, 'orbit': 11085, 'dotted': 11086, 'dm': 11087, 'pict': 11088, 'ccgs': 11089, 'raised': 11090, 'informia': 11091, '9': 11092, 'stereotrust': 11093, 'taxonomical': 11094, 'persist': 11095, 'searcher': 11096, 'featureide': 11097, 'authenticity': 11098, 'scsl': 11099, 'germanet': 11100, 'insite': 11101, 'demon': 11102, 'conset': 11103, 'synset': 11104, 'deformations': 11105, 'workplaces': 11106, 'suport': 11107, 'elliptic': 11108, 'prob': 11109, 'maxn': 11110, 'brained': 11111, 'reengineer': 11112, 'morphing': 11113, 'rhode': 11114, 'polestar': 11115, 'understands': 11116, 'nanotheories': 11117, 'boosts': 11118, 'sac': 11119, 'cleanliness': 11120, 'viral': 11121, 'zones': 11122, '94': 11123, 'tpr': 11124, 'swordfish': 11125, 'altricial': 11126, 'precocial': 11127, 'intro': 11128, 'kddcs': 11129, 'compatibilities': 11130, 'civedi': 11131, 'qbism': 11132, 'osaka': 11133, 'adas': 11134, 'spars': 11135, 'j': 11136, 'waypoint': 11137, 'cuber': 11138, 'acta': 11139, 'botanical': 11140, 'subsystems': 11141, 'impress': 11142, 'ddt': 11143, 'enchancing': 11144, 'spectroscopy': 11145, 'eigenspaces': 11146, 'prometheus': 11147, 'mugi': 11148, 'multimodel': 11149, 'blogvox': 11150, 'wap': 11151, 'qard': 11152, 'restore': 11153, 'defeating': 11154, 'enforced': 11155, 'xtream': 11156, 'implied': 11157, 'hdsampler': 11158, 'ending': 11159, 'teleputing': 11160, 'corev': 11161, 'sctp': 11162, 'fase': 11163, 'mlcs': 11164, 'urdu': 11165, 'webfilter': 11166, 'undestanding': 11167, 'denormalized': 11168, 'tinycasper': 11169, 'routes': 11170, 'impersonation': 11171, 'perpetual': 11172, 'cc2001': 11173, 'practitioners': 11174, 'inection': 11175, 'decadal': 11176, 'landsat': 11177, 'collabrank': 11178, 'perceive': 11179, 'acquisitional': 11180, 'parsercompiler': 11181, 'v8': 11182, 'sintesi': 11183, 'nonemptiness': 11184, 'webgraph': 11185, 'scannerless': 11186, 'nslr1': 11187, 'recognizers': 11188, 'paratimer': 11189, 'lmrp': 11190, 'quickstart': 11191, 'deos': 11192, 'boasting': 11193, 'ltrules': 11194, 'holism': 11195, 'outlet': 11196, 'mss': 11197, 'mus': 11198, 'cyberwar': 11199, 'conception': 11200, 'harmless': 11201, 'sparking': 11202, 'debunking': 11203, 'arsa': 11204, 'factories': 11205, 'daimler': 11206, 'benz': 11207, 'impediments': 11208, 'ops5': 11209, 'pps': 11210, 'undesired': 11211, 'grammer': 11212, 'freebase': 11213, 'arising': 11214, 'forging': 11215, 'invert': 11216, 'hrdm': 11217, 'lifespans': 11218, 'comprehensions': 11219, 'unpredictable': 11220, 'loanwords': 11221, 'umlsec': 11222, 'transcriptions': 11223, 'metamorph': 11224, 'leaming': 11225, 'porel': 11226, 'romance': 11227, 'yoopick': 11228, 'sports': 11229, 'pays': 11230, 'arcs': 11231, 'rapidly': 11232, '2pxminer': 11233, 'openrulebench': 11234, 'presenter': 11235, 'lecturing': 11236, 'principality': 11237, 'postulates': 11238, 'hugin': 11239, 'universes': 11240, 'phrasetable': 11241, 'infomaster': 11242, 'medians': 11243, 'insanity': 11244, 'himotoki': 11245, 'smoothness': 11246, 'dbgraph': 11247, 'mlisp2': 11248, 'multifractals': 11249, 'piggy': 11250, 'nonmontonic': 11251, 'traitor': 11252, 'comprehensible': 11253, 'fzi': 11254, 'karlsruhe': 11255, 'dfr': 11256, 'setups': 11257, 'rosettanet': 11258, 'yq': 11259, 'satisficing': 11260, 'prisoner': 11261, 'believed': 11262, 'webquilt': 11263, 'offics': 11264, 'telling': 11265, 'multisync': 11266, 'toggle': 11267, 'pebm': 11268, 'homomorphism': 11269, 'f4': 11270, 'colour': 11271, 'curler': 11272, 'ibal': 11273, 'cfls': 11274, 'stencil': 11275, 'distinctness': 11276, 'dqp': 11277, 'congolog': 11278, 'switches': 11279, 'marriage': 11280, 'subdeletion': 11281, 'lapprentissage': 11282, 'referents': 11283, 'suppliers': 11284, 'pronomial': 11285, 'mud': 11286, 'quarantine': 11287, 'mission': 11288, 'accessses': 11289, 'minesweeper': 11290, 'cocoviz': 11291, 'footstep': 11292, 'exovm': 11293, 'picodbms': 11294, 'ladder': 11295, 'vizql': 11296, 'regularities': 11297, 'simdb': 11298, 'replies': 11299, 'unorganized': 11300, 'empower': 11301, 'privileged': 11302, 'succession': 11303, 'drc': 11304, 'bantu': 11305, 'psychsim': 11306, 'raptor': 11307, 'threat': 11308, 'dcube': 11309, 'wa': 11310, 'kdmas': 11311, 'cws': 11312, 'procos': 11313, 'studied': 11314, 'grip': 11315, 'capbased': 11316, 'ams': 11317, 'plurality': 11318, 'colorful': 11319, 'losing': 11320, 'factorisation': 11321, 'diffuse': 11322, 'absent': 11323, 'semaplan': 11324, 'skinny': 11325, 'fleshy': 11326, 'failing': 11327, 'reallocation': 11328, 'quantization': 11329, 'configuraton': 11330, 'bijective': 11331, 'cpm': 11332, 'wlans': 11333, 'prevalence': 11334, 'mesa': 11335, 'deadliner': 11336, 'velodrome': 11337, 'consultable': 11338, 'drastic': 11339, 'slr': 11340, 'league': 11341, 'sequentially': 11342, 'numericalvectors': 11343, 'techonology': 11344, 'regexex': 11345, 'linearized': 11346, 'acse': 11347, 'distributd': 11348, 'synthesized': 11349, 'dispositions': 11350, 'converses': 11351, 'pumping': 11352, 'lemmas': 11353, 'catchup': 11354, 'replaying': 11355, 'refactorings': 11356, 'politecnico': 11357, 'milano': 11358, 'forth': 11359, 'infosuasive': 11360, 'selectionist': 11361, 'lingering': 11362, 'wdas': 11363, 'frontal': 11364, 'print': 11365, 'monologues': 11366, 'feistel': 11367, 'rounds': 11368, 'equip': 11369, 'tourists': 11370, 'travelogues': 11371, 'mmdb': 11372, 'reload': 11373, 'loopy': 11374, 'sam': 11375, 'prepare': 11376, 'sqlolb': 11377, 'martlet': 11378, 'abstracted': 11379, 'parallelisation': 11380, 'virgis': 11381, 'wfs': 11382, 'tagmark': 11383, 'chianti': 11384, 'philadelphia': 11385, 'twigs': 11386, 'undecidable': 11387, 'rdbvms': 11388, 'missl': 11389, 'axiomatizations': 11390, 'negligible': 11391, 'rankers': 11392, 'forensics': 11393, 'permanents': 11394, 'polytopes': 11395, 'kleio': 11396, 'bidterm': 11397, 'israel': 11398, 'tells': 11399, 'deserves': 11400, 'harlan': 11401, 'mills': 11402, 'youtube': 11403, 'spc': 11404, 'cwb': 11405, 'interchangeabilities': 11406, 'jaunt': 11407, 'sedna': 11408, 'playout': 11409, 'venture': 11410, 'threesomes': 11411, 'methodical': 11412, 'fasttrack': 11413, 'infinitedb': 11414, 'dolap07': 11415, 'intersecting': 11416, 'sslip': 11417, 'partite': 11418, 'fcvw': 11419, 'downgrading': 11420, 'csd': 11421, 'uoc': 11422, 'inconsisent': 11423, 'seth': 11424, 'reconsidering': 11425, 'paisley': 11426, 'undersea': 11427, 'lightwave': 11428, 'cable': 11429, 'orthogonality': 11430, 'spotter': 11431, 'solo': 11432, 'orthosis': 11433, 'boot': 11434, 'camp': 11435, 'perturb': 11436, 'interruptable': 11437, 'disentangling': 11438, 'called': 11439, 'punctuality': 11440, 'hierarchyscan': 11441, 'xcerpt': 11442, 'visxcerpt': 11443, 'trait': 11444, 'flexpath': 11445, 'surveys': 11446, 'specificaiton': 11447, 's4f': 11448, 'surgical': 11449, 'backfitting': 11450, 'autotagging': 11451, 'closurize': 11452, 'concentrate': 11453, 'magical': 11454, 'coil': 11455, 'orthography': 11456, 'workfile': 11457, 'laguna': 11458, 'waters': 11459, 'squire': 11460, 'superstabilizing': 11461, 'dignosis': 11462, 'ascending': 11463, 'alibi': 11464, 'timestamping': 11465, 'regularity': 11466, 'wikirelate': 11467, 'nuclei': 11468, 'filtered': 11469, 'wiser': 11470, 'seaweed': 11471, 'speedup': 11472, 'contiguous': 11473, 'meme': 11474, 'rightnow': 11475, 'nf': 11476, 'simplicial': 11477, 'voronoi': 11478, 'copa': 11479, 'kobra': 11480, 'qada': 11481, 'levelwise': 11482, 'ditributed': 11483, 'raddle': 11484, 'lid': 11485, 'stanfords': 11486, 'spotfire': 11487, 'assume': 11488, 'houston': 11489, 'tank': 11490, 'were': 11491, 'classwide': 11492, 'communcation': 11493, 'enduser': 11494, 'ariesim': 11495, 'broken': 11496, 'plural': 11497, 'masth': 11498, 'adopt': 11499, 'ing': 11500, 'unitary': 11501, 'flsi': 11502, 'extenders': 11503, 'abcd': 11504, 'flattening': 11505, 'birds': 11506, 'stone': 11507, 'smallest': 11508, 'achitecture': 11509, 'peephole': 11510, 'advertisers': 11511, 'foaf': 11512, 'bess': 11513, 'marion': 11514, 'networkweb': 11515, 'hospitals': 11516, 'others': 11517, 'decline': 11518, 'collapsibility': 11519, 'reified': 11520, 'unreify': 11521, 'cylinder': 11522, 'faceled': 11523, 'clonedetective': 11524, 'dlv': 11525, 'agora': 11526, 'mechatronic': 11527, 'camel': 11528, 'dely': 11529, 'globedb': 11530, 'alcoa': 11531, 'noncorrecting': 11532, 'cubeexplorer': 11533, 'partitional': 11534, 'cryptosystem': 11535, 'morally': 11536, 'encapsulating': 11537, 'deckard': 11538, 'toolkits': 11539, 'opium': 11540, 'installuninstall': 11541, 'membrane': 11542, 'x2morf': 11543, 'magiccube': 11544, 'each': 11545, 'dictation': 11546, 'grassmann': 11547, 'edbt02': 11548, 'saussurian': 11549, 'mirth': 11550, 'nfas': 11551, 'gameboy': 11552, 'homebrew': 11553, 'webpod': 11554, 'pocketable': 11555, 'reviewer': 11556, 'metho': 11557, 'hyperterms': 11558, 'recruit': 11559, 'retain': 11560, 'csiec': 11561, 'alps': 11562, 'fingertips': 11563, 'geoinformation': 11564, 'metaphonemes': 11565, 'codecrawler': 11566, 'pepsys': 11567, 'resin': 11568, 'mints': 11569, 'suffixing': 11570, 'ntjfsatnot': 11571, 'constraintcfl': 11572, 'downdate': 11573, 'commands': 11574, 'undo': 11575, 'diet': 11576, 'foks': 11577, 'fql': 11578, 'timeml': 11579, 'purposeful': 11580, 'mandatory': 11581, 'dossier': 11582, 'contraints': 11583, 'alen': 11584, 'shovels': 11585, 'xsearch': 11586, 'museum': 11587, 'accident': 11588, 'quirky': 11589, 'herding': 11590, 'holographic': 11591, 'sor': 11592, 'kindergarten': 11593, 'sagas': 11594, 'navigations': 11595, 'hinting': 11596, 'operands': 11597, 'indexable': 11598, 'pla': 11599, 'froff': 11600, 'decodable': 11601, 'tiger': 11602, 'nlhe': 11603, 'village': 11604, 'conways': 11605, 'underwater': 11606, 'datasplash': 11607, 'unbinding': 11608, 'bagger': 11609, 'extends': 11610, 'generalizes': 11611, 'wikipedias': 11612, 'pasta': 11613, '3s': 11614, 'brooklyn': 11615, 'dementia': 11616, 'cognitively': 11617, 'groupwork': 11618, 'durative': 11619, 'breakdown': 11620, 'rigel': 11621, 'assumeguarantee': 11622, 'wishlists': 11623, 'montague': 11624, 'photon': 11625, 'restarting': 11626, 'unrelated': 11627, 'chopping': 11628, 'hypertextbooks': 11629, 'ossobook': 11630, 'knowledgemanagement': 11631, 'archaeozoology': 11632, 'ebmt': 11633, 'arguable': 11634, 'shneidermans': 11635, 'odesew': 11636, 'pointwise': 11637, 'loophole': 11638, 'naturally': 11639, 'provable': 11640, 'ituned': 11641, 'supernormal': 11642, 'lost': 11643, 'ethnography': 11644, 'obstructed': 11645, 'javiva': 11646, 'gpu': 11647, 'socializing': 11648, 'reifying': 11649, 'uksearch': 11650, 'hebbian': 11651, 'plasticity': 11652, 'selectivities': 11653, 'metareasoning': 11654, 'khepera': 11655, 'krobot': 11656, 'orden': 11657, 'psychometric': 11658, 'volatility': 11659, 'xkvalidator': 11660, 'empowering': 11661, 'millenium': 11662, 'mad': 11663, 'eventrons': 11664, 'abe': 11665, 'hps': 11666, 'xas': 11667, 'lexemes': 11668, 'idarex': 11669, 'discernment': 11670, 'mobileminer': 11671, 'worldwide': 11672, 'telescope': 11673, 'scramble': 11674, 'voodb': 11675, 'falcon': 11676, 'psr': 11677, 'jkarelrobot': 11678, 'monologue': 11679, 'accadian': 11680, 'groupings': 11681, 'superquadrics': 11682, 'mul': 11683, 'illustration': 11684, 'phonemic': 11685, 'corel': 11686, 'probfuse': 11687, 'pipe': 11688, 'cvs': 11689, 'gini': 11690, 'internets': 11691, 'resoution': 11692, 'danaphore': 11693, 'partir': 11694, 'grammaire': 11695, 'verbes': 11696, 'anaphoriques': 11697, 'btrees': 11698, 'mistake': 11699, 'paninian': 11700, 'lbs': 11701, 'leximin': 11702, 'covered': 11703, 'federations': 11704, 'immigration': 11705, 'tal': 11706, 'necessarily': 11707, 'bolasso': 11708, 'utilize': 11709, 'microfluidics': 11710, 'insider': 11711, 'tasknavigator': 11712, 'chasm': 11713, 'kda': 11714, 'chaotic': 11715, 'expense': 11716, 'reimbursement': 11717, 'goethe': 11718, 'hypersurfaces': 11719, 'hyperspread': 11720, 'dublo': 11721, 'cbir': 11722, 'subimplication': 11723, 'verfication': 11724, 'sleve': 11725, 'summation': 11726, 'quad': 11727, 'cabot': 11728, 'salts': 11729, '3dstring': 11730, 'udafs': 11731, 'speeds': 11732, 'certificate': 11733, 'revocation': 11734, 'duping': 11735, 'quasigroup': 11736, 'niagaracq': 11737, 'phone': 11738, 'cursors': 11739, 'rendered': 11740, 'hikm': 11741, 'violate': 11742, 'doodle': 11743, 'aod': 11744, 'backout': 11745, 'dejavu': 11746, 'operative': 11747, 'inputoutput': 11748, 'hddbrs': 11749, 'tiie': 11750, 'sprinkling': 11751, 'bilingually': 11752, 'yields': 11753, 'restoring': 11754, 'batched': 11755, 'instatiations': 11756, 'obligatory': 11757, 'actants': 11758, 'voila': 11759, 'mach': 11760, 'supersonic': 11761, 'weiner': 11762, 'presenting': 11763, 'microkernels': 11764, 'submodule': 11765, 'nitpick': 11766, 'quotations': 11767, 'arena': 11768, 'diarc': 11769, 'maximin': 11770, 'fat': 11771, 'btree': 11772, 'caofes': 11773, 'padsml': 11774, 'infusion': 11775, 'foundational': 11776, 'segras': 11777, 'semigraphical': 11778, 'preparedness': 11779, 'cms': 11780, 'frontend': 11781, 'cpg': 11782, 'biped': 11783, 'rpref': 11784, 'fst': 11785, 'niches': 11786, 'datalens': 11787, 'retrofitting': 11788, 'asilomar': 11789, 'wavecluster': 11790, 'claremont': 11791, 'passwords': 11792, 'twist': 11793, 'optimalities': 11794, 'cep': 11795, 'cursive': 11796, 'depths': 11797, 'polytime': 11798, 'redbrick': 11799, 'legos': 11800, 'nonstandard': 11801, 'bilkent': 11802, 'defunctionalization': 11803, 'graphlet': 11804, 'stealth': 11805, 'schedulers': 11806, 'planarisation': 11807, 'stl': 11808, 'sardsrn': 11809, 'dedale': 11810, 'hider': 11811, 'minos': 11812, 'bisimulations': 11813, 'unknowns': 11814, 'stages': 11815, 'territorial': 11816, 'misconfigured': 11817, 'trackers': 11818, 'kanata': 11819, 'mb': 11820, 'mercy': 11821, 'turings': 11822, 'sndocrank': 11823, 'nonrecursive': 11824, 'genoa': 11825, '83': 11826, 'tailed': 11827, 'magnetoencephalography': 11828, 'lvm': 11829, 'demographic': 11830, 'shafers': 11831, 'xsl': 11832, 'sls': 11833, 'automate': 11834, 'slots': 11835, 'electoral': 11836, 'verkiezingskijker': 11837, 'datamining': 11838, 'picasso': 11839, 'novo': 11840, 'gogo': 11841, 'mallows': 11842, 'tge': 11843, 'tlinks': 11844, 'legged': 11845, 'blinks': 11846, 'spicy': 11847, 'chomsky': 11848, 'diderichsen': 11849, 'progressing': 11850, 'atomizer': 11851, 'keyhole': 11852, 'revitalizing': 11853, 'trying': 11854, 'robotstxt': 11855, 'krdb': 11856, '5th': 11857, 'mpsocs': 11858, 'comment': 11859, 'sgl': 11860, 'cognizant': 11861, 'formula': 11862, 'mildly': 11863, 'amuse': 11864, 'swam': 11865, 'asymmetrically': 11866, 'unconditional': 11867, 'i11': 11868, 'optimised': 11869, 'm3ic': 11870, 'replicability': 11871, 'peg': 11872, 'towers': 11873, 'hanoi': 11874, 'grabber': 11875, 'deyecting': 11876, 'vist': 11877, 'circumspective': 11878, 'myopia': 11879, 'opengl': 11880, 'sessionlock': 11881, 'eavesdropping': 11882, 'beneficial': 11883, 'egs': 11884, 'ex': 11885, 'contradictione': 11886, 'nihil': 11887, 'sequitur': 11888, 'electives': 11889, 'gpca': 11890, '232': 11891, 'brokers': 11892, 'tri': 11893, 'expressional': 11894, 'uninteresting': 11895, 'pdl': 11896, 'revisted': 11897, 'projectron': 11898, 'portlet': 11899, 'chronicles': 11900, 'tbt': 11901, 'interating': 11902, 'customes': 11903, 'port': 11904, 'singapore': 11905, 'psa': 11906, 'localizable': 11907, 'dualising': 11908, 'heterogereous': 11909, 'maids': 11910, 'alarming': 11911, 'quiescene': 11912, 'sacrifices': 11913, 'medmaker': 11914, 'ransac': 11915, 'cylinders': 11916, 'ball': 11917, 'lham': 11918, 'biopatentminer': 11919, 'diane': 11920, 'flowgraphs': 11921, 'tensorial': 11922, 'watchdog': 11923, 'curiosity': 11924, 'flick': 11925, 'idl': 11926, 'graphscope': 11927, 'crescando': 11928, 'supermarket': 11929, 'profset': 11930, 'alep': 11931, 'gpsgs': 11932, 'characterizes': 11933, 'concernlines': 11934, 'erknn': 11935, 'behaved': 11936, 'located': 11937, 'psiphi': 11938, 'dre': 11939, 'locus': 11940, 'ray': 11941, 'mbrs': 11942, 'rhythms': 11943, 'megaprogramming': 11944, 'bkg': 11945, 'plays': 11946, 'backgammon': 11947, 'braking': 11948, 'multiply': 11949, 'quasar': 11950, 'eigentransfer': 11951, 'combinatorical': 11952, 'asp': 11953, 'dblp': 11954, 'initiator': 11955, 'facetedpedia': 11956, 'snap': 11957, 'substrings': 11958, 'graduating': 11959, 'beamforming': 11960, 'hdd': 11961, 'bot': 11962, 'instantiating': 11963, 'coefficients': 11964, 'senselearner': 11965, 'multicontainer': 11966, 'superiority': 11967, 'sesfjava': 11968, 'contracting': 11969, 'ebusiness': 11970, 'matchmaker': 11971, 'tagclouds': 11972, 'isdt': 11973, 'align': 11974, 'englishfrench': 11975, 'bridger': 11976, 'edition': 11977, 'noriegas': 11978, 'nonprofit': 11979, 'delete': 11980, 'objectrelational': 11981, 'hibernate': 11982, 'edm': 11983, 'binaries': 11984, 'autopilot': 11985, 'fleet': 11986, 'counterexamples': 11987, 'atomization': 11988, 'uninterrupted': 11989, 'buidling': 11990, 'peta': 11991, 'grailkaos': 11992, 'rala': 11993, 'digitalis': 11994, 'incidental': 11995, 'esc': 11996, 'mitosis': 11997, 'yam': 11998, 'bicord': 11999, 'revitalized': 12000, 'wordbreak': 12001, 'folders': 12002, 'rags': 12003, 'riches': 12004, 'semhe': 12005, 'coresets': 12006, 'mcdc': 12007, 'rankingcom': 12008, 'fronting': 12009, 'outranking': 12010, 'make3d': 12011, 'stholes': 12012, 'pacer': 12013, 'theontologies': 12014, 'fclust': 12015, 'transversals': 12016, 'hardening': 12017, 'nonground': 12018, 'nationwide': 12019, 'phoebus': 12020, 'nilssons': 12021, 'exogeneous': 12022, 'endogeneous': 12023, 'pad': 12024, 'blackbox': 12025, 'overhearing': 12026, 'carnot': 12027, 'zipfs': 12028, 'weibull': 12029, 'dwell': 12030, 'glossing': 12031, 'sina': 12032, 'alphonse': 12033, 'river': 12034, 'floods': 12035, 'bnn': 12036, 'reconceptualizing': 12037, 'isetl': 12038, 'yaping': 12039, 'plagueing': 12040, 'overspecified': 12041, 'victoria': 12042, 'wellington': 12043, 'cork': 12044, 'mechanics': 12045, 'edison': 12046, 'swap': 12047, 'confirmations': 12048, 'tame': 12049, 'strg': 12050, 'kabiria': 12051, 'stakeholder': 12052, 'wildcard': 12053, 'inegration': 12054, 'tiny': 12055, 'nerve': 12056, 'parthood': 12057, 'componenthood': 12058, 'inverting': 12059, 'viterbi': 12060, 'lockprotocols': 12061, 'manageable': 12062, 'searchersystem': 12063, 'qualitatively': 12064, 'pfs': 12065, 'peace': 12066, 'indifferentiability': 12067, 'chopmd': 12068, 'gdr': 12069, 'temporary': 12070, 'restraints': 12071, 'configuartions': 12072, 'movable': 12073, 'ordbms': 12074, 'attract': 12075, 'obnet': 12076, 'lived': 12077, 'vpns': 12078, 'ditto': 12079, 'incrementalization': 12080, 'mc': 12081, 'kbms': 12082, 'basedsensemaking': 12083, 'yellow': 12084, 'sand': 12085, 'ridesharing': 12086, 'qfilter': 12087, 'believe': 12088, 'soap': 12089, 'polling': 12090, 'xcon': 12091, 'ldoce': 12092, 'xport': 12093, 'modalities': 12094, 'alitheia': 12095, 'curated': 12096, 'soqa': 12097, 'simpack': 12098, 'modeler': 12099, 'judgment': 12100, 'tijah': 12101, 'profilers': 12102, 'fortransaction': 12103, 'relativization': 12104, 'dataflows': 12105, 'controversial': 12106, 'epinionscom': 12107, 'ixp': 12108, 'ides': 12109, 'perfective': 12110, 'resumable': 12111, 'crpgs': 12112, 'iskodor': 12113, 'pebl': 12114, 'opnet': 12115, 'wireshark': 12116, 'appgen': 12117, 'paragraphs': 12118, 'cfi': 12119, 'inking': 12120, 'multifactor': 12121, 'alt': 12122, 'menory': 12123, 'agna': 12124, 'orgenization': 12125, 'eigenrank': 12126, 'dpmis': 12127, 'timestamps': 12128, 'squared': 12129, 'tmss': 12130, 'corrections': 12131, 'klyde': 12132, 'somali': 12133, 'hourly': 12134, 'dance': 12135, 'roccer': 12136, 'ecological': 12137, 'insecure': 12138, 'pig': 12139, 'enactability': 12140, 'oops': 12141, 'faciltity': 12142, 'zbroker': 12143, 'z3950': 12144, 'infoharness': 12145, '¬1nf': 12146, 'starting': 12147, 'occupancy': 12148, 'releases': 12149, 'sehas': 12150, 'decompositional': 12151, 'greo': 12152, 'propagated': 12153, 'unmasking': 12154, 'cq': 12155, 'lc3uarch': 12156, 'lc': 12157, 'microarchitecture': 12158, 'balances': 12159, 'faqs': 12160, 'discsps': 12161, 'semisupervised': 12162, 'coevolved': 12163, 'specialists': 12164, 'utilizations': 12165, 'sunny': 12166, 'haemo': 12167, 'dialysis': 12168, 'fitted': 12169, 'jiljuliette': 12170, 'evicted': 12171, 'accidental': 12172, 'dwarf': 12173, 'petacube': 12174, 'eventualities': 12175, 'immigrant': 12176, 'questionbank': 12177, 'janninks': 12178, 'cold': 12179, 'staring': 12180, 'semiformal': 12181, 'precondition': 12182, 'cclisp\\x99': 12183, 'ipsc\\x99': 12184, 'destaging': 12185, 'mohca': 12186, 'reactivity': 12187, 'buffet': 12188, 'hmms': 12189, 'stupid': 12190, 'moved': 12191, 'memorization': 12192, 'liteminutes': 12193, 'minutes': 12194, 'extensionality': 12195, 'intensionality': 12196, 'authorial': 12197, 'ttd': 12198, 'citeseerx': 12199, 'inspectors': 12200, 'produced': 12201, 'cart': 12202, 'svt': 12203, 'simlarity': 12204, 'sims': 12205, 'magazine': 12206, 'tam': 12207, 'subtheories': 12208, 'jeli': 12209, 'promoters': 12210, 'evolino': 12211, 'neuroevolutionoptimal': 12212, 'jun': 12213, 'accrual': 12214, 'arma': 12215, 'clipped': 12216, 'heartbeat': 12217, 'idrqr': 12218, 'exel': 12219, 'spiffi': 12220, 'vexed': 12221, 'turmoil': 12222, 'gatutor': 12223, 'locale': 12224, 'greibach': 12225, 'mlpqgis': 12226, 'swarming': 12227, 'wikis': 12228, 'lexicase': 12229, 'ahaa': 12230, 'smes': 12231, 'whodunit': 12232, 'diamond': 12233, 'facetnet': 12234, 'evolutions': 12235, 'bidirectionality': 12236, 'lifeguards': 12237, 'aircraft': 12238, 'xcache': 12239, 'xqgen': 12240, 'suspense': 12241, 'consonant': 12242, 'interdependent': 12243, 'indexical': 12244, 'arrhythmias': 12245, 'crystal': 12246, 'quicr': 12247, 'malpha': 12248, 'ethnicity': 12249, 'mask': 12250, 'gamesense': 12251, 'manually': 12252, 'ontosearch': 12253, 'cutset': 12254, 'predetermined': 12255, 'sun': 12256, 'tastier': 12257, 'disfluent': 12258, 'grammatico': 12259, 'nominally': 12260, 'premodified': 12261, 'xdp': 12262, 'laying': 12263, 'todo': 12264, 'smartest': 12265, 'piers': 12266, 'dna': 12267, 'verificatino': 12268, 'suboptimality': 12269, 'subproblem': 12270, 'reseda': 12271, 'callassist': 12272, 'promotional': 12273, 'listens': 12274, 'asks': 12275, 'grael': 12276, 'visualize': 12277, 'criminals': 12278, 'hyperequivalence': 12279, 'duplicated': 12280, 'alouds': 12281, 'soping': 12282, 'loadstar': 12283, 'impersonate': 12284, 'reining': 12285, 'pseudorandomness': 12286, 'rc6': 12287, 'pseudoword': 12288, 'html2rss': 12289, 'upml': 12290, 'myxdns': 12291, 'resquest': 12292, 'dns': 12293, 'mmr': 12294, 'advertiser': 12295, 'adfactors': 12296, 'ants': 12297, 'secrets': 12298, '90': 12299, 'reassessment': 12300, 'imputations': 12301, 'iota': 12302, 'outilex': 12303, 'inertia': 12304, 'unstable': 12305, 'bitemporal': 12306, 'epidemiology': 12307, 'csi': 12308, '1998': 12309, 'cars': 12310, 'goddesses': 12311, 'enzymes': 12312, 'parametrizable': 12313, 'styled': 12314, 'picsdesk': 12315, 'ronald': 12316, 'ravi': 12317, 'kumar': 12318, 'sivakumar': 12319, 'proc': 12320, 'sigmod03': 12321, 'got': 12322, 'sharper': 12323, 'stretch': 12324, 'resizing': 12325, 'relocatable': 12326, 'microbial': 12327, 'img': 12328, 'technically': 12329, 'pictor': 12330, 'ansix3sparc': 12331, 'conjoined': 12332, 'payoffs': 12333, 'changed': 12334, 'ictd': 12335, 'periodically': 12336, 'opinionfinder': 12337, 'sorttables': 12338, 'digesting': 12339, 'geek': 12340, 'relay': 12341, 'chats': 12342, 'compose': 12343, 'compset': 12344, 'sortal': 12345, 'atomate': 12346, 'unanticipated': 12347, 'eurolang': 12348, 'homer': 12349, 'dapple': 12350, 'sensorimotor': 12351, 'cbmir': 12352, 'tanka': 12353, 'monkey': 12354, 'monopolizing': 12355, 'mimic': 12356, 'system370': 12357, 'bicycling': 12358, 'prerogative': 12359, 'proves': 12360, 'imprimitive': 12361, 'trapdoors': 12362, 'gaia': 12363, 'mcp': 12364, 'feedbackfor': 12365, 'downloading': 12366, 'fsa': 12367, 'pegs': 12368, 'chips': 12369, 'paragon': 12370, 'incognito': 12371, 'mysearchview': 12372, 'ofl': 12373, 'servicing': 12374, 'tye': 12375, 'gimmick': 12376, 'piggybacking': 12377, 'informationretrieval': 12378, 'illustrate': 12379, 'schemacentric': 12380, 'esql2': 12381, 'aura': 12382, 'overall': 12383, 'reexecution': 12384, 'actually': 12385, 'elucidation': 12386, 'internship': 12387, 'minimips': 12388, 'tributaries': 12389, 'recrawling': 12390, 'caprera': 12391, 'millennium': 12392, 'noah': 12393, 'degradations': 12394, 'rebuilds': 12395, 'mature': 12396, 'logal': 12397, 'firehose': 12398, 'quiver': 12399, 'clitics': 12400, 'colorectal': 12401, 'ineffectiveness': 12402, 'umist': 12403, 'facekit': 12404, 'mdi': 12405, 'posted': 12406, 'quantitatively': 12407, 'edutella': 12408, 'optimums': 12409, 'visualizaiton': 12410, 'varieties': 12411, 'robotstudio': 12412, 'insiders': 12413, 'javas': 12414, 'turkic': 12415, 'averse': 12416, 'symchaff': 12417, 'das': 12418, 'geromesuite': 12419, 'constrain': 12420, 'senserelate': 12421, 'targetword': 12422, 'deas': 12423, 'georgia': 12424, 'computes': 12425, 'symbolico': 12426, 'documentary': 12427, 'interrogation': 12428, 'george': 12429, 'mason': 12430, 'telemeetings': 12431, 'liter': 12432, 'hubble': 12433, 'folder': 12434, 'gestalts': 12435, 'portrait': 12436, 'steganalysis': 12437, 'lsb': 12438, 'stegangoraphy': 12439, 'grayscale': 12440, 'rapt': 12441, 'unary': 12442, 'activated': 12443, 'expertclerk': 12444, 'shoppers': 12445, 'buying': 12446, 'ub': 12447, 'multisentential': 12448, 'reefs': 12449, 'itopn': 12450, 'inequal': 12451, 'accumulation': 12452, 'moral': 12453, 'luposdate': 12454, 'contstruct': 12455, 'weaver': 12456, 'sensed': 12457, 'geophysical': 12458, 'contractible': 12459, 'sushi': 12460, 'wysiwyt': 12461, 'evaluators': 12462, 'rebate': 12463, 'integrates': 12464, 'mono': 12465, 'syllabic': 12466, 'atns': 12467, 'justifying': 12468, 'iq': 12469, 'contextualized': 12470, 'pr': 12471, 'responsibilities': 12472, 'justifications': 12473, 'cogram': 12474, 'alcogram': 12475, 'happening': 12476, 'placements': 12477, 'critically': 12478, 'vec': 12479, 'semex': 12480, 'xqforms': 12481, 'braided': 12482, 'coupons': 12483, 'cadena': 12484, 'tulsa': 12485, 'establish': 12486, 'keysurf': 12487, 'murphy': 12488, 'adroit': 12489, 'fusem': 12490, 'carte': 12491, 'oblique': 12492, 'athlon': 12493, 'comma': 12494, 'basque': 12495, 'applets': 12496, 'oversearching': 12497, 'kato': 12498, 'possessives': 12499, 'partitives': 12500, 'affordable': 12501, 'sr': 12502, 'discharge': 12503, 'changepoints': 12504, 'wheres': 12505, 'beef': 12506, 'realities': 12507, 'neighbourhoods': 12508, 'conspectus': 12509, 'trainer': 12510, 'georeferencing': 12511, 'nonprocedural': 12512, 'ucgs': 12513, 'mfis': 12514, 'foveal': 12515, 'osprey': 12516, 'semantifying': 12517, 'tricolor': 12518, 'infocrystal': 12519, 'unplugged': 12520, 'emulators': 12521, 'elf': 12522, 'aim': 12523, 'returning': 12524, 'sigir': 12525, 'synthy': 12526, 'fractured': 12527, 'calligraphic': 12528, 'consortium': 12529, 'permissions': 12530, 'icvlsi': 12531, 'orchestration': 12532, 'forcehttps': 12533, 'circularity': 12534, 'vm370': 12535, 'corms': 12536, 'hope': 12537, 'inria': 12538, 'vocal': 12539, 'oraclizable': 12540, 'kahns': 12541, 'allocators': 12542, 'potentials': 12543, 'gladder': 12544, 'ipp': 12545, 'netcube': 12546, 'hedge': 12547, 'adls': 12548, 'coincidence': 12549, 'synthesizer': 12550, 'xirql': 12551, 'genders': 12552, 'denormalization': 12553, 'adarank': 12554, 'bitbots': 12555, 'rebound': 12556, 'hyperdisk': 12557, 'infers': 12558, 'economy': 12559, 'biasing': 12560, 'nkrl': 12561, 'lamppost': 12562, 'dsis': 12563, 'interrelational': 12564, 'coolcat': 12565, 'calanda': 12566, 'vox': 12567, 'pba': 12568, 'unplanned': 12569, 'epci': 12570, 'potentially': 12571, 'infringement': 12572, 'blockmodel': 12573, 'hcc': 12574, 'bfs': 12575, 'undecomposable': 12576, 'vagueness': 12577, 'partly': 12578, 'suggesting': 12579, 'shuffle': 12580, 'crossover': 12581, 'openii': 12582, 'rescoring': 12583, 'recipes': 12584, 'counterpart': 12585, 'ccc': 12586, 'responds': 12587, 'inflective': 12588, 'genus': 12589, 'symp': 12590, 'russellian': 12591, 'plight': 12592, 'coca': 12593, 'seminal': 12594, 'metaheuristic': 12595, 'ideographic': 12596, 'reservation': 12597, 'traceback': 12598, 'graft': 12599, 'courserank': 12600, 'pronouncing': 12601, 'wll': 12602, 'rogets': 12603, 'citeseer': 12604, 'interlinking': 12605, 'rhist': 12606, 'reu': 12607, 'ovarian': 12608, 'lpsat': 12609, 'twente': 12610, 'l2r': 12611, 'sdoc': 12612, 'vistrails': 12613, 'carot': 12614, 'deferring': 12615, 'lots': 12616, 'ticks': 12617, 'trades': 12618, 'quotes': 12619, 'characterising': 12620, 'buildrs': 12621, 'gazpacho': 12622, 'rash': 12623, 'percepts': 12624, 'calysto': 12625, 'ns2': 12626, 'cascadia': 12627, 'diary': 12628, 'fastsort': 12629, 'classpects': 12630, 'programmability': 12631, 'spl': 12632, 'dsp': 12633, 'stereographics': 12634, 'proust': 12635, 'bucky': 12636, 'onyx': 12637, 'moments': 12638, 'citizen': 12639, 'orevalence': 12640, 'dijkstras': 12641, 'xspect': 12642, 'xlink': 12643, 'dummy': 12644, 'fro': 12645, 'complementation': 12646, 'haplo': 12647, 'replets': 12648, 'mist': 12649, 'theorys': 12650, 'archiver': 12651, 'shock': 12652, 'upending': 12653, 'uncanny': 12654, 'valley': 12655, 'primer': 12656, 'hiring': 12657, 'sequenced': 12658, 'ipsi': 12659, 'worked': 12660, 'didnt': 12661, 'deviant': 12662, 'discoverability': 12663, 'huockel': 12664, 'airfare': 12665, 'minimize': 12666, 'gigabits': 12667, 'cur': 12668, 'dogs': 12669, 'gogetit': 12670, 'nonatomic': 12671, 'ucc': 12672, 'metadeliberation': 12673, 'pander': 12674, 'ponder': 12675, 'saturation': 12676, 'gimme': 12677, 'pankow': 12678, 'electricity': 12679, 'feeder': 12680, 'susceptibility': 12681, 'logicist': 12682, 'laziness': 12683, 'activerdf': 12684, 'multipotential': 12685, 'xbenchmatch': 12686, 'comparsion': 12687, 'htm': 12688, 'hypertexts': 12689, 'schemascope': 12690, 'inary': 12691, 'daptation': 12692, 'rosser': 12693, 'terminating': 12694, 'apogee': 12695, 'statisticallinguistic': 12696, 'gists': 12697, 'topes': 12698, 'treeforest': 12699, 'youserv': 12700, 'fewer': 12701, 'vgram': 12702, 'invitational': 12703, 'arpansf': 12704, 'indormation': 12705, 'war': 12706, 'hyperbase': 12707, 'unlively': 12708, 'interchangeable': 12709, 'include': 12710, 'autofeed': 12711, 'webfeeds': 12712, 'mtcache': 12713, 'mult': 12714, 'lineare': 12715, 'mereotopology': 12716, 'dysy': 12717, 'disequilibration': 12718, 'persian': 12719, 'numerica': 12720, 'epistatic': 12721, 'preparatory': 12722, 'speechweb': 12723, 'hy': 12724, 'hygraph': 12725, 'halsteads': 12726, 'worlinfo': 12727, 'switched': 12728, 'rewiring': 12729, 'lit': 12730, 'periodical': 12731, 'discriminators': 12732, 'dependently': 12733, 'bitam': 12734, 'dormant': 12735, 'polysemous': 12736, 'adnominal': 12737, 'corollary': 12738, 'yesterday': 12739, 'minds': 12740, 'spyware': 12741, 'statemate': 12742, 'gentzen': 12743, 'formel': 12744, 'spice': 12745, 'blanket': 12746, 'alldiff': 12747, 'resumes': 12748, 'italia': 12749, 'ranksvm': 12750, 'ids': 12751, 'monochromatic': 12752, 'bichromatic': 12753, 'manner': 12754, 'liaison': 12755, 'on2l': 12756, 'fund': 12757, 'gives': 12758, 'kimmos': 12759, 'downside': 12760, 'atdd': 12761, 'easyaccept': 12762, 'xarch': 12763, 'wing': 12764, 'conspiracies': 12765, 'cocitation': 12766, 'shooting': 12767, 'deviants': 12768, 'catamorphisms': 12769, 'datatypes': 12770, 'innovations': 12771, 'contextually': 12772, 'taga': 12773, 'agentcities': 12774, 'folds': 12775, 'infused': 12776, 'referenced': 12777, 'aspera': 12778, 'horizons': 12779, 'especially': 12780, 'bdioctl': 12781, 'anthrax': 12782, 'teammate': 12783, 'dependentindependent': 12784, 'updatable': 12785, 'obstacle': 12786, 'turbulence': 12787, 'multirelations': 12788, 'semantice': 12789, 'tiscover': 12790, 'detail': 12791, 'plot': 12792, 'privileges': 12793, 'holonomic': 12794, 'rescue': 12795, 'reductive': 12796, 'relaxing': 12797, 'blockmodels': 12798, 'validators': 12799, 'dynammo': 12800, 'interdependencies': 12801, 'pramatics': 12802, 'multisafe': 12803, 'instability': 12804, 'lexicographer': 12805, 'illustrative': 12806, 'oi': 12807, 'alternate': 12808, 'dogmatix': 12809, 'rekeying': 12810, 'commonality': 12811, 'unboxed': 12812, 'indistinguishable': 12813, 'previously': 12814, 'jinn': 12815, 'junior': 12816, 'sqldata': 12817, 'hinge': 12818, 'llull': 12819, 'copeland': 12820, 'broadly': 12821, 'resist': 12822, 'statstream': 12823, 'les': 12824, 'dindexation': 12825, 'linist': 12826, 'ufos': 12827, 'artful': 12828, 'ot': 12829, 'besm': 12830, 'reach': 12831, 'youngster': 12832, 'assigned': 12833, 'vcode': 12834, 'correlating': 12835, 'homotopy': 12836, 'extra': 12837, 'deaccenting': 12838, 'pianists': 12839, 'perceptive': 12840, 'elevation': 12841, 'tanzania': 12842, 'finland': 12843, 'dependentspatial': 12844, 'watchman': 12845, 'mujava': 12846, '1994': 12847, 'honest': 12848, 'southern': 12849, 'earthquake': 12850, 'virtues': 12851, 'sl5': 12852, 'stereotyping': 12853, 'redwoods': 12854, 'acq': 12855, 'ood': 12856, 'odmgs': 12857, 'poirot': 12858, 'severities': 12859, 'gep': 12860, 'restrictive': 12861, 'metaclustering': 12862, 'textal\\x99': 12863, 'crystallographic': 12864, 'practica': 12865, 'timestamped': 12866, 'xj': 12867, 'kms': 12868, 'suade': 12869, 'ary': 12870, 'uncaught': 12871, 'maintainance': 12872, 'stan': 12873, 'gordian': 12874, 'serializable': 12875, 'eigenvectors': 12876, 'frank': 12877, 'predominant': 12878, 'cnf': 12879, 'comparatives': 12880, 'speculations': 12881, 'xquec': 12882, 'imaging': 12883, 'bibnetminer': 12884, 'safeguarding': 12885, 'largest': 12886, 'networkever': 12887, 'arnetminer': 12888, 'multithreading': 12889, 'ellipses': 12890, 'subscript': 12891, 'devolution': 12892, 'fdm': 12893, 'scidb': 12894, 'nltk': 12895, 'ebag': 12896, 'conquers': 12897, 'plurals': 12898, 'taped': 12899, 'disputed': 12900, 'featurehouse': 12901, 'deciphering': 12902, 'affecting': 12903, 'infominer': 12904, 'mechanized': 12905, 'unobtrusive': 12906, 'wodisee': 12907, 'minimizations': 12908, 'stepping': 12909, 'stones': 12910, 'incomparability': 12911, 'indias': 12912, 'scrambled': 12913, 'senteces': 12914, 'svp': 12915, 'synthesising': 12916, 'wic': 12917, 'subscripted': 12918, 'annual': 12919, 'accredited': 12920, 'factopinion': 12921, 'marginalized': 12922, 'quel': 12923, 'eighth': 12924, 'dolap05': 12925, 'voicemail': 12926, 'annodomini': 12927, 'microprocessors': 12928, 'partner': 12929, 'planningscheduling': 12930, 'privacygrid': 12931, 'intermediates': 12932, 'monolinguals': 12933, 'eetails': 12934, 'hypercuboid': 12935, 'rx': 12936, 'othello': 12937, 'aaa': 12938, 'parameterization': 12939, 'hardest': 12940, 'processable': 12941, 'tagset': 12942, 'autolocker': 12943, 'ceal': 12944, 'pylighter': 12945, 'highlighter': 12946, 'mashuphub': 12947, 'tendum': 12948, 'achilles': 12949, 'heel': 12950, 'releasing': 12951, 'privately': 12952, 'kendalls': 12953, 'tau': 12954, 'scatter': 12955, 'aida': 12956, 'synapses': 12957, 'lan': 12958, 'td': 12959, 'manifoldboost': 12960, 'stagewise': 12961, 'autoregressive': 12962, 'oranges': 12963, 'preview': 12964, 'thumbnails': 12965, 'lav': 12966, 'nonpoint': 12967, 'backstop': 12968, 'tsql2': 12969, 'parallax': 12970, 'cml': 12971, 'ge': 12972, 'nltoolset': 12973, 'turst': 12974, 'cheetah': 12975, 'newsjunkie': 12976, 'newsfeeds': 12977, 'ties': 12978, 'conic': 12979, 'textplanning': 12980, 'pit': 12981, 'kalchas': 12982, 'crd': 12983, 'constructorsets': 12984, 'prolearn': 12985, 'itrails': 12986, 'resemblance': 12987, 'declare': 12988, 'maxims': 12989, 'delegating': 12990, 'endangered': 12991, 'caused': 12992, 'holes': 12993, 'inherent': 12994, 'harmfulness': 12995, 'trimming': 12996, 'schoolers': 12997, 'imaginary': 12998, 'abilities': 12999, 'netprobe': 13000, 'catalognet': 13001, 'peering': 13002, 'mvds': 13003, 'preallocation': 13004, 'maple': 13005, 'perspectival': 13006, 'theses': 13007, 'movemine': 13008, 'artoo': 13009, 'weboql': 13010, 'parenthesis': 13011, 'remediation': 13012, 'expenditures': 13013, 'geometrical': 13014, 'stb': 13015, 'rk': 13016, 'hist': 13017, 'resets': 13018, 'conjugate': 13019, 'executables': 13020, 'eliminability': 13021, 'nonnumerical': 13022, 'recruiting': 13023, 'bestcut': 13024, 'earchivarius': 13025, 'scott': 13026, 'parallels': 13027, 'tetris': 13028, 'vmodel': 13029, 'mrm': 13030, 'mlr': 13031, 'wider': 13032, 'diagnose': 13033, 'bitslice': 13034, 'publishsubscibe': 13035, 'lgedbms': 13036, 'optimizied': 13037, 'mirrored': 13038, 'pep8cpu': 13039, 'cachingoffloading': 13040, 'oci': 13041, 'perracotta': 13042, 'ncr': 13043, '3700': 13044, 'clickthroughs': 13045, 'evaluated': 13046, 'vstrails': 13047, 'practicalexample': 13048, 'trilingual': 13049, 'inanimate': 13050, 'architects': 13051, 'touchstone': 13052, 'para': 13053, 'tan': 13054, 'maya': 13055, 'dispatch': 13056, 'colibri': 13057, 'designers': 13058, 'sacrificing': 13059, 'animalscript': 13060, 'staying': 13061, 'differentiation': 13062, 'w3c': 13063, 'panq': 13064, 'emf': 13065, 'woda': 13066, 'communicator': 13067, 'overstructured': 13068, 'cubic': 13069, 'dbminer': 13070, 'subcomputation': 13071, 'lungcad': 13072, 'clinically': 13073, 'approved': 13074, 'transputer': 13075, 'occam2': 13076, 'nonparallel': 13077, 'subverting': 13078, 'favour': 13079, 'checkfence': 13080, 'sdp': 13081, 'qp': 13082, 'worry': 13083, 'upgrades': 13084, 'mailer': 13085, 'ole': 13086, 'metagrammar': 13087, 'abb': 13088, 'proqid': 13089, 'corresponding': 13090, 'accuracies': 13091, 'centralizeddistributed': 13092, 'relatinships': 13093, 'nominalisations': 13094, 'webucation': 13095, 'flsa': 13096, 'vacationing': 13097, 'mpsbr': 13098, 'cmmi': 13099, 'bl': 13100, 'informaticas': 13101, 'cuts3vm': 13102, 'chamfer': 13103, 'warranted': 13104, 'eniam': 13105, 'avoidable': 13106, 'refutations': 13107, 'pain': 13108, 'radford': 13109, 'replicating': 13110, 'preh': 13111, 'assuming': 13112, 'conducting': 13113, 'nigeria': 13114, 'posing': 13115, 'cisc': 13116, 'quran': 13117, 'tamper': 13118, 'conceptional': 13119, 'timelines': 13120, 'polysemic': 13121, 'prospector': 13122, 'swaps': 13123, 'gravity': 13124, 'traced': 13125, 'unnormalized': 13126, 'trailblazer': 13127, 'cartography': 13128, 'reinforce': 13129, 'lingol': 13130, 'navy': 13131, 'ins': 13132, 'outs': 13133, 'discriminativegenerative': 13134, 'clicking': 13135, 'prompts': 13136, 'adimage': 13137, 'textract': 13138, 'vhdl': 13139, 'cloaking': 13140, 'amalgams': 13141, 'attempts': 13142, 'battle': 13143, 'owners': 13144, 'academics': 13145, 'comings': 13146, 'unsearchmo': 13147, 'queue': 13148, 'ant': 13149, 'grasshopper': 13150, 'millions': 13151, 'assortment': 13152, 'unannotated': 13153, 'ordpaths': 13154, 'insert': 13155, 'gems': 13156, 'biomarker': 13157, 'snarpy': 13158, 'kr': 13159, 'abl': 13160, 'itg': 13161, 'bigraphs': 13162, 'ix': 13163, 'gplag': 13164, 'relieving': 13165, 'pmg': 13166, 'smil20': 13167, 'revisionintegration': 13168, 'istar': 13169, 'codewords': 13170, 'dada': 13171, 'toolpack': 13172, 'cilk': 13173, 'talker': 13174, 'inflected': 13175, 'nondestructive': 13176, 'plastics': 13177, 'odefs': 13178, 'subelectorate': 13179, 'concretion': 13180, 'argus': 13181, 'uncurrying': 13182, 'blogger': 13183, 'offshore': 13184, 'apple': 13185, 'splicing': 13186, 'misordered': 13187, 'hyperion': 13188, 'aditi': 13189, 'ipac': 13190, 'engineeringor': 13191, '64': 13192, 'decrease': 13193, 'tectogrammatical': 13194, 'fatigue': 13195, 'handhelds': 13196, 'spells': 13197, 'sockets': 13198, 'rmi': 13199, 'polyvariant': 13200, 'rocchio': 13201, 'toronto': 13202, 'partitionable': 13203, 'switchable': 13204, 'semtalk': 13205, 'paired': 13206, 'toss': 13207, 'tax': 13208, 'archipelago': 13209, 'pruned': 13210, 'characterisation': 13211, 'theorist': 13212, 'kill': 13213, 'trada': 13214, 'rkhs': 13215, 'raindrop': 13216, 'ironcode': 13217, 'twice': 13218, 'chebyshev': 13219, 'polynomials': 13220, 'queryupdate': 13221, 'ngits99': 13222, 'darmstadt': 13223, 'browse': 13224, 'recover': 13225, 'nonextensive': 13226, 'wosq': 13227, 'nomograms': 13228, 'feedbackbypass': 13229, 'emailsift': 13230, 'disclosing': 13231, 'instructor': 13232, 'compactly': 13233, 'sructural': 13234, 'ltags': 13235, 'corefernece': 13236, 'nic': 13237, 'independant': 13238, 'pivoted': 13239, 'nogoods': 13240, 'yinyang': 13241, 'kqml': 13242, 'glueqos': 13243, 'sweeten': 13244, 'swings': 13245, 'twelve': 13246, 'limitation': 13247, 'critac': 13248, 'ariane': 13249, '784': 13250, 'dtgolog': 13251, 'rationalizability': 13252, 'flowgraph': 13253, 'encarta': 13254, 'siphon': 13255, 'webcrawler': 13256, 'empathetic': 13257, 'eco': 13258, 'places': 13259, 'plagiarized': 13260, 'predicated': 13261, 'syntagrus': 13262, 'starvation': 13263, 'commuting': 13264, 'sync': 13265, 'tinylex': 13266, 'kids': 13267, 'multilogue': 13268, 'bmd': 13269, 'tboxes': 13270, 'stratifiable': 13271, 'gspim': 13272, 'mizar': 13273}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5pV6n1VIyX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ref_to = tokenizer.texts_to_sequences(cross_ref2.ref_to)\n",
        "ref_from = tokenizer.texts_to_sequences(cross_ref2.ref_from)\n",
        "merged = tokenizer.texts_to_sequences(train3.merged)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSe-7MEtcgXE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "29adf30b-3d12-4db2-b956-42b720753921"
      },
      "source": [
        "print(ref_to[:10])\n",
        "print(ref_from[:10])\n",
        "print(merged[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3, 59, 1, 55, 827, 8, 176, 35, 3695, 484, 1003, 1321, 5165, 161, 5, 8, 176], [142, 118, 1, 836, 119, 18, 19, 4360, 3, 90, 57, 1329, 18, 63, 617, 102, 4, 49, 596, 559, 988, 634, 9, 180, 58], [7090, 422, 56, 2207, 193, 56, 40, 10, 302, 8, 359, 210, 9, 326, 2, 261, 1166, 4, 750, 1075, 1, 40, 10, 143, 8, 176, 152, 37, 2250, 5, 3, 195, 2, 980, 476, 12, 3058, 4, 937, 10117, 475, 56, 146, 5, 49, 29, 14, 818, 980, 476, 1, 6, 130, 2, 704, 24, 56, 8, 6, 56, 15, 3, 154, 72, 888, 56, 210, 1160, 24, 56, 8, 12690, 3, 16, 1, 888, 4, 1548, 56, 704, 130, 2, 2340, 4674, 24, 56, 8], [74, 29, 1474, 4, 228, 1381], [53, 2233, 937, 4, 3721, 108, 1, 1092, 3324, 8, 230, 70, 8, 35, 1, 272, 108, 35, 484, 133, 416, 2229, 69, 35, 484, 1456, 319, 33, 3370, 975, 11, 160, 634, 9, 54, 1, 35, 272, 108, 35, 272, 108, 181, 319, 2, 1626, 5, 45, 29, 110, 58, 1, 35, 272, 108, 5, 45, 29], [], [6450, 3, 107, 26, 16, 1, 433, 26, 215], [], [3520, 6, 452, 3088, 3135, 77, 761, 447, 1, 1938, 1354, 48, 4, 770, 325], [86, 11, 142, 2, 18, 46, 19, 12, 74, 83]]\n",
            "[[], [1081, 651, 83, 1, 3, 195, 2, 165, 83, 40, 53, 23, 48, 517, 3438, 2, 663, 5, 6, 6095, 23, 43, 16], [], [], [185, 1200, 1866, 33, 1027, 6103], [], [], [], [], [226, 782, 5, 74, 29]]\n",
            "[[123, 239, 421, 2, 766, 9, 133, 5, 8, 176, 3, 59, 1, 55, 827, 8, 176, 35, 3695, 484, 1003, 1321, 5165, 161, 5, 8, 176], [49, 2612, 1299, 58, 4, 428, 57, 142, 118, 1, 836, 119, 18, 19, 4360, 3, 90, 57, 1329, 18, 63, 617, 102, 4, 49, 596, 559, 988, 634, 9, 180, 58, 1081, 651, 83, 1, 3, 195, 2, 165, 83, 40, 53, 23, 48, 517, 3438, 2, 663, 5, 6, 6095, 23, 43, 16], [2432, 56, 210, 6588, 530, 2, 2142, 980, 476, 7090, 422, 56, 2207, 193, 56, 40, 10, 302, 8, 359, 210, 9, 326, 2, 261, 1166, 4, 750, 1075, 1, 40, 10, 143, 8, 176, 152, 37, 2250, 5, 3, 195, 2, 980, 476, 12, 3058, 4, 937, 10117, 475, 56, 146, 5, 49, 29, 14, 818, 980, 476, 1, 6, 130, 2, 704, 24, 56, 8, 6, 56, 15, 3, 154, 72, 888, 56, 210, 1160, 24, 56, 8, 12690, 3, 16, 1, 888, 4, 1548, 56, 704, 130, 2, 2340, 4674, 24, 56, 8], [6589, 3, 346, 9, 17, 46, 16, 74, 29, 1474, 4, 228, 1381], [924, 568, 30, 156, 2, 484, 1626, 5, 45, 662, 5, 6, 106, 2, 123, 35, 53, 2233, 937, 4, 3721, 108, 1, 1092, 3324, 8, 230, 70, 8, 35, 1, 272, 108, 35, 484, 133, 416, 2229, 69, 35, 484, 1456, 319, 33, 3370, 975, 11, 160, 634, 9, 54, 1, 35, 272, 108, 35, 272, 108, 181, 319, 2, 1626, 5, 45, 29, 110, 58, 1, 35, 272, 108, 5, 45, 29, 185, 1200, 1866, 33, 1027, 6103], [266, 825, 2, 1897, 5, 1898, 192], [6590, 3, 127, 65, 375, 14, 7, 1300, 433, 26, 6450, 3, 107, 26, 16, 1, 433, 26, 215], [908, 6, 6592, 2143, 579, 6, 282, 2, 21, 3143, 5, 15, 767], [6593, 1030, 3, 6594, 1127, 283, 1, 6, 15, 10, 2615, 50, 3520, 6, 452, 3088, 3135, 77, 761, 447, 1, 1938, 1354, 48, 4, 770, 325], [114, 1207, 93, 1, 6, 67, 2, 74, 1627, 86, 11, 142, 2, 18, 46, 19, 12, 74, 83, 226, 782, 5, 74, 29]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRFb_raUdjZ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "6405a921-547a-44cc-cfe7-ec1807410402"
      },
      "source": [
        "cross_ref2.ref_to[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    a framework for clustering evolving data strea...\n",
              "1    implementation techniques for main memory data...\n",
              "2    statix making xml count answering xml queries ...\n",
              "3    temporal databases   status and research direc...\n",
              "4    dynamic itemset counting and implication rules...\n",
              "5                                                noref\n",
              "6    gemini a natural language system for spoken la...\n",
              "7                                                noref\n",
              "8    knowing the users every move user activity tra...\n",
              "9    towards an implementation of database manageme...\n",
              "Name: ref_to, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdxF8D9Uf9fT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "6622ce1a-67d7-4a3e-99a7-59b88d7bb9f5"
      },
      "source": [
        "cross_ref2.ref_from[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                noref\n",
              "1    providing better support for a class of decisi...\n",
              "2                                                noref\n",
              "3                                                noref\n",
              "4         pattern lattice traversal by selective jumps\n",
              "5                                                noref\n",
              "6                                                noref\n",
              "7                                                noref\n",
              "8                                                noref\n",
              "9             generalized events in temporal databases\n",
              "Name: ref_from, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFjJsvcPJPhu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "623174d4-2278-4156-9b8f-39e0e389736d"
      },
      "source": [
        "print(len(max(ref_to, key=len)))\n",
        "sent_len_to = []\n",
        "for i in ref_to:\n",
        "  sent_len_to.append(len(i))\n",
        "\n",
        "plt.hist(sent_len_to,bins=28)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "371\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bgTQab1M1fA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "fea844af-a487-4e32-f767-b829e7e5f156"
      },
      "source": [
        "print(len(max(ref_from, key=len)))\n",
        "sent_len_from = []\n",
        "for i in ref_from:\n",
        "  sent_len_from.append(len(i))\n",
        "\n",
        "plt.hist(sent_len_from,bins=100)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkhoDQZIEGAiSpMZAkCQBBoIkqfl/ZfAo2P+KvcMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGMkknRejsFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "bb18801e-fc05-40f3-afd1-d80311de0b75"
      },
      "source": [
        "print(len(max(merged, key=len)))\n",
        "sent_len_merged = []\n",
        "for i in merged:\n",
        "  sent_len_merged.append(len(i))\n",
        "\n",
        "plt.hist(sent_len_merged,bins=100)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2340\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAQHUlEQVR4nO3dbYxcV33H8e8Pm4QKKHGIa1m21TXF\nUhVeECIrcQVCLRGOk1R1KgFKVTVWaslvggRSq9YpL0KBSEmlkhKpRHKJVQdRQsSDYhHa4IYg1Bd5\n2EDIY4OX4Ci2knjBJoAQaRP+fTFno2nY9e7au7Pxnu9HGs25/3tm5pyrmd/cvXNnNlWFJKkPr1vq\nAUiSRsfQl6SOGPqS1BFDX5I6YuhLUkdWLvUATuScc86psbGxpR6GJJ1WHnzwwR9X1erp1r2mQ39s\nbIzx8fGlHoYknVaSPD3TOg/vSFJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtS\nR17T38g9VWO773ylfej6y5ZwJJL02uCeviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0\nJakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkfmFPpJDiV5JMlDScZb7ewkB5IcbNerWj1JbkoykeTh\nJOcP3c+O1v9gkh2LMyVJ0kzms6f/R1V1XlVtbsu7gburahNwd1sGuATY1C67gJth8CYBXAtcCFwA\nXDv1RiFJGo1TObyzHdjX2vuAy4fqt9bAvcBZSdYCFwMHqupYVR0HDgDbTuHxJUnzNNfQL+CbSR5M\nsqvV1lTVs639HLCmtdcBzwzd9nCrzVT/f5LsSjKeZHxycnKOw5MkzcVc/3PWe6rqSJLfAQ4k+e/h\nlVVVSWohBlRVe4A9AJs3b16Q+5QkDcxpT7+qjrTro8DXGByTf74dtqFdH23djwAbhm6+vtVmqkuS\nRmTW0E/yxiRvnmoDW4FHgf3A1Bk4O4A7Wns/cGU7i2cL8EI7DHQXsDXJqvYB7tZWkySNyFwO76wB\nvpZkqv+/VdV/JHkAuD3JTuBp4EOt/zeAS4EJ4JfAVQBVdSzJJ4EHWr9PVNWxBZuJJGlWs4Z+VT0F\nvHOa+k+Ai6apF3D1DPe1F9g7/2FKkhaC38iVpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakj\nhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLo\nS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SerInEM/yYok30vy9ba8\nMcl9SSaSfCnJGa1+ZlueaOvHhu7jmlZ/MsnFCz0ZSdKJzWdP/yPAE0PLNwA3VtXbgePAzlbfCRxv\n9RtbP5KcC1wBvAPYBnw2yYpTG74kaT7mFPpJ1gOXAZ9rywHeB3y5ddkHXN7a29sybf1Frf924Laq\nerGqfgRMABcsxCQkSXMz1z39fwL+Bvh1W34r8NOqeqktHwbWtfY64BmAtv6F1v+V+jS3eUWSXUnG\nk4xPTk7OYyqSpNnMGvpJ/hg4WlUPjmA8VNWeqtpcVZtXr149ioeUpG6snEOfdwN/kuRS4A3AbwOf\nAc5KsrLtza8HjrT+R4ANwOEkK4G3AD8Zqk8Zvo0kaQRm3dOvqmuqan1VjTH4IPZbVfXnwD3AB1q3\nHcAdrb2/LdPWf6uqqtWvaGf3bAQ2Afcv2EwkSbOay57+TP4WuC3Jp4DvAbe0+i3A55NMAMcYvFFQ\nVY8luR14HHgJuLqqXj6Fx5ckzdO8Qr+qvg18u7WfYpqzb6rqV8AHZ7j9dcB18x2kJGlh+I1cSeqI\noS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6\nktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9J\nHTH0Jakjhr4kdcTQl6SOzBr6Sd6Q5P4k30/yWJK/b/WNSe5LMpHkS0nOaPUz2/JEWz82dF/XtPqT\nSS5erElJkqY3lz39F4H3VdU7gfOAbUm2ADcAN1bV24HjwM7WfydwvNVvbP1Ici5wBfAOYBvw2SQr\nFnIykqQTmzX0a+AXbfH17VLA+4Avt/o+4PLW3t6WaesvSpJWv62qXqyqHwETwAULMgtJ0pzM6Zh+\nkhVJHgKOAgeAHwI/raqXWpfDwLrWXgc8A9DWvwC8dbg+zW2GH2tXkvEk45OTk/OfkSRpRnMK/ap6\nuarOA9Yz2Dv//cUaUFXtqarNVbV59erVi/UwktSleZ29U1U/Be4B/gA4K8nKtmo9cKS1jwAbANr6\ntwA/Ga5PcxtJ0gjM5eyd1UnOau3fAt4PPMEg/D/Quu0A7mjt/W2Ztv5bVVWtfkU7u2cjsAm4f6Em\nIkma3crZu7AW2NfOtHkdcHtVfT3J48BtST4FfA+4pfW/Bfh8kgngGIMzdqiqx5LcDjwOvARcXVUv\nL+x0JEknMmvoV9XDwLumqT/FNGffVNWvgA/OcF/XAdfNf5iSpIXgN3IlqSOGviR1ZC7H9JeFsd13\nvtI+dP1lSzgSSVo67ulLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J\n6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SO\nGPqS1BFDX5I6YuhLUkcMfUnqyKyhn2RDknuSPJ7ksSQfafWzkxxIcrBdr2r1JLkpyUSSh5OcP3Rf\nO1r/g0l2LN60JEnTmcue/kvAX1XVucAW4Ook5wK7gburahNwd1sGuATY1C67gJth8CYBXAtcCFwA\nXDv1RiFJGo1ZQ7+qnq2q77b2z4EngHXAdmBf67YPuLy1twO31sC9wFlJ1gIXAweq6lhVHQcOANsW\ndDaSpBOa1zH9JGPAu4D7gDVV9Wxb9RywprXXAc8M3exwq81Uf/Vj7EoynmR8cnJyPsOTJM1izqGf\n5E3AV4CPVtXPhtdVVQG1EAOqqj1VtbmqNq9evXoh7lKS1Mwp9JO8nkHgf6GqvtrKz7fDNrTro61+\nBNgwdPP1rTZTXZI0InM5eyfALcATVfXpoVX7gakzcHYAdwzVr2xn8WwBXmiHge4CtiZZ1T7A3dpq\nkqQRWTmHPu8G/gJ4JMlDrfZ3wPXA7Ul2Ak8DH2rrvgFcCkwAvwSuAqiqY0k+CTzQ+n2iqo4tyCwk\nSXMya+hX1X8BmWH1RdP0L+DqGe5rL7B3PgOUJC0cv5ErSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+S\nOmLoS1JHDH1J6oihL0kdmcvPMCw7Y7vvfKV96PrLlnAkkjRa7ulLUkcMfUnqiKEvSR0x9CWpI4a+\nJHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtS\nRwx9SeqIoS9JHZk19JPsTXI0yaNDtbOTHEhysF2vavUkuSnJRJKHk5w/dJsdrf/BJDsWZzqSpBOZ\ny57+vwLbXlXbDdxdVZuAu9sywCXApnbZBdwMgzcJ4FrgQuAC4NqpNwpJ0ujMGvpV9R3g2KvK24F9\nrb0PuHyofmsN3AuclWQtcDFwoKqOVdVx4AC/+UYiSVpkJ3tMf01VPdvazwFrWnsd8MxQv8OtNlP9\nNyTZlWQ8yfjk5ORJDk+SNJ1T/iC3qgqoBRjL1P3tqarNVbV59erVC3W3kiROPvSfb4dtaNdHW/0I\nsGGo3/pWm6kuSRqhkw39/cDUGTg7gDuG6le2s3i2AC+0w0B3AVuTrGof4G5ttSU3tvvOVy6StNyt\nnK1Dki8Cfwick+Qwg7NwrgduT7ITeBr4UOv+DeBSYAL4JXAVQFUdS/JJ4IHW7xNV9eoPhyVJi2zW\n0K+qP5th1UXT9C3g6hnuZy+wd16jkyQtKL+RK0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtS\nRwx9SerIrF/O6snwTzEcuv6yJRyJJC0O9/QlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqI\noS9JHfHLWTPwi1qSliP39CWpI4a+JHXE0Jekjhj6ktQRP8idAz/UlbRcuKcvSR0x9CWpIx7emScP\n9Ug6nbmnL0kdcU//FLjXL+l0456+JHVk5Hv6SbYBnwFWAJ+rqutHPYbFMLzXP8y/ACS9low09JOs\nAP4ZeD9wGHggyf6qenyU4xglDwFJei0Z9Z7+BcBEVT0FkOQ2YDuwbEN/2Ex/DSwU31QkzWbUob8O\neGZo+TBw4XCHJLuAXW3xF0mePMnHOgf48Une9rSUG36j1N02mIHbwW0AfW2D351pxWvu7J2q2gPs\nOdX7STJeVZsXYEinLbfBgNvBbQBugymjPnvnCLBhaHl9q0mSRmDUof8AsCnJxiRnAFcA+0c8Bknq\n1kgP71TVS0k+DNzF4JTNvVX12CI93CkfIloG3AYDbge3AbgNAEhVLfUYJEkj4jdyJakjhr4kdWRZ\nhn6SbUmeTDKRZPdSj2cxJTmU5JEkDyUZb7WzkxxIcrBdr2r1JLmpbZeHk5y/tKM/OUn2Jjma5NGh\n2rznnGRH638wyY6lmMvJmmEbfDzJkfZceCjJpUPrrmnb4MkkFw/VT9vXSpINSe5J8niSx5J8pNW7\nei7MW1UtqwuDD4h/CLwNOAP4PnDuUo9rEed7CDjnVbV/AHa39m7ghta+FPh3IMAW4L6lHv9Jzvm9\nwPnAoyc7Z+Bs4Kl2vaq1Vy313E5xG3wc+Otp+p7bXgdnAhvb62PF6f5aAdYC57f2m4EftLl29VyY\n72U57um/8lMPVfU/wNRPPfRkO7CvtfcBlw/Vb62Be4GzkqxdigGeiqr6DnDsVeX5zvli4EBVHauq\n48ABYNvij35hzLANZrIduK2qXqyqHwETDF4np/VrpaqerarvtvbPgScYfOu/q+fCfC3H0J/upx7W\nLdFYRqGAbyZ5sP2EBcCaqnq2tZ8D1rT2ct42853zct0WH26HLvZOHdagg22QZAx4F3AfPhdOaDmG\nfm/eU1XnA5cAVyd57/DKGvz92tV5uT3OubkZ+D3gPOBZ4B+XdjijkeRNwFeAj1bVz4bXdfxcmNFy\nDP2ufuqhqo6066PA1xj8yf781GGbdn20dV/O22a+c15226Kqnq+ql6vq18C/MHguwDLeBklezyDw\nv1BVX23l7p8LJ7IcQ7+bn3pI8sYkb55qA1uBRxnMd+oMhB3AHa29H7iyncWwBXhh6M/g091853wX\nsDXJqnYYZGurnbZe9fnMnzJ4LsBgG1yR5MwkG4FNwP2c5q+VJAFuAZ6oqk8Prer+uXBCS/1J8mJc\nGHxK/wMGZyZ8bKnHs4jzfBuDMy6+Dzw2NVfgrcDdwEHgP4GzWz0M/onND4FHgM1LPYeTnPcXGRy+\n+F8Gx193nsycgb9k8KHmBHDVUs9rAbbB59scH2YQcGuH+n+sbYMngUuG6qftawV4D4NDNw8DD7XL\npb09F+Z78WcYJKkjy/HwjiRpBoa+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6sj/AdUC6b2Zfsmn\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRzpvZH6_Wg1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenize train data (on the whole set of labeled data)\n",
        "X = tokenizer.texts_to_sequences(train.title)\n",
        "X = pad_sequences(X, maxlen=20)\n",
        "\n",
        "X_to = tokenizer.texts_to_sequences(train3.ref_to)\n",
        "X_to = pad_sequences(X_to, maxlen=100)\n",
        "\n",
        "X_from = tokenizer.texts_to_sequences(train3.ref_from)\n",
        "X_from = pad_sequences(X_from, maxlen=100)\n",
        "\n",
        "X_merged = tokenizer.texts_to_sequences(train3.merged)\n",
        "X_merged = pad_sequences(X_merged, maxlen=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AQaDYz-WUGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TOKENIZE TEST SET\n",
        "\n",
        "X_new = tokenizer.texts_to_sequences(test3.title)\n",
        "X_new = pad_sequences(X_new, maxlen=20)\n",
        "\n",
        "X_new_to = tokenizer.texts_to_sequences(test3.ref_to)\n",
        "X_new_to = pad_sequences(X_new_to, maxlen=100)\n",
        "\n",
        "X_new_from = tokenizer.texts_to_sequences(test3.ref_from)\n",
        "X_new_from = pad_sequences(X_new_from, maxlen=100)\n",
        "\n",
        "X_new_merged = tokenizer.texts_to_sequences(test3.merged)\n",
        "X_new_merged = pad_sequences(X_new_merged, maxlen=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpN4TczxPaz7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "35c58445-98b0-4f16-bcdb-12d9732f5988"
      },
      "source": [
        "X[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,  123,\n",
              "         239,  421,    2,  766,    9,  133,    5,    8,  176],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,   49, 2612, 1299,   58,    4,  428,   57],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "        2432,   56,  210, 6588,  530,    2, 2142,  980,  476],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0, 6589,    3,  346,    9,   17,   46,   16],\n",
              "       [   0,    0,    0,    0,  924,  568,   30,  156,    2,  484, 1626,\n",
              "           5,   45,  662,    5,    6,  106,    2,  123,   35],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,  266,  825,    2, 1897,    5, 1898,  192],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0, 6590,\n",
              "           3,  127,   65,  375,   14,    7, 1300,  433,   26],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,  908,    6, 6592, 2143,\n",
              "         579,    6,  282,    2,   21, 3143,    5,   15,  767],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0, 6593, 1030,    3,\n",
              "        6594, 1127,  283,    1,    6,   15,   10, 2615,   50],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "         114, 1207,   93,    1,    6,   67,    2,   74, 1627]],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OWcwp6HhUa9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "449f4200-d0cf-4ef6-ca85-ed423adf4988"
      },
      "source": [
        "X_to[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,  142,  118,    1,  836,  119,   18,   19, 4360,\n",
              "          3,   90,   57, 1329,   18,   63,  617,  102,    4,   49,  596,\n",
              "        559,  988,  634,    9,  180,   58], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn_aFPDIhcxg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "outputId": "f76c92af-7db0-4d76-9dfd-a730c550b0e8"
      },
      "source": [
        "X_from[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0, 1081,  651,   83,    1,    3,  195,\n",
              "          2,  165,   83,   40,   53,   23,   48,  517, 3438,    2,  663,\n",
              "          5,    6, 6095,   23,   43,   16], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1ws3paUl4Op",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "5eaaee7d-6c18-4d16-8faa-82a25daf4118"
      },
      "source": [
        "X_merged[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,   49, 2612, 1299,   58,    4,  428,   57,  142,  118,\n",
              "          1,  836,  119,   18,   19, 4360,    3,   90,   57, 1329,   18,\n",
              "         63,  617,  102,    4,   49,  596,  559,  988,  634,    9,  180,\n",
              "         58, 1081,  651,   83,    1,    3,  195,    2,  165,   83,   40,\n",
              "         53,   23,   48,  517, 3438,    2,  663,    5,    6, 6095,   23,\n",
              "         43,   16], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GIS1GRPNPqcv",
        "colab": {}
      },
      "source": [
        "# MAKE A SECOND DATA SPLIT\n",
        "X_train_, X_test_, Y_train_, Y_test_ = train_test_split(X, Y, test_size=0.2, random_state=245, shuffle=True)\n",
        "X_to_train_, X_to_test_, X_from_train_, X_from_test_ = train_test_split(X_to,X_from, test_size=0.2, random_state=245, shuffle=True)\n",
        "X_merged_train_, X_merged_test_ = train_test_split(X_merged, test_size=0.2, random_state=245, shuffle=True)\n",
        "X_train2_, X_test2_ = train_test_split(np.array(train2), test_size=0.2, random_state=245, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN7PoNecGqvp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "58baacd0-1a5c-48af-86e5-a7dbf208d3e2"
      },
      "source": [
        "X_to_train_[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,   11,  172,   27,   20,    9,   10, 1798,   60,   24,\n",
              "         143,  146,    7,  516,   23, 1962],\n",
              "       [ 699,   35,  484,  161,    5,    3, 3142,   34, 1686,   51,   12,\n",
              "        1686, 2576,    4, 2181, 2576,  237,    3,  716, 2032,    2,   34,\n",
              "         378,  102,   52,   71,    2,   34, 1686,  329,  919, 2513,  586,\n",
              "         237,    1,   34,   51,  863,    6,  307, 2446,    5,   34,  378,\n",
              "         311,  152, 1279,    5,  152,   37],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0],\n",
              "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C40fgCMoQLaU",
        "colab_type": "text"
      },
      "source": [
        "### Training models + summary\n",
        "\n",
        "\"Merged\" means titles were merged in the following order: \"title\" + \"ref_to\" + \"ref_from\".\n",
        "\n",
        "3 separate embeddings means that \"title\" + \"ref_to\" + \"ref_from\" were inputed as three diff. embeddings (in diferent layers).\n",
        "\n",
        "3 concatenated embeddings means that \"title\" + \"ref_to\" + \"ref_from\" were concatenated (all with their paddings) before feeding to a model.\n",
        "\n",
        " in/out ref max size means per type of reference (eg. 50 per ref_to, 50 per ref_from). \n",
        "\n",
        "\n",
        "| Titles and in/out   refs  | Model                                    | Max input1 length                            | Max input2 length               | Loss   | Accuracy | Epoch |\n",
        "|---------------------------|------------------------------------------|----------------------------------------------|---------------------------------|--------|----------|-------|\n",
        "|                           |                                          | title size or merged title+ref size + references | in/out ref max size (*2) |        |          |       |\n",
        "| Merged                    | CNN(emb=100,hu=500,k=3,dense=250)        | 20                                           |  --                             | 0.6269 | 0.7883   | 3     |\n",
        "| Merged                    | CNN(emb=100,hu=500,k=3,dense=250)        | 50                                           |  --                             | 0.5589 | 0.8009   | 3     |\n",
        "| Merged                    | CNN(emb=100,hu=500,k=3,dense=250)        | 50                                           |  --                             | 0.56   | 0.8009   | 2     |\n",
        "| Merged                    | CNN(emb=100,hu=500,k=3,dense=250)        | 100                                          |  --                             | 0.54   | 0.802    | 2     |\n",
        "| Merged                    | CNN(emb=100,hu=500,k=3,dense=250)        | 200                                          |  --                             | **0.5304** | 0.8016   | 2     |\n",
        "|                           |                                          |                                              |                                 |        |          |       |\n",
        "| Merged                    | LSTM(emb=128,hu=128)                     | 50                                           |  --                             | 0.5494 | 0.8044   | 4     |\n",
        "| Merged                    | LSTM(emb=128,hu=128)                     | 100                                          |  --                             | 0.5704 | 0.7989   | 3     |\n",
        "| Merged                    | LSTM(emb=128,hu=128)                     | 200                                          |  --                             | **0.5435** | **0.8114**   | 4     |\n",
        "|                           |                                          |                                              |                                 |        |          |       |\n",
        "| Merged                    | CNN(emb=100, ks=3,4,5, hu=100,dense=500) | 50                                           |  --                             | 0.5426 | 0.8059   | 2     |\n",
        "| Merged                    | CNN(emb=100, ks=3,4,5, hu=100,dense=500) | 100                                          |  --                             |        |          |       |\n",
        "| Merged                    | CNN(emb=100, ks=3,4,5, hu=100,dense=500) | 200                                          |  --                             | 0.5441 | 0.8009   | 2     |\n",
        "|                           |                                          |                                              |                                 |        |          |       |\n",
        "| 3 separate embeddings     | CNN(emb=100,k=3,hu=100,dense=500)        | 20                                           | 50                              | 0.5524 | 0.7985   | 3     |\n",
        "| 3 separate embeddings     | CNN(emb=100,k=3,hu=100,dense=500)        | 20                                           | 100                             | 0.5519 | 0.8024   | 3     |\n",
        "|                           |                                          |                                              |                                 |        |          |       |\n",
        "| 3 concatenated embeddings | CNN(emb=100,k=3,hu=500,dense=250)        | 20                                           | 100                             | 0.5387 | 0.802    | 2     |\n",
        "| 3 concatenated embeddings | CNN(emb=100,k=3,hu=500,dense=250)        | 20                                           | 100                             | 0.5487 | 0.8056   | 3     |\n",
        "|                           |                                          |                                              |                                 |        |          |       |\n",
        "| 3 concatenated embeddings | CNN(emb=100, ks=3,4,5, hu=100,dense=500) | 20                                           | 50                              | 0.5815 | 0.8087   | 2     |\n",
        "| 3 concatenated embeddings | CNN(emb=100, ks=3,4,5, hu=100,dense=500) | 20                                           | 100                             | 0.5494 | 0.8083   | 3     |\n",
        "| 3 concatenated embeddings | CNN(emb=100, ks=4,6,8, hu=100,dense=500) | 20                                           | 50                              | **0.5402** | **0.8071**   | 4     |\n",
        "| 3 concatenated embeddings | CNN(emb=100, ks=4,6,8, hu=100,dense=500) | 20                                           | 100                             | **0.5351** | **0.8075**   | 3     |\n",
        "|                           |                                          |                                              |                                 |        |          |       |\n",
        "| 3 concatenated embeddings | LSTM(emb=128,hu=128), RMSprop lr=0.01    | 20                                           | 50                              | 0.5632 | 0.8052   | 3     |\n",
        "| 3 concatenated embeddings | LSTM(emb=128,hu=128), RMSprop lr=0.01    | 20                                           | 100                             | 0.596  | 0.7903   | 4     |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLJCnp7GpnHQ",
        "colab_type": "text"
      },
      "source": [
        "#### With only MERGED titles/refs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiDMzaebuFP0",
        "colab_type": "text"
      },
      "source": [
        "##### CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zUyrhVImT63",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "outputId": "1f01f851-ac5f-4f0e-b0a6-e9ae1bd1645f"
      },
      "source": [
        "# with input_length=20\n",
        "\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "kernel_size = 3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(dict_len3 + 1, output_dim=100,\n",
        "                    input_length=20))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(500,\n",
        "                 kernel_size,\n",
        "#  \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input.\n",
        "                 padding='same', # changed padding here; 0.78p better with \"same\"\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(250))\n",
        "# model.add(Dropout(0.2)) # REMOVED DROPOUT HERE\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "history = model.fit(X_merged_train_, Y_train_, validation_data = (X_merged_test_, Y_test_), batch_size=64, epochs=5) \n",
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 20, 100)           1327400   \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 20, 100)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 20, 500)           150500    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_5 (Glob (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 250)               125250    \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 5)                 1255      \n",
            "=================================================================\n",
            "Total params: 1,604,405\n",
            "Trainable params: 1,604,405\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/5\n",
            "10223/10223 [==============================] - 11s 1ms/sample - loss: 0.9428 - accuracy: 0.6483 - val_loss: 0.6760 - val_accuracy: 0.7586\n",
            "Epoch 2/5\n",
            "10223/10223 [==============================] - 11s 1ms/sample - loss: 0.5465 - accuracy: 0.8035 - val_loss: 0.6269 - val_accuracy: 0.7703\n",
            "Epoch 3/5\n",
            "10223/10223 [==============================] - 10s 1ms/sample - loss: 0.4329 - accuracy: 0.8455 - val_loss: 0.6113 - val_accuracy: 0.7883\n",
            "Epoch 4/5\n",
            "10223/10223 [==============================] - 11s 1ms/sample - loss: 0.3506 - accuracy: 0.8753 - val_loss: 0.6790 - val_accuracy: 0.7633\n",
            "Epoch 5/5\n",
            "10223/10223 [==============================] - 11s 1ms/sample - loss: 0.2905 - accuracy: 0.8998 - val_loss: 0.6581 - val_accuracy: 0.7848\n",
            "2556/2556 [==============================] - 0s 178us/sample - loss: 3.1249 - accuracy: 0.2520\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.1248556922112645, 0.2519562]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTV2LHMkpkm6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "outputId": "77dbb66b-ea86-4b9a-9a52-7c217be4ae9d"
      },
      "source": [
        "# with input_length=50\n",
        "\n",
        "np.random.seed(42)\n",
        "random.seed(12345)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(1234) \n",
        "\n",
        "kernel_size = 3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(dict_len3 + 1, output_dim=100,\n",
        "                    input_length=50))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(500,\n",
        "                 kernel_size,\n",
        "#  \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input.\n",
        "                 padding='same', # changed padding here; 0.78p better with \"same\"\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(250))\n",
        "# model.add(Dropout(0.2)) # REMOVED DROPOUT HERE\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "model.summary()\n",
        "history = model.fit(X_merged_train_, Y_train_, validation_data = (X_merged_test_, Y_test_), batch_size=64, epochs=5) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_10 (Embedding)     (None, 50, 100)           1327400   \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 50, 100)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_10 (Conv1D)           (None, 50, 500)           150500    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_10 (Glo (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 250)               125250    \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 5)                 1255      \n",
            "=================================================================\n",
            "Total params: 1,604,405\n",
            "Trainable params: 1,604,405\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/5\n",
            "10223/10223 [==============================] - 19s 2ms/sample - loss: 0.9104 - accuracy: 0.6542 - val_loss: 0.6262 - val_accuracy: 0.7656\n",
            "Epoch 2/5\n",
            "10223/10223 [==============================] - 19s 2ms/sample - loss: 0.5071 - accuracy: 0.8156 - val_loss: 0.5921 - val_accuracy: 0.7907\n",
            "Epoch 3/5\n",
            "10223/10223 [==============================] - 19s 2ms/sample - loss: 0.4003 - accuracy: 0.8575 - val_loss: 0.5589 - val_accuracy: 0.8009\n",
            "Epoch 4/5\n",
            "10223/10223 [==============================] - 19s 2ms/sample - loss: 0.3260 - accuracy: 0.8887 - val_loss: 0.6348 - val_accuracy: 0.7790\n",
            "Epoch 5/5\n",
            "10223/10223 [==============================] - 19s 2ms/sample - loss: 0.2596 - accuracy: 0.9093 - val_loss: 0.6166 - val_accuracy: 0.8009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p5IPXZor6ecZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "7fc0831a-d0a4-4973-9ae8-552a9643d579"
      },
      "source": [
        "# with input_length=50, compatible seed with other models below\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5) \n",
        "\n",
        "kernel_size = 3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(dict_len3 + 1, output_dim=100,input_length=50))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(500,\n",
        "                 kernel_size,\n",
        "#  \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input.\n",
        "                 padding='same', # changed padding here; 0.78p better with \"same\"\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(250))\n",
        "# model.add(Dropout(0.2)) # REMOVED DROPOUT HERE\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# model.summary()\n",
        "history = model.fit(X_merged_train_, Y_train_, validation_data = (X_merged_test_, Y_test_), batch_size=64, epochs=5) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/5\n",
            "10223/10223 [==============================] - 19s 2ms/sample - loss: 0.9057 - accuracy: 0.6540 - val_loss: 0.6246 - val_accuracy: 0.7825\n",
            "Epoch 2/5\n",
            "10223/10223 [==============================] - 18s 2ms/sample - loss: 0.5097 - accuracy: 0.8180 - val_loss: 0.5600 - val_accuracy: 0.8009\n",
            "Epoch 3/5\n",
            "10223/10223 [==============================] - 18s 2ms/sample - loss: 0.4058 - accuracy: 0.8532 - val_loss: 0.5852 - val_accuracy: 0.7872\n",
            "Epoch 4/5\n",
            "10223/10223 [==============================] - 18s 2ms/sample - loss: 0.3322 - accuracy: 0.8834 - val_loss: 0.5718 - val_accuracy: 0.7938\n",
            "Epoch 5/5\n",
            "10223/10223 [==============================] - 18s 2ms/sample - loss: 0.2677 - accuracy: 0.9079 - val_loss: 0.6291 - val_accuracy: 0.7844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4qyaVOy-eZO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "8fb4e6fe-568b-45b8-c3eb-33640ec781bd"
      },
      "source": [
        "# with input_length=100, compatible seed with other models below\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5) \n",
        "\n",
        "kernel_size = 3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(dict_len3 + 1, output_dim=100,input_length=100))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(500,\n",
        "                 kernel_size,\n",
        "#  \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input.\n",
        "                 padding='same', # changed padding here; 0.78p better with \"same\"\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(250))\n",
        "# model.add(Dropout(0.2)) # REMOVED DROPOUT HERE\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# model.summary()\n",
        "history = model.fit(X_merged_train_, Y_train_, validation_data = (X_merged_test_, Y_test_), batch_size=64, epochs=5) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/5\n",
            "10223/10223 [==============================] - 30s 3ms/sample - loss: 0.8891 - accuracy: 0.6665 - val_loss: 0.6107 - val_accuracy: 0.7840\n",
            "Epoch 2/5\n",
            "10223/10223 [==============================] - 29s 3ms/sample - loss: 0.4963 - accuracy: 0.8226 - val_loss: 0.5400 - val_accuracy: 0.8020\n",
            "Epoch 3/5\n",
            "10223/10223 [==============================] - 29s 3ms/sample - loss: 0.3934 - accuracy: 0.8587 - val_loss: 0.5555 - val_accuracy: 0.7969\n",
            "Epoch 4/5\n",
            "10223/10223 [==============================] - 29s 3ms/sample - loss: 0.3268 - accuracy: 0.8856 - val_loss: 0.5519 - val_accuracy: 0.7958\n",
            "Epoch 5/5\n",
            "10223/10223 [==============================] - 29s 3ms/sample - loss: 0.2644 - accuracy: 0.9104 - val_loss: 0.5987 - val_accuracy: 0.7887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUqUZNUumuEj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "63f1ecef-0fc5-4ed6-b14a-53552157e8e0"
      },
      "source": [
        "# with input_length=200, compatible seed with other models below\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5) \n",
        "\n",
        "kernel_size = 3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(dict_len3 + 1, output_dim=100,input_length=200))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(500,\n",
        "                 kernel_size,\n",
        "#  \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input.\n",
        "                 padding='same', # changed padding here; 0.78p better with \"same\"\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(250))\n",
        "# model.add(Dropout(0.2)) # REMOVED DROPOUT HERE\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "# model.summary()\n",
        "history = model.fit(X_merged_train_, Y_train_, validation_data = (X_merged_test_, Y_test_), batch_size=64, epochs=5) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/5\n",
            "10223/10223 [==============================] - 53s 5ms/sample - loss: 0.8956 - accuracy: 0.6660 - val_loss: 0.6186 - val_accuracy: 0.7813\n",
            "Epoch 2/5\n",
            "10223/10223 [==============================] - 52s 5ms/sample - loss: 0.4962 - accuracy: 0.8231 - val_loss: 0.5304 - val_accuracy: 0.8016\n",
            "Epoch 3/5\n",
            "10223/10223 [==============================] - 53s 5ms/sample - loss: 0.3924 - accuracy: 0.8587 - val_loss: 0.5562 - val_accuracy: 0.7981\n",
            "Epoch 4/5\n",
            "10223/10223 [==============================] - 54s 5ms/sample - loss: 0.3222 - accuracy: 0.8866 - val_loss: 0.5579 - val_accuracy: 0.7989\n",
            "Epoch 5/5\n",
            "10223/10223 [==============================] - 54s 5ms/sample - loss: 0.2626 - accuracy: 0.9078 - val_loss: 0.5904 - val_accuracy: 0.7962\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTcupetaoqXo",
        "colab_type": "text"
      },
      "source": [
        "##### CNN from paper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUxuz7Mttr52",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "db9aabe3-fc08-47bf-d299-07167b133576"
      },
      "source": [
        "# input length = 50\n",
        "\n",
        "def custom_CNN(input_length=50,vocab_size=dict_len3+1,emb_dim = 100):\n",
        "  # define CNN layer\n",
        "  inputs1 = Input(shape=(input_length,))\n",
        "  emb1 = Embedding(vocab_size, emb_dim)(inputs1)\n",
        "  conv1 = Conv1D(filters=100, kernel_size=3, padding='same', activation='relu', strides=1)(emb1)\n",
        "  drop1 = Dropout(0.5)(conv1)\n",
        "  pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
        "  flat1 = Flatten()(pool1)\n",
        "\n",
        "  inputs2 = Input(shape=(input_length,))\n",
        "  emb2 = Embedding(vocab_size, emb_dim)(inputs2)\n",
        "  conv2 = Conv1D(filters=100, kernel_size=4, padding='same', activation='relu', strides=1)(emb2)\n",
        "  drop2 = Dropout(0.5)(conv2)\n",
        "  pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
        "  flat2 = Flatten()(pool2)\n",
        "\n",
        "  inputs3 = Input(shape=(input_length,))\n",
        "  emb3 = Embedding(vocab_size, emb_dim)(inputs3)\n",
        "  conv3 = Conv1D(filters=100, kernel_size=5, padding='same', activation='relu', strides=1)(emb3)\n",
        "  drop3 = Dropout(0.5)(conv3)\n",
        "  pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
        "  flat3 = Flatten()(pool3)\n",
        "\n",
        "  # merge CNN output with reference stats\n",
        "  merged = concatenate([flat1, flat2, flat3])\n",
        "\n",
        "  dense1 = Dense(500, activation='relu')(merged)\n",
        "  outputs = Dense(5, activation=\"softmax\")(dense1)\n",
        "  model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  # print(model.summary())\n",
        "  # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "  return model\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "model = custom_CNN(input_length=50, vocab_size=dict_len3+1,emb_dim = 100)\n",
        "history = model.fit(x=[X_merged_train_,X_merged_train_,X_merged_train_], y=Y_train_, \n",
        "                    validation_data = ([X_merged_test_,X_merged_test_,X_merged_test_], Y_test_), batch_size=64, epochs=5) \n",
        "# save the model\n",
        "# model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/5\n",
            "10223/10223 [==============================] - 26s 3ms/sample - loss: 0.8278 - accuracy: 0.6861 - val_loss: 0.5671 - val_accuracy: 0.8059\n",
            "Epoch 2/5\n",
            "10223/10223 [==============================] - 25s 2ms/sample - loss: 0.4121 - accuracy: 0.8539 - val_loss: 0.5426 - val_accuracy: 0.8059\n",
            "Epoch 3/5\n",
            "10223/10223 [==============================] - 24s 2ms/sample - loss: 0.2517 - accuracy: 0.9103 - val_loss: 0.5958 - val_accuracy: 0.7950\n",
            "Epoch 4/5\n",
            "10223/10223 [==============================] - 23s 2ms/sample - loss: 0.1169 - accuracy: 0.9610 - val_loss: 0.7285 - val_accuracy: 0.7762\n",
            "Epoch 5/5\n",
            "10223/10223 [==============================] - 23s 2ms/sample - loss: 0.0476 - accuracy: 0.9855 - val_loss: 0.8951 - val_accuracy: 0.7833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXgtwDQ0uusW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "270aff00-0d49-47ea-c7d8-81dfc8fc342a"
      },
      "source": [
        "# input length = 100\n",
        "\n",
        "def custom_CNN(input_length=100,vocab_size=dict_len3+1,emb_dim = 100):\n",
        "  # define CNN layer\n",
        "  inputs1 = Input(shape=(input_length,))\n",
        "  emb1 = Embedding(vocab_size, emb_dim)(inputs1)\n",
        "  conv1 = Conv1D(filters=100, kernel_size=3, padding='same', activation='relu', strides=1)(emb1)\n",
        "  drop1 = Dropout(0.5)(conv1)\n",
        "  pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
        "  flat1 = Flatten()(pool1)\n",
        "\n",
        "  inputs2 = Input(shape=(input_length,))\n",
        "  emb2 = Embedding(vocab_size, emb_dim)(inputs2)\n",
        "  conv2 = Conv1D(filters=100, kernel_size=4, padding='same', activation='relu', strides=1)(emb2)\n",
        "  drop2 = Dropout(0.5)(conv2)\n",
        "  pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
        "  flat2 = Flatten()(pool2)\n",
        "\n",
        "  inputs3 = Input(shape=(input_length,))\n",
        "  emb3 = Embedding(vocab_size, emb_dim)(inputs3)\n",
        "  conv3 = Conv1D(filters=100, kernel_size=5, padding='same', activation='relu', strides=1)(emb3)\n",
        "  drop3 = Dropout(0.5)(conv3)\n",
        "  pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
        "  flat3 = Flatten()(pool3)\n",
        "\n",
        "  # merge CNN output with reference stats\n",
        "  merged = concatenate([flat1, flat2, flat3])\n",
        "\n",
        "  dense1 = Dense(500, activation='relu')(merged)\n",
        "  outputs = Dense(5, activation=\"softmax\")(dense1)\n",
        "  model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  # print(model.summary())\n",
        "  # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "  return model\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "model = custom_CNN(input_length=100, vocab_size=dict_len3+1,emb_dim = 100)\n",
        "history = model.fit(x=[X_merged_train_,X_merged_train_,X_merged_train_], y=Y_train_, \n",
        "                    validation_data = ([X_merged_test_,X_merged_test_,X_merged_test_], Y_test_), batch_size=64, epochs=5) \n",
        "# save the model\n",
        "# model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/5\n",
            "10223/10223 [==============================] - 44s 4ms/sample - loss: 0.8429 - accuracy: 0.6908 - val_loss: 0.5740 - val_accuracy: 0.8036\n",
            "Epoch 2/5\n",
            "10223/10223 [==============================] - 43s 4ms/sample - loss: 0.4068 - accuracy: 0.8554 - val_loss: 0.5339 - val_accuracy: 0.8056\n",
            "Epoch 3/5\n",
            "10223/10223 [==============================] - 43s 4ms/sample - loss: 0.2452 - accuracy: 0.9130 - val_loss: 0.6049 - val_accuracy: 0.7915\n",
            "Epoch 4/5\n",
            "10223/10223 [==============================] - 43s 4ms/sample - loss: 0.1163 - accuracy: 0.9597 - val_loss: 0.7270 - val_accuracy: 0.7852\n",
            "Epoch 5/5\n",
            "10223/10223 [==============================] - 42s 4ms/sample - loss: 0.0487 - accuracy: 0.9855 - val_loss: 0.9034 - val_accuracy: 0.7817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VP-BXEaWoouP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "f99a977d-c9e8-4302-d1cf-32ac11bb9f2a"
      },
      "source": [
        "# input length = 200\n",
        "\n",
        "def custom_CNN(input_length=200,vocab_size=dict_len3+1,emb_dim = 100):\n",
        "  # define CNN layer\n",
        "  inputs1 = Input(shape=(input_length,))\n",
        "  emb1 = Embedding(vocab_size, emb_dim)(inputs1)\n",
        "  conv1 = Conv1D(filters=100, kernel_size=3, padding='same', activation='relu', strides=1)(emb1)\n",
        "  drop1 = Dropout(0.5)(conv1)\n",
        "  pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
        "  flat1 = Flatten()(pool1)\n",
        "\n",
        "  inputs2 = Input(shape=(input_length,))\n",
        "  emb2 = Embedding(vocab_size, emb_dim)(inputs2)\n",
        "  conv2 = Conv1D(filters=100, kernel_size=4, padding='same', activation='relu', strides=1)(emb2)\n",
        "  drop2 = Dropout(0.5)(conv2)\n",
        "  pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
        "  flat2 = Flatten()(pool2)\n",
        "\n",
        "  inputs3 = Input(shape=(input_length,))\n",
        "  emb3 = Embedding(vocab_size, emb_dim)(inputs3)\n",
        "  conv3 = Conv1D(filters=100, kernel_size=5, padding='same', activation='relu', strides=1)(emb3)\n",
        "  drop3 = Dropout(0.5)(conv3)\n",
        "  pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
        "  flat3 = Flatten()(pool3)\n",
        "\n",
        "  # merge CNN output with reference stats\n",
        "  merged = concatenate([flat1, flat2, flat3])\n",
        "\n",
        "  dense1 = Dense(500, activation='relu')(merged)\n",
        "  outputs = Dense(5, activation=\"softmax\")(dense1)\n",
        "  model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  # print(model.summary())\n",
        "  # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "  return model\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "model = custom_CNN(input_length=200, vocab_size=dict_len3+1,emb_dim = 100)\n",
        "history = model.fit(x=[X_merged_train_,X_merged_train_,X_merged_train_], y=Y_train_, \n",
        "                    validation_data = ([X_merged_test_,X_merged_test_,X_merged_test_], Y_test_), batch_size=64, epochs=5) \n",
        "# save the model\n",
        "# model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/5\n",
            "10223/10223 [==============================] - 91s 9ms/sample - loss: 0.8777 - accuracy: 0.6860 - val_loss: 0.5883 - val_accuracy: 0.7966\n",
            "Epoch 2/5\n",
            "10223/10223 [==============================] - 89s 9ms/sample - loss: 0.4118 - accuracy: 0.8543 - val_loss: 0.5441 - val_accuracy: 0.8009\n",
            "Epoch 3/5\n",
            "10223/10223 [==============================] - 89s 9ms/sample - loss: 0.2574 - accuracy: 0.9094 - val_loss: 0.6205 - val_accuracy: 0.7903\n",
            "Epoch 4/5\n",
            "10223/10223 [==============================] - 90s 9ms/sample - loss: 0.1272 - accuracy: 0.9544 - val_loss: 0.7325 - val_accuracy: 0.7860\n",
            "Epoch 5/5\n",
            "10223/10223 [==============================] - 89s 9ms/sample - loss: 0.0535 - accuracy: 0.9848 - val_loss: 0.9590 - val_accuracy: 0.7766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUL_sdTo9vkm",
        "colab_type": "text"
      },
      "source": [
        "##### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD99DNUX9yF1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "e1a6bbae-e522-489c-f768-75ad2de16fd0"
      },
      "source": [
        "# with input_length=50\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len3 + 1, 128, input_length=50)) # adding trainable=True does not change thre result, trainable by default?\n",
        "model.add(LSTM(128, dropout=0.2)) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "history = model.fit(X_merged_train_, Y_train_, validation_data = (X_merged_test_, Y_test_), batch_size=64, epochs=5) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/5\n",
            "10223/10223 [==============================] - 25s 2ms/sample - loss: 0.9646 - accuracy: 0.6368 - val_loss: 0.6451 - val_accuracy: 0.7739\n",
            "Epoch 2/5\n",
            "10223/10223 [==============================] - 23s 2ms/sample - loss: 0.5355 - accuracy: 0.8144 - val_loss: 0.5962 - val_accuracy: 0.7793\n",
            "Epoch 3/5\n",
            "10223/10223 [==============================] - 24s 2ms/sample - loss: 0.4409 - accuracy: 0.8485 - val_loss: 0.5673 - val_accuracy: 0.7977\n",
            "Epoch 4/5\n",
            "10223/10223 [==============================] - 23s 2ms/sample - loss: 0.3812 - accuracy: 0.8692 - val_loss: 0.5493 - val_accuracy: 0.8044\n",
            "Epoch 5/5\n",
            "10223/10223 [==============================] - 23s 2ms/sample - loss: 0.3376 - accuracy: 0.8833 - val_loss: 0.5908 - val_accuracy: 0.7770\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x-HbRRj-wou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "fda26404-9f0a-42f7-eee5-83b24e8b05a8"
      },
      "source": [
        "# with input_length=100\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len3 + 1, 128, input_length=100)) # adding trainable=True does not change thre result, trainable by default?\n",
        "model.add(LSTM(128, dropout=0.2)) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "history = model.fit(X_merged_train_, Y_train_, validation_data = (X_merged_test_, Y_test_), batch_size=64, epochs=5) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/5\n",
            "10223/10223 [==============================] - 46s 4ms/sample - loss: 0.9743 - accuracy: 0.6359 - val_loss: 0.6593 - val_accuracy: 0.7625\n",
            "Epoch 2/5\n",
            "10223/10223 [==============================] - 44s 4ms/sample - loss: 0.5334 - accuracy: 0.8164 - val_loss: 0.5756 - val_accuracy: 0.7891\n",
            "Epoch 3/5\n",
            "10223/10223 [==============================] - 45s 4ms/sample - loss: 0.4395 - accuracy: 0.8508 - val_loss: 0.5704 - val_accuracy: 0.7989\n",
            "Epoch 4/5\n",
            "10223/10223 [==============================] - 45s 4ms/sample - loss: 0.3811 - accuracy: 0.8706 - val_loss: 0.5720 - val_accuracy: 0.7934\n",
            "Epoch 5/5\n",
            "10223/10223 [==============================] - 45s 4ms/sample - loss: 0.3379 - accuracy: 0.8837 - val_loss: 0.5809 - val_accuracy: 0.7860\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrUq6S54nVHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "outputId": "99f98980-d7a0-4ce6-8915-79f5d2c2cd82"
      },
      "source": [
        "# with input_length=200\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5) \n",
        "model = Sequential() \n",
        "model.add(Embedding(dict_len3 + 1, 128, input_length=200)) # adding trainable=True does not change thre result, trainable by default?\n",
        "model.add(LSTM(128, dropout=0.2)) \n",
        "model.add(Dense(5, activation=\"softmax\"))  \n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "history = model.fit(X_merged_train_, Y_train_, validation_data = (X_merged_test_, Y_test_), batch_size=64, epochs=4) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/4\n",
            "10223/10223 [==============================] - 91s 9ms/sample - loss: 0.9704 - accuracy: 0.6357 - val_loss: 0.6615 - val_accuracy: 0.7578\n",
            "Epoch 2/4\n",
            "10223/10223 [==============================] - 89s 9ms/sample - loss: 0.5343 - accuracy: 0.8153 - val_loss: 0.5484 - val_accuracy: 0.7938\n",
            "Epoch 3/4\n",
            "10223/10223 [==============================] - 89s 9ms/sample - loss: 0.4407 - accuracy: 0.8498 - val_loss: 0.5654 - val_accuracy: 0.7993\n",
            "Epoch 4/4\n",
            "10223/10223 [==============================] - 89s 9ms/sample - loss: 0.3814 - accuracy: 0.8671 - val_loss: 0.5435 - val_accuracy: 0.8114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IccjKeJDUiSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_new = tokenizer.texts_to_sequences(train.title)\n",
        "# X_new = pad_sequences(X_new, maxlen=20)\n",
        "\n",
        "# X_new_to = tokenizer.texts_to_sequences(train3.ref_to)\n",
        "# X_new_to = pad_sequences(X_new_to, maxlen=100)\n",
        "\n",
        "# X_new_from = tokenizer.texts_to_sequences(train3.ref_from)\n",
        "# X_new_from = pad_sequences(X_new_from, maxlen=100)\n",
        "\n",
        "# X_new_merged = tokenizer.texts_to_sequences(train3.merged)\n",
        "# X_new_merged = pad_sequences(X_new_merged, maxlen=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPjLmQ60WkwC",
        "colab_type": "text"
      },
      "source": [
        "##### Predict on test set for kaggle (10th upload)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KtHjnROMUKQN",
        "colab": {}
      },
      "source": [
        "Y_new10 = model.predict(x=X_new_merged)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O-GT9_eSUKQb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "1b9f033c-1459-4b83-a0d0-306bfed03ad4"
      },
      "source": [
        "Y_new10[:3] # results before softmax are shown"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.8813621e-01, 3.4839161e-02, 1.7492132e-02, 3.0435205e-03,\n",
              "        5.6489006e-02],\n",
              "       [8.5078202e-02, 1.2647440e-02, 8.9278609e-01, 6.2744338e-03,\n",
              "        3.2138061e-03],\n",
              "       [8.9990628e-01, 8.4698750e-03, 3.7087988e-02, 4.6848823e-04,\n",
              "        5.4067414e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "slNlTpzGUKQg",
        "colab": {}
      },
      "source": [
        "# pick the label with max score.\n",
        "flat_predictions = np.argmax(Y_new10, axis=1).flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YLwDX4NLUKQm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "63b29c49-8429-4706-aed5-d077eb815de7"
      },
      "source": [
        "flat_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 0, ..., 0, 2, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9sz-1-wsUKQr",
        "colab": {}
      },
      "source": [
        "test10 = pd.DataFrame(list(zip(test['id'], flat_predictions)), \n",
        "               columns = ['id', 'label'])\n",
        "test10\n",
        "test10.to_csv('test10.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMggRYvlq-5X",
        "colab_type": "text"
      },
      "source": [
        "#### With separate embeddings for titles and in/out references"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pR-2H_5Wvfel",
        "colab_type": "text"
      },
      "source": [
        "##### CNN 3 diff embeddings, kernel = 3, filters = 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tdt8GOjITzbQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "d3d3020d-f5fe-41b4-d850-9fdf45a50061"
      },
      "source": [
        "# with input_length2=50\n",
        "\n",
        "def custom_model(input_length=20, input_length2=50, vocab_size=13274, emb_dim = 100):\n",
        "  # define CNN layer\n",
        "  inputs1 = Input(shape=(input_length,))\n",
        "  emb1 = Embedding(vocab_size, emb_dim)(inputs1)\n",
        "  conv1 = Conv1D(filters=100, kernel_size=3, padding='same', activation='relu', strides=1)(emb1)\n",
        "  drop1 = Dropout(0.5)(conv1)\n",
        "  pool1 = GlobalMaxPooling1D()(drop1) # MaxOverTime\n",
        "  # pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
        "  flat1 = Flatten()(pool1)\n",
        "\n",
        "  inputs2 = Input(shape=(input_length2,))\n",
        "  emb2 = Embedding(vocab_size, emb_dim)(inputs2)\n",
        "  conv2 = Conv1D(filters=100, kernel_size=3, padding='same', activation='relu', strides=1)(emb2)\n",
        "  drop2 = Dropout(0.5)(conv2)\n",
        "  pool2 = GlobalMaxPooling1D()(drop2)\n",
        "  # pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
        "  flat2 = Flatten()(pool2)\n",
        "\n",
        "  inputs3 = Input(shape=(input_length2,))\n",
        "  emb3 = Embedding(vocab_size, emb_dim)(inputs3)\n",
        "  conv3 = Conv1D(filters=100, kernel_size=3, padding='same', activation='relu', strides=1)(emb3)\n",
        "  drop3 = Dropout(0.5)(conv3)\n",
        "  pool3 = GlobalMaxPooling1D()(drop3)\n",
        "  # pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
        "  flat3 = Flatten()(pool3)\n",
        "\n",
        "  # inputs4 = Input(shape=(input_length2,))\n",
        "\n",
        "  # merge CNN output with reference stats\n",
        "  # merged = concatenate([flat1, flat2, flat3, inputs4])\n",
        "  merged = concatenate([flat1, flat2, flat3])\n",
        "\n",
        "  dense1 = Dense(500, activation='relu')(merged)\n",
        "  outputs = Dense(5, activation=\"softmax\")(dense1)\n",
        "  model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs) # , inputs4\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  # print(model.summary())\n",
        "  # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "  return model\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "model = custom_model(input_length=20, input_length2=50, vocab_size=13274, emb_dim = 100)\n",
        "model.fit(x=[X_train_,X_to_train_,X_from_train_], y=Y_train_, validation_data = ([X_test_,X_to_test_,X_from_test_], Y_test_), batch_size=64, epochs=5) \n",
        "# save the model\n",
        "# model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/5\n",
            "10223/10223 [==============================] - 13s 1ms/sample - loss: 0.9312 - accuracy: 0.6447 - val_loss: 0.6852 - val_accuracy: 0.7723\n",
            "Epoch 2/5\n",
            "10223/10223 [==============================] - 12s 1ms/sample - loss: 0.4599 - accuracy: 0.8395 - val_loss: 0.5899 - val_accuracy: 0.7856\n",
            "Epoch 3/5\n",
            "10223/10223 [==============================] - 12s 1ms/sample - loss: 0.3224 - accuracy: 0.8849 - val_loss: 0.5524 - val_accuracy: 0.7985\n",
            "Epoch 4/5\n",
            "10223/10223 [==============================] - 12s 1ms/sample - loss: 0.2278 - accuracy: 0.9227 - val_loss: 0.5534 - val_accuracy: 0.7930\n",
            "Epoch 5/5\n",
            "10223/10223 [==============================] - 12s 1ms/sample - loss: 0.1532 - accuracy: 0.9498 - val_loss: 0.5866 - val_accuracy: 0.7879\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe477e2f128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdMz038Ux-Wu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "02feeb0e-ba13-4911-86d0-f5efc50737bc"
      },
      "source": [
        "# with input_length2=100\n",
        "\n",
        "def custom_model(input_length=20, input_length2=100, vocab_size=13274, emb_dim = 100):\n",
        "  # define CNN layer\n",
        "  inputs1 = Input(shape=(input_length,))\n",
        "  emb1 = Embedding(vocab_size, emb_dim)(inputs1)\n",
        "  conv1 = Conv1D(filters=100, kernel_size=3, padding='same', activation='relu', strides=1)(emb1)\n",
        "  drop1 = Dropout(0.5)(conv1)\n",
        "  pool1 = GlobalMaxPooling1D()(drop1) # MaxOverTime\n",
        "  # pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
        "  flat1 = Flatten()(pool1)\n",
        "\n",
        "  inputs2 = Input(shape=(input_length2,))\n",
        "  emb2 = Embedding(vocab_size, emb_dim)(inputs2)\n",
        "  conv2 = Conv1D(filters=100, kernel_size=3, padding='same', activation='relu', strides=1)(emb2)\n",
        "  drop2 = Dropout(0.5)(conv2)\n",
        "  pool2 = GlobalMaxPooling1D()(drop2)\n",
        "  # pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
        "  flat2 = Flatten()(pool2)\n",
        "\n",
        "  inputs3 = Input(shape=(input_length2,))\n",
        "  emb3 = Embedding(vocab_size, emb_dim)(inputs3)\n",
        "  conv3 = Conv1D(filters=100, kernel_size=3, padding='same', activation='relu', strides=1)(emb3)\n",
        "  drop3 = Dropout(0.5)(conv3)\n",
        "  pool3 = GlobalMaxPooling1D()(drop3)\n",
        "  # pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
        "  flat3 = Flatten()(pool3)\n",
        "\n",
        "  # inputs4 = Input(shape=(input_length2,))\n",
        "\n",
        "  # merge CNN output with reference stats\n",
        "  # merged = concatenate([flat1, flat2, flat3, inputs4])\n",
        "  merged = concatenate([flat1, flat2, flat3])\n",
        "\n",
        "  dense1 = Dense(500, activation='relu')(merged)\n",
        "  outputs = Dense(5, activation=\"softmax\")(dense1)\n",
        "  model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs) # , inputs4\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  # print(model.summary())\n",
        "  # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "  return model\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "model = custom_model(input_length=20, input_length2=100, vocab_size=13274, emb_dim = 100)\n",
        "model.fit(x=[X_train_,X_to_train_,X_from_train_], y=Y_train_, validation_data = ([X_test_,X_to_test_,X_from_test_], Y_test_), batch_size=64, epochs=5) \n",
        "# save the model\n",
        "# model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/5\n",
            "10223/10223 [==============================] - 20s 2ms/sample - loss: 0.9292 - accuracy: 0.6424 - val_loss: 0.6792 - val_accuracy: 0.7778\n",
            "Epoch 2/5\n",
            "10223/10223 [==============================] - 19s 2ms/sample - loss: 0.4591 - accuracy: 0.8376 - val_loss: 0.5857 - val_accuracy: 0.7907\n",
            "Epoch 3/5\n",
            "10223/10223 [==============================] - 19s 2ms/sample - loss: 0.3231 - accuracy: 0.8853 - val_loss: 0.5519 - val_accuracy: 0.8024\n",
            "Epoch 4/5\n",
            "10223/10223 [==============================] - 19s 2ms/sample - loss: 0.2321 - accuracy: 0.9202 - val_loss: 0.5557 - val_accuracy: 0.7919\n",
            "Epoch 5/5\n",
            "10223/10223 [==============================] - 19s 2ms/sample - loss: 0.1586 - accuracy: 0.9467 - val_loss: 0.5718 - val_accuracy: 0.7911\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe474dcd940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R93_6iZvv7mS",
        "colab_type": "text"
      },
      "source": [
        "#### With concatenated embeddings for titles and in/out references"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74qLDzQiuOUR",
        "colab_type": "text"
      },
      "source": [
        "##### Simple CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8jh7gHz5UIh2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "27811e8c-5f41-4b59-8d2d-aeaf8fd233af"
      },
      "source": [
        "# with input_length2=100\n",
        "\n",
        "def custom_model(input_length=20, input_length2=100, vocab_size=13274, emb_dim = 100):\n",
        "  # define CNN layer\n",
        "  inputs1 = Input(shape=(input_length,))\n",
        "  inputs2 = Input(shape=(input_length2,))\n",
        "  inputs3 = Input(shape=(input_length2,))\n",
        "  merged = concatenate([inputs1, inputs2, inputs3])\n",
        "\n",
        "  emb1 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  drop1 = Dropout(0.2)(emb1)\n",
        "  conv1 = Conv1D(filters=500, kernel_size=3, padding='same', activation='relu', strides=1)(drop1)\n",
        "  pool1 = GlobalMaxPooling1D()(conv1)\n",
        "  flat1 = Flatten()(pool1)\n",
        "\n",
        "  dense1 = Dense(250, activation='relu')(flat1)\n",
        "  outputs = Dense(5, activation=\"softmax\")(dense1)\n",
        "  model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
        "  # rmsprop = optimizers.RMSprop(lr=0.01)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "  # print(model.summary())\n",
        "  # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "  return model\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "# define model\n",
        "model = custom_model(input_length=20, input_length2=100,vocab_size=13273+1,emb_dim = 100)\n",
        "model.fit(x=[X_train_,X_to_train_,X_from_train_], y=Y_train_, validation_data = ([X_test_,X_to_test_,X_from_test_], Y_test_), batch_size=64, epochs=5) \n",
        "# save the model\n",
        "# model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/5\n",
            "10223/10223 [==============================] - 58s 6ms/sample - loss: 0.8964 - accuracy: 0.6669 - val_loss: 0.6232 - val_accuracy: 0.7801\n",
            "Epoch 2/5\n",
            "10223/10223 [==============================] - 57s 6ms/sample - loss: 0.4992 - accuracy: 0.8208 - val_loss: 0.5387 - val_accuracy: 0.8020\n",
            "Epoch 3/5\n",
            "10223/10223 [==============================] - 57s 6ms/sample - loss: 0.4001 - accuracy: 0.8571 - val_loss: 0.5487 - val_accuracy: 0.8056\n",
            "Epoch 4/5\n",
            "10223/10223 [==============================] - 57s 6ms/sample - loss: 0.3319 - accuracy: 0.8837 - val_loss: 0.5653 - val_accuracy: 0.7942\n",
            "Epoch 5/5\n",
            "10223/10223 [==============================] - 57s 6ms/sample - loss: 0.2720 - accuracy: 0.9064 - val_loss: 0.6137 - val_accuracy: 0.7829\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0b6ede8fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncUbj43I3s5D",
        "colab_type": "text"
      },
      "source": [
        "##### CNN with kernels=3,4,5 and 4,6,8, one concatenated embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I28LBJa30s6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "0928b9ed-d899-4c7e-fb44-43ef8d9d6d63"
      },
      "source": [
        "# with input_length2=50\n",
        "# kernels = 3,4,5\n",
        "\n",
        "def custom_model(input_length=20, input_length2=50, vocab_size=13274, emb_dim = 100):\n",
        "  # define CNN layer\n",
        "  inputs1 = Input(shape=(input_length,))\n",
        "  inputs2 = Input(shape=(input_length2,))\n",
        "  inputs3 = Input(shape=(input_length2,))\n",
        "  merged = concatenate([inputs1, inputs2, inputs3])\n",
        "\n",
        "  emb1 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  conv1 = Conv1D(filters=100, kernel_size=3, padding='same', activation='relu', strides=1)(emb1)\n",
        "  drop1 = Dropout(0.5)(conv1)\n",
        "  pool1 = GlobalMaxPooling1D()(drop1) # MaxOverTime\n",
        "  # pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
        "  flat1 = Flatten()(pool1)\n",
        "\n",
        "  emb2 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  conv2 = Conv1D(filters=100, kernel_size=4, padding='same', activation='relu', strides=1)(emb2)\n",
        "  drop2 = Dropout(0.5)(conv2)\n",
        "  pool2 = GlobalMaxPooling1D()(drop2)\n",
        "  # pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
        "  flat2 = Flatten()(pool2)\n",
        "\n",
        "  emb3 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  conv3 = Conv1D(filters=100, kernel_size=5, padding='same', activation='relu', strides=1)(emb3)\n",
        "  drop3 = Dropout(0.5)(conv3)\n",
        "  pool3 = GlobalMaxPooling1D()(drop3)\n",
        "  # pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
        "  flat3 = Flatten()(pool3)\n",
        "\n",
        "  # inputs4 = Input(shape=(input_length2,))\n",
        "\n",
        "  # merge CNN output with reference stats\n",
        "  # merged = concatenate([flat1, flat2, flat3, inputs4])\n",
        "  merged = concatenate([flat1, flat2, flat3])\n",
        "\n",
        "  dense1 = Dense(500, activation='relu')(merged)\n",
        "  outputs = Dense(5, activation=\"softmax\")(dense1)\n",
        "  model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs) # , inputs4\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  # print(model.summary())\n",
        "  # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "  return model\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "model = custom_model(input_length=20, input_length2=50, vocab_size=13274, emb_dim = 100)\n",
        "model.fit(x=[X_train_,X_to_train_,X_from_train_], y=Y_train_, validation_data = ([X_test_,X_to_test_,X_from_test_], Y_test_), batch_size=64, epochs=5) \n",
        "# save the model\n",
        "# model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/5\n",
            "10223/10223 [==============================] - 36s 3ms/sample - loss: 0.8285 - accuracy: 0.6928 - val_loss: 0.6628 - val_accuracy: 0.7962\n",
            "Epoch 2/5\n",
            "10223/10223 [==============================] - 34s 3ms/sample - loss: 0.4385 - accuracy: 0.8418 - val_loss: 0.5815 - val_accuracy: 0.8087\n",
            "Epoch 3/5\n",
            "10223/10223 [==============================] - 34s 3ms/sample - loss: 0.3254 - accuracy: 0.8831 - val_loss: 0.5563 - val_accuracy: 0.8052\n",
            "Epoch 4/5\n",
            "10223/10223 [==============================] - 34s 3ms/sample - loss: 0.2395 - accuracy: 0.9192 - val_loss: 0.5487 - val_accuracy: 0.8016\n",
            "Epoch 5/5\n",
            "10223/10223 [==============================] - 33s 3ms/sample - loss: 0.1728 - accuracy: 0.9401 - val_loss: 0.5854 - val_accuracy: 0.7856\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe4754bc208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Sil0aG15U7g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "78a32233-2172-47ed-9c98-b5da8a369b00"
      },
      "source": [
        "# with input_length2=50\n",
        "# kernels = 4,6,8\n",
        "\n",
        "def custom_model(input_length=20, input_length2=50, vocab_size=13274, emb_dim = 100):\n",
        "  # define CNN layer\n",
        "  inputs1 = Input(shape=(input_length,))\n",
        "  inputs2 = Input(shape=(input_length2,))\n",
        "  inputs3 = Input(shape=(input_length2,))\n",
        "  merged = concatenate([inputs1, inputs2, inputs3])\n",
        "\n",
        "  emb1 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  conv1 = Conv1D(filters=100, kernel_size=4, padding='same', activation='relu', strides=1)(emb1)\n",
        "  drop1 = Dropout(0.5)(conv1)\n",
        "  pool1 = GlobalMaxPooling1D()(drop1) # MaxOverTime\n",
        "  # pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
        "  flat1 = Flatten()(pool1)\n",
        "\n",
        "  emb2 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  conv2 = Conv1D(filters=100, kernel_size=6, padding='same', activation='relu', strides=1)(emb2)\n",
        "  drop2 = Dropout(0.5)(conv2)\n",
        "  pool2 = GlobalMaxPooling1D()(drop2)\n",
        "  # pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
        "  flat2 = Flatten()(pool2)\n",
        "\n",
        "  emb3 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  conv3 = Conv1D(filters=100, kernel_size=8, padding='same', activation='relu', strides=1)(emb3)\n",
        "  drop3 = Dropout(0.5)(conv3)\n",
        "  pool3 = GlobalMaxPooling1D()(drop3)\n",
        "  # pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
        "  flat3 = Flatten()(pool3)\n",
        "\n",
        "  # inputs4 = Input(shape=(input_length2,))\n",
        "\n",
        "  # merge CNN output with reference stats\n",
        "  # merged = concatenate([flat1, flat2, flat3, inputs4])\n",
        "  merged = concatenate([flat1, flat2, flat3])\n",
        "\n",
        "  dense1 = Dense(500, activation='relu')(merged)\n",
        "  outputs = Dense(5, activation=\"softmax\")(dense1)\n",
        "  model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs) # , inputs4\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  # print(model.summary())\n",
        "  # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "  return model\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "model = custom_model(input_length=20, input_length2=50, vocab_size=13274, emb_dim = 100)\n",
        "model.fit(x=[X_train_,X_to_train_,X_from_train_], y=Y_train_, validation_data = ([X_test_,X_to_test_,X_from_test_], Y_test_), batch_size=64, epochs=5) \n",
        "# save the model\n",
        "# model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/5\n",
            "10223/10223 [==============================] - 49s 5ms/sample - loss: 0.8278 - accuracy: 0.6905 - val_loss: 0.6520 - val_accuracy: 0.8020\n",
            "Epoch 2/5\n",
            "10223/10223 [==============================] - 48s 5ms/sample - loss: 0.4276 - accuracy: 0.8481 - val_loss: 0.5850 - val_accuracy: 0.8052\n",
            "Epoch 3/5\n",
            "10223/10223 [==============================] - 48s 5ms/sample - loss: 0.3084 - accuracy: 0.8895 - val_loss: 0.5558 - val_accuracy: 0.8048\n",
            "Epoch 4/5\n",
            "10223/10223 [==============================] - 48s 5ms/sample - loss: 0.2155 - accuracy: 0.9251 - val_loss: 0.5402 - val_accuracy: 0.8071\n",
            "Epoch 5/5\n",
            "10223/10223 [==============================] - 49s 5ms/sample - loss: 0.1491 - accuracy: 0.9523 - val_loss: 0.5986 - val_accuracy: 0.7833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe4751f2ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XdhkSm8R7Mnj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "979e91cf-7aa7-4907-da4a-d7cab777ae76"
      },
      "source": [
        "# with input_length2=100\n",
        "# kernels = 3,4,5\n",
        "\n",
        "def custom_model(input_length=20, input_length2=100, vocab_size=13274, emb_dim = 100):\n",
        "  # define CNN layer\n",
        "  inputs1 = Input(shape=(input_length,))\n",
        "  inputs2 = Input(shape=(input_length2,))\n",
        "  inputs3 = Input(shape=(input_length2,))\n",
        "  merged = concatenate([inputs1, inputs2, inputs3])\n",
        "\n",
        "  emb1 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  conv1 = Conv1D(filters=100, kernel_size=3, padding='same', activation='relu', strides=1)(emb1)\n",
        "  drop1 = Dropout(0.5)(conv1)\n",
        "  pool1 = GlobalMaxPooling1D()(drop1) # MaxOverTime\n",
        "  # pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
        "  flat1 = Flatten()(pool1)\n",
        "\n",
        "  emb2 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  conv2 = Conv1D(filters=100, kernel_size=4, padding='same', activation='relu', strides=1)(emb2)\n",
        "  drop2 = Dropout(0.5)(conv2)\n",
        "  pool2 = GlobalMaxPooling1D()(drop2)\n",
        "  # pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
        "  flat2 = Flatten()(pool2)\n",
        "\n",
        "  emb3 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  conv3 = Conv1D(filters=100, kernel_size=5, padding='same', activation='relu', strides=1)(emb3)\n",
        "  drop3 = Dropout(0.5)(conv3)\n",
        "  pool3 = GlobalMaxPooling1D()(drop3)\n",
        "  # pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
        "  flat3 = Flatten()(pool3)\n",
        "\n",
        "  # inputs4 = Input(shape=(input_length2,))\n",
        "\n",
        "  # merge CNN output with reference stats\n",
        "  # merged = concatenate([flat1, flat2, flat3, inputs4])\n",
        "  merged = concatenate([flat1, flat2, flat3])\n",
        "\n",
        "  dense1 = Dense(500, activation='relu')(merged)\n",
        "  outputs = Dense(5, activation=\"softmax\")(dense1)\n",
        "  model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs) # , inputs4\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  # print(model.summary())\n",
        "  # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "  return model\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "model = custom_model(input_length=20, input_length2=100, vocab_size=13274, emb_dim = 100)\n",
        "model.fit(x=[X_train_,X_to_train_,X_from_train_], y=Y_train_, validation_data = ([X_test_,X_to_test_,X_from_test_], Y_test_), batch_size=64, epochs=5) \n",
        "# save the model\n",
        "# model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/5\n",
            "10223/10223 [==============================] - 60s 6ms/sample - loss: 0.8250 - accuracy: 0.6939 - val_loss: 0.6545 - val_accuracy: 0.7938\n",
            "Epoch 2/5\n",
            "10223/10223 [==============================] - 59s 6ms/sample - loss: 0.4406 - accuracy: 0.8443 - val_loss: 0.5868 - val_accuracy: 0.7997\n",
            "Epoch 3/5\n",
            "10223/10223 [==============================] - 59s 6ms/sample - loss: 0.3247 - accuracy: 0.8862 - val_loss: 0.5493 - val_accuracy: 0.8083\n",
            "Epoch 4/5\n",
            "10223/10223 [==============================] - 59s 6ms/sample - loss: 0.2395 - accuracy: 0.9175 - val_loss: 0.5501 - val_accuracy: 0.7934\n",
            "Epoch 5/5\n",
            "10223/10223 [==============================] - 60s 6ms/sample - loss: 0.1683 - accuracy: 0.9396 - val_loss: 0.5480 - val_accuracy: 0.8005\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe473271d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3-5aHQEy7Mnu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "d77c86df-1ad4-4b85-de95-c2360842bbfa"
      },
      "source": [
        "# with input_length2=100\n",
        "# kernels = 4,6,8\n",
        "\n",
        "def custom_model(input_length=20, input_length2=100, vocab_size=13274, emb_dim = 100):\n",
        "  # define CNN layer\n",
        "  inputs1 = Input(shape=(input_length,))\n",
        "  inputs2 = Input(shape=(input_length2,))\n",
        "  inputs3 = Input(shape=(input_length2,))\n",
        "  merged = concatenate([inputs1, inputs2, inputs3])\n",
        "\n",
        "  emb1 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  conv1 = Conv1D(filters=100, kernel_size=4, padding='same', activation='relu', strides=1)(emb1)\n",
        "  drop1 = Dropout(0.5)(conv1)\n",
        "  pool1 = GlobalMaxPooling1D()(drop1) # MaxOverTime\n",
        "  # pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
        "  flat1 = Flatten()(pool1)\n",
        "\n",
        "  emb2 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  conv2 = Conv1D(filters=100, kernel_size=6, padding='same', activation='relu', strides=1)(emb2)\n",
        "  drop2 = Dropout(0.5)(conv2)\n",
        "  pool2 = GlobalMaxPooling1D()(drop2)\n",
        "  # pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
        "  flat2 = Flatten()(pool2)\n",
        "\n",
        "  emb3 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  conv3 = Conv1D(filters=100, kernel_size=8, padding='same', activation='relu', strides=1)(emb3)\n",
        "  drop3 = Dropout(0.5)(conv3)\n",
        "  pool3 = GlobalMaxPooling1D()(drop3)\n",
        "  # pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
        "  flat3 = Flatten()(pool3)\n",
        "\n",
        "  # inputs4 = Input(shape=(input_length2,))\n",
        "\n",
        "  # merge CNN output with reference stats\n",
        "  # merged = concatenate([flat1, flat2, flat3, inputs4])\n",
        "  merged = concatenate([flat1, flat2, flat3])\n",
        "\n",
        "  dense1 = Dense(500, activation='relu')(merged)\n",
        "  outputs = Dense(5, activation=\"softmax\")(dense1)\n",
        "  model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs) # , inputs4\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  # print(model.summary())\n",
        "  # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "  return model\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "model = custom_model(input_length=20, input_length2=100, vocab_size=13274, emb_dim = 100)\n",
        "model.fit(x=[X_train_,X_to_train_,X_from_train_], y=Y_train_, validation_data = ([X_test_,X_to_test_,X_from_test_], Y_test_), batch_size=64, epochs=3) \n",
        "# save the model\n",
        "# model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/3\n",
            "10223/10223 [==============================] - 83s 8ms/sample - loss: 0.8238 - accuracy: 0.6932 - val_loss: 0.6508 - val_accuracy: 0.8024\n",
            "Epoch 2/3\n",
            "10223/10223 [==============================] - 82s 8ms/sample - loss: 0.4227 - accuracy: 0.8481 - val_loss: 0.5830 - val_accuracy: 0.8013\n",
            "Epoch 3/3\n",
            "10223/10223 [==============================] - 82s 8ms/sample - loss: 0.3017 - accuracy: 0.8917 - val_loss: 0.5351 - val_accuracy: 0.8075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcc3c0d0438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z_7SPscJVwqi"
      },
      "source": [
        "###### Predict on test set for kaggle (11th upload) - 81.77%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TSf0M7vcVwqm",
        "colab": {}
      },
      "source": [
        "Y_new11 = model.predict(x=[X_new, X_new_to, X_new_from])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VCBmDI7nVwqu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "abd124bb-e1e3-4d25-fcda-95bcf65f90f7"
      },
      "source": [
        "Y_new11[:3] # results before softmax are shown"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7271129 , 0.17593327, 0.03700046, 0.03728134, 0.02267204],\n",
              "       [0.20437443, 0.06697048, 0.7124184 , 0.00811259, 0.00812415],\n",
              "       [0.82428205, 0.07986361, 0.07299255, 0.00736944, 0.01549236]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "no8d86D1Vwq1",
        "colab": {}
      },
      "source": [
        "# pick the label with max score.\n",
        "flat_predictions = np.argmax(Y_new11, axis=1).flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2X7Ix3cTVwq6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8aa0565e-2a18-4194-a32a-eb16d1120e13"
      },
      "source": [
        "flat_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 0, ..., 0, 2, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1MFaX-F3Vwq-",
        "colab": {}
      },
      "source": [
        "test11 = pd.DataFrame(list(zip(test['id'], flat_predictions)), \n",
        "               columns = ['id', 'label'])\n",
        "test11\n",
        "test11.to_csv('test11.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1zccWrch_gw",
        "colab_type": "text"
      },
      "source": [
        "##### Run model on the whole training data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rxdtFe-9iHv0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "c767b86c-ff9a-41de-8808-7ede2e93c0e3"
      },
      "source": [
        "# with input_length2=100\n",
        "# kernels = 4,6,8\n",
        "\n",
        "def custom_model(input_length=20, input_length2=100, vocab_size=13274, emb_dim = 100):\n",
        "  # define CNN layer\n",
        "  inputs1 = Input(shape=(input_length,))\n",
        "  inputs2 = Input(shape=(input_length2,))\n",
        "  inputs3 = Input(shape=(input_length2,))\n",
        "  merged = concatenate([inputs1, inputs2, inputs3])\n",
        "\n",
        "  emb1 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  conv1 = Conv1D(filters=100, kernel_size=4, padding='same', activation='relu', strides=1)(emb1)\n",
        "  drop1 = Dropout(0.5)(conv1)\n",
        "  pool1 = GlobalMaxPooling1D()(drop1) # MaxOverTime\n",
        "  # pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
        "  flat1 = Flatten()(pool1)\n",
        "\n",
        "  emb2 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  conv2 = Conv1D(filters=100, kernel_size=6, padding='same', activation='relu', strides=1)(emb2)\n",
        "  drop2 = Dropout(0.5)(conv2)\n",
        "  pool2 = GlobalMaxPooling1D()(drop2)\n",
        "  # pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
        "  flat2 = Flatten()(pool2)\n",
        "\n",
        "  emb3 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  conv3 = Conv1D(filters=100, kernel_size=8, padding='same', activation='relu', strides=1)(emb3)\n",
        "  drop3 = Dropout(0.5)(conv3)\n",
        "  pool3 = GlobalMaxPooling1D()(drop3)\n",
        "  # pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
        "  flat3 = Flatten()(pool3)\n",
        "\n",
        "  # inputs4 = Input(shape=(input_length2,))\n",
        "\n",
        "  # merge CNN output with reference stats\n",
        "  # merged = concatenate([flat1, flat2, flat3, inputs4])\n",
        "  merged = concatenate([flat1, flat2, flat3])\n",
        "\n",
        "  dense1 = Dense(500, activation='relu')(merged)\n",
        "  outputs = Dense(5, activation=\"softmax\")(dense1)\n",
        "  model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs) # , inputs4\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  # print(model.summary())\n",
        "  # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "  return model\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "model = custom_model(input_length=20, input_length2=100, vocab_size=13274, emb_dim = 100)\n",
        "model.fit(x=[X,X_to,X_from], y=Y, batch_size=64, epochs=3) \n",
        "# save the model\n",
        "# model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 12779 samples\n",
            "Epoch 1/3\n",
            "12779/12779 [==============================] - 98s 8ms/sample - loss: 0.7745 - accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "12779/12779 [==============================] - 97s 8ms/sample - loss: 0.4171 - accuracy: 0.8510\n",
            "Epoch 3/3\n",
            "12779/12779 [==============================] - 97s 8ms/sample - loss: 0.3121 - accuracy: 0.8891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb33cd0b048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sbGXe_ZYihcn"
      },
      "source": [
        "###### Predict on test set for kaggle (13th upload) - 82.1% on Kaggle.\n",
        "\n",
        "Using the whole training set for training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LaOg-hsUihcr",
        "colab": {}
      },
      "source": [
        "Y_new13 = model.predict(x=[X_new, X_new_to, X_new_from])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "usxy_GGAihcz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "33931e56-3210-40df-b01b-e9b079c9aa18"
      },
      "source": [
        "Y_new13[:3] # results before softmax are shown"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7490175 , 0.20132141, 0.02974566, 0.01197721, 0.00793809],\n",
              "       [0.28935567, 0.2452781 , 0.44919783, 0.00643598, 0.00973232],\n",
              "       [0.8710673 , 0.06758085, 0.04683995, 0.00284915, 0.01166281]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4tLMgaquihc4",
        "colab": {}
      },
      "source": [
        "# pick the label with max score.\n",
        "flat_predictions = np.argmax(Y_new13, axis=1).flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FZiVZalAihc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "184e195e-b521-4b93-c34a-b149a939ac30"
      },
      "source": [
        "flat_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 0, ..., 0, 2, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4rnsWxYmihdB",
        "colab": {}
      },
      "source": [
        "test13 = pd.DataFrame(list(zip(test['id'], flat_predictions)), \n",
        "               columns = ['id', 'label'])\n",
        "test13\n",
        "test13.to_csv('test13.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1Vra8fiJqQhJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "f31fb527-e80a-4b17-9e73-d461fd3b325b"
      },
      "source": [
        "# with input_length2=100\n",
        "# kernels = 4,6,8\n",
        "# dropout = 0.2\n",
        "\n",
        "def custom_model(input_length=20, input_length2=100, vocab_size=13274, emb_dim = 100):\n",
        "  # define CNN layer\n",
        "  inputs1 = Input(shape=(input_length,))\n",
        "  inputs2 = Input(shape=(input_length2,))\n",
        "  inputs3 = Input(shape=(input_length2,))\n",
        "  merged = concatenate([inputs1, inputs2, inputs3])\n",
        "\n",
        "  emb1 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  conv1 = Conv1D(filters=100, kernel_size=4, padding='same', activation='relu', strides=1)(emb1)\n",
        "  drop1 = Dropout(0.2)(conv1)\n",
        "  pool1 = GlobalMaxPooling1D()(drop1) # MaxOverTime\n",
        "  # pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
        "  flat1 = Flatten()(pool1)\n",
        "\n",
        "  emb2 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  conv2 = Conv1D(filters=100, kernel_size=6, padding='same', activation='relu', strides=1)(emb2)\n",
        "  drop2 = Dropout(0.2)(conv2)\n",
        "  pool2 = GlobalMaxPooling1D()(drop2)\n",
        "  # pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
        "  flat2 = Flatten()(pool2)\n",
        "\n",
        "  emb3 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  conv3 = Conv1D(filters=100, kernel_size=8, padding='same', activation='relu', strides=1)(emb3)\n",
        "  drop3 = Dropout(0.2)(conv3)\n",
        "  pool3 = GlobalMaxPooling1D()(drop3)\n",
        "  # pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
        "  flat3 = Flatten()(pool3)\n",
        "\n",
        "  # inputs4 = Input(shape=(input_length2,))\n",
        "\n",
        "  # merge CNN output with reference stats\n",
        "  # merged = concatenate([flat1, flat2, flat3, inputs4])\n",
        "  merged = concatenate([flat1, flat2, flat3])\n",
        "\n",
        "  dense1 = Dense(500, activation='relu')(merged)\n",
        "  outputs = Dense(5, activation=\"softmax\")(dense1)\n",
        "  model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs) # , inputs4\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "  # print(model.summary())\n",
        "  # plot_model(model, show_shapes=True, to_file='multichannel.png')\n",
        "  return model\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "model = custom_model(input_length=20, input_length2=100, vocab_size=13274, emb_dim = 100)\n",
        "model.fit(x=[X_train_,X_to_train_,X_from_train_], y=Y_train_, validation_data = ([X_test_,X_to_test_,X_from_test_], Y_test_), batch_size=64, epochs=5) \n",
        "# save the model\n",
        "# model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/5\n",
            "10223/10223 [==============================] - 83s 8ms/sample - loss: 0.8323 - accuracy: 0.6883 - val_loss: 0.5742 - val_accuracy: 0.8001\n",
            "Epoch 2/5\n",
            "10223/10223 [==============================] - 82s 8ms/sample - loss: 0.4077 - accuracy: 0.8543 - val_loss: 0.5367 - val_accuracy: 0.8009\n",
            "Epoch 3/5\n",
            "10223/10223 [==============================] - 82s 8ms/sample - loss: 0.2604 - accuracy: 0.9067 - val_loss: 0.5391 - val_accuracy: 0.8067\n",
            "Epoch 4/5\n",
            "10223/10223 [==============================] - 83s 8ms/sample - loss: 0.1516 - accuracy: 0.9488 - val_loss: 0.5800 - val_accuracy: 0.8024\n",
            "Epoch 5/5\n",
            "10223/10223 [==============================] - 82s 8ms/sample - loss: 0.0754 - accuracy: 0.9769 - val_loss: 0.7006 - val_accuracy: 0.7997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb332e1f390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sEtEutOuhXE",
        "colab_type": "text"
      },
      "source": [
        "##### LSTM\n",
        "\n",
        "Set RMSprop lr=0.01 otherwise convergence too slow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTbO2tRCTyRK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "a348e009-2985-47ff-9867-6b6a700e12be"
      },
      "source": [
        "# input_length2=50\n",
        "\n",
        "def custom_model(input_length=20, input_length2=50, vocab_size=13274, emb_dim = 128):\n",
        "  inputs1 = Input(shape=(input_length,))\n",
        "  inputs2 = Input(shape=(input_length2,))\n",
        "  inputs3 = Input(shape=(input_length2,))\n",
        "  merged = concatenate([inputs1, inputs2, inputs3])\n",
        "\n",
        "  emb1 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  lstm = LSTM(128, dropout=0.2)(emb1)\n",
        "  outputs = Dense(5, activation=\"softmax\")(lstm)\n",
        "  model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
        "  rmsprop = optimizers.RMSprop(lr=0.01)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  return model\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "model = custom_model(input_length=20,input_length2=50,vocab_size=13273+1,emb_dim = 128)\n",
        "model.fit(x=[X_train_,X_to_train_,X_from_train_], y=Y_train_, validation_data = ([X_test_,X_to_test_,X_from_test_], Y_test_), batch_size=64, epochs=5) \n",
        "# save the model\n",
        "# model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_14 (InputLayer)           [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_15 (InputLayer)           [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_4 (TensorFlo [(None, 120)]        0           input_13[0][0]                   \n",
            "                                                                 input_14[0][0]                   \n",
            "                                                                 input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_12 (Embedding)        (None, 120, 128)     1699072     tf_op_layer_concat_4[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 128)          131584      embedding_12[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 5)            645         lstm[0][0]                       \n",
            "==================================================================================================\n",
            "Total params: 1,831,301\n",
            "Trainable params: 1,831,301\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/5\n",
            "10223/10223 [==============================] - 55s 5ms/sample - loss: 1.2891 - accuracy: 0.4868 - val_loss: 1.1271 - val_accuracy: 0.5481\n",
            "Epoch 2/5\n",
            "10223/10223 [==============================] - 52s 5ms/sample - loss: 0.9754 - accuracy: 0.6138 - val_loss: 0.6409 - val_accuracy: 0.7703\n",
            "Epoch 3/5\n",
            "10223/10223 [==============================] - 53s 5ms/sample - loss: 0.5055 - accuracy: 0.8239 - val_loss: 0.5632 - val_accuracy: 0.8052\n",
            "Epoch 4/5\n",
            "10223/10223 [==============================] - 53s 5ms/sample - loss: 0.3666 - accuracy: 0.8741 - val_loss: 0.5675 - val_accuracy: 0.8013\n",
            "Epoch 5/5\n",
            "10223/10223 [==============================] - 54s 5ms/sample - loss: 0.2713 - accuracy: 0.9081 - val_loss: 0.6217 - val_accuracy: 0.7911\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe474999780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XwtmNoeDxoza",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "0717102b-3cc9-4049-f63e-e30e611cd13a"
      },
      "source": [
        "# input_length2=100\n",
        "\n",
        "def custom_model(input_length=20, input_length2=100, vocab_size=13274, emb_dim = 128):\n",
        "  inputs1 = Input(shape=(input_length,))\n",
        "  inputs2 = Input(shape=(input_length2,))\n",
        "  inputs3 = Input(shape=(input_length2,))\n",
        "  merged = concatenate([inputs1, inputs2, inputs3])\n",
        "\n",
        "  emb1 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  lstm = LSTM(128, dropout=0.2)(emb1)\n",
        "  outputs = Dense(5, activation=\"softmax\")(lstm)\n",
        "  model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
        "  rmsprop = optimizers.RMSprop(lr=0.01)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  return model\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "model = custom_model(input_length=20,input_length2=100,vocab_size=13273+1,emb_dim = 128)\n",
        "model.fit(x=[X_train_,X_to_train_,X_from_train_], y=Y_train_, validation_data = ([X_test_,X_to_test_,X_from_test_], Y_test_), batch_size=64, epochs=5) \n",
        "# save the model\n",
        "# model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_18\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_62 (InputLayer)           [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_63 (InputLayer)           [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_64 (InputLayer)           [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_25 (TensorFl [(None, 220)]        0           input_62[0][0]                   \n",
            "                                                                 input_63[0][0]                   \n",
            "                                                                 input_64[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_53 (Embedding)        (None, 220, 128)     1699072     tf_op_layer_concat_25[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lstm_9 (LSTM)                   (None, 128)          131584      embedding_53[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_58 (Dense)                (None, 5)            645         lstm_9[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,831,301\n",
            "Trainable params: 1,831,301\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/5\n",
            "10223/10223 [==============================] - 95s 9ms/sample - loss: 1.4771 - accuracy: 0.3718 - val_loss: 1.2271 - val_accuracy: 0.5110\n",
            "Epoch 2/5\n",
            "10223/10223 [==============================] - 93s 9ms/sample - loss: 1.0790 - accuracy: 0.5671 - val_loss: 1.1313 - val_accuracy: 0.5450\n",
            "Epoch 3/5\n",
            "10223/10223 [==============================] - 93s 9ms/sample - loss: 0.9407 - accuracy: 0.6201 - val_loss: 0.9443 - val_accuracy: 0.5775\n",
            "Epoch 4/5\n",
            "10223/10223 [==============================] - 94s 9ms/sample - loss: 0.5393 - accuracy: 0.7987 - val_loss: 0.5960 - val_accuracy: 0.7903\n",
            "Epoch 5/5\n",
            "10223/10223 [==============================] - 93s 9ms/sample - loss: 0.3596 - accuracy: 0.8751 - val_loss: 0.6279 - val_accuracy: 0.7903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe473a487b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTLYYPX90rDh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "outputId": "a12b8cfc-dd4f-4c5d-900c-fdf89a291930"
      },
      "source": [
        "# input_length2=50, 2 hidden layers\n",
        "\n",
        "def custom_model(input_length=20, input_length2=50, vocab_size=13274, emb_dim = 128):\n",
        "  inputs1 = Input(shape=(input_length,))\n",
        "  inputs2 = Input(shape=(input_length2,))\n",
        "  inputs3 = Input(shape=(input_length2,))\n",
        "  merged = concatenate([inputs1, inputs2, inputs3])\n",
        "\n",
        "  emb1 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  lstm = LSTM(128, dropout=0.2,return_sequences=True)(emb1)\n",
        "  lstm2 = LSTM(128, dropout=0.2)(lstm)\n",
        "  outputs = Dense(5, activation=\"softmax\")(lstm2)\n",
        "  model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
        "  rmsprop = optimizers.RMSprop(lr=0.01)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  return model\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "model = custom_model(input_length=20,input_length2=50,vocab_size=13273+1,emb_dim = 128)\n",
        "model.fit(x=[X_train_,X_to_train_,X_from_train_], y=Y_train_, validation_data = ([X_test_,X_to_test_,X_from_test_], Y_test_), batch_size=64, epochs=5) \n",
        "# save the model\n",
        "# model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_31 (InputLayer)           [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_32 (InputLayer)           [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_33 (InputLayer)           [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_10 (TensorFl [(None, 120)]        0           input_31[0][0]                   \n",
            "                                                                 input_32[0][0]                   \n",
            "                                                                 input_33[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_24 (Embedding)        (None, 120, 128)     1699072     tf_op_layer_concat_10[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   (None, 120, 128)     131584      embedding_24[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   (None, 128)          131584      lstm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_32 (Dense)                (None, 5)            645         lstm_5[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 1,962,885\n",
            "Trainable params: 1,962,885\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/5\n",
            "10223/10223 [==============================] - 106s 10ms/sample - loss: 1.5889 - accuracy: 0.2693 - val_loss: 1.3288 - val_accuracy: 0.4296\n",
            "Epoch 2/5\n",
            "10223/10223 [==============================] - 104s 10ms/sample - loss: 1.1425 - accuracy: 0.5311 - val_loss: 0.9034 - val_accuracy: 0.6510\n",
            "Epoch 3/5\n",
            "10223/10223 [==============================] - 103s 10ms/sample - loss: 0.6703 - accuracy: 0.7564 - val_loss: 0.6468 - val_accuracy: 0.7688\n",
            "Epoch 4/5\n",
            "10223/10223 [==============================] - 103s 10ms/sample - loss: 0.5136 - accuracy: 0.8257 - val_loss: 0.7035 - val_accuracy: 0.7629\n",
            "Epoch 5/5\n",
            "10223/10223 [==============================] - 103s 10ms/sample - loss: 0.4252 - accuracy: 0.8562 - val_loss: 0.6036 - val_accuracy: 0.7864\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe476792748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNQTgCGYxij4",
        "colab_type": "text"
      },
      "source": [
        "##### Bi-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz0D_S6YwLx0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "26d41c4b-fdf8-41cd-d561-6cfb58dc11d1"
      },
      "source": [
        "# input_length2=50\n",
        "\n",
        "def custom_model(input_length=20, input_length2=50, vocab_size=13274, emb_dim = 128):\n",
        "  inputs1 = Input(shape=(input_length,))\n",
        "  inputs2 = Input(shape=(input_length2,))\n",
        "  inputs3 = Input(shape=(input_length2,))\n",
        "  merged = concatenate([inputs1, inputs2, inputs3])\n",
        "\n",
        "  emb1 = Embedding(vocab_size, emb_dim)(merged)\n",
        "  lstm = Bidirectional(LSTM(128, dropout=0.2))(emb1)\n",
        "  outputs = Dense(5, activation=\"softmax\")(lstm)\n",
        "  model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
        "  rmsprop = optimizers.RMSprop(lr=0.01)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  return model\n",
        "\n",
        "np.random.seed(5)\n",
        "random.seed(5)\n",
        "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,\n",
        "                              inter_op_parallelism_threads=1)\n",
        "tf.compat.v1.set_random_seed(5)\n",
        "\n",
        "model = custom_model(input_length=20,input_length2=50,vocab_size=13273+1,emb_dim = 128)\n",
        "model.fit(x=[X_train_,X_to_train_,X_from_train_], y=Y_train_, validation_data = ([X_test_,X_to_test_,X_from_test_], Y_test_), batch_size=64, epochs=5) \n",
        "# save the model\n",
        "# model.save('model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_25 (InputLayer)           [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_26 (InputLayer)           [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_27 (InputLayer)           [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_8 (TensorFlo [(None, 120)]        0           input_25[0][0]                   \n",
            "                                                                 input_26[0][0]                   \n",
            "                                                                 input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_22 (Embedding)        (None, 120, 128)     1699072     tf_op_layer_concat_8[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 256)          263168      embedding_22[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_31 (Dense)                (None, 5)            1285        bidirectional[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 1,963,525\n",
            "Trainable params: 1,963,525\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 10223 samples, validate on 2556 samples\n",
            "Epoch 1/5\n",
            "10223/10223 [==============================] - 105s 10ms/sample - loss: 1.3186 - accuracy: 0.4697 - val_loss: 1.1504 - val_accuracy: 0.5469\n",
            "Epoch 2/5\n",
            "10223/10223 [==============================] - 102s 10ms/sample - loss: 0.6742 - accuracy: 0.7521 - val_loss: 0.5626 - val_accuracy: 0.7969\n",
            "Epoch 3/5\n",
            "10223/10223 [==============================] - 102s 10ms/sample - loss: 0.4230 - accuracy: 0.8569 - val_loss: 0.5942 - val_accuracy: 0.7969\n",
            "Epoch 4/5\n",
            "10223/10223 [==============================] - 101s 10ms/sample - loss: 0.3110 - accuracy: 0.8946 - val_loss: 0.6282 - val_accuracy: 0.7926\n",
            "Epoch 5/5\n",
            "10223/10223 [==============================] - 100s 10ms/sample - loss: 0.2282 - accuracy: 0.9253 - val_loss: 0.6200 - val_accuracy: 0.7958\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe478492f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    }
  ]
}